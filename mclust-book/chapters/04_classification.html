<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>4&nbsp; Mixture-Based Classification – Model-Based Clustering, Classification, and Density Estimation 
Using mclust in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/05_dens.html" rel="next">
<link href="../chapters/03_cluster.html" rel="prev">
<link href="../images/cover.jpg" rel="icon" type="image/jpeg">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/04_classification.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Mixture-Based Classification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Model-Based Clustering, Classification, and Density Estimation Using mclust in R</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/00_preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02_mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Finite Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03_cluster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model-Based Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04_classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Mixture-Based Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05_dens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Model-Based Density Estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06_graphics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Visualizing Gaussian Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07_miscellanea.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Miscellanea</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/99_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#classification-as-supervised-learning" id="toc-classification-as-supervised-learning" class="nav-link active" data-scroll-target="#classification-as-supervised-learning"><span class="header-section-number">4.1</span> Classification as Supervised Learning</a></li>
  <li>
<a href="#sec-gaussmixmodclas" id="toc-sec-gaussmixmodclas" class="nav-link" data-scroll-target="#sec-gaussmixmodclas"><span class="header-section-number">4.2</span> Gaussian Mixture Models for Classification</a>
  <ul class="collapse">
<li><a href="#prediction" id="toc-prediction" class="nav-link" data-scroll-target="#prediction"><span class="header-section-number">4.2.1</span> Prediction</a></li>
  <li><a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation"><span class="header-section-number">4.2.2</span> Estimation</a></li>
  </ul>
</li>
  <li><a href="#sec-mclustclass" id="toc-sec-mclustclass" class="nav-link" data-scroll-target="#sec-mclustclass"><span class="header-section-number">4.3</span> Classification in mclust</a></li>
  <li>
<a href="#sec-evalclassifier" id="toc-sec-evalclassifier" class="nav-link" data-scroll-target="#sec-evalclassifier"><span class="header-section-number">4.4</span> Evaluating Classifier Performance</a>
  <ul class="collapse">
<li><a href="#evaluating-predicted-classes-classification-error" id="toc-evaluating-predicted-classes-classification-error" class="nav-link" data-scroll-target="#evaluating-predicted-classes-classification-error"><span class="header-section-number">4.4.1</span> Evaluating Predicted Classes: Classification Error</a></li>
  <li><a href="#evaluating-class-probabilities-brier-score" id="toc-evaluating-class-probabilities-brier-score" class="nav-link" data-scroll-target="#evaluating-class-probabilities-brier-score"><span class="header-section-number">4.4.2</span> Evaluating Class Probabilities: Brier Score</a></li>
  <li><a href="#sec-classif_performance" id="toc-sec-classif_performance" class="nav-link" data-scroll-target="#sec-classif_performance"><span class="header-section-number">4.4.3</span> Estimating Classifier Performance: Test Set and Resampling-Based Validation</a></li>
  <li><a href="#sec-crossvalidation" id="toc-sec-crossvalidation" class="nav-link" data-scroll-target="#sec-crossvalidation"><span class="header-section-number">4.4.4</span> Cross-Validation in mclust</a></li>
  </ul>
</li>
  <li><a href="#sec-misclascosts" id="toc-sec-misclascosts" class="nav-link" data-scroll-target="#sec-misclascosts"><span class="header-section-number">4.5</span> Classification with Unequal Costs of Misclassification</a></li>
  <li><a href="#sec-imbalclass" id="toc-sec-imbalclass" class="nav-link" data-scroll-target="#sec-imbalclass"><span class="header-section-number">4.6</span> Classification with Unbalanced Classes</a></li>
  <li><a href="#sec-classonedim" id="toc-sec-classonedim" class="nav-link" data-scroll-target="#sec-classonedim"><span class="header-section-number">4.7</span> Classification of Univariate Data</a></li>
  <li><a href="#sec-ssc" id="toc-sec-ssc" class="nav-link" data-scroll-target="#sec-ssc"><span class="header-section-number">4.8</span> Semi-Supervised Classification</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-classif" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Mixture-Based Classification</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="hidden">
<p><span class="math display">\[
\DeclareMathOperator{\Real}{\mathbb{R}}
\DeclareMathOperator{\Proj}{\text{P}}
\DeclareMathOperator{\Exp}{\text{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\var}{\text{var}}
\DeclareMathOperator{\sd}{\text{sd}}
\DeclareMathOperator{\cov}{\text{cov}}
\DeclareMathOperator{\cor}{\text{cor}}
\DeclareMathOperator{\range}{\text{range}}
\DeclareMathOperator{\rank}{\text{rank}}
\DeclareMathOperator{\ind}{\perp\hspace*{-1.1ex}\perp}
\DeclareMathOperator{\CE}{\text{CE}}
\DeclareMathOperator{\BS}{\text{BS}}
\DeclareMathOperator{\ECM}{\text{ECM}}
\DeclareMathOperator{\BSS}{\text{BSS}}
\DeclareMathOperator{\WSS}{\text{WSS}}
\DeclareMathOperator{\TSS}{\text{TSS}}
\DeclareMathOperator{\BIC}{\text{BIC}}
\DeclareMathOperator{\ICL}{\text{ICL}}
\DeclareMathOperator{\CV}{\text{CV}}
\DeclareMathOperator{\diag}{\text{diag}}
\DeclareMathOperator{\se}{\text{se}}
\DeclareMathOperator{\Cov}{\text{Cov}}
\DeclareMathOperator{\boot}{\text{boot}}
\DeclareMathOperator{\LRTS}{\text{LRTS}}
\DeclareMathOperator{\Model}{\mathcal{M}}
\DeclareMathOperator*{\argmin}{arg\min}
\DeclareMathOperator*{\argmax}{arg\max}
\DeclareMathOperator{\vech}{vech}
\DeclareMathOperator{\tr}{tr}
\]</span></p>
<!-- \definecolor{quarto-callout-note-color}{HTML}{4477AA} -->
</div>
<p>Classification is an instance of supervised learning, where the class of each observation is known. Unlike in the unsupervised case, the main objective here is to build a classifier for classifying future observations. This chapter describes probabilistic classification following a mixture-based approach. It describes various Gaussian mixture models for supervised learning. The implementation available in <strong>mclust</strong> is presented using several data analysis examples. Different ways of assessing classifier performance are also discussed. The problem of unequal costs of misclassification and the classification with unbalanced classes is presented, followed by solutions implemented in <strong>mclust</strong>. The chapter concludes with an introduction to the semi-supervised classification problems, in which only some of the training data have known labels.</p>
<section id="classification-as-supervised-learning" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="classification-as-supervised-learning">
<span class="header-section-number">4.1</span> Classification as Supervised Learning</h2>
<p><a href="03_cluster.html" class="quarto-xref"><span>Chapter 3</span></a> discussed methods for clustering, an instance of <em>unsupervised learning</em>. There the main goal was to identify the presence of groups of homogeneous observations based on the measurements available for a set of variables or features. This chapter deals with the <em>supervised learning</em> <!-- \index{supervised learning}  --> problem, where the classification of each observation is known. In this case, the main objective is to build a classifier (or decision rule) for classifying future observations from the available data <span class="citation" data-cites="Bishop:2006 Hastie:Tibshirani:Friedman:2009 Alpaydin:2014">(<a href="99_references.html#ref-Bishop:2006" role="doc-biblioref">Bishop 2006</a>; <a href="99_references.html#ref-Hastie:Tibshirani:Friedman:2009" role="doc-biblioref">T. Hastie, Tibshirani, and Friedman 2009</a>; <a href="99_references.html#ref-Alpaydin:2014" role="doc-biblioref">Alpaydin 2014</a>)</span>. This task is also known by various other names, such as <em>statistical pattern recognition</em> or <em>discriminant analysis</em> <span class="citation" data-cites="McLachlan:2004">(<a href="99_references.html#ref-McLachlan:2004" role="doc-biblioref">G. McLachlan 2004</a>)</span>.</p>
<p>In the probabilistic approach to classification, a statistical model is estimated to predict the class <span class="math inline">\(C_k\)</span> for <span class="math inline">\(k=1, \dots, K\)</span> of a given observation with feature vector <span class="math inline">\(\boldsymbol{x}\)</span>. This model provides a <em>posterior class probability</em> <!-- \index{posterior class probability}  --> <span class="math inline">\(\Pr(C_k|\boldsymbol{x})\)</span> for each class, which can then be used to determine the class membership for new observations. Some modeling methods directly estimate posterior probabilities by constructing, or <em>learning</em>, a discriminant function <span class="math inline">\(\eta_k(\boldsymbol{x}) = \Pr(C_k|\boldsymbol{x})\)</span> that maps the features <span class="math inline">\(\boldsymbol{x}\)</span> directly onto a class <span class="math inline">\(C_k\)</span>. These are called <em>discriminative models</em>, <!-- \index{supervised learning!discriminative models} --> of which a popular instance is the logistic regression model for binary-class problems.</p>
<p>Other approaches try to explicitly or implicitly model the distribution of features as well as classes, and then obtain the posterior probabilities using Bayes’ theorem. Thus, by learning the class-conditional densities <span class="math inline">\(f(\boldsymbol{x}|C_k)\)</span> and the prior class probabilities <span class="math inline">\(\Pr(C_k)\)</span> for each class <span class="math inline">\(C_k\)</span> (<span class="math inline">\(k=1, \dots, K\)</span>), the posterior class probabilities are given by% can be found as <span class="math display">\[
\Pr(C_k|\boldsymbol{x}) = \frac{f(\boldsymbol{x}|C_k) \Pr(C_k)}{\displaystyle\sum_{g=1}^K f(\boldsymbol{x}|C_g) \Pr(C_g)} .
\]</span> Methods that follow this approach, such as those based on finite mixture modeling, are called <em>generative models</em>. <!-- \index{supervised learning!generative models} --></p>
<p>Typically, classification models are estimated using the information from a <em>training set</em>, meaning a dataset used for learning or fitting the model in order to obtain parameter estimates. The same dataset, if used also for model tuning such as hyperparameter estimation or feature selection and for evaluating the classifier, tends to produce an optimistic assessment of performance. This phenomenon is called <em>overfitting</em>, <!-- \index{overfitting} --> meaning that there is a risk of fitting a model that too closely corresponds to a particular set of data, and therefore may fail to fit additional data or predict future observations well. For these reasons, it is advisable to perform model tuning using a <em>validation set</em>, a dataset designed for this purpose and usually set aside from the original dataset. An alternative is to repeatedly split into a training set and a validation set using resampling approaches, such as <em>cross-validation</em>, to be discussed in <a href="#sec-classif_performance" class="quarto-xref"><span>Section 4.4.3</span></a>. Another subset of the original dataset is also set aside in advance as a <em>test set</em> for the final evaluation of the classifier.</p>
</section><section id="sec-gaussmixmodclas" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="sec-gaussmixmodclas">
<span class="header-section-number">4.2</span> Gaussian Mixture Models for Classification</h2>
<p>Consider a training dataset <span class="math inline">\(\mathcal{D}_\text{train}= \{(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_n, y_n)\}\)</span> for which both the feature vectors <span class="math inline">\(\boldsymbol{x}_i\)</span> and the true classes <span class="math inline">\(y_i \in \{C_1, \dots, C_K\}\)</span> are known. Each observation has an associated class label <span class="math inline">\(C_k\)</span>.</p>
<p>Mixture-based classification models typically assume that the density within each class follows a Gaussian mixture distribution: <span id="eq-mixgaussclass"><span class="math display">\[
f(\boldsymbol{x}|C_k) = \sum_{g=1}^{G_k} \pi_{g,k} \phi(\boldsymbol{x}; \boldsymbol{\mu}_{g,k}, \boldsymbol{\Sigma}_{g,k}),
\tag{4.1}\]</span></span> where <span class="math inline">\(G_k\)</span> is the number of components within class <span class="math inline">\(k\)</span>, <span class="math inline">\(\pi_{g,k}\)</span> are the mixing probabilities for class <span class="math inline">\(k\)</span> (<span class="math inline">\(\pi_{g,k} &gt; 0\)</span> and <span class="math inline">\(\sum_{g=1}^{G_k}\pi_{g,k}=1\)</span>), and <span class="math inline">\(\boldsymbol{\mu}_{g,k}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{g,k}\)</span> are, respectively, the mean vectors and the covariance matrices for component <span class="math inline">\(g\)</span> within class <span class="math inline">\(k\)</span>.</p>
<p><span class="citation" data-cites="Hastie:Tibshirani:1996">Trevor Hastie and Tibshirani (<a href="99_references.html#ref-Hastie:Tibshirani:1996" role="doc-biblioref">1996</a>)</span> proposed the <em>Mixture Discriminant Analysis</em> (MDA) <!-- \index{mixture discriminant analysis (MDA)}  --> model where it is assumed that the covariance matrix is the same for all classes but is otherwise unconstrained (<span class="math inline">\(\boldsymbol{\Sigma}_{gk} = \boldsymbol{\Sigma}\)</span> for all <span class="math inline">\(g=1,\dots,G_k\)</span> and <span class="math inline">\(k=1,\dots,K\)</span> in <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a>). Moreover, the number of mixture components is the same for each class and assumed known.</p>
<p><span class="citation" data-cites="Bensmail:Celeux:1996">Bensmail and Celeux (<a href="99_references.html#ref-Bensmail:Celeux:1996" role="doc-biblioref">1996</a>)</span> proposed the <em>Eigenvalue Decomposition Discriminant Analysis</em> (EDDA) <!-- \index{eigenvalue discriminant analysis (EDDA)}  --> model which assumes that the density for each class can be described by a single Gaussian component (<span class="math inline">\(G_k=1\)</span> for all <span class="math inline">\(k\)</span> in <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a>), with the class covariance structure factorized as <span class="math display">\[
\boldsymbol{\Sigma}_{k} = \lambda_k\boldsymbol{U}_k\boldsymbol{\Delta}_k\boldsymbol{U}{}^{\!\top}_k.
\]</span></p>
<p>As for GMM clustering, several classification models can be obtained from the above decomposition. If each component has the same covariance matrix (<span class="math inline">\(\boldsymbol{\Sigma}_{k} = \lambda\boldsymbol{U}\boldsymbol{\Delta}\boldsymbol{U}{}^{\!\top}\)</span> — model <code>EEE</code> in <a href="02_mixture.html#tbl-covar_param" class="quarto-xref">Table&nbsp;<span>2.1</span></a>), then EDDA is equivalent to the classical <em>Linear Discriminant Analysis</em> (LDA) model. If the component covariance matrices are unconstrained and vary between components (<span class="math inline">\(\boldsymbol{\Sigma}_{k} = \lambda_k\boldsymbol{U}_k\boldsymbol{\Delta}_k\boldsymbol{U}{}^{\!\top}_k\)</span> — model <code>VVV</code> in <a href="02_mixture.html#tbl-covar_param" class="quarto-xref">Table&nbsp;<span>2.1</span></a>), then EDDA is equivalent to the <em>Quadratic Discriminant Analysis</em> (QDA) model. Finally, by assuming conditional independence of features within each class (models with coordinate axes orientation, denoted by <code>**I</code> in <a href="02_mixture.html#tbl-covar_param" class="quarto-xref">Table&nbsp;<span>2.1</span></a>), the <em>Naïve-Bayes</em> models are obtained.</p>
<p>The most general model from <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> is the <em>MclustDA</em> <!-- \index{MclustDA}  --> model proposed by <span class="citation" data-cites="Fraley:Raftery:2002">Fraley and Raftery (<a href="99_references.html#ref-Fraley:Raftery:2002" role="doc-biblioref">2002</a>)</span>, which uses a finite mixture of Gaussian distributions within each class, in which the number of components and covariance matrix (parameterized by the eigen-decomposition described in <a href="02_mixture.html#sec-eigendecomp" class="quarto-xref"><span>Section 2.2.1</span></a>) may differ among classes.</p>
<section id="prediction" class="level3" data-number="4.2.1"><h3 data-number="4.2.1" class="anchored" data-anchor-id="prediction">
<span class="header-section-number">4.2.1</span> Prediction</h3>
<p>Let <span class="math inline">\(\tau_k\)</span> be the class prior probability that an observation <span class="math inline">\(\boldsymbol{x}\)</span> comes from class <span class="math inline">\(C_k\)</span> (<span class="math inline">\(k=1,\dots,K\)</span>). By Bayes’ theorem we can compute the posterior probability that an observation <span class="math inline">\(\boldsymbol{x}\)</span> belongs to class <span class="math inline">\(C_k\)</span> as <span id="eq-classpostprob"><span class="math display">\[
\Pr(C_k | \boldsymbol{x}) = \frac{\tau_k f(\boldsymbol{x}| C_k)}{\displaystyle\sum_{j=1}^K \tau_{j} f(\boldsymbol{x}| C_{j})},
\tag{4.2}\]</span></span> where <span class="math inline">\(f(\boldsymbol{x}|C_k)\)</span> is the probability density function in <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> specific to class <span class="math inline">\(C_k\)</span>. As discussed earlier, this density depends on the assumed model for within-class distributions.</p>
<p>Thus an observation <span class="math inline">\(\boldsymbol{x}\)</span> can be classified according to the maximum a posteriori (MAP) rule to the class which has the highest posterior probability: <span id="eq-classmap"><span class="math display">\[
y = \{ C_{\widehat{k}} \}
\qquad\text{where}\quad
\widehat{k} = \argmax_{k} \Pr(C_k | \boldsymbol{x}) \propto \tau_k f(\boldsymbol{x}| C_k),
\tag{4.3}\]</span></span> where the right-hand side follows by noting that the denominator in <a href="#eq-classpostprob" class="quarto-xref">Equation&nbsp;<span>4.2</span></a> is just a constant of normalization. This rule minimizes the expected misclassification rate and is known as the <em>Bayes classifier</em>. <!-- \index{Bayes classifier} --></p>
</section><section id="estimation" class="level3" data-number="4.2.2"><h3 data-number="4.2.2" class="anchored" data-anchor-id="estimation">
<span class="header-section-number">4.2.2</span> Estimation</h3>
<p>The parameters of the model in <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> can be estimated from the training dataset by maximum likelihood. In particular, for the EDDA model the parameters can be obtained with a single M-step from the EM algorithm for Gaussian mixtures described in <a href="02_mixture.html#sec-EM_GMM" class="quarto-xref"><span>Section 2.2.2</span></a>, with <span class="math inline">\(z_{ik}\)</span> set to <span class="math inline">\(1\)</span> if observation <span class="math inline">\(i\)</span> belongs to class <span class="math inline">\(k\)</span> and <span class="math inline">\(0\)</span> otherwise. For the general MclustDA model, as well as for MDA, a Gaussian mixture model can be estimated separately for each class using the EM algorithm, and parameters cannot be constrained across classes.</p>
<p>For the class prior probabilities, if the training data have been obtained by random sampling from the underlying population, the mixing proportions <span class="math inline">\(\tau_k\)</span> can be simply estimated by the sample proportions <span class="math inline">\(n_k/n\)</span>, where <span class="math inline">\(n_k\)</span> denotes the number of observations known to belong to class <span class="math inline">\(k\)</span> and <span class="math inline">\(n = \sum_{k=1}^K n_k\)</span> is the number of observations in the training set. However, there are instances in which different values have to be assigned to the prior probabilities for the classes.<br>
This includes cases where the cost of misclassification may differ depending on the affected classes, and cases where classes have very different numbers of members. These issues are further discussed in <a href="#sec-imbalclass" class="quarto-xref"><span>Section 4.6</span></a> and <a href="#sec-misclascosts" class="quarto-xref"><span>Section 4.5</span></a>, respectively.</p>
</section></section><section id="sec-mclustclass" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="sec-mclustclass">
<span class="header-section-number">4.3</span> Classification in mclust</h2>
<p>The main function available in <strong>mclust</strong> for classification tasks is <code>MclustDA()</code>, <!-- \index{mclust!\code{MclustDA()}} --> which requires a data frame or a matrix for the training data (<code>data</code>) and the corresponding vector of class labels (<code>class</code>). The type of mixture model to be fitted is specified by the argument <code>modelType</code>, a string that can take the values <code>"MclustDA"</code> (default) or <code>"EDDA"</code>.</p>
<div id="exm-wdbc" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.1</strong></span> &nbsp;&nbsp;<strong>Classification of Wisconsin diagnostic breast cancer data</strong></p>
<p>Consider a dataset of measurements for 569 patients on 30 features of the cell nuclei obtained from a digitized image of a fine needle aspirate (FNA) of a breast mass [<span class="citation" data-cites="Street:etal:1993">Street, Wolberg, and Mangasarian (<a href="99_references.html#ref-Street:etal:1993" role="doc-biblioref">1993</a>)</span>; Mangasarian:etal:1995], available as one of several contributions to the “Breast Cancer Wisconsin (Diagnostic) Data Set” of the UCI Machine Learning Repository <span class="citation" data-cites="UCI:dataset">(<a href="99_references.html#ref-UCI:dataset" role="doc-biblioref">Dua and Graff 2017</a>)</span>. For each patient, the mass was diagnosed as either malignant or benign. This data can be obtained in <strong>mclust</strong> via the <code>data</code> command under the name <code>wdbc</code>. Following <span class="citation" data-cites="Mangasarian:etal:1995">Mangasarian, Street, and Wolberg (<a href="99_references.html#ref-Mangasarian:etal:1995" role="doc-biblioref">1995</a>)</span> and <span class="citation" data-cites="Fraley:Raftery:2002">Fraley and Raftery (<a href="99_references.html#ref-Fraley:Raftery:2002" role="doc-biblioref">2002</a>)</span>,we consider only three attributes in the following analysis: extreme area, extreme smoothness, and mean texture.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"wdbc"</span>, package <span class="op">=</span> <span class="st">"mclust"</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="va">wdbc</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Texture_mean"</span>, <span class="st">"Area_extreme"</span>, <span class="st">"Smoothness_extreme"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">Class</span> <span class="op">=</span> <span class="va">wdbc</span><span class="op">[</span>, <span class="st">"Diagnosis"</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We randomly assign approximately two-thirds of the observations to the training set, and the remaining ones to the test set, as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">X_train</span> <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span></span>
<span><span class="va">Class_train</span> <span class="op">=</span> <span class="va">Class</span><span class="op">[</span><span class="va">train</span><span class="op">]</span></span>
<span><span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Class_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>Counts <span class="op">=</span> <span class="va">tab</span>, <span class="st">"%"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="va">tab</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="co">##   Counts      %</span></span>
<span><span class="co">## B    251 66.227</span></span>
<span><span class="co">## M    128 33.773</span></span>
<span><span class="va">X_test</span> <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">train</span>, <span class="op">]</span></span>
<span><span class="va">Class_test</span> <span class="op">=</span> <span class="va">Class</span><span class="op">[</span><span class="op">-</span><span class="va">train</span><span class="op">]</span></span>
<span><span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Class_test</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>Counts <span class="op">=</span> <span class="va">tab</span>, <span class="st">"%"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="va">tab</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="co">##   Counts      %</span></span>
<span><span class="co">## B    106 55.789</span></span>
<span><span class="co">## M     84 44.211</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The distribution of the features with training data points marked according to cancer diagnosis is shown in <a href="#fig-wdbc1" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">clp</span> <span class="op">=</span> <span class="fu">clPairs</span><span class="op">(</span><span class="va">X_train</span>, <span class="va">Class_train</span>, lower.panel <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span><span class="fu">clPairsLegend</span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.3</span>, col <span class="op">=</span> <span class="va">clp</span><span class="op">$</span><span class="va">col</span>, pch <span class="op">=</span> <span class="va">clp</span><span class="op">$</span><span class="va">pch</span>, </span>
<span>              class <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">clp</span><span class="op">$</span><span class="va">class</span> <span class="op">==</span> <span class="st">"B"</span>, <span class="st">"Benign"</span>, <span class="st">"Malign"</span><span class="op">)</span>,</span>
<span>              title <span class="op">=</span> <span class="st">"Breast cancer diagnosis:"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbc1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Pairwise scatterplot matrix of selected features for the breast cancer data with points distinguished by tumor diagnosis.
</figcaption></figure>
</div>
</div>
</div>
<p>The function <code>MclustDA()</code> provides fitting capabilities for the EDDA model by specifying the optional argument <code>modelType = "EDDA"</code>. The corresponding function call is as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod1</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X_train</span>, <span class="va">Class_train</span>, modelType <span class="op">=</span> <span class="st">"EDDA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod1</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## EDDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df     BIC</span></span>
<span><span class="co">##         -2934.1 379 13 -5945.4</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 251 66.23   VVI 1</span></span>
<span><span class="co">##       M 128 33.77   VVI 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 249   2</span></span>
<span><span class="co">##     M  17 111</span></span>
<span><span class="co">## Classification error = 0.0501 </span></span>
<span><span class="co">## Brier score          = 0.0374</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The estimated EDDA mixture model with the largest BIC is the <code>VVI</code> model, in which each group is described by a single Gaussian component with varying volume and shape, and orientation aligned with the coordinate axes. As mentioned earlier, this model is a member of the Naïve-Bayes family. By default, the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> <!-- \index{mclust!\code{summary.MclustDA()}}  --> function also returns the confusion matrix obtained by cross-tabulation of the input and predicted classes, followed by two measures of accuracy to be discussed in <a href="#sec-evalclassifier" class="quarto-xref"><span>Section 4.4</span></a>.</p>
<p>Estimated parameters can be shown with the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function by setting the optional argument <code>parameters</code> as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod1</span>, parameters <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## EDDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df     BIC</span></span>
<span><span class="co">##         -2934.1 379 13 -5945.4</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 251 66.23   VVI 1</span></span>
<span><span class="co">##       M 128 33.77   VVI 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class prior probabilities:</span></span>
<span><span class="co">##       B       M </span></span>
<span><span class="co">## 0.66227 0.33773 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class = B</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Means:</span></span>
<span><span class="co">##                         [,1]</span></span>
<span><span class="co">## Texture_mean        17.95530</span></span>
<span><span class="co">## Area_extreme       562.71673</span></span>
<span><span class="co">## Smoothness_extreme   0.12486</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">## [,,1]</span></span>
<span><span class="co">##                    Texture_mean Area_extreme Smoothness_extreme</span></span>
<span><span class="co">## Texture_mean             15.312            0         0.00000000</span></span>
<span><span class="co">## Area_extreme              0.000        26588         0.00000000</span></span>
<span><span class="co">## Smoothness_extreme        0.000            0         0.00040151</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class = M</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Means:</span></span>
<span><span class="co">##                          [,1]</span></span>
<span><span class="co">## Texture_mean         21.80203</span></span>
<span><span class="co">## Area_extreme       1343.71094</span></span>
<span><span class="co">## Smoothness_extreme    0.14478</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">## [,,1]</span></span>
<span><span class="co">##                    Texture_mean Area_extreme Smoothness_extreme</span></span>
<span><span class="co">## Texture_mean             12.408            0         0.00000000</span></span>
<span><span class="co">## Area_extreme              0.000       288727         0.00000000</span></span>
<span><span class="co">## Smoothness_extreme        0.000            0         0.00060343</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 249   2</span></span>
<span><span class="co">##     M  17 111</span></span>
<span><span class="co">## Classification error = 0.0501 </span></span>
<span><span class="co">## Brier score          = 0.0374</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The confusion matrix and evaluation metrics for a new test set can be obtained by providing the data matrix of features (<code>newdata</code>) and the corresponding classes (<code>newclass</code>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod1</span>, newdata <span class="op">=</span> <span class="va">X_test</span>, newclass <span class="op">=</span> <span class="va">Class_test</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## EDDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df     BIC</span></span>
<span><span class="co">##         -2934.1 379 13 -5945.4</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 251 66.23   VVI 1</span></span>
<span><span class="co">##       M 128 33.77   VVI 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 249   2</span></span>
<span><span class="co">##     M  17 111</span></span>
<span><span class="co">## Classification error = 0.0501 </span></span>
<span><span class="co">## Brier score          = 0.0374 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Test confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 103   3</span></span>
<span><span class="co">##     M   5  79</span></span>
<span><span class="co">## Classification error = 0.0421 </span></span>
<span><span class="co">## Brier score          = 0.0357</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that, for this model, the performance metrics on the test set are no worse than those for the training set, and in fact are even slightly better. This indicates that the estimated model is not overfitting the data, which is likely due to the parsimonious covariance model adopted.</p>
<p>Objects returned by <code>MclustDA()</code> can be visualized in a variety of ways through the associated <code>plot</code> <!-- \index{mclust!\code{plot.MclustDA()}} --> method. For instance, the pairwise scatterplot matrix between the features, showing both the known classes and the estimated mixture components, is displayed in <a href="#fig-wdbc2" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> and obtained with the code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod1</span>, what <span class="op">=</span> <span class="st">"scatterplot"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbc2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbc2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbc2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: Pairwise scatterplot matrix of selected features for the breast cancer training data with points distinguished by observed classes and ellipses representing the Gaussian distribution estimated for each class by EDDA.
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-wdbc3" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> displays the pairwise scatterplots showing the misclassified training data points obtained with the following code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod1</span>, what <span class="op">=</span> <span class="st">"error"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbc3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbc3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbc3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Pairwise scatterplot matrix of selected features for the breast cancer training data with points distinguished by observed classes and filled black points representing those cases misclassified by the fitted EDDA model.
</figcaption></figure>
</div>
</div>
</div>
<p>EDDA imposes a single mixture component for each group. However, in certain circumstances, a more flexible model may result in a better classifier. As mentioned in <a href="#sec-gaussmixmodclas" class="quarto-xref"><span>Section 4.2</span></a>, a more general approach, called <em>MclustDA</em>, is available, in which a finite mixture of Gaussian distributions is used within each class, with both the number of components and covariance matrix structures (expressed following the usual eigen-decomposition in <a href="02_mixture.html#eq-eigendecomp" class="quarto-xref">Equation&nbsp;<span>2.4</span></a> allowed to differ among classes. This is the model estimated by default (or by setting <code>modelType = "MclustDA"</code>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod2</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X_train</span>, <span class="va">Class_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod2</span>, newdata <span class="op">=</span> <span class="va">X_test</span>, newclass <span class="op">=</span> <span class="va">Class_test</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## MclustDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df     BIC</span></span>
<span><span class="co">##         -2893.6 379 27 -5947.5</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 251 66.23   EEI 3</span></span>
<span><span class="co">##       M 128 33.77   EVI 2</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 248   3</span></span>
<span><span class="co">##     M   8 120</span></span>
<span><span class="co">## Classification error = 0.029 </span></span>
<span><span class="co">## Brier score          = 0.0262 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Test confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 103   3</span></span>
<span><span class="co">##     M   5  79</span></span>
<span><span class="co">## Classification error = 0.0421 </span></span>
<span><span class="co">## Brier score          = 0.0273</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>MclustDA fits a three-component <code>EEI</code> mixture to benign cases, and a two-component <code>EVI</code> mixture to the malignant cases. Note that diagonal covariance structures are used within each class. The training classification error rate is smaller for this model than for the EDDA model. However, the test misclassification rate is the same for the two types of models. This is an effect of <em>overfitting</em> induced by the increased complexity of the MclustDA model, which has 26 parameters to estimate, more than twice the number required by the EDDA model.</p>
<p><a href="#fig-wdbc4" class="quarto-xref">Figure&nbsp;<span>4.4</span></a> displays a matrix of pairwise scatterplots between the features showing both the known classes and the estimated mixture components drawn with the code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod2</span>, what <span class="op">=</span> <span class="st">"scatterplot"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbc4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbc4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbc4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: Scatterplots of selected features for the breast cancer training data with points distinguished by observed classes and ellipses representing the Gaussian distribution estimated for each class by MclustDA.
</figcaption></figure>
</div>
</div>
</div>
<p>Specific marginals can be obtained by using the optional argument <code>dimens</code>. For instance, the following code produces the scatterplot for the first two features:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod2</span>, what <span class="op">=</span> <span class="st">"scatterplot"</span>, dimens <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, note that the MDA model of <span class="citation" data-cites="Hastie:Tibshirani:1996">Trevor Hastie and Tibshirani (<a href="99_references.html#ref-Hastie:Tibshirani:1996" role="doc-biblioref">1996</a>)</span> is equivalent to MclustDA with <span class="math inline">\(\boldsymbol{\Sigma}_{k} = \lambda\boldsymbol{U}\boldsymbol{\Delta}\boldsymbol{U}{}^{\!\top}\)</span> (model <code>EEE</code>) and fixed <span class="math inline">\(G_k \ge 1\)</span> for each class. For instance, an MDA model with two mixture components for each class can be fitted using the code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod3</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X_train</span>, <span class="va">Class_train</span>, G <span class="op">=</span> <span class="fl">2</span>, modelNames <span class="op">=</span> <span class="st">"EEE"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod3</span>, newdata <span class="op">=</span> <span class="va">X_test</span>, newclass <span class="op">=</span> <span class="va">Class_test</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## MclustDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df     BIC</span></span>
<span><span class="co">##         -2910.8 379 27 -5981.9</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 251 66.23   EEE 2</span></span>
<span><span class="co">##       M 128 33.77   EEE 2</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 247   4</span></span>
<span><span class="co">##     M  10 118</span></span>
<span><span class="co">## Classification error = 0.0369 </span></span>
<span><span class="co">## Brier score          = 0.0297 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Test confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 104   2</span></span>
<span><span class="co">##     M   4  80</span></span>
<span><span class="co">## Classification error = 0.0316 </span></span>
<span><span class="co">## Brier score          = 0.0248</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section><section id="sec-evalclassifier" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="sec-evalclassifier">
<span class="header-section-number">4.4</span> Evaluating Classifier Performance</h2>
<p>Evaluating the performance of a classifier is an essential part of any classification task. Mixture models used for classification are able to generate two types of predictions: the most likely class label according to the MAP rule in <a href="#eq-classmap" class="quarto-xref">Equation&nbsp;<span>4.3</span></a>, and the posterior probabilities of class membership from <a href="#eq-classpostprob" class="quarto-xref">Equation&nbsp;<span>4.2</span></a>. <strong>mclust</strong> automatically computes one performance measure for each type of prediction, namely the <em>misclassification error</em> and the <em>Brier score</em>, to be described in the following sections. Note, however, that several other measures exist, such as the Receiving Operating Characteristic (ROC) curve and the Area Under the [ROC] Curve (AUC) for two-class cases, and it is possible to compute them using the estimates provided by the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> method associated with <code>MclustDA</code> objects.</p>
<section id="evaluating-predicted-classes-classification-error" class="level3" data-number="4.4.1"><h3 data-number="4.4.1" class="anchored" data-anchor-id="evaluating-predicted-classes-classification-error">
<span class="header-section-number">4.4.1</span> Evaluating Predicted Classes: Classification Error</h3>
<p>The simplest measure available is the <em>misclassification error rate</em>, <!-- \index{misclassification error rate} --> or simply the <em>classification error</em>, which is the proportion of wrong predictions made by the classifier: <span id="eq-ce"><span class="math display">\[
\CE = \frac{1}{n} \sum_{i=1}^n \mathnormal{I}(\widehat{y}_i \ne y_i) ,
\tag{4.4}\]</span></span> where <span class="math inline">\(y_i = \{C_k\}\)</span> is the known class for the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(\widehat{y}_i = \{C_{\widehat{k}}\}\)</span> is the predicted class label, and <span class="math inline">\(\mathnormal{I}(\widehat{y}_i \ne y_i)\)</span> is an indicator function that equals <span class="math inline">\(1\)</span> if <span class="math inline">\(\widehat{y}_i \ne y_i\)</span> and <span class="math inline">\(0\)</span> otherwise. A good classifier should have a small error rate, preferably close to zero. Equivalently, the <em>accuracy</em> of a classifier is defined as the proportion of correct predictions, <span class="math inline">\(1 - \CE\)</span>. Note, however, that when classes are <em>unbalanced</em> (not represented more or less equally), the error rate or accuracy may not be meaningful. A classifier could have a high overall accuracy yet not be able to accurately detect members of small classes.</p>
</section><section id="evaluating-class-probabilities-brier-score" class="level3" data-number="4.4.2"><h3 data-number="4.4.2" class="anchored" data-anchor-id="evaluating-class-probabilities-brier-score">
<span class="header-section-number">4.4.2</span> Evaluating Class Probabilities: Brier Score</h3>
<p>The Brier score is a measure of the predictive accuracy for probabilistic predictions. It is computed as the mean squared difference between the true class indicators and the predicted probabilities.</p>
<p>Based on the original multi-class definition by <span class="citation" data-cites="Brier:1950">Brier (<a href="99_references.html#ref-Brier:1950" role="doc-biblioref">1950</a>)</span>, the following formula provides the normalized Brier score: <!-- \index{Brier score} --> <span class="math display">\[
\BS = \frac{1}{2n} \sum_{i=1}^n \sum_{k=1}^K (C_{ik} - \widehat{p}_{ik})^2 ,
\]</span> where <span class="math inline">\(n\)</span> is the number of observations, <span class="math inline">\(K\)</span> is the number of classes, <span class="math inline">\(C_{ik} = 1\)</span> if observation <span class="math inline">\(i\)</span> is from class <span class="math inline">\(k\)</span> and 0 otherwise, and <span class="math inline">\(\widehat{p}_{ik}\)</span> is the predicted probability that observation <span class="math inline">\(i\)</span> belongs to class <span class="math inline">\(k\)</span>. In this formula, the inclusion of the constant 2 in the denominator ensures that the index takes values in the range <span class="math inline">\([0,1]\)</span> <span class="citation" data-cites="Kruppa:etal:2014a">(<a href="99_references.html#ref-Kruppa:etal:2014a" role="doc-biblioref">Kruppa et al. 2014, Kruppa:etal:2014b</a>)</span>.</p>
<p>The Brier score is a strictly proper score <span class="citation" data-cites="Gneiting:Raftery:2007">(<a href="99_references.html#ref-Gneiting:Raftery:2007" role="doc-biblioref">Gneiting and Raftery 2007</a>)</span>, which implies that it takes its minimal value only when the predicted probabilities match the empirical probabilities. Thus, small values of the Brier score indicate high prediction accuracy, with <span class="math inline">\(\BS = 0\)</span> when the observations are all correctly classified with probability one.</p>
</section><section id="sec-classif_performance" class="level3" data-number="4.4.3"><h3 data-number="4.4.3" class="anchored" data-anchor-id="sec-classif_performance">
<span class="header-section-number">4.4.3</span> Estimating Classifier Performance: Test Set and Resampling-Based Validation</h3>
<p>Any performance measure computed using the training set will tend to provide an optimistic performance estimate. For instance, the training classification error rate <span class="math inline">\(\CE_{\text{train}}\)</span> is obtained by applying <a href="#eq-ce" class="quarto-xref">Equation&nbsp;<span>4.4</span></a> to the training observations. This measure of the accuracy of a classifier is optimistic because the same set of observations is used for both model estimation and for its assessment. A more realistic estimate can be obtained by computing the test misclassification error rate, which is the error rate computed on a fresh test set of <span class="math inline">\(m\)</span> observations <span class="math inline">\(\mathcal{D}_\text{test}= \{(\boldsymbol{x}^*_1,y^*_1), \dots, (\boldsymbol{x}^*_m,y^*_m)\}\)</span>: <span class="math display">\[
\CE_{\text{test}} = \frac{1}{m} \sum_{i=1}^{m} \mathnormal{I}(y^*_i \ne \widehat{y}^*_i),
\]</span> where <span class="math inline">\(\widehat{y}^*_i\)</span> is the predicted class label that results from applying the classifier with feature vector <span class="math inline">\(\boldsymbol{x}^*\)</span>.<br>
This seems an obvious choice, “but, to get reasonable precision of the performance values, the size of the test set may need to be large” <span class="citation" data-cites="Kuhn:Johnson:2013">(<a href="99_references.html#ref-Kuhn:Johnson:2013" role="doc-biblioref">Kuhn and Johnson 2013, 66</a>)</span>. The same considerations also apply to the Brier score.</p>
<p>In cases where a test set is not available, or its size is not sufficient to guarantee reliable estimates, an assessment of a model’s performance can be obtained by resampling methods. Different resampling schemes are available, but all rely on modeling repeated samples drawn from a training set.</p>
<p><em>Cross-validation</em> <!-- \index{cross-validation}  --> is a simple and intuitive way to obtain a realistic performance measure. A standard resampling scheme is the <span class="math inline">\(V\)</span>-fold cross-validation approach, which randomly splits the set of training observations into <span class="math inline">\(V\)</span> parts or <em>folds</em>. At each step of the procedure, data from <span class="math inline">\(V-1\)</span> folds are used for model fitting, and the held-out fold is used as a validation set. <a href="#fig-crossval_diagram" class="quarto-xref">Figure&nbsp;<span>4.5</span></a> provides a schematic view of 10-fold cross-validation.</p>
<p>Consider a generic loss function of the prediction error, say <span class="math inline">\(L(y,\widehat{y})\)</span>, that we would like to minimize. For instance, by setting <span class="math inline">\(L(y,\widehat{y}) = \mathnormal{I}(y \ne \widehat{y})\)</span>, the <span class="math inline">\(0-1\)</span> loss, we obtain the misclassification error rate, whereas by setting <span class="math inline">\(L(y,\widehat{y}) = (C_k - \widehat{p})^2\)</span>, the squared error with respect to the estimated probability <span class="math inline">\(\widehat{p}\)</span>, we obtain the Brier score. The <span class="math inline">\(V\)</span>-fold cross-validation steps are the following:</p>
<ol type="1">
<li>Split the training set into <span class="math inline">\(V\)</span> folds of roughly equal size (and stratified<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>), say <span class="math inline">\(F_1, \dots, F_V\)</span>.</li>
</ol>
<ol start="2" type="1">
<li>
<p>For <span class="math inline">\(v=1, \dots, V\)</span>:</p>
<ol type="a">
<li><p>fit the model using <span class="math inline">\(\{(\boldsymbol{x}_i,y_i): i \notin F_v\}\)</span> as training set;</p></li>
<li><p>evaluate the model using <span class="math inline">\(\{(\boldsymbol{x}_i,y_i): i \in F_v\}\)</span> as validating set by computing <span class="math display">\[
L_v = \frac{1}{n_v} \sum_{i \in F_v} L(y_i, \widehat{y}_i),
\]</span> where <span class="math inline">\(n_v\)</span> is the number of observations in fold <span class="math inline">\(F_v\)</span>.</p></li>
</ol>
</li>
<li><p>Average the loss function over the folds by computing <span class="math display">\[
L_{\CV} = \sum_{v = 1}^V \frac{n_v}{n} L_v
=   \frac{1}{n} \sum_{v = 1}^V \sum_{i \in F_v} L(y_i, \widehat{y}_i).
\]</span></p></li>
</ol>
<div id="fig-crossval_diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-crossval_diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><br></p>
<p><img src="../images/crossval_diagram.png" class="img-fluid figure-img" style="width:100.0%"></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-crossval_diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Schematic representation of the 10-fold cross-validation resampling technique.
</figcaption></figure>
</div>
<p>There is no general rule for choosing an optimal value for <span class="math inline">\(V\)</span>. If <span class="math inline">\(V = n\)</span>, the procedure is called <em>leave-one-out cross-validation</em> (LOOCV), because one data point is held out at a time. Large values of <span class="math inline">\(V\)</span> reduce the bias of the estimator but increase its variance, while small values of <span class="math inline">\(V\)</span> increase the bias but decrease the variance. Furthermore, for large values of <span class="math inline">\(V\)</span>, the computational burden may be quite high. For these reasons, it is often suggested to set <span class="math inline">\(V\)</span> equal to 5 or 10 <span class="citation" data-cites="Hastie:Tibshirani:Friedman:2009">(<a href="99_references.html#ref-Hastie:Tibshirani:Friedman:2009" role="doc-biblioref">T. Hastie, Tibshirani, and Friedman 2009, sec. 7.10</a>)</span>.</p>
<p>An advantage of using a cross-validation approach is that it provides an estimate of the standard error of the procedure. This can be computed as <span class="math display">\[
\se(L_{\CV}) = \frac{\sd(L)}{\sqrt{V}},
\]</span> where <span class="math display">\[
\sd(L) = \sqrt{ \frac{\sum_{v=1}^V (L_v - L_{\CV})^2 n_v}{n(V-1)/V} }.
\]</span> The estimate <span class="math inline">\(\se(L_{\CV})\)</span> is often used for implementing the <em>one-standard error rule</em>: when models of different complexity are compared, select the simplest model whose performance is within one standard error of the best value <span class="citation" data-cites="Breiman:etal:1984">(<a href="99_references.html#ref-Breiman:etal:1984" role="doc-biblioref">Breiman et al. 1984, sec. 8.1</a> and 14.1)</span>. For an in-depth investigation of the behavior of cross-validation for some commonly used statistical models, see <span class="citation" data-cites="Bates:etal:2021">Bates, Hastie, and Tibshirani (<a href="99_references.html#ref-Bates:etal:2021" role="doc-biblioref">2021</a>)</span>.</p>
</section><section id="sec-crossvalidation" class="level3" data-number="4.4.4"><h3 data-number="4.4.4" class="anchored" data-anchor-id="sec-crossvalidation">
<span class="header-section-number">4.4.4</span> Cross-Validation in mclust</h3>
<p>The function <code>cvMclustDA()</code> <!-- \index{mclust!\code{cvMclustDA()}}  --> is available in <strong>mclust</strong> to carry out <span class="math inline">\(V\)</span>-fold cross-validation as discussed above. It requires an object as returned by <code>MclustDA()</code> and, among the optional arguments, <code>nfold</code> can be used to set the number of folds (by default set to 10).</p>
<div id="exm-wdbc_cv" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.2</strong></span> &nbsp;&nbsp;<strong>Evaluation of classification models using cross-validation for the Wisconsin diagnostic breast cancer data</strong></p>
<p>Consider the classification models estimated in <a href="#exm-wdbc" class="quarto-xref">Example&nbsp;<span>4.1</span></a>. The following code computes the 10-fold CV for the selected EDDA and MclustDA models:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cv1</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">cv1</span><span class="op">)</span></span>
<span><span class="co">## List of 6</span></span>
<span><span class="co">## $ classification: Factor w/ 2 levels "B","M": 2 1 1 1 1 2 1 1 1 1 ...</span></span>
<span><span class="co">## $ z : num [1:379, 1:2] 0.191 0.744 0.972 0.927 0.705 ...</span></span>
<span><span class="co">## ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">## .. ..$ : NULL</span></span>
<span><span class="co">## .. ..$ : chr [1:2] "B" "M"</span></span>
<span><span class="co">## $ ce : num 0.0528</span></span>
<span><span class="co">## $ se.ce : num 0.0125</span></span>
<span><span class="co">## $ brier : num 0.0399</span></span>
<span><span class="co">## $ se.brier : num 0.00734</span></span>
<span><span class="va">cv2</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">cv2</span><span class="op">)</span></span>
<span><span class="co">## List of 6</span></span>
<span><span class="co">## $ classification: Factor w/ 2 levels "B","M": 2 1 1 1 2 2 1 1 1 2 ...</span></span>
<span><span class="co">## $ z : num [1:379, 1:2] 0.304 0.891 0.916 0.994 0.471 ...</span></span>
<span><span class="co">## ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">## .. ..$ : NULL</span></span>
<span><span class="co">## .. ..$ : chr [1:2] "B" "M"</span></span>
<span><span class="co">## $ ce : num 0.0317</span></span>
<span><span class="co">## $ se.ce : num 0.00765</span></span>
<span><span class="co">## $ brier : num 0.0298</span></span>
<span><span class="co">## $ se.brier : num 0.00462</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The list of values returned by <code>cvMclustDA()</code> contains the cross-validated predicted classes (<code>classification</code>), the posterior class conditional probabilities (<code>z</code>), followed by the cross-validated metrics (the misclassification error rate and the Brier score) and their standard errors. The latter can be extracted using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">cv1</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ce"</span>, <span class="st">"se.ce"</span>, <span class="st">"brier"</span>, <span class="st">"se.brier"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##        ce     se.ce     brier  se.brier </span></span>
<span><span class="co">## 0.0527704 0.0124978 0.0399285 0.0073402</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">cv2</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ce"</span>, <span class="st">"se.ce"</span>, <span class="st">"brier"</span>, <span class="st">"se.brier"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##        ce     se.ce     brier  se.brier </span></span>
<span><span class="co">## 0.0316623 0.0076524 0.0297516 0.0046195</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Training and resampling metrics for all of the EDDA models and the MclustDA model can be obtained using the following code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">models</span> <span class="op">=</span> <span class="fu">mclust.options</span><span class="op">(</span><span class="st">"emModelNames"</span><span class="op">)</span></span>
<span><span class="va">tab_CE</span> <span class="op">=</span> <span class="va">tab_Brier</span> <span class="op">=</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">models</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span>, ncol <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">tab_CE</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">tab_Brier</span><span class="op">)</span> <span class="op">=</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"EDDA["</span>, <span class="va">models</span>, <span class="st">"]"</span><span class="op">)</span>, <span class="st">"MCLUSTDA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">tab_CE</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">tab_Brier</span><span class="op">)</span> <span class="op">=</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Train"</span>, <span class="st">"10-fold CV"</span>, <span class="st">"se(CV)"</span>, <span class="st">"lower"</span>, <span class="st">"upper"</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">models</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">mod</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X</span>, <span class="va">Class</span>, modelType <span class="op">=</span> <span class="st">"EDDA"</span>, </span>
<span>                  modelNames <span class="op">=</span> <span class="va">models</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, <span class="va">X</span><span class="op">)</span></span>
<span>  <span class="va">cv</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span>, nfold <span class="op">=</span> <span class="fl">10</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="co">#</span></span>
<span>  <span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, <span class="va">Class</span><span class="op">)</span><span class="op">$</span><span class="va">errorRate</span></span>
<span>  <span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span></span>
<span>  <span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span>  <span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">-</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span>  <span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">+</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span>  <span class="co">#</span></span>
<span>  <span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">Class</span><span class="op">)</span></span>
<span>  <span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span></span>
<span>  <span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span>
<span>  <span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span> <span class="op">-</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span>
<span>  <span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span> <span class="op">+</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span>
<span><span class="op">}</span></span>
<span><span class="va">i</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">models</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span></span>
<span><span class="va">mod</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X</span>, <span class="va">Class</span>, modelType <span class="op">=</span> <span class="st">"MclustDA"</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, <span class="va">X</span><span class="op">)</span></span>
<span><span class="va">cv</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span>, nfold <span class="op">=</span> <span class="fl">10</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#</span></span>
<span><span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, <span class="va">Class</span><span class="op">)</span><span class="op">$</span><span class="va">errorRate</span></span>
<span><span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span></span>
<span><span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span><span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">-</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span><span class="va">tab_CE</span><span class="op">[</span><span class="va">i</span>, <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">+</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span><span class="co">#</span></span>
<span><span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">Class</span><span class="op">)</span></span>
<span><span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span></span>
<span><span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span>
<span><span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span> <span class="op">-</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span>
<span><span class="va">tab_Brier</span><span class="op">[</span><span class="va">i</span>, <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">brier</span> <span class="op">+</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.brier</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following table gives the training error, the 10-fold CV error with its standard error, and the lower and upper bounds computed as <span class="math inline">\(\pm\)</span> one standard error from the CV estimate:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tab_CE</span></span>
<span><span class="co">##              Train 10-fold CV    se(CV)    lower    upper</span></span>
<span><span class="co">## EDDA[EII] 0.112478   0.117750 0.0168034 0.100947 0.134554</span></span>
<span><span class="co">## EDDA[VII] 0.079086   0.079086 0.0120644 0.067022 0.091150</span></span>
<span><span class="co">## EDDA[EEI] 0.087873   0.087873 0.0089230 0.078950 0.096797</span></span>
<span><span class="co">## EDDA[VEI] 0.091388   0.093146 0.0128794 0.080266 0.106025</span></span>
<span><span class="co">## EDDA[EVI] 0.066784   0.072056 0.0083953 0.063661 0.080452</span></span>
<span><span class="co">## EDDA[VVI] 0.043937   0.047452 0.0064740 0.040978 0.053926</span></span>
<span><span class="co">## EDDA[EEE] 0.066784   0.068541 0.0076137 0.060928 0.076155</span></span>
<span><span class="co">## EDDA[VEE] 0.072056   0.073814 0.0159524 0.057861 0.089766</span></span>
<span><span class="co">## EDDA[EVE] 0.059754   0.065026 0.0073839 0.057642 0.072410</span></span>
<span><span class="co">## EDDA[VVE] 0.042179   0.043937 0.0088144 0.035122 0.052751</span></span>
<span><span class="co">## EDDA[EEV] 0.047452   0.050967 0.0075542 0.043412 0.058521</span></span>
<span><span class="co">## EDDA[VEV] 0.052724   0.056239 0.0108316 0.045407 0.067071</span></span>
<span><span class="co">## EDDA[EVV] 0.045694   0.047452 0.0074344 0.040017 0.054886</span></span>
<span><span class="co">## EDDA[VVV] 0.036907   0.038664 0.0090412 0.029623 0.047705</span></span>
<span><span class="co">## MCLUSTDA  0.022847   0.036907 0.0105586 0.026348 0.047465</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The same information is also shown graphically in <a href="#fig-cvmclustda_fig1" class="quarto-xref">Figure&nbsp;<span>4.6</span></a> using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">tab_CE</span><span class="op">)</span>, <span class="va">tab_CE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"model"</span>, <span class="st">"train"</span>, <span class="st">"cv"</span>, <span class="st">"se"</span>, <span class="st">"lower"</span>, <span class="st">"upper"</span><span class="op">)</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">model</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">model</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">model</span>, y <span class="op">=</span> <span class="va">cv</span>, ymin <span class="op">=</span> <span class="va">lower</span>, ymax <span class="op">=</span> <span class="va">upper</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="st">"s1"</span>, color <span class="op">=</span> <span class="st">"c1"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html">geom_errorbar</a></span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.5</span>, col <span class="op">=</span> <span class="st">"dodgerblue3"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">train</span>, shape <span class="op">=</span> <span class="st">"s2"</span>, color <span class="op">=</span> <span class="st">"c2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.2</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>, lim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="cn">NA</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">""</span>, </span>
<span>                     breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"c1"</span>, <span class="st">"c2"</span><span class="op">)</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"dodgerblue3"</span>, <span class="st">"black"</span><span class="op">)</span>,</span>
<span>                     labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"CV"</span>, <span class="st">"Train"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_shape_manual</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">""</span>, </span>
<span>                     breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"s1"</span>, <span class="st">"s2"</span><span class="op">)</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">19</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                     labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"CV"</span>, <span class="st">"Train"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Classification error"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">""</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-cvmclustda_fig1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cvmclustda_fig1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-cvmclustda_fig1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cvmclustda_fig1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.6: Training and cross-validated misclassification error rates of Gaussian mixture classification models for the breast cancer data.
</figcaption></figure>
</div>
</div>
</div>
<p>The analogous table for the Brier score is:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tab_Brier</span></span>
<span><span class="co">##              Train 10-fold CV    se(CV)    lower    upper</span></span>
<span><span class="co">## EDDA[EII] 0.095691   0.096282 0.0141399 0.082142 0.110422</span></span>
<span><span class="co">## EDDA[VII] 0.072572   0.072936 0.0099342 0.063001 0.082870</span></span>
<span><span class="co">## EDDA[EEI] 0.055086   0.055573 0.0055047 0.050068 0.061078</span></span>
<span><span class="co">## EDDA[VEI] 0.060386   0.062123 0.0094198 0.052703 0.071543</span></span>
<span><span class="co">## EDDA[EVI] 0.047277   0.049384 0.0067815 0.042603 0.056166</span></span>
<span><span class="co">## EDDA[VVI] 0.036197   0.037103 0.0044475 0.032655 0.041550</span></span>
<span><span class="co">## EDDA[EEE] 0.051470   0.052056 0.0040711 0.047984 0.056127</span></span>
<span><span class="co">## EDDA[VEE] 0.052813   0.054901 0.0085825 0.046318 0.063483</span></span>
<span><span class="co">## EDDA[EVE] 0.043315   0.046130 0.0053728 0.040757 0.051502</span></span>
<span><span class="co">## EDDA[VVE] 0.035243   0.035845 0.0065776 0.029268 0.042423</span></span>
<span><span class="co">## EDDA[EEV] 0.039127   0.040170 0.0040287 0.036141 0.044199</span></span>
<span><span class="co">## EDDA[VEV] 0.041625   0.043191 0.0074828 0.035708 0.050674</span></span>
<span><span class="co">## EDDA[EVV] 0.036139   0.037555 0.0050249 0.032530 0.042580</span></span>
<span><span class="co">## EDDA[VVV] 0.028803   0.030183 0.0063246 0.023859 0.036508</span></span>
<span><span class="co">## MCLUSTDA  0.022999   0.026530 0.0064555 0.020075 0.032986</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>with the corresponding plot in <a href="#fig-cvmclustda_fig2" class="quarto-xref">Figure&nbsp;<span>4.7</span></a>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">tab_Brier</span><span class="op">)</span>, <span class="va">tab_Brier</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"model"</span>, <span class="st">"train"</span>, <span class="st">"cv"</span>, <span class="st">"se"</span>, <span class="st">"lower"</span>, <span class="st">"upper"</span><span class="op">)</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">model</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">model</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">model</span>, y <span class="op">=</span> <span class="va">cv</span>, ymin <span class="op">=</span> <span class="va">lower</span>, ymax <span class="op">=</span> <span class="va">upper</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="st">"s1"</span>, color <span class="op">=</span> <span class="st">"c1"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html">geom_errorbar</a></span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.5</span>, col <span class="op">=</span> <span class="st">"dodgerblue3"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">train</span>, shape <span class="op">=</span> <span class="st">"s2"</span>, color <span class="op">=</span> <span class="st">"c2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.2</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>, lim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="cn">NA</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">""</span>, </span>
<span>                     breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"c1"</span>, <span class="st">"c2"</span><span class="op">)</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"dodgerblue3"</span>, <span class="st">"black"</span><span class="op">)</span>,</span>
<span>                     labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"CV"</span>, <span class="st">"Train"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_shape_manual</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">""</span>, </span>
<span>                     breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"s1"</span>, <span class="st">"s2"</span><span class="op">)</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">19</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                     labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"CV"</span>, <span class="st">"Train"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Brier score"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">""</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-cvmclustda_fig2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cvmclustda_fig2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-cvmclustda_fig2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cvmclustda_fig2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.7: Training and cross-validated Brier scores of Gaussian mixture classification models for the breast cancer data.
</figcaption></figure>
</div>
</div>
</div>
<p>The plots in <a href="#fig-cvmclustda_fig1" class="quarto-xref">Figure&nbsp;<span>4.6</span></a> and <a href="#fig-cvmclustda_fig2" class="quarto-xref">Figure&nbsp;<span>4.7</span></a> show that, by increasing the complexity of the model, it is sometimes possible to improve the accuracy of the predictions. In particular, the MclustDA model had better performance than the EDDA models, with the exception of the EDDA model with unconstrained covariances (<code>VVV</code>), which had both misclassification error rate and Brier score within one standard error from the best.</p>
</div>
<p>The information returned by <code>cvMclustDA()</code> can also be used for computing other cross-validation metrics. For instance, in the binary class case two popular measures are <em>sensitivity</em> and <em>specificity</em>. <!-- \index{sensitivity and specificity of a binary classifier} --> The sensitivity, or true positive rate, is given by the ratio of the number observations that are classified in the positive class to the total number of positive cases. The specificity, or true negative rate, is given by the ratio of observations that are classified in the negative class to the total number of negative cases. Both metrics are easily computed from the <em>confusion matrix</em>, obtained by cross-tabulating the true classes and the classes predicted by a classifier.</p>
<div id="exm-wdbc_roc_auc" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.3</strong></span> &nbsp;&nbsp;<strong>ROC-AUC analysis of classification models for the Wisconsin diagnostic breast cancer data</strong></p>
<p>Returning to the Wisconsin diagnostic breast cancer data in <a href="#exm-wdbc" class="quarto-xref">Example&nbsp;<span>4.1</span></a>, we are mainly interested in the identification of patients with malignant diagnosis, so the positive class can be taken to be class <code>M</code>, while benign cases (<code>B</code>) are assigned to the negative class.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># confusion matrix</span></span>
<span><span class="op">(</span><span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Predict <span class="op">=</span> <span class="va">cv1</span><span class="op">$</span><span class="va">classification</span>, Class <span class="op">=</span> <span class="va">Class_train</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">##        Class</span></span>
<span><span class="co">## Predict   B   M</span></span>
<span><span class="co">##       B 248  17</span></span>
<span><span class="co">##       M   3 111</span></span>
<span><span class="va">tab</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span>  <span class="co"># sensitivity</span></span>
<span><span class="co">## [1] 0.86719</span></span>
<span><span class="va">tab</span><span class="op">[</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>  <span class="co"># specificity</span></span>
<span><span class="co">## [1] 0.98805</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code above uses the cross-validated classifications obtained using the MAP approach, which for the binary class case is equivalent to setting the classification probability threshold at <span class="math inline">\(0.5\)</span>. However, the posterior probabilities returned by <code>cvMclustDA()</code> can be used to get classifications at different threshold values. The following code computes the sensitivity and specificity over a fine grid of threshold values:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">threshold</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">sensitivity</span> <span class="op">=</span> <span class="va">specificity</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">threshold</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">threshold</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">cv1</span><span class="op">$</span><span class="va">z</span><span class="op">[</span>, <span class="st">"M"</span><span class="op">]</span> <span class="op">&gt;</span> <span class="va">threshold</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="st">"M"</span>, <span class="st">"B"</span><span class="op">)</span>,</span>
<span>                 levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"B"</span>, <span class="st">"M"</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">pred</span>, <span class="va">Class_train</span><span class="op">)</span></span>
<span>  <span class="va">sensitivity</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="va">tab</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">specificity</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="va">tab</span><span class="op">[</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The metrics computed above for varying thresholds in binary decisions can be represented graphically using the <em>Receiver Operating Characteristic</em> (ROC) curve, <!-- \index{receiver operating characteristic (ROC) curve} --> which plots the sensitivity (true positive rate) vs.&nbsp;one minus the specificity (false positive rate). The resulting display is shown in <a href="#fig-wdbc_roc-1" class="quarto-xref">Figure&nbsp;<span>4.8 (a)</span></a> and obtained with the following code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">specificity</span>, <span class="va">sensitivity</span>, type <span class="op">=</span> <span class="st">"l"</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>  <span class="co"># ROC curve</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>  <span class="co"># limits of [0,1]x[0,1] region</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>  <span class="co"># line of random classification</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice that the optimal ROC curve would pass through the upper left corner, which corresponds to both sensitivity and specificity equal to 1.</p>
<p>A summary of the ROC curve which is used for evaluating the overall performance of a classifier is the <em>Area Under the Curve</em> (AUC). <!-- \index{Area Under the Curve (AUC)} --> This is equal to 1 for a perfect classifier, and 0.5 for a random classification; values larger than 0.8 are considered to be good <span class="citation" data-cites="Lantz:2019">(<a href="99_references.html#ref-Lantz:2019" role="doc-biblioref">Lantz 2019, 333</a>)</span>. Provided that the threshold grid is fine enough, a simple approximation of the AUC is obtained using the following function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">auc_approx</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">tpr</span>, <span class="va">fpr</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">x</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">fpr</span></span>
<span>  <span class="va">y</span> <span class="op">=</span> <span class="va">tpr</span></span>
<span>  <span class="va">dx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">dy</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span> <span class="op">*</span> <span class="va">dx</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">dy</span> <span class="op">*</span> <span class="va">dx</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">auc_approx</span><span class="op">(</span>tpr <span class="op">=</span> <span class="va">sensitivity</span>, fpr <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">specificity</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.98129</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The value of AUC indicates a classifier with a very good classification performance.</p>
<p>The same ROC-AUC analysis can also be replicated for the selected MclustDA model (in object <code>mod2</code>), producing the ROC curve shown in <a href="#fig-wdbc_roc-2" class="quarto-xref">Figure&nbsp;<span>4.8 (b)</span></a>. The corresponding value of the AUC is 0.98506.</p>
<div id="fig-wdbc_roc" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbc_roc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-wdbc_roc" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-wdbc_roc-1" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-wdbc_roc-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc_roc-1.png" id="fig-wdbc_roc-1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-wdbc_roc">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-wdbc_roc-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-wdbc_roc" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-wdbc_roc-2" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-wdbc_roc-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbc_roc-2.png" id="fig-wdbc_roc-2" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-wdbc_roc">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-wdbc_roc-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbc_roc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.8: ROC curves from the cross-validated predictions of selected (a) EDDA and (b) MclustDA models for the breast cancer data.
</figcaption></figure>
</div>
<p>Finally, the ROC curve can also be used to select an optimal threshold value. This can be set at the value where the true positive rate is high and the false positive rate is low, which is equivalent to maximizing <em>Youden’s index</em>: <!-- \index{Youden’s index} --> <span class="math display">\[
J = \text{Sensitivity} - (1 - \text{Specificity}) = \text{Sensitivity} + \text{Specificity} - 1.
\]</span> Note that <span class="math inline">\(J\)</span> corresponds to the vertical distance between the ROC curve and the random classification line. The following code computes Youden’s index and the optimal threshold for the selected EDDA model:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">J</span> <span class="op">=</span> <span class="va">sensitivity</span> <span class="op">+</span> <span class="va">specificity</span> <span class="op">-</span> <span class="fl">1</span> </span>
<span><span class="va">threshold</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">J</span><span class="op">)</span><span class="op">]</span>     <span class="co"># optimal threshold</span></span>
<span><span class="co">## [1] 0.28</span></span>
<span><span class="va">sensitivity</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">J</span><span class="op">)</span><span class="op">]</span>   <span class="co"># sensitivity at optimal threshold</span></span>
<span><span class="co">## [1] 0.94531</span></span>
<span><span class="va">specificity</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">J</span><span class="op">)</span><span class="op">]</span>   <span class="co"># specificity at optimal threshold</span></span>
<span><span class="co">## [1] 0.96813</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>ROC curves are a suitable measure of performance when the distribution of the two classes is approximately equal. Otherwise, Precision-Recall (PR) curves are a better alternative. Both measures require a sufficient number of thresholds to obtain an accurate estimate of the corresponding area under the curve. A discussion of the relationship between ROC and PR curves can be found in <span class="citation" data-cites="Davis:Goadrich:2006">Davis and Goadrich (<a href="99_references.html#ref-Davis:Goadrich:2006" role="doc-biblioref">2006</a>)</span>. R implementations include CRAN package <strong>PRROC</strong> <span class="citation" data-cites="Keilwagen:Grosse:Grau:2014 Grau:Grosse:Keilwagen:2015">(<a href="99_references.html#ref-Keilwagen:Grosse:Grau:2014" role="doc-biblioref">Keilwagen, Grosse, and Grau 2014</a>; <a href="99_references.html#ref-Grau:Grosse:Keilwagen:2015" role="doc-biblioref">Grau, Grosse, and Keilwagen 2015</a>)</span> and <strong>ROCR</strong> <span class="citation" data-cites="Sing:etal:2005">(<a href="99_references.html#ref-Sing:etal:2005" role="doc-biblioref">Sing et al. 2005</a>)</span>.</p>
</section></section><section id="sec-misclascosts" class="level2" data-number="4.5"><h2 data-number="4.5" class="anchored" data-anchor-id="sec-misclascosts">
<span class="header-section-number">4.5</span> Classification with Unequal Costs of Misclassification</h2>
<p>In many practical applications, different costs are associated with different types of classification error. Thus it can be argued that the decision rule should be based on the principle that the total cost of misclassification should be minimized. Costs can be incorporated into a decision rule either at the learning stage or at the prediction stage.</p>
<p>We now describe a strategy for Gaussian mixtures that takes costs into account only at the final prediction stage. Let <span class="math inline">\(c(k|j)\)</span> be the cost of allocating an observation from class <span class="math inline">\(j\)</span> to class <span class="math inline">\(k \ne j\)</span>, with <span class="math inline">\(c(j|j) = 0\)</span>. Let <span class="math inline">\(p(k|j) = \Pr(C_k | \boldsymbol{x}\in C_j)\)</span> be the probability of allocating an observation coming from class <span class="math inline">\(j\)</span> to class <span class="math inline">\(k\)</span>. The expected cost of misclassification (ECM) <!-- \index{expected cost of misclassification (ECM)}  --> for class <span class="math inline">\(j\)</span> is given by <span class="math display">\[
\ECM(j) = \sum_{k \ne j}^K c(k|j) p(k|j) \propto \sum_{k \ne j}^K c(k|j) \tau_k f(\boldsymbol{x}| C_k),
\]</span> and the overall ECM is thus <span class="math display">\[
\ECM = \sum_{j=1}^K \ECM(j) = \sum_{j=1}^K \sum_{k \ne j}^K c(k|j) p(k|j).
\]</span> According to this criterion, a new observation <span class="math inline">\(\boldsymbol{x}\)</span> should be allocated by minimizing the expected cost of misclassification.</p>
<p>In the case of equal costs of misclassification (<span class="math inline">\(c(k|j) = 1\)</span> if <span class="math inline">\(k \ne j\)</span>), we obtain <span class="math display">\[
\ECM(j) = \sum_{k \ne j}^K p(k|j) \propto \sum_{k \ne j}^K \tau_k f(\boldsymbol{x}| C_k),
\]</span> and we allocate an observation <span class="math inline">\(\boldsymbol{x}\)</span> to the class <span class="math inline">\(C_k\)</span> that minimizes <span class="math inline">\(\ECM(j)\)</span>, or, equivalently, that maximizes <span class="math inline">\(\tau_k f(\boldsymbol{x}| C_k)\)</span>. This rule is the same as the standard MAP rule which uses the posterior probability from <a href="#eq-classpostprob" class="quarto-xref">Equation&nbsp;<span>4.2</span></a>.</p>
<p>In the case of unequal costs of misclassification, consider the <span class="math inline">\(K \times K\)</span> matrix of costs having the form: <span class="math display">\[
C = \{ c(k|j) \} =
\begin{bmatrix}
0 &amp; c(2|1) &amp; c(3|1) &amp; \dots &amp; c(K|1) \\
c(1|2) &amp; 0 &amp; c(3|2) &amp; \dots &amp; c(K|2) \\
c(1|3) &amp; c(2|3) &amp; 0 &amp; \dots &amp; c(K|3) \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
c(1|K) &amp; c(2|K) &amp; c(3|K) &amp; \dots &amp; 0 \\
\end{bmatrix}
.
\]</span> A simple solution can be obtained if we assume a constant cost of misclassifying an observation from class <span class="math inline">\(j\)</span>, irrespective of the class predicted. Following <span class="citation" data-cites="Breiman:etal:1984">(<a href="99_references.html#ref-Breiman:etal:1984" role="doc-biblioref">Breiman et al. 1984, 112–15</a>)</span>, we can compute the per-class cost <span class="math inline">\(c(k|j) = c(j)\)</span> for <span class="math inline">\(j \neq k\)</span>, and then get the predictions as in the unit-cost case with adjusted prior probabilities for the classes: <span class="math display">\[
\tau^*_j = \frac{c(j)\tau_j}{\displaystyle\sum_{j=1}^K c(j)\tau_j}.
\]</span> Note that for two-class problems the use of the per-class cost vector is equivalent to using the original cost matrix.</p>
<div id="exm-bankruptcy" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.4</strong></span> &nbsp;&nbsp;<strong>Bankruptcy prediction based on financial ratios of corporations</strong></p>
<p>Consider the data on financial ratios from <span class="citation" data-cites="Altman:1968">Altman (<a href="99_references.html#ref-Altman:1968" role="doc-biblioref">1968</a>)</span>, and available in the R package <strong>MixGHD</strong> <span class="citation" data-cites="Rpkg:MixGHD">(<a href="99_references.html#ref-Rpkg:MixGHD" role="doc-biblioref">Tortora et al. 2022</a>)</span>, which provides the ratio of retained earnings (<code>RE</code>) to total assets, and the ratio of earnings before interests and taxes (<code>EBIT</code>) to total assets, for 66 American corporations, of which half had filed for bankruptcy.</p>
<p>The following code loads the data and plots the financial ratios conditional on the class (see <a href="#fig-bankruptcy1" class="quarto-xref">Figure&nbsp;<span>4.9</span></a>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"bankruptcy"</span>, package <span class="op">=</span> <span class="st">"MixGHD"</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="va">bankruptcy</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">Class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">bankruptcy</span><span class="op">$</span><span class="va">Y</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">0</span><span class="op">)</span>, </span>
<span>               labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"solvent"</span>, <span class="st">"bankrupt"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cl</span> <span class="op">=</span> <span class="fu">clPairs</span><span class="op">(</span><span class="va">X</span>, <span class="va">Class</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>, legend <span class="op">=</span> <span class="va">cl</span><span class="op">$</span><span class="va">class</span>, </span>
<span>       pch <span class="op">=</span> <span class="va">cl</span><span class="op">$</span><span class="va">pch</span>, col <span class="op">=</span> <span class="va">cl</span> <span class="op">$</span><span class="va">col</span>, inset <span class="op">=</span> <span class="fl">0.02</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bankruptcy1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-bankruptcy1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-bankruptcy1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bankruptcy1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.9: Scatterplot of financial ratios with points distinguished by observed classes.
</figcaption></figure>
</div>
</div>
</div>
<p>Although the within-class distribution is clearly not Gaussian, in particular for the companies that have declared bankruptcy, we fit an EDDA classification model:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X</span>, <span class="va">Class</span>, modelType <span class="op">=</span> <span class="st">"EDDA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## EDDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood  n df     BIC</span></span>
<span><span class="co">##         -661.27 66  9 -1360.3</span></span>
<span><span class="co">##           </span></span>
<span><span class="co">## Classes     n  % Model G</span></span>
<span><span class="co">##   solvent  33 50   VEE 1</span></span>
<span><span class="co">##   bankrupt 33 50   VEE 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##           Predicted</span></span>
<span><span class="co">## Class      solvent bankrupt</span></span>
<span><span class="co">##   solvent       33        0</span></span>
<span><span class="co">##   bankrupt       2       31</span></span>
<span><span class="co">## Classification error = 0.0303 </span></span>
<span><span class="co">## Brier score          = 0.0295</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The confusion matrix indicates that two training data points are misclassified. Both are bankrupt firms which have been classified as solvent. The following plots show the distribution of financial ratios with (a) Gaussian ellipses implied by the estimated model, and (b) black points corresponding to the misclassified observations (see <a href="#fig-bankruptcy2" class="quarto-xref">Figure&nbsp;<span>4.10</span></a>):</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, what <span class="op">=</span> <span class="st">"scatterplot"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, what <span class="op">=</span> <span class="st">"error"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-bankruptcy2" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-bankruptcy2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bankruptcy2" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-bankruptcy2-1" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-bankruptcy2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-bankruptcy2-1.png" id="fig-bankruptcy2-1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-bankruptcy2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-bankruptcy2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bankruptcy2" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-bankruptcy2-2" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-bankruptcy2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-bankruptcy2-2.png" id="fig-bankruptcy2-2" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-bankruptcy2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-bankruptcy2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bankruptcy2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.10: Scatterplots of financial ratios with points distinguished by observed classes. Panel (a) shows the ellipses implied by the estimated model. Panel (b) includes black points corresponding to the misclassified observations.
</figcaption></figure>
</div>
<p>Now consider the error of misclassifying a bankrupt firm as solvent to be more serious than the opposite. We quantify these different costs of misclassification in a matrix <span class="math inline">\(C\)</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">C</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">10</span>, <span class="fl">0</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, ncol <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">##      [,1] [,2]</span></span>
<span><span class="co">## [1,]    0    1</span></span>
<span><span class="co">## [2,]   10    0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and obtain the per-class cost vector:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span></span>
<span><span class="co">## [1]  1 10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The total cost of misclassification for the MAP predictions is</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Class</span>, Predicted <span class="op">=</span> <span class="va">pred</span><span class="op">$</span><span class="va">classification</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">##           Predicted</span></span>
<span><span class="co">## Class      solvent bankrupt</span></span>
<span><span class="co">##   solvent       33        0</span></span>
<span><span class="co">##   bankrupt       2       31</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span> <span class="op">*</span> <span class="va">C</span><span class="op">)</span></span>
<span><span class="co">## [1] 20</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Unequal costs of misclassification can be included in the prediction as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, prop <span class="op">=</span> <span class="va">mod</span><span class="op">$</span><span class="va">prop</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">tab</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Class</span>, Predicted <span class="op">=</span> <span class="va">pred</span><span class="op">$</span><span class="va">classification</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">##           Predicted</span></span>
<span><span class="co">## Class      solvent bankrupt</span></span>
<span><span class="co">##   solvent       28        5</span></span>
<span><span class="co">##   bankrupt       0       33</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tab</span> <span class="op">*</span> <span class="va">C</span><span class="op">)</span></span>
<span><span class="co">## [1] 5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The last command shows that we have been able to reduce the total cost by zeroing out the errors for bankrupt firms, at the same time increasing the errors for solvent corporations.</p>
</div>
</section><section id="sec-imbalclass" class="level2" data-number="4.6"><h2 data-number="4.6" class="anchored" data-anchor-id="sec-imbalclass">
<span class="header-section-number">4.6</span> Classification with Unbalanced Classes</h2>
<p>Most classification datasets are not balanced; <!-- \index{unbalanced classes} --> that is, classes have unequal numbers of instances. Small differences between the number of instances in different classes can usually be ignored. In some cases, however, the imbalance in class proportions can be dramatic, and the class of interest is sometimes the class with the smallest number of cases. For instance, in studies aimed at identifying fraudulent transactions, classes are typically unbalanced, with the vast majority of the transactions not being fraudulent. In medical studies aimed at characterizing rare diseases, the class of individuals with the disease is only a small fraction of the total population (the <em>prevalence</em>).</p>
<p>In such situations, a case-control sampling scheme can be adopted by sampling approximately 505 of the data from the cases (fraudulent transactions, individuals suffering from a disease) and 50% from the controls. Balanced datasets can also be obtained in observational studies by <em>undersampling</em>, or downsizing the majority class by removing observations at random until the dataset is balanced. In both cases the class prior probabilities estimated from the training set do not reflect the “true” <em>a priori</em> probabilities. As a result, the predicted posterior class probabilities are not well estimated, resulting in a loss of classification accuracy compared to a classifier based on the true prior probabilities for the classes.</p>
<div id="exm-unbalsimdata" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.5</strong></span> &nbsp;&nbsp;<strong>Classification of synthetic unbalanced two-class data</strong></p>
<p>As an example, consider a simulated binary classification task, with the majority class having distribution <span class="math inline">\(x | (y = 0) \sim N(0, 1)\)</span>, whereas the distribution of the minority class is <span class="math inline">\(x | (y = 1) \sim N(3, 1)\)</span>, and in the population the latter accounts for 10% of cases. Suppose that a training sample is obtained using case-control sampling, so that the two groups have about the same proportion of cases.</p>
<p>A synthetic dataset from this specification can be simulated with the following code and shown graphically in <a href="#fig-simimbal1" class="quarto-xref">Figure&nbsp;<span>4.11</span></a>:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># generate training data from a balanced case-control sample</span></span>
<span><span class="va">n_train</span> <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="va">class_train</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, size <span class="op">=</span> <span class="va">n_train</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span>, </span>
<span>                             replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x_train</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">class_train</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_train</span>, mean <span class="op">=</span> <span class="fl">3</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, </span>
<span>                                    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_train</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">[</span><span class="va">class_train</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span>, breaks <span class="op">=</span> <span class="fl">11</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>, </span>
<span>     main <span class="op">=</span> <span class="st">""</span>, xlab <span class="op">=</span> <span class="st">"x"</span>, </span>
<span>     col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/adjustcolor.html">adjustcolor</a></span><span class="op">(</span><span class="st">"dodgerblue2"</span>, alpha.f <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, border <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">[</span><span class="va">class_train</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span>, breaks <span class="op">=</span> <span class="fl">11</span>, add <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>     col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/adjustcolor.html">adjustcolor</a></span><span class="op">(</span><span class="st">"red3"</span>, alpha.f <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, border <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/box.html">box</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># generate test data from mixture f(x) = 0.9 * N(0,1) + 0.1 * N(3,1)</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">10000</span></span>
<span><span class="va">mixpro</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.9</span>, <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">class_test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">mixpro</span>, </span>
<span>                            replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x_test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">class_test</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">3</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, </span>
<span>                                  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">[</span><span class="va">class_test</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span>, breaks <span class="op">=</span> <span class="fl">15</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span>, </span>
<span>     main <span class="op">=</span> <span class="st">""</span>, xlab <span class="op">=</span> <span class="st">"x"</span>, </span>
<span>     col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/adjustcolor.html">adjustcolor</a></span><span class="op">(</span><span class="st">"dodgerblue2"</span>, alpha.f <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, border <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">[</span><span class="va">class_test</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span>, breaks <span class="op">=</span> <span class="fl">11</span>, add <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>     col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/adjustcolor.html">adjustcolor</a></span><span class="op">(</span><span class="st">"red3"</span>, alpha.f <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, border <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/box.html">box</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-simimbal1" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-simimbal1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-simimbal1" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-simimbal1-1" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-simimbal1-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-simimbal1-1.png" id="fig-simimbal1-1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-simimbal1">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-simimbal1-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-simimbal1" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-simimbal1-2" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-simimbal1-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-simimbal1-2.png" id="fig-simimbal1-2" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-simimbal1">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-simimbal1-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simimbal1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.11: Histograms for synthetic datasets with observations sampled from two different Gaussian distributions. In the training data set, the cases (<span class="math inline">\(y=1\)</span>) and the controls (<span class="math inline">\(y=0\)</span>) are sampled in about the same proportions (a), whereas the cases (<span class="math inline">\(y=1\)</span>) account for 10% of the observations in the whole population (b).
</figcaption></figure>
</div>
<p>Using the training sample we can estimate a classification Gaussian mixture model:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">x_train</span>, <span class="va">class_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span>, parameters <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## MclustDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood    n df     BIC</span></span>
<span><span class="co">##         -1947.1 1000  5 -3928.8</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n    % Model G</span></span>
<span><span class="co">##       0 505 50.5     X 1</span></span>
<span><span class="co">##       1 495 49.5     X 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class prior probabilities:</span></span>
<span><span class="co">##     0     1 </span></span>
<span><span class="co">## 0.505 0.495 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class = 0</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Mixing probabilities: 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Means:</span></span>
<span><span class="co">## [1] 0.043067</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">## [1] 0.93808</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Class = 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Mixing probabilities: 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Means:</span></span>
<span><span class="co">## [1] 3.0959</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">## [1] 0.96652</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   0   1</span></span>
<span><span class="co">##     0 479  26</span></span>
<span><span class="co">##     1  24 471</span></span>
<span><span class="co">## Classification error = 0.05 </span></span>
<span><span class="co">## Brier score          = 0.0402</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The estimated parameters for the class conditional distributions are close to the true values, but the prior class probabilities are highly biased due to the sampling scheme adopted. Performance measures can be computed for the test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_test</span><span class="op">)</span></span>
<span><span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, <span class="va">class_test</span><span class="op">)</span><span class="op">$</span><span class="va">error</span></span>
<span><span class="co">## [1] 0.0592</span></span>
<span><span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">class_test</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.045927</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>showing that they are slightly worse than those for the training set, as is often the case.</p>
<p>For such simulated data we know the true classes, so we can compute the performance measures over a grid of values of the prior probability of the minority class:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">priorProp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">0.99</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">CE</span> <span class="op">=</span> <span class="va">BS</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">priorProp</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">priorProp</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_test</span>, </span>
<span>                  prop <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">priorProp</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="va">priorProp</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">CE</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, class <span class="op">=</span> <span class="va">class_test</span><span class="op">)</span><span class="op">$</span><span class="va">error</span></span>
<span>  <span class="va">BS</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">class_test</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following code produces <a href="#fig-simimbal2" class="quarto-xref">Figure&nbsp;<span>4.12</span></a>, which shows the classification error and the Brier score as functions of the prior probability for the minority class.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/matplot.html">matplot</a></span><span class="op">(</span><span class="va">priorProp</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">CE</span>, <span class="va">BS</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"l"</span>, lty <span class="op">=</span> <span class="fl">1</span>, lwd <span class="op">=</span> <span class="fl">2</span>, xaxt <span class="op">=</span> <span class="st">"n"</span>,</span>
<span>        xlab <span class="op">=</span> <span class="st">"Class prior probability"</span>, ylab <span class="op">=</span> <span class="st">""</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">CE</span>, <span class="va">BS</span><span class="op">)</span><span class="op">)</span>, </span>
<span>        col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red3"</span>, <span class="st">"dodgerblue3"</span><span class="op">)</span>,</span>
<span>        panel.first <span class="op">=</span> </span>
<span>          <span class="op">{</span> <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"grey"</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span>            <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"grey"</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> </span>
<span>          <span class="op">}</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span>, at <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">mod</span><span class="op">$</span><span class="va">prop</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,             <span class="co"># training proportions</span></span>
<span>       lty <span class="op">=</span> <span class="fl">2</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>            </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">class_test</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span>,   <span class="co"># test proportions (usually unknown)</span></span>
<span>       lty <span class="op">=</span> <span class="fl">3</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>   </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topleft"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ClassError"</span>, <span class="st">"BrierScore"</span><span class="op">)</span>,</span>
<span>       col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red3"</span>, <span class="st">"dodgerblue3"</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">1</span>, lwd <span class="op">=</span> <span class="fl">2</span>, inset <span class="op">=</span> <span class="fl">0.02</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-simimbal2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-simimbal2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-simimbal2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simimbal2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.12: Classification error and Brier score as functions of the prior probability for the minority class. The vertical segments show the biased sample proportion of cases in the training set (dashed line), and the sample proportion of cases in the test set (dotted line), which is usually unknown.
</figcaption></figure>
</div>
</div>
</div>
<p>Vertical lines are drawn at the proportion for the minority class in the training set (dashed line), and at the proportion computed on the test set (dotted lines). However, the latter is usually unknown, but the plot clearly shows that there is room for improving the classification accuracy by using an unbiased estimate of the class prior probabilities.</p>
</div>
<p>To solve this problem, <span class="citation" data-cites="Saerens:etal:2002">Saerens, Latinne, and Decaestecker (<a href="99_references.html#ref-Saerens:etal:2002" role="doc-biblioref">2002</a>)</span> proposed an EM algorithm that aims at estimating the adjusted posterior conditional probabilities of a classifier, <!-- \index{EM for estimating the adjusted posterior probabilities} --> and, as a by-product, provides estimates of the prior class probabilities. This method can be easily adapted to classifiers based on Gaussian mixtures.</p>
<p>Suppose a Gaussian mixture of the type in <a href="#eq-mixgaussclass" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> is estimated on the training set <span class="math inline">\(\mathcal{D}_\text{train}= \{(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_n, y_n)\}\)</span>, and a new test set <span class="math inline">\(\mathcal{D}_\text{test}= \{\boldsymbol{x}^*_1, \dots, \boldsymbol{x}^*_m\}\)</span> is available. From <a href="#eq-classpostprob" class="quarto-xref">Equation&nbsp;<span>4.2</span></a> the posterior probabilities that an observation <span class="math inline">\(\boldsymbol{x}_i^{*}\)</span> belongs to class <span class="math inline">\(C_k\)</span> are <span class="math display">\[
\widehat{z}_{ik}^{*} = \widehat{\Pr}(C_k | \boldsymbol{x}_i^{*})
\quad\text{for } k=1,\dots,K.
\]</span> Let <span class="math inline">\(\tilde{\tau}_k = \sum_{i = 1}^n \mathnormal{I}(y_i = C_k)/n\)</span> be the proportion of cases from class <span class="math inline">\(k\)</span> in the training set, and <span class="math inline">\(\widehat{\tau}_k^{0} = \sum_{i=1}^m \widehat{z}^{*}_{ik}/m\)</span> be a preliminary estimate of the prior probabilities for class <span class="math inline">\(k\)</span> (<span class="math inline">\(k=1,\dots,K\)</span>). Starting with <span class="math inline">\(s=1\)</span>, the algorithm iterates the following steps: <span class="math display">\[\begin{align*}
\widehat{z}_{ik}^{(s)} &amp; =
\frac{ \dfrac{\widehat{\tau}_k^{(s-1)}}{\tilde{\tau}_k} \widehat{z}_{ik}^{*} }
     { \displaystyle\sum_{g=1}^K \dfrac{\widehat{\tau}_g^{(s-1)}}{\tilde{\tau}_k} \widehat{z}_{ig}^{*} } ~ , &amp;
\widehat{\tau}_k^{(s)} &amp; = \dfrac{1}{m} \displaystyle\sum_{i=1}^m \widehat{z}_{ik}^{(s)},
\end{align*}\]</span> until the estimates <span class="math inline">\((\widehat{\tau}_1,\dots,\widehat{\tau}_K)\)</span> stabilize.</p>
<p>In <strong>mclust</strong> the estimated class prior probabilities, computed following the algorithm outlined above, can be obtained using the function <code>classPriorProbs()</code>. <!-- \index{mclust!\code{classPriorProbs()}} --></p>
<div id="exm-sim_data_adjust_prior_probs" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.6</strong></span> &nbsp;&nbsp;<strong>Adjusting prior probabilities in unbalanced synthetic two-class data</strong> &nbsp;&nbsp; Continuing the analysis in <a href="#exm-unbalsimdata" class="quarto-xref">Example&nbsp;<span>4.5</span></a>, the class prior probabilities are obtained as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">priorProbs</span> <span class="op">=</span> <span class="fu">classPriorProbs</span><span class="op">(</span><span class="va">mod</span>, <span class="va">x_test</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">##       0       1 </span></span>
<span><span class="co">## 0.89452 0.10548</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>which provides estimates that are close to the true parameters. These can then be used to adjust the predictions to get:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_test</span>, prop <span class="op">=</span> <span class="va">priorProbs</span><span class="op">)</span></span>
<span><span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, class <span class="op">=</span> <span class="va">class_test</span><span class="op">)</span><span class="op">$</span><span class="va">error</span></span>
<span><span class="co">## [1] 0.035</span></span>
<span><span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">class_test</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.025576</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The performance measures can be contrasted with those obtained from the (usually unknown) class proportions in the test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">prior_test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">class_test</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## class_test</span></span>
<span><span class="co">##     0     1 </span></span>
<span><span class="co">## 0.896 0.104</span></span>
<span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_test</span>, prop <span class="op">=</span> <span class="va">prior_test</span><span class="op">)</span></span>
<span><span class="fu">classError</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">classification</span>, class <span class="op">=</span> <span class="va">class_test</span><span class="op">)</span><span class="op">$</span><span class="va">error</span></span>
<span><span class="co">## [1] 0.0351</span></span>
<span><span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span>, <span class="va">class_test</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.025568</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section><section id="sec-classonedim" class="level2" data-number="4.7"><h2 data-number="4.7" class="anchored" data-anchor-id="sec-classonedim">
<span class="header-section-number">4.7</span> Classification of Univariate Data</h2>
<p>The classification of univariate data follows the same principles as discussed in previous sections, with the caveat that only two possible models are available in the EDDA case, namely <code>E</code> for equal within-class variance, and <code>V</code> for varying variances across classes. The same constraints on variances also apply to each mixture component within-class in MclustDA.</p>
<div id="exm-wdbc_lincomb_classif" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.7</strong></span> &nbsp;&nbsp;<strong>Classification of single-index linear combination for the Wisconsin diagnostic breast cancer data</strong></p>
<p>To increase the accuracy of breast cancer diagnosis and prognosis, <span class="citation" data-cites="Mangasarian:etal:1995">Mangasarian, Street, and Wolberg (<a href="99_references.html#ref-Mangasarian:etal:1995" role="doc-biblioref">1995</a>)</span> used linear programming to identify the linear combination of features that optimally discriminate the benign from the malignant tumor cases. The linear combination was estimated to be <span class="math display">\[
0.2322\;\mathtt{Texture\_mean} + 0.01117\;\mathtt{Area\_extreme} + 68.37\;\mathtt{Smoothness\_extreme}
\]</span> With this extracted feature the authors reported being able to achieve a cross-validated predictive accuracy of 97.5% (which is equivalent to 0.025 misclassification error rate).</p>
<p>To illustrate the use of Gaussian mixtures to classify univariate data, we fit an <code>MclustDA</code> model to the same one-dimensional projection of the UCI <code>wdbc</code> data:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"wdbc"</span>, package <span class="op">=</span> <span class="st">"mclust"</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">wdbc</span>, </span>
<span>    <span class="fl">0.2322</span><span class="op">*</span><span class="va">Texture_mean</span> <span class="op">+</span> <span class="fl">0.01117</span><span class="op">*</span><span class="va">Area_extreme</span> <span class="op">+</span> <span class="fl">68.37</span><span class="op">*</span><span class="va">Smoothness_extreme</span><span class="op">)</span></span>
<span><span class="va">Class</span> <span class="op">=</span> <span class="va">wdbc</span><span class="op">[</span>, <span class="st">"Diagnosis"</span><span class="op">]</span></span>
<span><span class="va">mod</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">x</span>, <span class="va">Class</span>, modelType <span class="op">=</span> <span class="st">"MclustDA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## Gaussian finite mixture model for classification </span></span>
<span><span class="co">## ------------------------------------------------ </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## MclustDA model summary: </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n df   BIC</span></span>
<span><span class="co">##         -1763.1 569 11 -3596</span></span>
<span><span class="co">##        </span></span>
<span><span class="co">## Classes   n     % Model G</span></span>
<span><span class="co">##       B 357 62.74     X 1</span></span>
<span><span class="co">##       M 212 37.26     V 3</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Training confusion matrix:</span></span>
<span><span class="co">##      Predicted</span></span>
<span><span class="co">## Class   B   M</span></span>
<span><span class="co">##     B 351   6</span></span>
<span><span class="co">##     M  14 198</span></span>
<span><span class="co">## Classification error = 0.0351 </span></span>
<span><span class="co">## Brier score          = 0.0226</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The selected model uses a single Gaussian component for the benign cancer cases and a three-component heterogeneous mixture for the malignant cases. The estimated within-class densities are shown in <a href="#fig-wdbcuniv1" class="quarto-xref">Figure&nbsp;<span>4.13</span></a>, indicating a bimodal distribution for the malignant tumors. This plot essentially agrees with previous findings reported in <span class="citation" data-cites="Mangasarian:etal:1995">Mangasarian, Street, and Wolberg (<a href="99_references.html#ref-Mangasarian:etal:1995" role="doc-biblioref">1995, fig. 3</a>)</span> using non-parametric density estimation. The following code can be used to obtain <a href="#fig-wdbcuniv1" class="quarto-xref">Figure&nbsp;<span>4.13</span></a>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">prop</span> <span class="op">=</span> <span class="va">mod</span><span class="op">$</span><span class="va">prop</span><span class="op">)</span></span>
<span><span class="co">##       B       M </span></span>
<span><span class="co">## 0.62742 0.37258</span></span>
<span><span class="va">col</span> <span class="op">=</span> <span class="fu">mclust.options</span><span class="op">(</span><span class="st">"classPlotColors"</span><span class="op">)</span></span>
<span><span class="va">x0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">*</span><span class="fl">1.1</span>, length <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">par1</span> <span class="op">=</span> <span class="va">mod</span><span class="op">$</span><span class="va">models</span><span class="op">[[</span><span class="st">"B"</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">parameters</span></span>
<span><span class="va">f1</span> <span class="op">=</span> <span class="fu">dens</span><span class="op">(</span><span class="va">par1</span><span class="op">$</span><span class="va">variance</span><span class="op">$</span><span class="va">modelName</span>, data <span class="op">=</span> <span class="va">x0</span>, parameters <span class="op">=</span> <span class="va">par1</span><span class="op">)</span></span>
<span><span class="va">par2</span> <span class="op">=</span> <span class="va">mod</span><span class="op">$</span><span class="va">models</span><span class="op">[[</span><span class="st">"M"</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">parameters</span></span>
<span><span class="va">f2</span> <span class="op">=</span> <span class="fu">dens</span><span class="op">(</span><span class="va">par2</span><span class="op">$</span><span class="va">variance</span><span class="op">$</span><span class="va">modelName</span>, data <span class="op">=</span> <span class="va">x0</span>, parameters <span class="op">=</span> <span class="va">par2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/matplot.html">matplot</a></span><span class="op">(</span><span class="va">x0</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">prop</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">*</span><span class="va">f1</span>, <span class="va">prop</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">*</span><span class="va">f2</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"l"</span>, lty <span class="op">=</span> <span class="fl">1</span>, </span>
<span>        col <span class="op">=</span> <span class="va">col</span>, ylab <span class="op">=</span> <span class="st">"Class density"</span>, xlab <span class="op">=</span> <span class="st">"x"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, title <span class="op">=</span> <span class="st">"Diagnosis:"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">prop</span><span class="op">)</span>, </span>
<span>       col <span class="op">=</span> <span class="va">col</span>, lty <span class="op">=</span> <span class="fl">1</span>, inset <span class="op">=</span> <span class="fl">0.02</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbcuniv1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbcuniv1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbcuniv1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbcuniv1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.13: Densities for the benign and malignant tumors estimated using the univariate feature extracted from the breast cancer dataset.
</figcaption></figure>
</div>
</div>
</div>
<p>The cross-validated misclassification error for the estimated MclustDA model is obtained as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cv</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span><span class="op">)</span>  <span class="co"># by default: prop = mod$prop</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">cv</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ce"</span>, <span class="st">"se.ce"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##        ce     se.ce </span></span>
<span><span class="co">## 0.0351494 0.0075474</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Adjusting the class prior probabilities, as suggested by <span class="citation" data-cites="Mangasarian:etal:1995">Mangasarian, Street, and Wolberg (<a href="99_references.html#ref-Mangasarian:etal:1995" role="doc-biblioref">1995</a>)</span>, we get:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cv</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span>, prop <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">cv</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ce"</span>, <span class="st">"se.ce"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##        ce     se.ce </span></span>
<span><span class="co">## 0.0263620 0.0071121</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Thus, assuming an equal class prior probability, the CV error rate goes down from 3.5% to 2.6%. It is possible to derive the corresponding discriminant thresholds numerically as:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x0</span><span class="op">)</span> </span>
<span><span class="op">(</span><span class="va">threshold1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/approxfun.html">approx</a></span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>, <span class="va">x0</span>, xout <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="co">## [1] 23.166</span></span>
<span><span class="va">pred</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x0</span>, prop <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">threshold2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/approxfun.html">approx</a></span><span class="op">(</span><span class="va">pred</span><span class="op">$</span><span class="va">z</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>, <span class="va">x0</span>, xout <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="co">## [1] 22.851</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that the first threshold is equivalent to the point where the two densities in <a href="#fig-wdbcuniv1" class="quarto-xref">Figure&nbsp;<span>4.13</span></a> intersect. Using the default discriminant threshold, we can represent the training data graphically with the observed and predicted classes:</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, what <span class="op">=</span> <span class="st">"scatterplot"</span>, main <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">threshold1</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod</span>, what <span class="op">=</span> <span class="st">"classification"</span>, main <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">threshold1</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-wdbcuniv2" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbcuniv2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-wdbcuniv2" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-wdbcuniv2-1" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-wdbcuniv2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbcuniv2-1.png" id="fig-wdbcuniv2-1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-wdbcuniv2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-wdbcuniv2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-wdbcuniv2" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-wdbcuniv2-2" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-wdbcuniv2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbcuniv2-2.png" id="fig-wdbcuniv2-2" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-wdbcuniv2">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-wdbcuniv2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbcuniv2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.14: Distribution of the training data conditional on the true classes and on the predicted classes for the univariate feature extracted from the breast cancer data.
</figcaption></figure>
</div>
<p>In the search for the optimal classification rule by cross-validation, we can proceed by tuning either the probability threshold for the decision rule or the prior class probabilities. The following code computes and plots the misclassification error rate as a function of the probability threshold used for the classification (see <a href="#fig-wdbcuniv3" class="quarto-xref">Figure&nbsp;<span>4.15</span></a>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">threshold</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span>, by <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="va">ngrid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">threshold</span><span class="op">)</span></span>
<span><span class="va">cv</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">threshold</span>, error <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">ngrid</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cverr</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">threshold</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">cv</span><span class="op">$</span><span class="va">error</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="fu">classError</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">cverr</span><span class="op">$</span><span class="va">z</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">&gt;</span> <span class="va">threshold</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="st">"M"</span>, <span class="st">"B"</span><span class="op">)</span>,</span>
<span>                            <span class="va">Class</span><span class="op">)</span><span class="op">$</span><span class="va">errorRate</span></span>
<span><span class="op">}</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cv</span><span class="op">$</span><span class="va">error</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.024605</span></span>
<span><span class="va">threshold</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">cv</span><span class="op">$</span><span class="va">error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">## [1] 0.35</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cv</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">threshold</span>, y <span class="op">=</span> <span class="va">error</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"CV misclassification error"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Probability threshold of malignant (M) tumor class"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbcuniv3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbcuniv3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbcuniv3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbcuniv3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.15: The cross-validated misclassification error rate as a function of the probability threshold for the univariate feature extracted from the breast cancer data.
</figcaption></figure>
</div>
</div>
</div>
<p>It is thus possible to get a misclassification error of 2.46% by setting the probability threshold to 0.35.</p>
<p>A similar result can also be achieved by adjusting the class prior probabilities. However, because the CV procedure must be replicated for each value specified over a regular grid, this is more computationally demanding. Nevertheless, the added computational effort has the advantage of providing an estimate of the standard error of the CV error estimate itself. This allows us to compute intervals around the CV estimate for assessing the significance of observed differences. The following code computes the CV misclassification error by adjusting the class prior probability of being a malignant tumor, followed by the code for plotting the CV results:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">priorProb</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span>, by <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="va">ngrid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">priorProb</span><span class="op">)</span></span>
<span><span class="va">cv_error2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">priorProb</span>, </span>
<span>                       cv <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">ngrid</span><span class="op">)</span>, </span>
<span>                       lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">ngrid</span><span class="op">)</span>, </span>
<span>                       upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">ngrid</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">priorProb</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">cv</span> <span class="op">=</span> <span class="fu">cvMclustDA</span><span class="op">(</span><span class="va">mod</span>, prop <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">priorProb</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="va">priorProb</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>, </span>
<span>                  verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">cv_error2</span><span class="op">$</span><span class="va">cv</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>    <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span></span>
<span>  <span class="va">cv_error2</span><span class="op">$</span><span class="va">lower</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">-</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span>  <span class="va">cv_error2</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="va">cv</span><span class="op">$</span><span class="va">ce</span> <span class="op">+</span> <span class="va">cv</span><span class="op">$</span><span class="va">se.ce</span></span>
<span><span class="op">}</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cv_error2</span><span class="op">$</span><span class="va">cv</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.026362</span></span>
<span><span class="va">priorProb</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">cv_error2</span><span class="op">$</span><span class="va">cv</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">## [1] 0.5</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cv_error2</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">priorProb</span>, y <span class="op">=</span> <span class="va">cv</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html">geom_linerange</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>ymin <span class="op">=</span> <span class="va">lower</span>, ymax <span class="op">=</span> <span class="va">upper</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"CV misclassification error"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Malignant (M) tumor class prior probability"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-wdbcuniv4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-wdbcuniv4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-wdbcuniv4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wdbcuniv4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.16: Plot of the CV misclassification error rate as a function of the class prior probability, with error bars shown at <span class="math inline">\(\pm\)</span> one standard error of the CV procedure, for the univariate feature extracted from the breast cancer data.
</figcaption></figure>
</div>
</div>
</div>
<p>By setting the class prior probabilities at 0.5 each, we get a misclassification error of 2.64%, which is similar to the result obtained by tuning the threshold. The strategy of assuming an equal prior class probability for each breast cancer class adopted by <span class="citation" data-cites="Mangasarian:etal:1995">Mangasarian, Street, and Wolberg (<a href="99_references.html#ref-Mangasarian:etal:1995" role="doc-biblioref">1995</a>)</span> appears to be the best approach available.</p>
</div>
</section><section id="sec-ssc" class="level2" data-number="4.8"><h2 data-number="4.8" class="anchored" data-anchor-id="sec-ssc">
<span class="header-section-number">4.8</span> Semi-Supervised Classification</h2>
<p>Supervised learning methods require knowing the correct class labels for the training data. However, in certain situations the available labeled data may be scarce because they are difficult or expensive to collect, for instance, in anomaly detection, computer-aided diagnosis, drug discovery, and speech recognition. Semi-supervised learning <!-- \index{semi-supervised learning}  --> refers to models and algorithms that use both labeled and unlabeled data to perform certain learning tasks [<span class="citation" data-cites="Zhu:Goldberg:2009">Zhu and Goldberg (<a href="99_references.html#ref-Zhu:Goldberg:2009" role="doc-biblioref">2009</a>)</span>; VanEngelenHoos:2020]. In classification scenarios, the main goal of semi-supervised learning is to train a classifier using both the labeled and unlabeled data such that its classification performance is better than the one obtained using a classifier trained on the labeled data alone.</p>
<div id="fig-ssc_example" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ssc_example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ssc_example" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ssc_example-1" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-ssc_example-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-ssc_example-1.png" id="fig-ssc_example-1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-ssc_example">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ssc_example-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ssc_example" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ssc_example-2" class="quarto-float quarto-figure quarto-figure-center anchored" width="100%" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-ssc_example-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-ssc_example-2.png" id="fig-ssc_example-2" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:100.0%" data-ref-parent="fig-ssc_example">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ssc_example-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ssc_example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.17: Example of two-class simulated dataset with (a) all labeled data (points are marked according to the true classes) and (b) only partial knowledge of labeled data (unlabeled data are shown as grey squares).
</figcaption></figure>
</div>
<p><a href="#fig-ssc_example" class="quarto-xref">Figure&nbsp;<span>4.17</span></a> shows a simulated two-class dataset with all the observations labeled (see left panel), and with only a few cases labeled (see right panel). In the typical supervised classification setting we would have access to the dataset in <a href="#fig-ssc_example-1" class="quarto-xref">Figure&nbsp;<span>4.17 (a)</span></a> where labels are available for all the observations. When most of the labels are unknown, as in <a href="#fig-ssc_example-2" class="quarto-xref">Figure&nbsp;<span>4.17 (b)</span></a>, two possible approaches are available. We could use only the (few) labeled cases to estimate a classifier, or we could use both labeled and unlabeled data in a semi-supervised learning approach.</p>
<p><a href="#fig-ssc_example2" class="quarto-xref">Figure&nbsp;<span>4.18</span></a> shows the classification boundaries corresponding to a supervised classification model estimated under the assumption that the true classes are known (solid line), the boundary for the classification model trained on the labeled data alone (dotted line), and the boundary obtained from a semi-supervised classification model (dashed line). The latter coincides almost exactly with the boundary arising from the full knowledge of class labels. In contrast, the classification boundary from the model estimated using only the labeled data is quite different.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ssc_example2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ssc_example2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-ssc_example2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ssc_example2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.18: Classification boundaries for the two-class simulated dataset obtained (i) under the assumption of full knowledge of class labels (cyan solid line), (ii) using only the labeled data (black dashed line), and (iii) both labeled and unlabeled data (black dotted line).
</figcaption></figure>
</div>
</div>
</div>
<p>Consider a training dataset <span class="math inline">\(\mathcal{D}_\text{train}\)</span> made of both <span class="math inline">\(l\)</span> labeled cases <span class="math inline">\(\{ (\boldsymbol{x}_i, y_i) \}_{i=1}^l\)</span> and <span class="math inline">\(u\)</span> unlabeled cases <span class="math inline">\(\{ \boldsymbol{x}_j \}_{j=l+1}^{n}\)</span>, where <span class="math inline">\(n = l + u\)</span> is the overall sample size. As mentioned earlier, there are usually many more unlabeled than labeled data, so we assume that <span class="math inline">\(u \gg l\)</span>. The likelihood of a semi-supervised mixture model <!-- \index{semi-supervised learning!likelihood}  --> depends on both the labeled and the unlabeled data, so the observed log-likelihood is <span class="math display">\[
\ell(\boldsymbol{\Psi}) = \sum_{i=1}^l \sum_{k=1}^K c_{ik} \log\left\{ \pi_k f_k(\boldsymbol{x}_i ; \boldsymbol{\theta}_k) \right\} +
              \sum_{j=l+1}^{n} \log\left\{ \sum_{g=1}^G \pi_g f_g(\boldsymbol{x}_j ; \boldsymbol{\theta}_g) \right\},
\]</span> where <span class="math inline">\(c_{ik} = 1\)</span> if observation <span class="math inline">\(i\)</span> belongs to class <span class="math inline">\(k\)</span> and <span class="math inline">\(0\)</span> otherwise. Although in principle the number of components <span class="math inline">\(G\)</span> can be greater than the number of classes <span class="math inline">\(K\)</span>, it is usually assumed that <span class="math inline">\(G = K\)</span>.</p>
<p>If we treat the unknown labels as missing data, the complete-data log-likelihood <!-- \index{semi-supervised learning!complete-data likelihood}  --> can be written as <span class="math display">\[\begin{align*}
\ell_C(\boldsymbol{\Psi}) = &amp; \sum_{i=1}^l \sum_{k=1}^K c_{ik} \left\{ \log(\pi_k) + \log(f_k(\boldsymbol{x}_i ; \boldsymbol{\theta}_k)) \right\} + \\
                &amp; \sum_{j=l+1}^{n} \sum_{g=1}^G z_{jg} \left\{ \log(\pi_g) + \log(f_g(\boldsymbol{x}_j ; \boldsymbol{\theta}_g)) \right\},
\end{align*}\]</span> {#eq-ssmixcloglik} where <span class="math inline">\(z_{jg} \in (0,1)\)</span> is the conditional probability of observation <span class="math inline">\(j\)</span> to belong to class <span class="math inline">\(g\)</span>. By assuming a specific parametric distribution for the class and component densities, such as the multivariate Gaussian distribution, the EM algorithm can be used to find maximum likelihood estimates for the unknown parameters of the model. The estimated parameters are then used to classify the unlabeled data, as well as future data. More details can be found in <span class="citation" data-cites="McLachlan:1977">G. J. McLachlan (<a href="99_references.html#ref-McLachlan:1977" role="doc-biblioref">1977</a>)</span>, <span class="citation" data-cites="ONeill:1978">O’Neill (<a href="99_references.html#ref-ONeill:1978" role="doc-biblioref">1978</a>)</span>, #McLachlan:Peel:2000 [section 2.19] and <span class="citation" data-cites="Dean:Murphy:Downey:2006">Dean, Murphy, and Downey (<a href="99_references.html#ref-Dean:Murphy:Downey:2006" role="doc-biblioref">2006</a>)</span>.</p>
<p><strong>mclust</strong> provides an implementation for fitting Gaussian semi-supervised classification models through the function <code>MclustSSC()</code>. <!-- \index{mclust!\code{MclustSSC()}} --> This requires the input of a data matrix and a vector of class labels, %in which <code>NA</code> with unlabeled data encoded by <code>NA</code>. By default all the available models are fitted and the one with the largest BIC is returned. Optionally, the covariance decompositions described in <a href="02_mixture.html#sec-eigendecomp" class="quarto-xref"><span>Section 2.2.1</span></a> can be specified via the argument <code>modelNames</code> using the usual nomenclature from <a href="02_mixture.html#tbl-covar_param" class="quarto-xref">Table&nbsp;<span>2.1</span></a>. In addition, the optional argument <code>G</code> can be used to specify the number of mixture components. By default, this is set equal to the number of classes from the labeled data.</p>
<div id="exm-olive" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.8</strong></span> &nbsp;&nbsp;<strong>Semi-supervised learning of Italian olive oils data</strong></p>
<p>Consider the Italian olive oils dataset available in the <strong>pgmm</strong> R package <span class="citation" data-cites="Rpkg:pgmm">(<a href="99_references.html#ref-Rpkg:pgmm" role="doc-biblioref">McNicholas et al. 2022</a>)</span>. The data are from a study conducted to determine the authenticity of olive oil <span class="citation" data-cites="Forina:1983">(<a href="99_references.html#ref-Forina:1983" role="doc-biblioref">Forina et al. 1983</a>)</span> and provide the percentage composition of eight fatty acids found by lipid fraction of 572 Italian olive oils. The olive oils came from nine areas of Italy, which can be further grouped into three regions: Southern Italy, Sardinia, and Northern Italy. The following code reads the data, sets the data frame <code>X</code> of features to build the classifier, and creates the factor <code>class</code> containing the labels for all the observations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"olive"</span>, package <span class="op">=</span> <span class="st">"pgmm"</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="va">olive</span><span class="op">[</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span><span class="va">class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">olive</span><span class="op">$</span><span class="va">Region</span>, levels <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>                labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"South"</span>, <span class="st">"Sardinia"</span>, <span class="st">"North"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">class</span><span class="op">)</span></span>
<span><span class="co">## class</span></span>
<span><span class="co">##    South Sardinia    North </span></span>
<span><span class="co">##      323       98      151</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Knowing all the class labels, we can easily fit a discriminant analysis model using the EDDA mixture model discussed in <a href="#sec-gaussmixmodclas" class="quarto-xref"><span>Section 4.2</span></a>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod_EDDA_full</span> <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X</span>, <span class="va">class</span>, modelType <span class="op">=</span> <span class="st">"EDDA"</span><span class="op">)</span></span>
<span><span class="va">pred_EDDA_full</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_EDDA_full</span>, newdata <span class="op">=</span> <span class="va">X</span><span class="op">)</span></span>
<span><span class="fu">classError</span><span class="op">(</span><span class="va">pred_EDDA_full</span><span class="op">$</span><span class="va">classification</span>, <span class="va">class</span><span class="op">)</span><span class="op">$</span><span class="va">errorRate</span></span>
<span><span class="co">## [1] 0</span></span>
<span><span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred_EDDA_full</span><span class="op">$</span><span class="va">z</span>, <span class="va">class</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.00000010836</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This model has very good performance, as measured by the classification error and the Brier score, although we must remember that this is an optimistic assessment of model performance because both metrics are computed on the data used for training. Despite this, we can use this performance as a benchmark.</p>
<p>Suppose that only partial knowledge of class labels is available. For instance, we can randomly retain only 10% of the labels as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pct_labeled_data</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span><span class="va">cl</span> <span class="op">=</span> <span class="va">class</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">pct_labeled_data</span><span class="op">/</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">cl</span>, useNA <span class="op">=</span> <span class="st">"ifany"</span><span class="op">)</span></span>
<span><span class="co">## cl</span></span>
<span><span class="co">##    South Sardinia    North     &lt;NA&gt; </span></span>
<span><span class="co">##       28       11       18      515</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since approximately 90% of the data are unlabeled, a semi-supervised classification is called for:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod_SSC</span> <span class="op">=</span> <span class="fu">MclustSSC</span><span class="op">(</span><span class="va">X</span>, <span class="va">cl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mod_SSC</span>, what <span class="op">=</span> <span class="st">"BIC"</span><span class="op">)</span></span>
<span><span class="va">mod_SSC</span><span class="op">$</span><span class="va">BIC</span></span>
<span><span class="co">##      EII    VII    EEI    VEI    EVI    VVI    EEE    VEE    EVE    VVE</span></span>
<span><span class="co">## 3 -55641 -55449 -48321 -47813 -47057 -47073 -44348 -44140 -43640 -43323</span></span>
<span><span class="co">##      EEV    VEV    EVV    VVV</span></span>
<span><span class="co">## 3 -43829 -43539 -43191 -42768</span></span>
<span><span class="fu">pickBIC</span><span class="op">(</span><span class="va">mod_SSC</span><span class="op">$</span><span class="va">BIC</span>, <span class="fl">5</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">mod_SSC</span><span class="op">$</span><span class="va">BIC</span><span class="op">)</span>  <span class="co"># BIC diff for the top-5 models</span></span>
<span><span class="co">##   VVV,3   EVV,3   VVE,3   VEV,3   EVE,3 </span></span>
<span><span class="co">##    0.00 -422.20 -554.53 -770.71 -871.55</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-olive_ssc" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-olive_ssc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-olive_ssc-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-olive_ssc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.19: BIC values for the semi-supervised classification models fitted to the Italian olive oils data using 10% of labeled data.
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-olive_ssc" class="quarto-xref">Figure&nbsp;<span>4.19</span></a> plots the BIC values for the models fitted by <code>MclustSSC()</code> with <span class="math inline">\(G= K = 3\)</span> classes. The best estimated model according to BIC is the unconstrained <code>VVV</code> model. The <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> <!-- \index{mclust!\code{summary.MclustSSC()}}  --> function can be used to obtain a summary of the fit:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_SSC</span><span class="op">)</span></span>
<span><span class="co">## ---------------------------------------------------------------- </span></span>
<span><span class="co">## Gaussian finite mixture model for semi-supervised classification </span></span>
<span><span class="co">## ---------------------------------------------------------------- </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##  log-likelihood   n  df    BIC</span></span>
<span><span class="co">##          -20959 572 134 -42768</span></span>
<span><span class="co">##           </span></span>
<span><span class="co">## Classes      n     % Model G</span></span>
<span><span class="co">##   South     28  4.90   VVV 1</span></span>
<span><span class="co">##   Sardinia  11  1.92   VVV 1</span></span>
<span><span class="co">##   North     18  3.15   VVV 1</span></span>
<span><span class="co">##   &lt;NA&gt;     515 90.03        </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Classification summary:</span></span>
<span><span class="co">##           Predicted</span></span>
<span><span class="co">## Class      South Sardinia North</span></span>
<span><span class="co">##   South       28        0     0</span></span>
<span><span class="co">##   Sardinia     0       11     0</span></span>
<span><span class="co">##   North        0        0    18</span></span>
<span><span class="co">##   &lt;NA&gt;       295       86   134</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can evaluate the estimated classifier by comparing the predicted classes with the true classes for the unlabeled observations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred_SSC</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_SSC</span>, newdata <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Predicted <span class="op">=</span> <span class="va">pred_SSC</span><span class="op">$</span><span class="va">classification</span>, Class <span class="op">=</span> <span class="va">class</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##           Class</span></span>
<span><span class="co">## Predicted  South Sardinia North</span></span>
<span><span class="co">##   South      295        0     0</span></span>
<span><span class="co">##   Sardinia     0       86     0</span></span>
<span><span class="co">##   North        0        1   133</span></span>
<span><span class="fu">classError</span><span class="op">(</span><span class="va">pred_SSC</span><span class="op">$</span><span class="va">classification</span>, <span class="va">class</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">$</span><span class="va">errorRate</span></span>
<span><span class="co">## [1] 0.0019417</span></span>
<span><span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred_SSC</span><span class="op">$</span><span class="va">z</span>, <span class="va">class</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.0019417</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The performance appears quite good with only one unlabeled observation misclassified.</p>
<p>We now compare the semi-supervised approach with the classification approach that uses only the labeled data, as a function of the percentage of full data information. The following code implements this comparison using the Brier score as performance metric:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pct_labeled_data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">90</span>, by <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>, <span class="fl">95</span><span class="op">)</span></span>
<span><span class="va">BS</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">pct_labeled_data</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span>,</span>
<span>             dimnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">pct_labeled_data</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"EDDA"</span>, <span class="st">"SSC"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">pct_labeled_data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">cl</span> <span class="op">=</span> <span class="va">class</span></span>
<span>  <span class="va">labeled</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">pct_labeled_data</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">/</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">cl</span><span class="op">[</span><span class="op">-</span><span class="va">labeled</span><span class="op">]</span> <span class="op">=</span> <span class="cn">NA</span></span>
<span>  <span class="co"># Classification on labeled data</span></span>
<span>  <span class="va">mod_EDDA</span>  <span class="op">=</span> <span class="fu">MclustDA</span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">labeled</span>, <span class="op">]</span>, <span class="va">cl</span><span class="op">[</span><span class="va">labeled</span><span class="op">]</span>, </span>
<span>                        modelType <span class="op">=</span> <span class="st">"EDDA"</span><span class="op">)</span></span>
<span>  <span class="co"># prediction for the unlabeled data</span></span>
<span>  <span class="va">pred_EDDA</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_EDDA</span>, newdata <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">labeled</span>, <span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">BS</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span>  <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred_EDDA</span><span class="op">$</span><span class="va">z</span>, <span class="va">class</span><span class="op">[</span><span class="op">-</span><span class="va">labeled</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="co"># Semi-supervised classification</span></span>
<span>  <span class="va">mod_SSC</span>  <span class="op">=</span> <span class="fu">MclustSSC</span><span class="op">(</span><span class="va">X</span>, <span class="va">cl</span><span class="op">)</span></span>
<span>  <span class="co"># prediction for the unlabeled data</span></span>
<span>  <span class="va">pred_SSC</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_SSC</span>, newdata <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">labeled</span>, <span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">BS</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred_SSC</span><span class="op">$</span><span class="va">z</span>, <span class="va">class</span><span class="op">[</span><span class="op">-</span><span class="va">labeled</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">BS</span></span>
<span><span class="co">##                   EDDA                 SSC</span></span>
<span><span class="co">## 5  0.36757342343703858 0.00184075724060626</span></span>
<span><span class="co">## 10 0.14649511848830127 0.00194083725139750</span></span>
<span><span class="co">## 20 0.00000004794698661 0.00218238248453443</span></span>
<span><span class="co">## 30 0.00500200204812944 0.00000000044264099</span></span>
<span><span class="co">## 40 0.00356335895644648 0.00000009331253357</span></span>
<span><span class="co">## 50 0.01740046202639491 0.00349653566200317</span></span>
<span><span class="co">## 60 0.00000033388757151 0.00000014123579678</span></span>
<span><span class="co">## 70 0.00585344025094451 0.00000037530321144</span></span>
<span><span class="co">## 80 0.00002069320555273 0.00000027964277368</span></span>
<span><span class="co">## 90 0.00000000012729332 0.00000000000499843</span></span>
<span><span class="co">## 95 0.00000000000069483 0.00000000000052263</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/matplot.html">matplot</a></span><span class="op">(</span><span class="va">pct_labeled_data</span>, <span class="va">BS</span>, type <span class="op">=</span> <span class="st">"b"</span>, </span>
<span>        lty <span class="op">=</span> <span class="fl">1</span>, pch <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">19</span>, <span class="fl">15</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span>, xaxt <span class="op">=</span> <span class="st">"n"</span>,</span>
<span>        xlab <span class="op">=</span> <span class="st">"Percentage of labeled data"</span>, ylab <span class="op">=</span> <span class="st">"Brier score"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span>, at <span class="op">=</span> <span class="va">pct_labeled_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fu">BrierScore</span><span class="op">(</span><span class="va">pred_EDDA_full</span><span class="op">$</span><span class="va">z</span>, <span class="va">class</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, pch <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">19</span>, <span class="fl">15</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">1</span>, </span>
<span>       legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"EDDA"</span>, <span class="st">"SSC"</span><span class="op">)</span>, inset <span class="op">=</span> <span class="fl">0.02</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-olive_ssc_sim" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-olive_ssc_sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/fig-olive_ssc_sim-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-olive_ssc_sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.20: Brier score values for the EDDA classification model on labeled data and the semi-supervised classification (SSC) model as a function of the percentage of labeled data.
</figcaption></figure>
</div>
</div>
</div>
<p>Looking at the table of results and <a href="#fig-olive_ssc_sim" class="quarto-xref">Figure&nbsp;<span>4.20</span></a>, it is clear that EDDA requires a large percentage of labeled data to achieve a reasonable performance. In contrast, the semi-supervised classification (SSC) model is able to achieve almost perfect classification accuracy with a very small portion of labeled data.</p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Alpaydin:2014" class="csl-entry" role="listitem">
Alpaydin, Ethem. 2014. <em>Introduction to Machine Learning</em>. 3rd ed. MIT Press.
</div>
<div id="ref-Altman:1968" class="csl-entry" role="listitem">
Altman, Edward I. 1968. <span>“Financial Ratios, Discriminant Analysis and the Prediction of Corporate Bankruptcy.”</span> <em>The Journal of Finance</em> 23 (4): 589–609.
</div>
<div id="ref-Bates:etal:2021" class="csl-entry" role="listitem">
Bates, Stephen, Trevor Hastie, and Robert Tibshirani. 2021. <span>“Cross-Validation: What Does It Estimate and How Well Does It Do It?”</span> <em>arXiv Preprint</em>. <a href="https://arxiv.org/abs/2104.00673">https://arxiv.org/abs/2104.00673</a>.
</div>
<div id="ref-Bensmail:Celeux:1996" class="csl-entry" role="listitem">
Bensmail, H., and G. Celeux. 1996. <span>“Regularized <span>G</span>aussian Discriminant Analysis Through Eigenvalue Decomposition.”</span> <em>Journal of the American Statistical Association</em> 91: 1743–48.
</div>
<div id="ref-Bishop:2006" class="csl-entry" role="listitem">
Bishop, Christopher. 2006. <em>Pattern Recognition and Machine Learning</em>. New York: Springer-Verlag Inc.
</div>
<div id="ref-Breiman:etal:1984" class="csl-entry" role="listitem">
Breiman, L., J. Friedman, R. Olshen, and C. J. Stone. 1984. <em>Classification and Regression Trees</em>. New York: Wadsworth.
</div>
<div id="ref-Brier:1950" class="csl-entry" role="listitem">
Brier, Glenn W. 1950. <span>“Verification of Forecasts Expressed in Terms of Probability.”</span> <em>Monthly Weather Review</em> 78 (1): 1–3.
</div>
<div id="ref-Davis:Goadrich:2006" class="csl-entry" role="listitem">
Davis, J., and M. Goadrich. 2006. <span>“The Relationship Between Precision-Recall and <span>ROC</span> Curves.”</span> In <em>Proceedings of the 23rd International Conference on Machine Learning</em>, 233–40.
</div>
<div id="ref-Dean:Murphy:Downey:2006" class="csl-entry" role="listitem">
Dean, Nema, Thomas Brendan Murphy, and Gerard Downey. 2006. <span>“Using Unlabelled Data to Update Classification Rules with Applications in Food Authenticity Studies.”</span> <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 55 (1): 1–14.
</div>
<div id="ref-UCI:dataset" class="csl-entry" role="listitem">
Dua, Dheeru, and Casey Graff. 2017. <span>“<span>UCI</span> <span>Machine</span> <span>Learning</span> <span>Repository</span>.”</span> University of California, Irvine, School of Information; Computer Sciences. <a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>.
</div>
<div id="ref-Forina:1983" class="csl-entry" role="listitem">
Forina, M., C. Armanino, S. Lanteri, and E. Tiscornia. 1983. <span>“Classification of Olive Oils from Their Fatty Acid Composition.”</span> In <em>Food Research and Data Analysis</em>, edited by H. Martens and H. Russwurm Jr., 189–214. London: Applied Science Publishers.
</div>
<div id="ref-Fraley:Raftery:2002" class="csl-entry" role="listitem">
Fraley, C., and A. E. Raftery. 2002. <span>“Model-Based Clustering, Discriminant Analysis, and Density Estimation.”</span> <em>Journal of the American Statistical Association</em> 97 (458): 611–31.
</div>
<div id="ref-Gneiting:Raftery:2007" class="csl-entry" role="listitem">
Gneiting, Tilmann, and Adrian E Raftery. 2007. <span>“Strictly Proper Scoring Rules, Prediction, and Estimation.”</span> <em>Journal of the American Statistical Association</em> 102 (477): 359–78.
</div>
<div id="ref-Grau:Grosse:Keilwagen:2015" class="csl-entry" role="listitem">
Grau, Jan, Ivo Grosse, and Jens Keilwagen. 2015. <span>“<span>PRROC</span>: Computing and Visualizing Precision-Recall and Receiver Operating Characteristic Curves in <span>R</span>.”</span> <em>Bioinformatics</em> 31 (15): 2595–97.
</div>
<div id="ref-Hastie:Tibshirani:1996" class="csl-entry" role="listitem">
Hastie, Trevor, and Robert Tibshirani. 1996. <span>“Discriminant Analysis by <span>G</span>aussian Mixtures.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 58 (1): 155–76.
</div>
<div id="ref-Hastie:Tibshirani:Friedman:2009" class="csl-entry" role="listitem">
Hastie, T., R. Tibshirani, and J. H. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd ed. Springer-Verlag. <a href="http://www-stat.stanford.edu/%7Etibs/ElemStatLearn/">http://www-stat.stanford.edu/%7Etibs/ElemStatLearn/</a>.
</div>
<div id="ref-Keilwagen:Grosse:Grau:2014" class="csl-entry" role="listitem">
Keilwagen, Jens, Ivo Grosse, and Jan Grau. 2014. <span>“Area Under Precision-Recall Curves for Weighted and Unweighted Data.”</span> <em>PLOS ONE</em> 9 (3).
</div>
<div id="ref-Kohavi:1995" class="csl-entry" role="listitem">
Kohavi, Ron. 1995. <span>“A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection.”</span> In <em>Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2</em>, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</div>
<div id="ref-Kruppa:etal:2014a" class="csl-entry" role="listitem">
Kruppa, Jochen, Yufeng Liu, Gérard Biau, Michael Kohler, Inke R König, James D Malley, and Andreas Ziegler. 2014. <span>“Probability Estimation with Machine Learning Methods for Dichotomous and Multicategory Outcome: Theory.”</span> <em>Biometrical Journal</em> 56 (4): 534–63.
</div>
<div id="ref-Kuhn:Johnson:2013" class="csl-entry" role="listitem">
Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-6849-3">https://doi.org/10.1007/978-1-4614-6849-3</a>.
</div>
<div id="ref-Lantz:2019" class="csl-entry" role="listitem">
Lantz, Brett. 2019. <em>Machine Learning with <span>R</span>: Expert Techniques for Predictive Modeling</em>. 3rd ed. Packt Publishing.
</div>
<div id="ref-Mangasarian:etal:1995" class="csl-entry" role="listitem">
Mangasarian, Olvi L, W Nick Street, and William H Wolberg. 1995. <span>“Breast Cancer Diagnosis and Prognosis via Linear Programming.”</span> <em>Operations Research</em> 43 (4): 570–77.
</div>
<div id="ref-McLachlan:2004" class="csl-entry" role="listitem">
McLachlan, Geoffrey. 2004. <em>Discriminant Analysis and Statistical Pattern Recognition</em>. New York: John Wiley &amp; Sons.
</div>
<div id="ref-McLachlan:1977" class="csl-entry" role="listitem">
McLachlan, Geoffrey John. 1977. <span>“Estimating the Linear Discriminant Function from Initial Samples Containing a Small Number of Unclassified Observations.”</span> <em>Journal of the American Statistical Association</em> 72 (358): 403–6.
</div>
<div id="ref-Rpkg:pgmm" class="csl-entry" role="listitem">
McNicholas, Paul D., Aisha ElSherbiny, Aaron F. McDaid, and T. Brendan Murphy. 2022. <em><span class="nocase">pgmm</span>: Parsimonious Gaussian Mixture Models</em>. <a href="https://CRAN.R-project.org/package=pgmm">https://CRAN.R-project.org/package=pgmm</a>.
</div>
<div id="ref-ONeill:1978" class="csl-entry" role="listitem">
O’Neill, Terence J. 1978. <span>“Normal Discrimination with Unclassified Observations.”</span> <em>Journal of the American Statistical Association</em> 73 (364): 821–26.
</div>
<div id="ref-Saerens:etal:2002" class="csl-entry" role="listitem">
Saerens, Marco, Patrice Latinne, and Christine Decaestecker. 2002. <span>“Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure.”</span> <em>Neural Computation</em> 14 (1): 21–41.
</div>
<div id="ref-Sing:etal:2005" class="csl-entry" role="listitem">
Sing, T., O. Sander, N. Beerenwinkel, and T. Lengauer. 2005. <span>“<span>ROCR</span>: Visualizing Classifier Performance in <span>R</span>.”</span> <em>Bioinformatics</em> 21 (20): 7881. <a href="http://rocr.bioinf.mpi-sb.mpg.de">http://rocr.bioinf.mpi-sb.mpg.de</a>.
</div>
<div id="ref-Street:etal:1993" class="csl-entry" role="listitem">
Street, W Nick, William H Wolberg, and Olvi L Mangasarian. 1993. <span>“Nuclear Feature Extraction for Breast Tumor Diagnosis.”</span> In <em>Biomedical Image Processing and Biomedical Visualization</em>, 1905:861–70. International Society for Optics; Photonics.
</div>
<div id="ref-Rpkg:MixGHD" class="csl-entry" role="listitem">
Tortora, Cristina, Aisha ElSherbiny, Ryan P. Browne, Brian C. Franczak, and Paul D. McNicholas, and Donald D. Amos. 2022. <em><span>MixGHD</span>: Model Based Clustering, Classification and Discriminant Analysis Using the Mixture of Generalized Hyperbolic Distributions</em>. <a href="https://CRAN.R-project.org/package=MixGHD">https://CRAN.R-project.org/package=MixGHD</a>.
</div>
<div id="ref-Zhu:Goldberg:2009" class="csl-entry" role="listitem">
Zhu, Xiaojin, and Andrew B Goldberg. 2009. <em>Introduction to Semi-Supervised Learning</em>. Vol. 3. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan &amp; Claypool Publishers.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>In stratified cross-validation the data are randomly split in such a way that maintains the same class distribution in each fold. This is of particular relevance in the case of unbalanced class distribution. Furthermore, it has been noted that “stratification is generally a better scheme, both in terms of bias and variance, when compared to regular cross-validation” <span class="citation" data-cites="Kohavi:1995">(<a href="99_references.html#ref-Kohavi:1995" role="doc-biblioref">Kohavi 1995</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../chapters/03_cluster.html" class="pagination-link" aria-label="Model-Based Clustering">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model-Based Clustering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/05_dens.html" class="pagination-link" aria-label="Model-Based Density Estimation">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Model-Based Density Estimation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Model-Based Clustering, Classification, and <br> Density Estimation Using mclust in R</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>