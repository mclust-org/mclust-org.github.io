[{"path":"https://mclust-org.github.io/clustvarsel/articles/clustvarsel.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A quick tour of clustvarsel","text":"clustvarsel package implements variable selection methodology Gaussian model-based clustering allows find (locally) optimal subset variables dataset group/cluster information. greedy headlong search can used, either forward-backward backward-forward direction, without sub-sampling hierarchical clustering stage starting mclust models. default algorithm uses sequential search, parallelisation also available. document gives quick tour clustvarsel (version 2.3.5) functionalities. written R Markdown, using knitr package production. See help(package=\"clustvarsel\") details references provided citation(\"clustvarsel\").","code":"library(mclust) library(clustvarsel)"},{"path":"https://mclust-org.github.io/clustvarsel/articles/clustvarsel.html","id":"simulated-clustering-data-example","dir":"Articles","previous_headings":"","what":"Simulated clustering data example","title":"A quick tour of clustvarsel","text":"example simulate dataset five dimensions first two variables contain clustering information, third highly correlated first one, remaining features simply noise variables.","code":"n <- 200      # sample size pro <- 0.5    # mixing proportion mu1 <- c(0,0) # mean vector for the first cluster mu2 <- c(3,3) # mean vector for the second cluster sigma1 <- matrix(c(1,0.5,0.5,1),2,2)       # covar matrix for the first cluster sigma2 <- matrix(c(1.5,-0.7,-0.7,1.5),2,2) # covar matrix for the second cluster X <- matrix(0, n, 5, dimnames = list(NULL, paste0(\"X\", 1:5))) set.seed(1234) # for replication u <- runif(n) Class <- ifelse(u < pro, 1, 2) X[u < pro, 1:2]  <- MASS::mvrnorm(sum(u < pro), mu = mu1, Sigma = sigma1) X[u >= pro, 1:2] <- MASS::mvrnorm(sum(u >= pro), mu = mu2, Sigma = sigma2) X[, 3] <- X[, 1] + rnorm(n) X[, 4] <- rnorm(n, mean = 1.5, sd = 2) X[, 5] <- rnorm(n, mean = 2, sd = 1) clPairs(X, Class) out <- clustvarsel(X) ## iter 1 ## + adding step ##   Var  BICdiff Step Decision ## 1  X2 11.17931  Add Accepted ## iter 2 ## + adding step ##   Var BICdiff Step Decision ## 2  X1 85.1953  Add Accepted ## iter 3  ## + adding step ## - removing step ##   Var   BICdiff   Step Decision ## 3  X3 -14.91130    Add Rejected ## 4  X1  85.19104 Remove Rejected ## final iter ## * fitting model on selected subset  out ## ------------------------------------------------------  ## Variable selection for Gaussian model-based clustering ## Stepwise (forward/backward) greedy search ## ------------------------------------------------------  ##  ##  Variable proposed Type of step   BICclust Model G   BICdiff Decision ##                 X2          Add  -822.6398     E 2  11.17931 Accepted ##                 X1          Add -1482.8408   VEV 2  85.19530 Accepted ##                 X3          Add -2047.7064   EEV 2 -14.91130 Rejected ##                 X1       Remove  -822.6355     E 2  85.19104 Rejected ##  ## Selected subset: X2, X1  summary(out$model) ## ----------------------------------------------------  ## Gaussian finite mixture model fitted by EM algorithm  ## ----------------------------------------------------  ##  ## Mclust VEV (ellipsoidal, equal shape) model with 2 components:  ##  ##  log.likelihood   n df       BIC       ICL ##       -714.9288 200 10 -1482.841 -1493.898 ##  ## Clustering table: ##   1   2  ##  99 101 out <- clustvarsel(X, direction = \"backward\", fit = FALSE) ## iter 1  ## - removing step ##   Var   BICdiff   Step Decision ## 1  X3 -38.09195 Remove Accepted ## iter 2  ## - removing step ##   Var   BICdiff   Step Decision ## 2  X4 -23.50212 Remove Accepted ## iter 3  ## - removing step ## + adding step ##   Var   BICdiff   Step Decision ## 3  X5 -16.25831 Remove Accepted ## 4  X3 -14.91130    Add Rejected ## iter 4  ## - removing step ## + adding step ##   Var   BICdiff   Step Decision ## 5  X1  95.55735 Remove Rejected ## 6  X3 -14.91130    Add Rejected  out ## ------------------------------------------------------  ## Variable selection for Gaussian model-based clustering ## Stepwise (backward/forward) greedy search ## ------------------------------------------------------  ##  ##  Variable proposed Type of step   BICclust Model G   BICdiff Decision ##                 X3       Remove -2925.4851   EVE 2 -38.09195 Accepted ##                 X4       Remove -2067.0668   EVE 2 -23.50212 Accepted ##                 X5       Remove -1482.8408   VEV 2 -16.25831 Accepted ##                 X3          Add -2047.7064   EEV 2 -14.91130 Rejected ##                 X1       Remove  -833.0019     V 2  95.55735 Rejected ##                 X3          Add -2047.7064   EEV 2 -14.91130 Rejected ##  ## Selected subset: X1, X2 out <- clustvarsel(X, search = \"headlong\") ## iter 1 ## + adding step ##   Var  BICdiff Step Decision ## 1  X2 11.17931  Add Accepted ## iter 2 ## + adding step ##   Var BICdiff Step Decision ## 2  X1 85.1953  Add Accepted ## iter 3  ## + adding step ## - removing step ##   Var  BICdiff   Step Decision ## 3  X3 -14.9113    Add Rejected ## 4  X1  85.1953 Remove Rejected ## final iter ## * fitting model on selected subset  out ## ------------------------------------------------------  ## Variable selection for Gaussian model-based clustering ## Headlong (forward/backward) search ## ------------------------------------------------------  ##  ##  Variable proposed Type of step   BICclust Model G   BICdiff Decision ##                 X2          Add  -822.6398     E 2  11.17931 Accepted ##                 X1          Add -1482.8408   VEV 2  85.19530 Accepted ##                 X3          Add -2047.7064   EEV 2 -14.91130 Rejected ##                 X1       Remove  -822.6398     E 2  85.19530 Rejected ##  ## Selected subset: X2, X1"},{"path":"https://mclust-org.github.io/clustvarsel/articles/clustvarsel.html","id":"simulated-no-clustering-data-example","dir":"Articles","previous_headings":"","what":"Simulated no-clustering data example","title":"A quick tour of clustvarsel","text":"example simulate dataset ten dimensions clustering. shown model-based clustering variables yield wrong conclusion 2 clusters present, subset selection Gaussian finite mixture model correctly select single cluster solution.  Model-based clustering available variables: Subset selection using forward/backward greedy algorithm: Note final clustering model shown clustvarsel() output EII 2 mixture components. However, model constrained G \\(\\ge\\) 2 components must clustering model. final model fitted selected variables without imposing constraint G, BIC correctly indicates single component model. Subset selection using backward/forward greedy algorithm: Although selected subset variables different obtained using forward greedy search, comments outlined previously apply .","code":"n <- 200 p <- 10 mu <- rep(0,p) sigma1 <- matrix(c(1,0.5,0.5,1),2,2) sigma2 <- matrix(c(1.5,-0.7,-0.7,1.5),2,2) sigma <- Matrix::bdiag(sigma1, sigma2, diag(6)) set.seed(12345) X <- MASS::mvrnorm(n, mu, sigma) colnames(X) <- paste0(\"X\", 1:p) clPairs(X) mod <- Mclust(X) summary(mod$BIC) ## Best BIC values: ##              EII,2       VII,2       EII,3 ## BIC      -5899.073 -5901.88582 -5922.53452 ## BIC diff     0.000    -2.81261   -23.46131 summary(mod) ## ---------------------------------------------------- ## Gaussian finite mixture model fitted by EM algorithm  ## ---------------------------------------------------- ##  ## Mclust EII (spherical, equal volume) model with 2 components: ##  ##  log.likelihood   n df       BIC       ICL ##       -2891.255 200 22 -5899.073 -5953.953 ##  ## Clustering table: ##   1   2  ##  90 110 (out1 <- clustvarsel(X, verbose = FALSE)) ## ------------------------------------------------------  ## Variable selection for Gaussian model-based clustering ## Stepwise (forward/backward) greedy search ## ------------------------------------------------------  ##  ##  Variable proposed Type of step   BICclust Model G    BICdiff Decision ##                 X3          Add  -666.9232     E 2 -4.8472740 Accepted ##                 X7          Add -1242.8998   EII 2  1.5678544 Accepted ##                X10          Add -1814.8848   EII 2  1.5172709 Accepted ##                X10       Remove -1242.8998   EII 2  1.5172709 Rejected ##                 X6          Add -2390.3224   EII 2  0.6539224 Accepted ##                 X6       Remove -1814.8848   EII 2  0.6539224 Rejected ##                 X2          Add -2942.2744   EII 2  0.1214452 Accepted ##                 X2       Remove -2390.3224   EII 2  0.1214452 Rejected ##                 X8          Add -3495.9758   EII 2  0.1104619 Accepted ##                 X8       Remove -2942.2744   EII 2  0.1104619 Rejected ##                 X9          Add -4081.9212   EII 2 -2.0296117 Rejected ##                 X8       Remove -2942.2744   EII 2  0.1104619 Rejected ##  ## Selected subset: X3, X7, X10, X6, X2, X8  summary(out1$model) # or # mod1 <- Mclust(X[,out1$subset]) # summary(mod1) ## ---------------------------------------------------- ## Gaussian finite mixture model fitted by EM algorithm  ## ---------------------------------------------------- ##  ## Mclust XII (spherical multivariate normal) model with 1 component: ##  ##  log.likelihood   n df       BIC       ICL ##       -1727.188 200  7 -3491.465 -3491.465 ##  ## Clustering table: ##   1  ## 200 (out2 <- clustvarsel(X, direction = \"backward\", verbose = FALSE)) ## ------------------------------------------------------  ## Variable selection for Gaussian model-based clustering ## Stepwise (backward/forward) greedy search ## ------------------------------------------------------  ##  ##  Variable proposed Type of step  BICclust Model G     BICdiff Decision ##                 X2       Remove -5346.204   EII 2 -48.0289667 Accepted ##                 X4       Remove -4696.525   EII 2  -7.1909995 Accepted ##                 X3       Remove -4032.114   EII 2  -2.3352781 Accepted ##                 X3          Add -4696.525   EII 2  -2.3352781 Rejected ##                 X7       Remove -3453.786   EII 2  -1.1967844 Accepted ##                 X7          Add -4032.114   EII 2  -1.1967844 Rejected ##                 X8       Remove -2899.545   EII 2  -0.4288443 Accepted ##                 X8          Add -3453.786   EII 2  -0.4288443 Rejected ##                 X5       Remove -2308.785   EII 2   1.0712786 Rejected ##                 X8          Add -3453.786   EII 2  -0.4288443 Rejected ##  ## Selected subset: X1, X5, X6, X9, X10  summary(out2$model) ## ---------------------------------------------------- ## Gaussian finite mixture model fitted by EM algorithm  ## ---------------------------------------------------- ##  ## Mclust XII (spherical multivariate normal) model with 1 component: ##  ##  log.likelihood   n df       BIC       ICL ##       -1424.072 200  6 -2879.934 -2879.934 ##  ## Clustering table: ##   1  ## 200"},{"path":"https://mclust-org.github.io/clustvarsel/articles/clustvarsel.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"A quick tour of clustvarsel","text":"Raftery, . E. Dean, N. (2006) Variable Selection Model-Based Clustering. Journal American Statistical Association, 101(473), 168-178. Maugis, C., Celeux, G., Martin-Magniette M. (2009) Variable Selection Clustering Gaussian Mixture Models. Biometrics, 65(3), 701-709. Scrucca, L. Raftery, . E. (2018) clustvarsel: Package Implementing Variable Selection Gaussian Model-based Clustering R. Journal Statistical Software, 84(1), pp. 1-28.","code":"sessionInfo() ## R version 4.2.2 (2022-10-31) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur ... 10.16 ##  ## Matrix products: default ## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib ##  ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] clustvarsel_2.3.5 mclust_6.0.0      knitr_1.42        ##  ## loaded via a namespace (and not attached): ##  [1] pcaPP_2.0-3       BMA_3.18.17       highr_0.10        DEoptimR_1.0-11   ##  [5] bslib_0.4.2       compiler_4.2.2    jquerylib_0.1.4   iterators_1.0.14  ##  [9] tools_4.2.2       digest_0.6.31     jsonlite_1.8.4    evaluate_0.20     ## [13] memoise_2.0.1     lifecycle_1.0.3   lattice_0.20-45   rlang_1.0.6       ## [17] Matrix_1.5-3      foreach_1.5.2     cli_3.6.0         yaml_2.3.7        ## [21] mvtnorm_1.1-3     pkgdown_2.0.7     xfun_0.37         fastmap_1.1.0     ## [25] stringr_1.5.0     desc_1.4.2        fs_1.6.1          vctrs_0.5.2       ## [29] sass_0.4.5        stats4_4.2.2      rprojroot_2.0.3   grid_4.2.2        ## [33] inline_0.3.19     glue_1.6.2        robustbase_0.95-0 rrcov_1.7-2       ## [37] R6_2.5.1          survival_3.4-0    rmarkdown_2.20    purrr_1.0.1       ## [41] magrittr_2.0.3    MASS_7.3-58.1     codetools_0.2-18  htmltools_0.5.4   ## [45] splines_4.2.2     leaps_3.1         stringi_1.7.12    cachem_1.0.6"},{"path":"https://mclust-org.github.io/clustvarsel/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nema Dean. Author. Adrian E. Raftery. Author. Luca Scrucca. Author, maintainer.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Scrucca L, Raftery AE (2018). “clustvarsel: Package Implementing Variable Selection Gaussian Model-Based Clustering R.” Journal Statistical Software, 84(1), 1–28. doi:10.18637/jss.v084.i01.","code":"@Article{,   title = {{clustvarsel}: A Package Implementing Variable Selection for Gaussian Model-Based Clustering in {R}},   author = {Luca Scrucca and Adrian E. Raftery},   journal = {Journal of Statistical Software},   year = {2018},   volume = {84},   number = {1},   pages = {1--28},   doi = {10.18637/jss.v084.i01}, }"},{"path":"https://mclust-org.github.io/clustvarsel/index.html","id":"clustvarsel","dir":"","previous_headings":"","what":"Variable Selection for Gaussian Model-Based Clustering","title":"Variable Selection for Gaussian Model-Based Clustering","text":"R package implementing Variable Selection Gaussian Model-Based Clustering. Variable selection Gaussian model-based clustering implemented mclust package. methodology allows find (locally) optimal subset variables data set group/cluster information. greedy headlong search can used, either forward-backward backward-forward direction, without sub-sampling hierarchical clustering stage starting mclust models. default algorithm uses sequential search, parallelisation also available.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Variable Selection for Gaussian Model-Based Clustering","text":"can install released version clustvarsel CRAN using:","code":"install.packages(\"clustvarsel\")"},{"path":"https://mclust-org.github.io/clustvarsel/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Variable Selection for Gaussian Model-Based Clustering","text":"Usage main functions several examples included papers shown references section . intro see vignette quick tour clustvarsel, available vignette also available Vignette section navigation bar top package’s web page.","code":"vignette(\"clustvarsel\")"},{"path":"https://mclust-org.github.io/clustvarsel/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Variable Selection for Gaussian Model-Based Clustering","text":"Raftery, . E. Dean, N. (2006) Variable Selection Model-Based Clustering. Journal American Statistical Association, 101(473), 168-178. Maugis, C., Celeux, G., Martin-Magniette M. (2009) Variable Selection Clustering Gaussian Mixture Models. Biometrics, 65(3), 701-709. Scrucca, L. Raftery, . E. (2018) clustvarsel: Package Implementing Variable Selection Gaussian Model-based Clustering R. Journal Statistical Software, 84(1), pp. 1-28.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal 'clustvarsel' functions — clustvarsel-internal","title":"Internal 'clustvarsel' functions — clustvarsel-internal","text":"Internal functions intended called directly users.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel-internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal 'clustvarsel' functions — clustvarsel-internal","text":"","code":"# S3 method for clustvarsel print(x, digits = getOption(\"digits\"), ...)   clvarselgrfwd(X, G = 1:9,               emModels1 = c(\"E\",\"V\"),                emModels2 = mclust.options(\"emModelNames\"),               samp = FALSE, sampsize = 2000,                hcModel = \"VVV\", allow.EEE = TRUE, forcetwo = TRUE,                BIC.diff = 0, itermax = 100,                parallel = FALSE, verbose = interactive())  clvarselgrbkw(X, G = 1:9,                emModels1 = c(\"E\",\"V\"),                emModels2 = mclust.options(\"emModelNames\"),               samp = FALSE, sampsize = 2000,                hcModel = \"VVV\", allow.EEE = TRUE, forcetwo = TRUE,                BIC.diff = 0, itermax = 100,               parallel = FALSE, verbose = interactive())  clvarselhlfwd(X, G = 1:9,               emModels1 = c(\"E\",\"V\"),                emModels2 = mclust.options(\"emModelNames\"),               samp = FALSE, sampsize = 2000,                hcModel = \"VVV\",               allow.EEE = TRUE, forcetwo = TRUE,                BIC.upper = 0, BIC.lower = -10,               itermax = 100, verbose = interactive())  clvarselhlbkw(X, G = 1:9,               emModels1 = c(\"E\",\"V\"),                emModels2 = mclust.options(\"emModelNames\"),               samp = FALSE, sampsize = 2000,                hcModel = \"VVV\",               allow.EEE = TRUE, forcetwo = TRUE,                BIC.upper = 0, BIC.lower = -10,               itermax = 100, verbose = interactive())  BICreg(x, y)  startParallel(parallel = TRUE, ...)"},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"function implements variable selection methodology model-based clustering allows find (locally) optimal subset variables dataset group/cluster information.  greedy headlong search can used, either forward-backward backward-forward direction, without sub-sampling hierarchical clustering stage starting  mclust models. default algorithm uses sequential search, parallelisation also available.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"","code":"clustvarsel(data,              G = 1:9,              search = c(\"greedy\", \"headlong\"),             direction = c(\"forward\", \"backward\"),             emModels1 = c(\"E\", \"V\"),              emModels2 = mclust.options(\"emModelNames\"),             samp = FALSE,              sampsize = round(nrow(data)/2),              hcModel = \"VVV\",              allow.EEE = TRUE,              forcetwo = TRUE,             BIC.diff = 0,              BIC.upper = 0,              BIC.lower = -10,              itermax = 100,              parallel = FALSE,             fit = TRUE,             verbose = interactive())"},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"data numeric matrix data frame rows correspond observations columns correspond variables. Categorical variables allowed. G integer vector specifying numbers mixture components (clusters) BIC calculated. default G = 1:9. search character vector indicating whether \"greedy\" , potentially quicker less optimal, \"headlong\" algorithm used search clustering variables. direction character vector indicating type search: \"forward\" starts empty model step algorithm adds/removes variable stopping criterion satisfied; \"backward\" starts model available variables step algorithm removes/adds variable stopping criterion satisfied. emModels1 vector character strings indicating models fitted EM phase univariate clustering. Possible models \"E\" \"V\", described mclustModelNames. emModels2 vector character strings indicating models fitted EM phase multivariate clustering. Possible models described mclustModelNames. samp logical value indicating whether subset observations used hierarchical clustering phase used get starting values EM algorithm. sampsize number observations used hierarchical clustering subset. default, random sample approximately half sample size used. hcModel character string specifying model used hierarchical clustering choosing starting values used EM algorithm. default, \"VVV\" covariance structure used (see hc). allow.EEE logical value indicating whether new clustering run equal within-cluster covariance hierarchical clustering get starting values, clusterings variable within-cluster covariance hierarchical clustering produce viable BIC values. forcetwo logical value indicating whether least two variables forced selected initially, regardless whether BIC evidence suggests bivariate clustering . BIC.diff numerical value indicating minimum BIC difference clustering clustering used accept inclusion variable set clustering variables forward step greedy search algorithm. Furthermore, minus BIC.diff used accept exclusion selected variable set clustering variable backward step greedy search algorithm. Default 0. BIC.upper numerical value indicating minimum BIC difference clustering clustering used select clustering variable headlong search. Default 0. BIC.lower numerical value indicating level BIC difference clustering clustering variable removed consideration headlong algorithm. Default -10. itermax integer value giving maximum number iterations (addition removal steps) selected algorithm allowed run . parallel optional argument allows specify selected \"greedy\" algorithm run sequentially parallel. single machine multiple cores, possible values : logical value specifying parallel computing used (TRUE) (FALSE, default) running algorithm; numerical value gives number cores employ. default, obtained function detectCores; character string specifying type parallelisation use. depends system OS: Windows OS \"snow\" type functionality available, Unix/Linux/Mac OSX \"snow\" \"multicore\" (default) functionalities available. cases described , end search cluster automatically stopped shutting workers. cluster multiple machines available, algorithm can run parallel using , subset , cores available machines belonging cluster. However, option requires work user, needs set register parallel back end.  case, cluster must explicitly stopped stopCluster. fit logical specifying model selected \"best\" subset fitted end procedure. default set TRUE. verbose logical indicating info must provided step algorithm. default set TRUE interactive sessions, FALSE otherwise.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"function implements variable selection methodology model-based clustering.  selection methods available \"greedy\" search \"headlong\" search (see argument search). greedy search step either checks variables currently included set clustering variables singly inclusion set, checks variables set clustering variables singly exclusion.  headlong search checks variable included excluded (.e., necessarily check possible variables inclusion/exclusion step) variable evidence clustering certain level stage removed consideration remainder algorithm.  Greedy search can performed forward-backward starting empty model, backward-forward starting model variables included (see argument direction). Currently, headlong search can run forward-backward. criterion assess variable's evidence useful clustering given difference BIC clustering model using set clustering variables already included variable checked, sum BICs model clustering using set already selected clustering variables without variable checked model variable checked conditionally independent clustering given clustering variables. latter modeled regression variable checked clustering variables. subset selection procedure also performed regression step. Clustering models fitted using Mclust, model allowed vary specified number components G different covariance parameterisations set emModels1 emModels2. default value forcetwo TRUE often practice little evidence clustering univariate bivariate level although multivariate clustering present variables used starting points attempt find clustering, necessary removed later algorithm. default value allow.EEE TRUE necessary speed algorithm can set FALSE. speeding-restrictions include reducing emModels1 (\"E\", say) emModels2 smaller set covariance parameterisations.  Reducing maximum possible number clusters present data also increase speed algorithm. Another time-saving device samp option uses algorithm uses subset observations expensive hierarchical phase initialisation EM algorithm Mclust.  Finally, headlong search may quicker greedy search option data sets large numbers variables (depending values upper lower bounds chosen BIC difference). defaults eps, tol itmax options Mclust steps run algorithm can changed using mclust.options function.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"object class 'clustvarsel' following components: variables name input variables. subset vector values specifying selected variables columns position input data.frame matrix. steps.info matrix row step algorithm providing: name variable proposed; BIC clustering variables' model end step; BIC difference clustering clustering variable; type step (Add/Remove); decision proposed step (Accepted/Rejected). search string specifying type search employed. direction string specifying direction search employed. model input argument fit = TRUE, 'Mclust' object containing final model fitted \"best\" subset selected.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"Raftery, . E. Dean, N. (2006) Variable Selection Model-Based Clustering. Journal American Statistical Association, 101(473), 168-178. Badsberg, J. H. (1992) Model search contingency tables CoCo. Dodge, Y. Whittaker, J. (Eds.), Computational Statistics, Volume 1, pp. 251-256 Maugis, C., Celeux, G., Martin-Magniette M. (2009) Variable Selection Clustering Gaussian Mixture Models. Biometrics, 65(3), 701-709. Scrucca, L. Raftery, . E. (2018) clustvarsel: Package Implementing Variable Selection Gaussian Model-based Clustering R. Journal Statistical Software, 84(1), pp. 1-28.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"N. Dean, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/clustvarsel/reference/clustvarsel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variable Selection for Gaussian Model-Based Clustering — clustvarsel","text":"","code":"# Simulate data with 2 clusters in the first two variables and no  # clustering in the rest. Clusters have mixing proportion pro, means  # mu1 and mu2 and variances sigma1 and sigma2 require(MASS) #> Loading required package: MASS n <- 200 pro <- 0.5 mu1 <- c(0,0) mu2 <- c(3,3) sigma1 <- matrix(c(1,0.5,0.5,1),2,2,byrow=TRUE) sigma2 <- matrix(c(1.5,-0.7,-0.7,1.5),2,2,byrow=TRUE) X <- matrix(0, n, 5) colnames(X) <- paste(\"X\", 1:ncol(X), sep =\"\") # generate the clustering variables u <- runif(n) Class <- ifelse(u < pro, 1, 2) X[u < pro, 1:2]  <- mvrnorm(sum(u < pro), mu = mu1, Sigma = sigma1) X[u >= pro, 1:2] <- mvrnorm(sum(u >= pro), mu = mu2, Sigma = sigma2) # generate the non-clustering variables X[,3] <- X[,1] + rnorm(n) X[,4] <- rnorm(n, mean = 1.5, sd = 2) X[,5] <- rnorm(n, mean = 2, sd = 1) # plot the data clPairs(X, Class, gap = 0)   # sequential forward greedy search (default) out <- clustvarsel(X, G = 1:5) out #> ------------------------------------------------------  #> Variable selection for Gaussian model-based clustering #> Stepwise (forward/backward) greedy search #> ------------------------------------------------------  #>  #>  Variable proposed Type of step   BICclust Model G   BICdiff Decision #>                 X2          Add  -812.6091     E 2  12.33430 Accepted #>                 X1          Add -1462.9877   VVE 2 100.46838 Accepted #>                 X3          Add -2080.0263   VEV 2 -17.41359 Rejected #>                 X1       Remove  -812.6098     E 2 100.46913 Rejected #>  #> Selected subset: X2, X1 summary(out$model) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VVE (ellipsoidal, equal orientation) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -705.0023 200 10 -1462.988 -1475.214 #>  #> Clustering table: #>   1   2  #> 112  88  table(Class, out$mod$classification) #>       #> Class   1   2 #>     1   3  87 #>     2 109   1  if (FALSE) { # sequential backward greedy search clustvarsel(X, G = 1:5, direction = \"backward\")  # sequential backward greedy search with subsampling at hierarchical  # intialisation stage clustvarsel(X, G = 1:5, direction = \"backward\",              samp = TRUE, sampsize = 50)  # parallel backward greedy search  clustvarsel(X, G = 1:5, direction = \"backward\", parallel = TRUE)  # headlong search  clustvarsel(X, G = 1:5, search = \"headlong\") }"},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-235-2021-11-not-on-cran","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3.5 (2021-11) NOT ON CRAN","title":"clustvarsel 2.3.5 (2021-11) NOT ON CRAN","text":"Explicitly defines use current value mclust.options(\"hcUse\") initialization models estimation.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-234-2020-12","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3.4 (2020-12)","title":"clustvarsel 2.3.4 (2020-12)","text":"CRAN release: 2020-12-16 Bug fixes polish.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-233-2018-11","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3.3 (2018-11)","title":"clustvarsel 2.3.3 (2018-11)","text":"CRAN release: 2018-11-19 Added final estimated model clustvarsel object. Solved bug stop execution greedy-backward search variables removed.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-232-2018-04","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3.2 (2018-04)","title":"clustvarsel 2.3.2 (2018-04)","text":"CRAN release: 2018-04-09 Package version accompanying JSS paper. Bug fixes extreme case clustering variable selected using greedy forward/backward search.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-231-2017-06","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3.1 (2017-06)","title":"clustvarsel 2.3.1 (2017-06)","text":"CRAN release: 2017-07-07 Fix bug executed condition length greater 1.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-23-2017-01","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.3 (2017-01)","title":"clustvarsel 2.3 (2017-01)","text":"CRAN release: 2017-02-24 Add optional argument verbose clustvarsel() printing steps info search. New print method clustvarsel objects. parallel cluster automatically stopped unless registered parallel back end provided argument parallel argument clustvarsel() function call. Add “quick tour clustvarsel” vignette.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-22-2015-11","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.2 (2015-11)","title":"clustvarsel 2.2 (2015-11)","text":"CRAN release: 2015-11-19 Reformat summary output clustvarsel object. Add update references main help page.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-21-2014-10","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.1 (2014-10)","title":"clustvarsel 2.1 (2014-10)","text":"CRAN release: 2014-10-15 Version associated JSS paper submission. Add explicitly stop clusters parallel used. Specifically included hc() function call argument name data = ... works mclust version 4.4 upper. bug fixes improvements.","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-20-2013-10","dir":"Changelog","previous_headings":"","what":"clustvarsel 2.0 (2013-10)","title":"clustvarsel 2.0 (2013-10)","text":"CRAN release: 2013-10-25 Partial rewriting package. “greedy” search option forward backward direction. “headlong” search option forward direction release. clustvarsel() argument G maximum number clusters must vector number cluster look . separate code sampling -sampling version search algorithm. Inclusion argument hcModel control initial hierarchical clustering. Include subset selection regression proposed variable variables already included. “greedy” search algorithms can executed either sequentially using parallel computing facilities available R. version package requires R (>= 3.0.0) mclust (>= 4.0).","code":""},{"path":"https://mclust-org.github.io/clustvarsel/news/index.html","id":"clustvarsel-13-2009-08","dir":"Changelog","previous_headings":"","what":"clustvarsel 1.3 (2009-08)","title":"clustvarsel 1.3 (2009-08)","text":"CRAN release: 2009-08-04 Last version CRAN available R-2.14.x mclust version 3.5","code":""}]
