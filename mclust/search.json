[{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A quick tour of mclust","text":"mclust contributed R package model-based clustering, classification, density estimation based finite normal mixture modelling. provides functions parameter estimation via EM algorithm normal mixture models variety covariance structures, functions simulation models. Also included functions combine model-based hierarchical clustering, EM mixture estimation Bayesian Information Criterion (BIC) comprehensive strategies clustering, density estimation discriminant analysis. Additional functionalities available displaying visualizing fitted models along clustering, classification, density estimation results. document gives quick tour mclust (version 6.1) functionalities. written R Markdown, using knitr package production. See help(package=\"mclust\") details references provided citation(\"mclust\").","code":"library(mclust) ##                    __           __  ##    ____ ___  _____/ /_  _______/ /_ ##   / __ `__ \\/ ___/ / / / / ___/ __/ ##  / / / / / / /__/ / /_/ (__  ) /_   ## /_/ /_/ /_/\\___/_/\\__,_/____/\\__/   version 6.1 ## Type 'citation(\"mclust\")' for citing this R package in publications."},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"clustering","dir":"Articles","previous_headings":"","what":"Clustering","title":"A quick tour of mclust","text":"","code":"data(diabetes) class <- diabetes$class table(class) ## class ## Chemical   Normal    Overt  ##       36       76       33 X <- diabetes[,-1] head(X) ##   glucose insulin sspg ## 1      80     356  124 ## 2      97     289  117 ## 3     105     319  143 ## 4      90     356  199 ## 5      90     323  240 ## 6      86     381  157 clPairs(X, class) BIC <- mclustBIC(X) plot(BIC) summary(BIC) ## Best BIC values: ##              VVV,3       VVV,4       EVE,6 ## BIC      -4751.316 -4784.32213 -4785.24591 ## BIC diff     0.000   -33.00573   -33.92951  mod1 <- Mclust(X, x = BIC) summary(mod1, parameters = TRUE) ## ----------------------------------------------------  ## Gaussian finite mixture model fitted by EM algorithm  ## ----------------------------------------------------  ##  ## Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 3 ## components:  ##  ##  log-likelihood   n df       BIC       ICL ##       -2303.496 145 29 -4751.316 -4770.169 ##  ## Clustering table: ##  1  2  3  ## 81 36 28  ##  ## Mixing probabilities: ##         1         2         3  ## 0.5368974 0.2650129 0.1980897  ##  ## Means: ##              [,1]     [,2]       [,3] ## glucose  90.96239 104.5335  229.42136 ## insulin 357.79083 494.8259 1098.25990 ## sspg    163.74858 309.5583   81.60001 ##  ## Variances: ## [,,1] ##          glucose    insulin       sspg ## glucose 57.18044   75.83206   14.73199 ## insulin 75.83206 2101.76553  322.82294 ## sspg    14.73199  322.82294 2416.99074 ## [,,2] ##           glucose   insulin       sspg ## glucose  185.0290  1282.340  -509.7313 ## insulin 1282.3398 14039.283 -2559.0251 ## sspg    -509.7313 -2559.025 23835.7278 ## [,,3] ##           glucose   insulin       sspg ## glucose  5529.250  20389.09  -2486.208 ## insulin 20389.088  83132.48 -10393.004 ## sspg    -2486.208 -10393.00   2217.533  plot(mod1, what = \"classification\") table(class, mod1$classification) ##            ## class       1  2  3 ##   Chemical  9 26  1 ##   Normal   72  4  0 ##   Overt     0  6 27  plot(mod1, what = \"uncertainty\") ICL <- mclustICL(X) summary(ICL) ## Best ICL values: ##              VVV,3       EVE,6       EVE,7 ## ICL      -4770.169 -4797.38232 -4797.50566 ## ICL diff     0.000   -27.21342   -27.33677 plot(ICL) LRT <- mclustBootstrapLRT(X, modelName = \"VVV\") LRT ## -------------------------------------------------------------  ## Bootstrap sequential LRT for the number of mixture components  ## -------------------------------------------------------------  ## Model        = VVV  ## Replications = 999  ##               LRTS bootstrap p-value ## 1 vs 2   361.16739             0.001 ## 2 vs 3   123.49685             0.001 ## 3 vs 4    16.76161             0.498"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"initialisation","dir":"Articles","previous_headings":"Clustering","what":"Initialisation","title":"A quick tour of mclust","text":"EM algorithm used mclust maximum likelihood estimation. Initialisation EM performed using partitions obtained agglomerative hierarchical clustering. details see help(mclustBIC) help(Mclust), help(hc). Update BIC merging best results:  Univariate fit using random starting points obtained creating random agglomerations (see help(hcRandomPairs)) merging best results:","code":"(hc1 <- hc(X, modelName = \"VVV\", use = \"SVD\")) ## Call: ## hc(data = X, modelName = \"VVV\", use = \"SVD\")  ##  ## Model-Based Agglomerative Hierarchical Clustering  ## Model name        = VVV  ## Use               = SVD  ## Number of objects = 145 BIC1 <- mclustBIC(X, initialization = list(hcPairs = hc1)) # default  summary(BIC1) ## Best BIC values: ##              VVV,3       VVV,4       EVE,6 ## BIC      -4751.316 -4784.32213 -4785.24591 ## BIC diff     0.000   -33.00573   -33.92951  (hc2 <- hc(X, modelName = \"VVV\", use = \"VARS\")) ## Call: ## hc(data = X, modelName = \"VVV\", use = \"VARS\")  ##  ## Model-Based Agglomerative Hierarchical Clustering  ## Model name        = VVV  ## Use               = VARS  ## Number of objects = 145 BIC2 <- mclustBIC(X, initialization = list(hcPairs = hc2)) summary(BIC2) ## Best BIC values: ##              VVV,3       VVE,3       EVE,4 ## BIC      -4760.091 -4775.53693 -4793.26143 ## BIC diff     0.000   -15.44628   -33.17079  (hc3 <- hc(X, modelName = \"EEE\", use = \"SVD\")) ## Call: ## hc(data = X, modelName = \"EEE\", use = \"SVD\")  ##  ## Model-Based Agglomerative Hierarchical Clustering  ## Model name        = EEE  ## Use               = SVD  ## Number of objects = 145 BIC3 <- mclustBIC(X, initialization = list(hcPairs = hc3)) summary(BIC3) ## Best BIC values: ##              VVV,3        VVE,4       VVE,3 ## BIC      -4751.354 -4757.091572 -4775.69587 ## BIC diff     0.000    -5.737822   -24.34212 BIC <- mclustBICupdate(BIC1, BIC2, BIC3) summary(BIC) ## Best BIC values: ##              VVV,3        VVE,4       VVE,3 ## BIC      -4751.316 -4757.091572 -4775.53693 ## BIC diff     0.000    -5.775172   -24.22053 plot(BIC) data(galaxies, package = \"MASS\")  galaxies <- galaxies / 1000 BIC <- NULL for(j in 1:20) {   rBIC <- mclustBIC(galaxies, verbose = FALSE,                     initialization = list(hcPairs = hcRandomPairs(galaxies)))   BIC <- mclustBICupdate(BIC, rBIC) } summary(BIC) ## Best BIC values: ##                V,3         V,4        V,5 ## BIC      -441.6122 -443.399746 -446.34966 ## BIC diff    0.0000   -1.787536   -4.73745 plot(BIC) mod <- Mclust(galaxies, x = BIC) summary(mod) ## ----------------------------------------------------  ## Gaussian finite mixture model fitted by EM algorithm  ## ----------------------------------------------------  ##  ## Mclust V (univariate, unequal variance) model with 3 components:  ##  ##  log-likelihood  n df       BIC       ICL ##       -203.1792 82  8 -441.6122 -441.6126 ##  ## Clustering table: ##  1  2  3  ##  3  7 72"},{"path":[]},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"edda","dir":"Articles","previous_headings":"Classification","what":"EDDA","title":"A quick tour of mclust","text":"","code":"data(iris) class <- iris$Species table(class) ## class ##     setosa versicolor  virginica  ##         50         50         50 X <- iris[,1:4] head(X) ##   Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1          5.1         3.5          1.4         0.2 ## 2          4.9         3.0          1.4         0.2 ## 3          4.7         3.2          1.3         0.2 ## 4          4.6         3.1          1.5         0.2 ## 5          5.0         3.6          1.4         0.2 ## 6          5.4         3.9          1.7         0.4 mod2 <- MclustDA(X, class, modelType = \"EDDA\") summary(mod2) ## ------------------------------------------------  ## Gaussian finite mixture model for classification  ## ------------------------------------------------  ##  ## EDDA model summary:  ##  ##  log-likelihood   n df       BIC ##       -187.7097 150 36 -555.8024 ##              ## Classes       n     % Model G ##   setosa     50 33.33   VEV 1 ##   versicolor 50 33.33   VEV 1 ##   virginica  50 33.33   VEV 1 ##  ## Training confusion matrix: ##             Predicted ## Class        setosa versicolor virginica ##   setosa         50          0         0 ##   versicolor      0         47         3 ##   virginica       0          0        50 ## Classification error = 0.02  ## Brier score          = 0.0127 plot(mod2, what = \"scatterplot\") plot(mod2, what = \"classification\")"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"mclustda","dir":"Articles","previous_headings":"Classification","what":"MclustDA","title":"A quick tour of mclust","text":"","code":"data(banknote) class <- banknote$Status table(class) ## class ## counterfeit     genuine  ##         100         100 X <- banknote[,-1] head(X) ##   Length  Left Right Bottom  Top Diagonal ## 1  214.8 131.0 131.1    9.0  9.7    141.0 ## 2  214.6 129.7 129.7    8.1  9.5    141.7 ## 3  214.8 129.7 129.7    8.7  9.6    142.2 ## 4  214.8 129.7 129.6    7.5 10.4    142.0 ## 5  215.0 129.6 129.7   10.4  7.7    141.8 ## 6  215.7 130.8 130.5    9.0 10.1    141.4 mod3 <- MclustDA(X, class) summary(mod3) ## ------------------------------------------------  ## Gaussian finite mixture model for classification  ## ------------------------------------------------  ##  ## MclustDA model summary:  ##  ##  log-likelihood   n df       BIC ##       -646.0801 200 66 -1641.849 ##               ## Classes         n  % Model G ##   counterfeit 100 50   EVE 2 ##   genuine     100 50   XXX 1 ##  ## Training confusion matrix: ##              Predicted ## Class         counterfeit genuine ##   counterfeit         100       0 ##   genuine               0     100 ## Classification error = 0  ## Brier score          = 0 plot(mod3, what = \"scatterplot\") plot(mod3, what = \"classification\")"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"cross-validation-error","dir":"Articles","previous_headings":"Classification","what":"Cross-validation error","title":"A quick tour of mclust","text":"","code":"cv <- cvMclustDA(mod2, nfold = 10) str(cv) ## List of 6 ##  $ classification: Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ z             : num [1:150, 1:3] 1 1 1 1 1 1 1 1 1 1 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##   .. ..$ : NULL ##   .. ..$ : chr [1:3] \"setosa\" \"versicolor\" \"virginica\" ##  $ ce            : num 0.0267 ##  $ se.ce         : num 0.0109 ##  $ brier         : num 0.0208 ##  $ se.brier      : num 0.00738 unlist(cv[3:6]) ##          ce       se.ce       brier    se.brier  ## 0.026666667 0.010886621 0.020795887 0.007383247 cv <- cvMclustDA(mod3, nfold = 10) str(cv) ## List of 6 ##  $ classification: Factor w/ 2 levels \"counterfeit\",..: 2 2 2 2 2 2 2 2 2 2 ... ##  $ z             : num [1:200, 1:2] 1.56e-06 3.50e-19 5.41e-28 3.33e-20 2.42e-29 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##   .. ..$ : NULL ##   .. ..$ : chr [1:2] \"counterfeit\" \"genuine\" ##  $ ce            : num 0.005 ##  $ se.ce         : num 0.005 ##  $ brier         : num 0.00514 ##  $ se.brier      : num 0.00498 unlist(cv[3:6]) ##          ce       se.ce       brier    se.brier  ## 0.005000000 0.005000000 0.005135796 0.004980123"},{"path":[]},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"univariate","dir":"Articles","previous_headings":"Density estimation","what":"Univariate","title":"A quick tour of mclust","text":"","code":"data(acidity) mod4 <- densityMclust(acidity) summary(mod4) ## -------------------------------------------------------  ## Density estimation via Gaussian finite mixture modeling  ## -------------------------------------------------------  ##  ## Mclust E (univariate, equal variance) model with 2 components:  ##  ##  log-likelihood   n df       BIC       ICL ##       -185.9493 155  4 -392.0723 -398.5554 plot(mod4, what = \"BIC\") plot(mod4, what = \"density\", data = acidity, breaks = 15) plot(mod4, what = \"diagnostic\", type = \"cdf\") plot(mod4, what = \"diagnostic\", type = \"qq\")"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"multivariate","dir":"Articles","previous_headings":"Density estimation","what":"Multivariate","title":"A quick tour of mclust","text":"","code":"data(faithful) mod5 <- densityMclust(faithful) summary(mod5) ## -------------------------------------------------------  ## Density estimation via Gaussian finite mixture modeling  ## -------------------------------------------------------  ##  ## Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 ## components:  ##  ##  log-likelihood   n df       BIC       ICL ##       -1126.326 272 11 -2314.316 -2357.824 plot(mod5, what = \"BIC\") plot(mod5, what = \"density\", type = \"hdr\", data = faithful, points.cex = 0.5) plot(mod5, what = \"density\", type = \"persp\")"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"bootstrap-inference","dir":"Articles","previous_headings":"","what":"Bootstrap inference","title":"A quick tour of mclust","text":"","code":"boot1 <- MclustBootstrap(mod1, nboot = 999, type = \"bs\") summary(boot1, what = \"se\") ## ----------------------------------------------------------  ## Resampling standard errors  ## ----------------------------------------------------------  ## Model                      = VVV  ## Num. of mixture components = 3  ## Replications               = 999  ## Type                       = nonparametric bootstrap  ##  ## Mixing probabilities: ##          1          2          3  ## 0.05185780 0.05058160 0.03559685  ##  ## Means: ##                1         2         3 ## glucose 1.042239  3.444948 16.340816 ## insulin 7.554105 29.047203 63.483315 ## sspg    7.669033 31.684647  9.926121 ##  ## Variances: ## [,,1] ##          glucose   insulin      sspg ## glucose 10.78177  51.28084  51.61617 ## insulin 51.28084 529.62298 416.38176 ## sspg    51.61617 416.38176 623.81098 ## [,,2] ##           glucose   insulin      sspg ## glucose  65.66172  616.6785  442.0993 ## insulin 616.67852 7279.0671 3240.3558 ## sspg    442.09927 3240.3558 7070.4152 ## [,,3] ##           glucose   insulin      sspg ## glucose 1045.6542  4178.685  667.2709 ## insulin 4178.6846 18873.253 2495.0278 ## sspg     667.2709  2495.028  506.8173 summary(boot1, what = \"ci\") ## ----------------------------------------------------------  ## Resampling confidence intervals  ## ----------------------------------------------------------  ## Model                      = VVV  ## Num. of mixture components = 3  ## Replications               = 999  ## Type                       = nonparametric bootstrap  ## Confidence level           = 0.95  ##  ## Mixing probabilities: ##               1         2         3 ## 2.5%  0.4490043 0.1510533 0.1324862 ## 97.5% 0.6518326 0.3548749 0.2688038 ##  ## Means: ## [,,1] ##        glucose  insulin     sspg ## 2.5%  89.13950 344.9890 150.8405 ## 97.5% 93.16603 374.7221 181.8322 ## [,,2] ##         glucose  insulin     sspg ## 2.5%   98.82567 447.4121 257.9011 ## 97.5% 112.28459 561.3273 374.6194 ## [,,3] ##        glucose   insulin      sspg ## 2.5%  198.5986  969.6231  63.22103 ## 97.5% 263.2932 1226.2654 101.09078 ##  ## Variances: ## [,,1] ##        glucose  insulin     sspg ## 2.5%  38.65508 1234.198 1514.416 ## 97.5% 79.43401 3287.722 4146.024 ## [,,2] ##         glucose   insulin     sspg ## 2.5%   88.35268  3514.662 12583.92 ## 97.5% 358.15175 31416.557 39228.47 ## [,,3] ##        glucose   insulin     sspg ## 2.5%  3377.773  47477.74 1317.041 ## 97.5% 7379.344 120297.75 3229.747 plot(boot1, what = \"pro\") plot(boot1, what = \"mean\") boot4 <- MclustBootstrap(mod4, nboot = 999, type = \"bs\") summary(boot4, what = \"se\") ## ----------------------------------------------------------  ## Resampling standard errors  ## ----------------------------------------------------------  ## Model                      = E  ## Num. of mixture components = 2  ## Replications               = 999  ## Type                       = nonparametric bootstrap  ##  ## Mixing probabilities: ##          1          2  ## 0.04130937 0.04130937  ##  ## Means: ##          1          2  ## 0.04669993 0.06719883  ##  ## Variances: ##          1          2  ## 0.02376885 0.02376885 summary(boot4, what = \"ci\") ## ----------------------------------------------------------  ## Resampling confidence intervals  ## ----------------------------------------------------------  ## Model                      = E  ## Num. of mixture components = 2  ## Replications               = 999  ## Type                       = nonparametric bootstrap  ## Confidence level           = 0.95  ##  ## Mixing probabilities: ##               1         2 ## 2.5%  0.5364895 0.3004131 ## 97.5% 0.6995869 0.4635105 ##  ## Means: ##              1        2 ## 2.5%  4.279055 6.184439 ## 97.5% 4.461108 6.449465 ##  ## Variances: ##               1         2 ## 2.5%  0.1395796 0.1395796 ## 97.5% 0.2317769 0.2317769 plot(boot4, what = \"pro\") plot(boot4, what = \"mean\")"},{"path":[]},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"clustering-1","dir":"Articles","previous_headings":"Dimension reduction","what":"Clustering","title":"A quick tour of mclust","text":"","code":"mod1dr <- MclustDR(mod1) summary(mod1dr) ## -----------------------------------------------------------------  ## Dimension reduction for model-based clustering and classification  ## -----------------------------------------------------------------  ##  ## Mixture model type: Mclust (VVV, 3)  ##          ## Clusters  n ##        1 81 ##        2 36 ##        3 28 ##  ## Estimated basis vectors:  ##              Dir1     Dir2 ## glucose  0.764699  0.86359 ## insulin -0.643961 -0.22219 ## sspg     0.023438 -0.45260 ##  ##                Dir1      Dir2 ## Eigenvalues  1.2629   0.35218 ## Cum. %      78.1939 100.00000 plot(mod1dr, what = \"pairs\") plot(mod1dr, what = \"boundaries\", ngrid = 200) mod1dr <- MclustDR(mod1, lambda = 1) summary(mod1dr) ## -----------------------------------------------------------------  ## Dimension reduction for model-based clustering and classification  ## -----------------------------------------------------------------  ##  ## Mixture model type: Mclust (VVV, 3)  ##          ## Clusters  n ##        1 81 ##        2 36 ##        3 28 ##  ## Estimated basis vectors:  ##              Dir1     Dir2 ## glucose  0.764699  0.86359 ## insulin -0.643961 -0.22219 ## sspg     0.023438 -0.45260 ##  ##                Dir1      Dir2 ## Eigenvalues  1.2629   0.35218 ## Cum. %      78.1939 100.00000 plot(mod1dr, what = \"scatterplot\") plot(mod1dr, what = \"boundaries\", ngrid = 200)"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"classification-1","dir":"Articles","previous_headings":"Dimension reduction","what":"Classification","title":"A quick tour of mclust","text":"","code":"mod2dr <- MclustDR(mod2) summary(mod2dr) ## -----------------------------------------------------------------  ## Dimension reduction for model-based clustering and classification  ## -----------------------------------------------------------------  ##  ## Mixture model type: EDDA  ##              ## Classes       n Model G ##   setosa     50   VEV 1 ##   versicolor 50   VEV 1 ##   virginica  50   VEV 1 ##  ## Estimated basis vectors:  ##                  Dir1      Dir2 ## Sepal.Length  0.20874 -0.006532 ## Sepal.Width   0.38620 -0.586611 ## Petal.Length -0.55401  0.252562 ## Petal.Width  -0.70735 -0.769453 ##  ##                Dir1       Dir2 ## Eigenvalues  1.8813   0.098592 ## Cum. %      95.0204 100.000000 plot(mod2dr, what = \"scatterplot\") plot(mod2dr, what = \"boundaries\", ngrid = 200) mod3dr <- MclustDR(mod3) summary(mod3dr) ## -----------------------------------------------------------------  ## Dimension reduction for model-based clustering and classification  ## -----------------------------------------------------------------  ##  ## Mixture model type: MclustDA  ##               ## Classes         n Model G ##   counterfeit 100   EVE 2 ##   genuine     100   XXX 1 ##  ## Estimated basis vectors:  ##              Dir1     Dir2 ## Length   -0.07016 -0.25690 ## Left     -0.36888 -0.19963 ## Right     0.29525 -0.10111 ## Bottom    0.54683  0.46254 ## Top       0.55720  0.41370 ## Diagonal -0.40290  0.70628 ##  ##                Dir1     Dir2 ## Eigenvalues  1.7188   1.0607 ## Cum. %      61.8373 100.0000 plot(mod3dr, what = \"scatterplot\") plot(mod3dr, what = \"boundaries\", ngrid = 200)"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"using-colorblind-friendly-palettes","dir":"Articles","previous_headings":"","what":"Using colorblind-friendly palettes","title":"A quick tour of mclust","text":"graphs produced mclust use colors default defined following options: first option controls colors used plotting BIC, ICL, etc. curves, whereas second option used assign colors indicating clusters classes plotting data. Starting R version 4.0, function can used retrieving colors pre-defined palettes. instance returns color-blind-friendly palette individuals suffering protanopia deuteranopia, two common forms inherited color blindness. earlier versions R palette can defined : assigned mclust options follows:    needed, users can easily define palettes following procedure outlined .","code":"mclust.options(\"bicPlotColors\") ##       EII       VII       EEI       EVI       VEI       VVI       EEE       VEE  ##    \"gray\"   \"black\" \"#218B21\" \"#41884F\" \"#508476\" \"#58819C\" \"#597DC3\" \"#5178EA\"  ##       EVE       VVE       EEV       VEV       EVV       VVV         E         V  ## \"#716EE7\" \"#9B60B8\" \"#B2508B\" \"#C03F60\" \"#C82A36\" \"#CC0000\"    \"gray\"   \"black\" mclust.options(\"classPlotColors\") ##  [1] \"dodgerblue2\"    \"red3\"           \"green3\"         \"slateblue\"      ##  [5] \"darkorange\"     \"skyblue1\"       \"violetred4\"     \"forestgreen\"    ##  [9] \"steelblue4\"     \"slategrey\"      \"brown\"          \"black\"          ## [13] \"darkseagreen\"   \"darkgoldenrod3\" \"olivedrab\"      \"royalblue\"      ## [17] \"tomato4\"        \"cyan2\"          \"springgreen2\" palette.colors(palette = \"Okabe-Ito\") cbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\",  \"#D55E00\", \"#CC79A7\", \"#999999\") bicPlotColors <- mclust.options(\"bicPlotColors\") bicPlotColors[1:14] <- c(cbPalette, cbPalette[1:5]) mclust.options(\"bicPlotColors\" = bicPlotColors) mclust.options(\"classPlotColors\" = cbPalette[-1])  clPairs(iris[,-5], iris$Species) mod <- Mclust(iris[,-5]) plot(mod, what = \"BIC\") plot(mod, what = \"classification\")"},{"path":"https://mclust-org.github.io/mclust/articles/mclust.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"A quick tour of mclust","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 205-233. https://journal.r-project.org/archive/2016/RJ-2016-021/RJ-2016-021.pdf Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631.","code":"sessionInfo() ## R version 4.3.2 (2023-10-31) ## Platform: x86_64-apple-darwin20 (64-bit) ## Running under: macOS Ventura 13.6 ##  ## Matrix products: default ## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib  ## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0 ##  ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ##  ## time zone: Europe/Rome ## tzcode source: internal ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] mclust_6.1 knitr_1.45 ##  ## loaded via a namespace (and not attached): ##  [1] vctrs_0.6.5     cli_3.6.2       rlang_1.1.3     xfun_0.42       ##  [5] highr_0.10      stringi_1.8.3   purrr_1.0.2     jsonlite_1.8.8  ##  [9] glue_1.7.0      htmltools_0.5.7 sass_0.4.8      rmarkdown_2.25  ## [13] evaluate_0.23   jquerylib_0.1.4 fastmap_1.1.1   yaml_2.3.8      ## [17] lifecycle_1.0.4 memoise_2.0.1   stringr_1.5.1   compiler_4.3.2  ## [21] fs_1.6.3        digest_0.6.34   R6_2.5.1        magrittr_2.0.3  ## [25] bslib_0.6.1     tools_4.3.2     pkgdown_2.0.7   cachem_1.0.8    ## [29] desc_1.4.3"},{"path":"https://mclust-org.github.io/mclust/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Chris Fraley. Author. Adrian E. Raftery. Author. Luca Scrucca. Author, maintainer. Thomas Brendan Murphy. Contributor. Michael Fop. Contributor.","code":""},{"path":"https://mclust-org.github.io/mclust/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Scrucca L, Fraley C, Murphy TB, Raftery AE (2023). Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman Hall/CRC. ISBN 978-1032234953, doi:10.1201/9781003277965, https://mclust-org.github.io/book/.","code":"@Book{,   title = {Model-Based Clustering, Classification, and Density Estimation Using {mclust} in {R}},   author = {Luca Scrucca and Chris Fraley and T. Brendan Murphy and Adrian E. Raftery},   publisher = {Chapman and Hall/CRC},   isbn = {978-1032234953},   doi = {10.1201/9781003277965},   year = {2023},   url = {https://mclust-org.github.io/book/}, }"},{"path":"https://mclust-org.github.io/mclust/index.html","id":"mclust-","dir":"","previous_headings":"","what":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation","text":"R package implementing Gaussian Mixture Modelling Model-Based Clustering, Classification, Density Estimation. Gaussian finite mixture models fitted via EM algorithm model-based clustering, classification, density estimation, including Bayesian regularization, dimension reduction visualization, resampling-based inference.","code":""},{"path":"https://mclust-org.github.io/mclust/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation","text":"can install released version mclust CRAN using:","code":"install.packages(\"mclust\")"},{"path":"https://mclust-org.github.io/mclust/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation","text":"Usage main functions several examples included papers shown references section . intro see vignette quick tour mclust, available vignette also available Vignette section navigation bar top package’s web page.","code":"vignette(\"mclust\")"},{"path":"https://mclust-org.github.io/mclust/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 205-233. Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Baudry_etal_2010_JCGS_examples.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","title":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","text":"Simulated datasets used Baudry et al. (2010) illustrate proposed mixture components combining method clustering. Please see cited article detailed presentation datasets. data frame name exN.M presented Section N.M paper. Test1D (article) simulated Gaussian mixture distribution R. ex4.1 ex4.2 simulated Gaussian mixture distribution R^2. ex4.3 simulated mixture uniform distribution square spherical Gaussian distribution R^2. ex4.4.1 simulated Gaussian mixture model R^2 ex4.4.2 simulated mixture two uniform distributions R^3.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Baudry_etal_2010_JCGS_examples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","text":"","code":"data(Baudry_etal_2010_JCGS_examples)"},{"path":"https://mclust-org.github.io/mclust/reference/Baudry_etal_2010_JCGS_examples.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","text":"ex4.1 data frame 600 observations 2 real variables. ex4.2 data frame 600 observations 2 real variables. ex4.3 data frame 200 observations 2 real variables. ex4.4.1 data frame 800 observations 2 real variables. ex4.4.2 data frame 300 observations 3 real variables. Test1D data frame 200 observations 1 real variable.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Baudry_etal_2010_JCGS_examples.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Baudry_etal_2010_JCGS_examples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Example Datasets From Baudry et al. (2010) — Baudry_etal_2010_JCGS_examples","text":"","code":"# \\donttest{ data(Baudry_etal_2010_JCGS_examples)  output <- clustCombi(data = ex4.4.1) output # is of class clustCombi #> 'clustCombi' object: #>  Mclust model: (VVI,4) #>  Available object components: classification combiM combiz MclustOutput  #>  Combining matrix (K+1 classes -> K classes): <object_name>$combiM[[K]] #>  Classification for K classes: <object_name>$classification[[K]]  # plots the hierarchy of combined solutions, then some \"entropy plots\" which  # may help one to select the number of classes plot(output)         # }"},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":null,"dir":"Reference","previous_headings":"","what":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"Brier score proper score function measures accuracy probabilistic predictions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"","code":"BrierScore(z, class)"},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"z matrix containing predicted probabilities observation    classified one classes.    Thus, number rows must match length class,   number columns number known classes. class numeric, character vector factor containing known class labels   observation.   class factor, number classes nlevels(class)   classes levels(class).   class numeric character vector, number classes   equal number classes obtained via unique(class).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"Brier Score mean square difference true classes predicted probabilities. function implements original multi-class definition Brier (1950), normalized \\([0,1]\\) Kruppa et al (2014). formula following: $$ BS = \\frac{1}{2n} \\sum_{=1}^n \\sum_{k=1}^K (C_{ik} - p_{ik})^2 $$ \\(n\\) number observations, \\(K\\) number classes, \\(C_{ik} = \\{0,1\\}\\) indicator class \\(k\\) observation \\(\\), \\(p_{ik}\\) predicted probability observation \\(\\) belong class \\(k\\). formulation applicable multi-class predictions, including binary case. small value Brier Score indicates high prediction accuracy. Brier Score strictly proper score (Gneiting Raftery, 2007), means takes minimal value predicted probabilities match empirical probabilities.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"Brier, G.W. (1950) Verification forecasts expressed terms probability. Monthly Weather Review, 78 (1): 1-3. Gneiting, G. Raftery, . E. (2007) Strictly proper scoring rules, prediction, estimation. Journal American Statistical Association 102 (477): 359-378. Kruppa, J., Liu, Y., Diener, H.-C., Holste, T., Weimar, C., Koonig, . R., Ziegler, . (2014) Probability estimation machine learning methods dichotomous multicategory outcome: Applications. Biometrical Journal, 56 (4): 564-583.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/BrierScore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brier score to assess the accuracy of probabilistic predictions — BrierScore","text":"","code":"# multi-class case class <- factor(c(5,5,5,2,5,3,1,2,1,1), levels = 1:5) probs <- matrix(c(0.15, 0.01, 0.08, 0.23, 0.01, 0.23, 0.59, 0.02, 0.38, 0.45,                    0.36, 0.05, 0.30, 0.46, 0.15, 0.13, 0.06, 0.19, 0.27, 0.17,                    0.40, 0.34, 0.18, 0.04, 0.47, 0.34, 0.32, 0.01, 0.03, 0.11,                    0.04, 0.04, 0.09, 0.05, 0.28, 0.27, 0.02, 0.03, 0.12, 0.25,                    0.05, 0.56, 0.35, 0.22, 0.09, 0.03, 0.01, 0.75, 0.20, 0.02),                 nrow = 10, ncol = 5) cbind(class, probs, map = map(probs)) #>       class                          map #>  [1,]     5 0.15 0.36 0.40 0.04 0.05   3 #>  [2,]     5 0.01 0.05 0.34 0.04 0.56   5 #>  [3,]     5 0.08 0.30 0.18 0.09 0.35   5 #>  [4,]     2 0.23 0.46 0.04 0.05 0.22   2 #>  [5,]     5 0.01 0.15 0.47 0.28 0.09   3 #>  [6,]     3 0.23 0.13 0.34 0.27 0.03   3 #>  [7,]     1 0.59 0.06 0.32 0.02 0.01   1 #>  [8,]     2 0.02 0.19 0.01 0.03 0.75   5 #>  [9,]     1 0.38 0.27 0.03 0.12 0.20   1 #> [10,]     1 0.45 0.17 0.11 0.25 0.02   1 BrierScore(probs, class) #> [1] 0.33144  # two-class case class <- factor(c(1,1,1,2,2,1,1,2,1,1), levels = 1:2) probs <- matrix(c(0.91, 0.4, 0.56, 0.27, 0.37, 0.7, 0.97, 0.22, 0.68, 0.43,                    0.09, 0.6, 0.44, 0.73, 0.63, 0.3, 0.03, 0.78, 0.32, 0.57),                 nrow = 10, ncol = 2) cbind(class, probs, map = map(probs)) #>       class           map #>  [1,]     1 0.91 0.09   1 #>  [2,]     1 0.40 0.60   2 #>  [3,]     1 0.56 0.44   1 #>  [4,]     2 0.27 0.73   2 #>  [5,]     2 0.37 0.63   2 #>  [6,]     1 0.70 0.30   1 #>  [7,]     1 0.97 0.03   1 #>  [8,]     2 0.22 0.78   2 #>  [9,]     1 0.68 0.32   1 #> [10,]     1 0.43 0.57   2 BrierScore(probs, class) #> [1] 0.13381  # two-class case when predicted probabilities are constrained to be equal to  # 0 or 1, then the (normalized) Brier Score is equal to the classification # error rate probs <- ifelse(probs > 0.5, 1, 0) cbind(class, probs, map = map(probs)) #>       class     map #>  [1,]     1 1 0   1 #>  [2,]     1 0 1   2 #>  [3,]     1 1 0   1 #>  [4,]     2 0 1   2 #>  [5,]     2 0 1   2 #>  [6,]     1 1 0   1 #>  [7,]     1 1 0   1 #>  [8,]     2 0 1   2 #>  [9,]     1 1 0   1 #> [10,]     1 0 1   2 BrierScore(probs, class) #> [1] 0.2 classError(map(probs), class)$errorRate #> [1] 0.2  # plot Brier score for predicted probabilities in range [0,1] class <- factor(rep(1, each = 100), levels = 0:1) prob  <- seq(0, 1, by = 0.01) brier <- sapply(prob, function(p)    { z <- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)     BrierScore(z, class)   }) plot(prob, brier, type = \"l\", main = \"Scoring all one class\",      xlab = \"Predicted probability\", ylab = \"Brier score\")   # brier score for predicting balanced data with constant prob class <- factor(rep(c(1,0), each = 50), levels = 0:1) prob  <- seq(0, 1, by = 0.01) brier <- sapply(prob, function(p)    { z <- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)     BrierScore(z, class)   }) plot(prob, brier, type = \"l\", main = \"Scoring balanced classes\",      xlab = \"Predicted probability\", ylab = \"Brier score\")   # brier score for predicting unbalanced data with constant prob class <- factor(rep(c(0,1), times = c(90,10)), levels = 0:1) prob  <- seq(0, 1, by = 0.01) brier <- sapply(prob, function(p)    { z <- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)     BrierScore(z, class)   }) plot(prob, brier, type = \"l\", main = \"Scoring unbalanced classes\",      xlab = \"Predicted probability\", ylab = \"Brier score\")"},{"path":"https://mclust-org.github.io/mclust/reference/EuroUnemployment.html","id":null,"dir":"Reference","previous_headings":"","what":"Unemployment data for European countries in 2014 — EuroUnemployment","title":"Unemployment data for European countries in 2014 — EuroUnemployment","text":"data set contains unemployment rates 31 European countries year 2014.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/EuroUnemployment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unemployment data for European countries in 2014 — EuroUnemployment","text":"","code":"data(EuroUnemployment)"},{"path":"https://mclust-org.github.io/mclust/reference/EuroUnemployment.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Unemployment data for European countries in 2014 — EuroUnemployment","text":"data frame following variables: TUR Total unemployment rate, .e. percentage unemployed persons aged 15-74 economically active population. YUR Youth unemployment rate, .e. percentage unemployed persons aged 15-24 economically active population. LUR Long-term unemployment rate, .e. percentage unemployed persons unemployed 12 months .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/EuroUnemployment.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Unemployment data for European countries in 2014 — EuroUnemployment","text":"Dataset downloaded EUROSTAT https://ec.europa.eu/eurostat.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/GvHD.html","id":null,"dir":"Reference","previous_headings":"","what":"GvHD Dataset — GvHD","title":"GvHD Dataset — GvHD","text":"GvHD (Graft-versus-Host Disease) data Brinkman et al. (2007). Two samples flow cytometry data, one patient GvHD, control patient. GvHD positive control samples consist 9083 6809 observations, respectively. samples include four biomarker variables, namely, CD4, CD8b, CD3, CD8. objective analysis identify CD3+ CD4+ CD8b+ cell sub-populations present GvHD positive sample. treatment data combining mixtures proposed Baudry et al. (2010).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/GvHD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GvHD Dataset — GvHD","text":"","code":"data(GvHD)"},{"path":"https://mclust-org.github.io/mclust/reference/GvHD.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"GvHD Dataset — GvHD","text":"GvHD.pos (positive patient) data frame 9083 observations following 4 variables, biomarker measurements. CD4  CD8b  CD3  CD8  GvHD.control (control patient) data frame 6809 observations following 4 variables, biomarker measurements. CD4  CD8b  CD3  CD8","code":""},{"path":"https://mclust-org.github.io/mclust/reference/GvHD.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GvHD Dataset — GvHD","text":"R. R. Brinkman, M. Gasparetto, S.-J. J. Lee, . J. Ribickas, J. Perkins, W. Janssen, R. Smiley C. Smith (2007). High-content flow cytometry temporal data analysis defining cellular signature Graft-versus-Host Disease. Biology Blood Marrow Transplantation, 13: 691-700. K. Lo, R. R. Brinkman, R. Gottardo (2008). Automated gating flow cytometry data via robust model-based clustering. Cytometry , 73: 321-332. J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/GvHD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GvHD Dataset — GvHD","text":"","code":"# \\donttest{ data(GvHD) dat <- GvHD.pos[1:500,] # only a few lines for a quick example output <- clustCombi(data = dat)  output # is of class clustCombi #> 'clustCombi' object: #>  Mclust model: (VEV,6) #>  Available object components: classification combiM combiz MclustOutput  #>  Combining matrix (K+1 classes -> K classes): <object_name>$combiM[[K]] #>  Classification for K classes: <object_name>$classification[[K]] # plot the hierarchy of combined solutions plot(output, what = \"classification\")        # plot some \"entropy plots\" which may help one to select the number of classes plot(output, what = \"entropy\")    # plot the tree structure obtained from combining mixture components plot(output, what = \"tree\")   # }"},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-Based Clustering — Mclust","title":"Model-Based Clustering — Mclust","text":"Model-based clustering based parameterized finite Gaussian mixture models.  Models estimated EM algorithm initialized hierarchical model-based agglomerative clustering. optimal model selected according BIC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-Based Clustering — Mclust","text":"","code":"Mclust(data, G = NULL, modelNames = NULL,       prior = NULL,       control = emControl(),       initialization = NULL,       warn = mclust.options(\"warn\"),       x =  NULL,       verbose = interactive(), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-Based Clustering — Mclust","text":"data numeric vector, matrix, data frame observations. Categorical   variables allowed. matrix data frame, rows   correspond observations (\\(n\\)) columns correspond variables (\\(d\\)). G integer vector specifying numbers mixture components   (clusters) BIC calculated.    default G=1:9. modelNames vector character strings indicating models fitted    EM phase clustering. default : univariate data (\\(d = 1\\)): c(\"E\", \"V\") multivariate data (\\(n > d\\)): models available mclust.options(\"emModelNames\") multivariate data (\\(n <= d\\)): spherical diagonal models, .e. c(\"EII\", \"VII\", \"EEI\", \"EVI\", \"VEI\", \"VVI\") help file mclustModelNames describes available models. prior default assumes prior, argument allows specification    conjugate prior means variances function    priorControl.    Note , described defaultPrior, multivariate    case 10 14 models may used conjunction prior, .e.   available MCLUST version 4.4. control list control parameters EM. defaults set call   emControl(). initialization list containing zero following components: hcPairs matrix merge pairs hierarchical clustering produced   function hc.    multivariate data, default compute hierarchical    agglomerative clustering tree applying function    hc    model specified mclust.options(\"hcModelName\"),   data transformation set mclust.options(\"hcUse\").   input subset indicated subset argument    used initial clustering.   hierarchical clustering results used start EM   algorithm given partition.   univariate data, default use quantiles start EM   algorithm. However, hierarchical clustering also used    calling hc model specified \"V\" \"E\". subset logical numeric vector specifying subset data   used initial hierarchical clustering phase.   subset used unless number observations exceeds    value specified mclust.options(\"subset\"),    default set 2000 (see mclust.options).   Note case guarantee exact reproducibility results    seed must specified (see set.seed). noise logical numeric vector indicating initial guess   observations noise data. numeric entries   correspond row indexes data. supplied, noise   term added model estimation.  warn logical value indicating whether certain warnings    (usually related singularity) issued.   default controlled mclust.options. x object class 'mclustBIC'. supplied, BIC values models     already computed available x     recomputed.     arguments, exception data, G     modelName, ignored values set specified    attributes x. Defaults G modelNames    taken x. verbose logical controlling text progress bar displayed   fitting procedure. default TRUE session    interactive, FALSE otherwise. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-Based Clustering — Mclust","text":"object class 'Mclust' providing optimal (according BIC)  mixture model estimation. details output components follows: call matched call data input data matrix. modelName character string denoting model optimal BIC occurs. n number observations data. d dimension data. G optimal number mixture components. BIC BIC values. loglik log-likelihood corresponding optimal BIC. df number estimated parameters. bic BIC value selected model. icl ICL value selected model. hypvol hypervolume parameter noise component required, otherwise set NULL (see hypvol). parameters list following components: pro vector whose kth component mixing proportion         kth component mixture model.         missing, equal proportions assumed. mean mean component. one component,         matrix whose kth column mean kth         component mixture model. variance list variance parameters model.         components list depend model         specification. See help file mclustVariance         details.  z matrix whose [,k]th entry probability observation   test data belongs kth class. classification classification corresponding z, .e. map(z). uncertainty uncertainty associated classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-Based Clustering — Mclust","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317. Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631. C. Fraley . E. Raftery (2007) Bayesian regularization normal mixture estimation model-based clustering. Journal Classification, 24, 155-181.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/Mclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-Based Clustering — Mclust","text":"","code":"mod1 <- Mclust(iris[,1:4]) summary(mod1) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Clustering table: #>   1   2  #>  50 100   mod2 <- Mclust(iris[,1:4], G = 3) summary(mod2, parameters = TRUE) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 3 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -186.074 150 38 -562.5522 -566.4673 #>  #> Clustering table: #>  1  2  3  #> 50 45 55  #>  #> Mixing probabilities: #>         1         2         3  #> 0.3333333 0.3005423 0.3661243  #>  #> Means: #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.915044 6.546807 #> Sepal.Width  3.428 2.777451 2.949613 #> Petal.Length 1.462 4.204002 5.482252 #> Petal.Width  0.246 1.298935 1.985523 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.13320850  0.10938369  0.019191764 0.011585649 #> Sepal.Width    0.10938369  0.15495369  0.012096999 0.010010130 #> Petal.Length   0.01919176  0.01209700  0.028275400 0.005818274 #> Petal.Width    0.01158565  0.01001013  0.005818274 0.010695632 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.22572159  0.07613348   0.14689934  0.04335826 #> Sepal.Width    0.07613348  0.08024338   0.07372331  0.03435893 #> Petal.Length   0.14689934  0.07372331   0.16613979  0.04953078 #> Petal.Width    0.04335826  0.03435893   0.04953078  0.03338619 #> [,,3] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.42943106  0.10784274   0.33452389  0.06538369 #> Sepal.Width    0.10784274  0.11596343   0.08905176  0.06134034 #> Petal.Length   0.33452389  0.08905176   0.36422115  0.08706895 #> Petal.Width    0.06538369  0.06134034   0.08706895  0.08663823  # Using prior mod3 <- Mclust(iris[,1:4], prior = priorControl()) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(mod3) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #> Prior: defaultPrior()  #>  #>  log-likelihood   n df       BIC      ICL #>       -225.2685 150 26 -580.8136 -580.814 #>  #> Clustering table: #>   1   2  #>  50 100   mod4 <- Mclust(iris[,1:4], prior = priorControl(functionName=\"defaultPrior\", shrinkage=0.1)) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(mod4) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #> Prior: defaultPrior(shrinkage = 0.1)  #>  #>  log-likelihood   n df       BIC       ICL #>       -227.6729 150 26 -585.6223 -585.6227 #>  #> Clustering table: #>   1   2  #>  50 100   # Clustering of faithful data with some artificial noise added  nNoise <- 100 set.seed(0) # to make it reproducible Noise <- apply(faithful, 2, function(x)                runif(nNoise, min = min(x)-.1, max = max(x)+.1)) data <- rbind(faithful, Noise) plot(faithful) points(Noise, pch = 20, cex = 0.5, col = \"lightgrey\")  set.seed(0) NoiseInit <- sample(c(TRUE,FALSE), size = nrow(faithful)+nNoise,            replace = TRUE, prob = c(3,1)/4) mod5 <- Mclust(data, initialization = list(noise = NoiseInit)) summary(mod5, parameter = TRUE) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VVE (ellipsoidal, equal orientation) model with 2 components and a noise #> term:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1746.033 372 12 -3563.093 -3674.077 #>  #> Clustering table: #>   1   2   0  #> 180  88 104  #>  #> Mixing probabilities: #>         1         2         0  #> 0.4301382 0.2112698 0.3585921  #>  #> Means: #>                [,1]      [,2] #> eruptions  4.342387  1.978433 #> waiting   80.218154 54.005828 #>  #> Variances: #> [,,1] #>           eruptions    waiting #> eruptions 0.1152778  0.4225761 #> waiting   0.4225761 30.6256680 #> [,,2] #>            eruptions    waiting #> eruptions 0.03873859  0.3776241 #> waiting   0.37762409 27.3035511 #>  #> Hypervolume of noise component: #> 191.8869  plot(mod5, what = \"classification\")"},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"Bootstrap jackknife estimation standard errors percentile bootstrap confidence intervals parameters Gaussian mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"","code":"MclustBootstrap(object, nboot = 999, type = c(\"bs\", \"wlbs\", \"pb\", \"jk\"),                 max.nonfit = 10*nboot, verbose = interactive(),                  ...)"},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"object object class 'Mclust' 'densityMclust' providing estimated Gaussian mixture model. nboot number bootstrap replications. type character string specifying type resampling use: \"bs\" nonparametric bootstrap \"wlbs\" weighted likelihood bootstrap \"pb\" parametric bootstrap \"jk\" jackknife  max.nonfit maximum number non-estimable models allowed. verbose logical controlling text progress bar displayed resampling procedure. default TRUE session interactive, FALSE otherwise. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"fitted Gaussian mixture model object$G mixture components covariances parameterisation object$modelName, function returns either bootstrap distribution jackknife distribution mixture parameters. former case, nonparametric bootstrap weighted likelihood bootstrap approach used, bootstrap procedure generates nboot bootstrap samples size original data resampling replacement observed data. jackknife case, procedure considers samples obtained omitting one observation time. resulting resampling distribution can used obtain standard errors percentile confidence intervals use summary.MclustBootstrap function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"object class 'MclustBootstrap' following components: n number observations data. d dimension data. G value specifying number mixture components. modelName character string specifying mixture model covariances      parameterisation (see mclustModelNames). parameters list estimated parameters mixture components following components: pro vector mixing proportions. mean matrix means component. variance array covariance matrices component.  nboot number bootstrap replications type = \"bs\" type = \"wlbs\". sample size type = \"jk\". type type resampling approach used. nonfit number resamples convergence procedure. pro matrix dimension (nboot x G) containing      bootstrap distribution mixing proportion. mean array dimension (nboot x d x G),      d dimension data, containing bootstrap      distribution component means. variance array dimension (nboot x d x d x      G), d dimension data, containing      bootstrap distribution component covariances.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"Davison, . Hinkley, D. (1997) Bootstrap Methods Applications. Cambridge University Press. McLachlan, G.J. Peel, D. (2000) Finite Mixture Models. Wiley. O'Hagan ., Murphy T. B., Gormley . C. Scrucca L. (2015) Estimation Parameter Uncertainty Model-Based Clustering. Submitted Computational Statistics.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/MclustBootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resampling-based Inference for Gaussian finite mixture models — MclustBootstrap","text":"","code":"# \\donttest{ data(diabetes) X <- diabetes[,-1] modClust <- Mclust(X)  bootClust <- MclustBootstrap(modClust) summary(bootClust, what = \"se\") #> ----------------------------------------------------------  #> Resampling standard errors  #> ----------------------------------------------------------  #> Model                      = VVV  #> Num. of mixture components = 3  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #>  #> Mixing probabilities: #>          1          2          3  #> 0.05233913 0.04934156 0.03494921  #>  #> Means: #>                1         2         3 #> glucose 1.006765  3.292138 16.647842 #> insulin 7.843462 27.548758 65.966648 #> sspg    7.779137 30.692950  9.983326 #>  #> Variances: #> [,,1] #>          glucose   insulin      sspg #> glucose 10.64753  50.63956  48.61746 #> insulin 50.63956 524.57448 404.58548 #> sspg    48.61746 404.58548 647.28663 #> [,,2] #>           glucose   insulin      sspg #> glucose  63.32924  615.6663  435.9384 #> insulin 615.66626 7336.6348 3086.8630 #> sspg    435.93842 3086.8630 6780.6833 #> [,,3] #>           glucose   insulin      sspg #> glucose  995.5757  4072.436  636.6375 #> insulin 4072.4359 18497.223 2422.3585 #> sspg     636.6375  2422.358  473.1342 summary(bootClust, what = \"ci\") #> ----------------------------------------------------------  #> Resampling confidence intervals  #> ----------------------------------------------------------  #> Model                      = VVV  #> Num. of mixture components = 3  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #> Confidence level           = 0.95  #>  #> Mixing probabilities: #>               1         2         3 #> 2.5%  0.4478146 0.1543735 0.1366100 #> 97.5% 0.6435917 0.3555992 0.2706844 #>  #> Means: #> [,,1] #>        glucose  insulin     sspg #> 2.5%  89.07430 344.1764 150.6252 #> 97.5% 93.22599 375.1545 182.3419 #> [,,2] #>         glucose  insulin     sspg #> 2.5%   98.94194 452.8820 258.8573 #> 97.5% 112.41549 558.5595 382.9069 #> [,,3] #>        glucose   insulin      sspg #> 2.5%  195.9121  962.2439  61.13393 #> 97.5% 263.0002 1228.3581 101.71555 #>  #> Variances: #> [,,1] #>        glucose  insulin     sspg #> 2.5%  38.64074 1257.854 1493.575 #> 97.5% 80.71107 3239.885 4053.007 #> [,,2] #>         glucose   insulin     sspg #> 2.5%   91.03058  3405.421 12808.23 #> 97.5% 345.01024 30217.896 38356.71 #> [,,3] #>        glucose   insulin     sspg #> 2.5%  3437.032  45919.79 1392.434 #> 97.5% 7452.134 119570.85 3311.401  data(acidity) modDens <- densityMclust(acidity, plot = FALSE) modDens <- MclustBootstrap(modDens) summary(modDens, what = \"se\") #> ----------------------------------------------------------  #> Resampling standard errors  #> ----------------------------------------------------------  #> Model                      = E  #> Num. of mixture components = 2  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #>  #> Mixing probabilities: #>          1          2  #> 0.04171062 0.04171062  #>  #> Means: #>          1          2  #> 0.04515616 0.06660559  #>  #> Variances: #>          1          2  #> 0.02362844 0.02362844  summary(modDens, what = \"ci\") #> ----------------------------------------------------------  #> Resampling confidence intervals  #> ----------------------------------------------------------  #> Model                      = E  #> Num. of mixture components = 2  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #> Confidence level           = 0.95  #>  #> Mixing probabilities: #>               1         2 #> 2.5%  0.5388678 0.2989128 #> 97.5% 0.7010872 0.4611322 #>  #> Means: #>              1        2 #> 2.5%  4.285496 6.179751 #> 97.5% 4.458050 6.442143 #>  #> Variances: #>               1         2 #> 2.5%  0.1390296 0.1390296 #> 97.5% 0.2297464 0.2297464 # }"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"MclustDA discriminant analysis — MclustDA","title":"MclustDA discriminant analysis — MclustDA","text":"Discriminant analysis based Gaussian finite mixture modeling.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MclustDA discriminant analysis — MclustDA","text":"","code":"MclustDA(data, class, G = NULL, modelNames = NULL,           modelType = c(\"MclustDA\", \"EDDA\"),           prior = NULL,           control = emControl(),           initialization = NULL,           warn = mclust.options(\"warn\"),           verbose = interactive(),          ...)"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MclustDA discriminant analysis — MclustDA","text":"data data frame matrix giving training data. class vector giving known class labels (either numerical value  \t\tcharacter string) observations training data. G integer vector specifying numbers mixture components     (clusters) BIC calculated within class.      default G = 1:5.     different set mixture components class can specified     providing argument list integers class.      See examples . modelNames vector character strings indicating models fitted      EM within class (see description      mclustModelNames).     different set mixture models class can specified     providing argument list character strings.     See examples . modelType character string specifying whether models given     modelNames fit different number mixture      components covariance structures class      (\"MclustDA\", default) constrained      single component class covariance      structure among classes (\"EDDA\").     See Details section examples . prior default assumes prior, argument allows specification      conjugate prior means variances function      priorControl. control list control parameters EM. defaults set call     emControl(). initialization list containing zero following components: hcPairs matrix merge pairs hierarchical clustering produced     function hc. default compute hierarchical     clustering tree applying function hc     modelName = \"E\" univariate data     modelName = \"VVV\" multivariate data     subset indicated subset argument.      hierarchical clustering results used starting values      EM. subset logical numeric vector specifying subset data     used initial hierarchical clustering phase.  warn logical value indicating whether certain warnings     (usually related singularity) issued     estimation fails.      default controlled mclust.options. verbose logical controlling text progress bar displayed     fitting procedure. default TRUE session      interactive, FALSE otherwise. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MclustDA discriminant analysis — MclustDA","text":"object class 'MclustDA' providing optimal (according   BIC) mixture model. details output components follows: call matched call. data input data matrix. class input class labels. type character string specifying modelType estimated. models list Mclust objects containing information   fitted model class. n total number observations data. d dimension data.  bic Optimal BIC value. loglik Log-likelihood selected model. df Number estimated parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MclustDA discriminant analysis — MclustDA","text":"\"EDDA\" method discriminant analysis described Bensmail Celeux (1996), \"MclustDA\" Fraley Raftery (2002).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MclustDA discriminant analysis — MclustDA","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317. Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631. Bensmail, H., Celeux, G. (1996) Regularized Gaussian Discriminant Analysis Eigenvalue Decomposition.Journal American Statistical Association, 91, 1743-1748.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MclustDA discriminant analysis — MclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/MclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MclustDA discriminant analysis — MclustDA","text":"","code":"odd <- seq(from = 1, to = nrow(iris), by = 2) even <- odd + 1 X.train <- iris[odd,-5] Class.train <- iris[odd,5] X.test <- iris[even,-5] Class.test <- iris[even,5]  # common EEE covariance structure (which is essentially equivalent to linear discriminant analysis) irisMclustDA <- MclustDA(X.train, Class.train, modelType = \"EDDA\", modelNames = \"EEE\") summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>        -125.443 75 22 -345.8707 #>              #> Classes       n     % Model G #>   setosa     25 33.33   EEE 1 #>   versicolor 25 33.33   EEE 1 #>   virginica  25 33.33   EEE 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Means: #>               [,1] #> Sepal.Length 5.024 #> Sepal.Width  3.480 #> Petal.Length 1.456 #> Petal.Width  0.228 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Class = versicolor #>  #> Means: #>               [,1] #> Sepal.Length 5.992 #> Sepal.Width  2.776 #> Petal.Length 4.308 #> Petal.Width  1.352 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Class = virginica #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0097  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>        -125.443 75 22 -345.8707 #>              #> Classes       n     % Model G #>   setosa     25 33.33   EEE 1 #>   versicolor 25 33.33   EEE 1 #>   virginica  25 33.33   EEE 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0097  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          2        23 #> Classification error = 0.04  #> Brier score          = 0.0243   # common covariance structure selected by BIC irisMclustDA <- MclustDA(X.train, Class.train, modelType = \"EDDA\") summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -87.93758 75 36 -331.3047 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEV 1 #>   versicolor 25 33.33   VEV 1 #>   virginica  25 33.33   VEV 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Means: #>               [,1] #> Sepal.Length 5.024 #> Sepal.Width  3.480 #> Petal.Length 1.456 #> Petal.Width  0.228 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  0.154450439 0.097646496  0.017347101 0.005327878 #> Sepal.Width   0.097646496 0.105230813  0.004066916 0.005599939 #> Petal.Length  0.017347101 0.004066916  0.041742267 0.003476241 #> Petal.Width   0.005327878 0.005599939  0.003476241 0.006454832 #>  #> Class = versicolor #>  #> Means: #>               [,1] #> Sepal.Length 5.992 #> Sepal.Width  2.776 #> Petal.Length 4.308 #> Petal.Width  1.352 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26653496  0.06976610   0.17015657  0.04336127 #> Sepal.Width    0.06976610  0.09861066   0.07509657  0.03823057 #> Petal.Length   0.17015657  0.07509657   0.19799871  0.06126251 #> Petal.Width    0.04336127  0.03823057   0.06126251  0.03627058 #>  #> Class = virginica #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.37570480 0.025364426  0.280227270  0.03871029 #> Sepal.Width    0.02536443 0.080872957  0.006413281  0.05009229 #> Petal.Length   0.28022727 0.006413281  0.309059434  0.05805268 #> Petal.Width    0.03871029 0.050092291  0.058052679  0.07540425 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          0        25 #> Classification error = 0.0133  #> Brier score          = 0.0054  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -87.93758 75 36 -331.3047 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEV 1 #>   versicolor 25 33.33   VEV 1 #>   virginica  25 33.33   VEV 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          0        25 #> Classification error = 0.0133  #> Brier score          = 0.0054  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          2        23 #> Classification error = 0.04  #> Brier score          = 0.0297   # general covariance structure selected by BIC irisMclustDA <- MclustDA(X.train, Class.train) summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -71.74193 75 48 -350.7233 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEI 2 #>   versicolor 25 33.33   VEE 2 #>   virginica  25 33.33   XXX 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Mixing probabilities: 0.7229143 0.2770857  #>  #> Means: #>                   [,1]      [,2] #> Sepal.Length 5.1761949 4.6269248 #> Sepal.Width  3.6366552 3.0712877 #> Petal.Length 1.4777585 1.3992323 #> Petal.Width  0.2441875 0.1857668 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.120728    0.000000   0.00000000 0.000000000 #> Sepal.Width      0.000000    0.046461   0.00000000 0.000000000 #> Petal.Length     0.000000    0.000000   0.04892923 0.000000000 #> Petal.Width      0.000000    0.000000   0.00000000 0.006358681 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.03044364  0.00000000   0.00000000 0.000000000 #> Sepal.Width    0.00000000  0.01171594   0.00000000 0.000000000 #> Petal.Length   0.00000000  0.00000000   0.01233835 0.000000000 #> Petal.Width    0.00000000  0.00000000   0.00000000 0.001603451 #>  #> Class = versicolor #>  #> Mixing probabilities: 0.2364317 0.7635683  #>  #> Means: #>                  [,1]     [,2] #> Sepal.Length 6.736465 5.761483 #> Sepal.Width  3.000982 2.706336 #> Petal.Length 4.669933 4.195931 #> Petal.Width  1.400893 1.336861 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  0.030012918 0.008262520   0.02533959 0.008673053 #> Sepal.Width   0.008262520 0.020600060   0.01200205 0.008400168 #> Petal.Length  0.025339590 0.012002053   0.03924151 0.013788157 #> Petal.Width   0.008673053 0.008400168   0.01378816 0.007666627 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.16630011  0.04578222   0.14040543  0.04805696 #> Sepal.Width    0.04578222  0.11414392   0.06650279  0.04654492 #> Petal.Length   0.14040543  0.06650279   0.21743528  0.07639950 #> Petal.Width    0.04805696  0.04654492   0.07639950  0.04248041 #>  #> Class = virginica #>  #> Mixing probabilities: 1  #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.349184    0.019056     0.272144    0.040896 #> Sepal.Width      0.019056    0.079104     0.011296    0.048064 #> Petal.Length     0.272144    0.011296     0.285504    0.049536 #> Petal.Width      0.040896    0.048064     0.049536    0.074624 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         25         0 #>   virginica       0          0        25 #> Classification error = 0  #> Brier score          = 0.0041  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -71.74193 75 48 -350.7233 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEI 2 #>   versicolor 25 33.33   VEE 2 #>   virginica  25 33.33   XXX 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         25         0 #>   virginica       0          0        25 #> Classification error = 0  #> Brier score          = 0.0041  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0159   plot(irisMclustDA)     plot(irisMclustDA, dimens = 3:4)     plot(irisMclustDA, dimens = 4)      plot(irisMclustDA, what = \"classification\")  plot(irisMclustDA, what = \"classification\", newdata = X.test)  plot(irisMclustDA, what = \"classification\", dimens = 3:4)  plot(irisMclustDA, what = \"classification\", newdata = X.test, dimens = 3:4)  plot(irisMclustDA, what = \"classification\", dimens = 4)  plot(irisMclustDA, what = \"classification\", dimens = 4, newdata = X.test)   plot(irisMclustDA, what = \"train&test\", newdata = X.test)  plot(irisMclustDA, what = \"train&test\", newdata = X.test, dimens = 3:4)  plot(irisMclustDA, what = \"train&test\", newdata = X.test, dimens = 4)   plot(irisMclustDA, what = \"error\")  plot(irisMclustDA, what = \"error\", dimens = 3:4)  plot(irisMclustDA, what = \"error\", dimens = 4)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test, dimens = 3:4)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test, dimens = 4)   # \\donttest{ # simulated 1D data n <- 250  set.seed(1) triModal <- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5)) triClass <- c(rep(1,n), rep(2,n), rep(3,n)) odd <- seq(from = 1, to = length(triModal), by = 2) even <- odd + 1 triMclustDA <- MclustDA(triModal[odd], triClass[odd]) summary(triMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -942.4306 375  6 -1920.423 #>         #> Classes   n     % Model G #>       1 125 33.33     X 1 #>       2 125 33.33     X 1 #>       3 125 33.33     X 1 #>  #> Class prior probabilities: #>         1         2         3  #> 0.3333333 0.3333333 0.3333333  #>  #> Class = 1 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] -4.951981 #>  #> Variances: #> [1] 0.8268339 #>  #> Class = 2 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] -0.01814707 #>  #> Variances: #> [1] 1.201987 #>  #> Class = 3 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] 4.875429 #>  #> Variances: #> [1] 1.200321 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   0 124   1 #>     3   0   0 125 #> Classification error = 0.0053  #> Brier score          = 0.0073  summary(triMclustDA, newdata = triModal[even], newclass = triClass[even]) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -942.4306 375  6 -1920.423 #>         #> Classes   n     % Model G #>       1 125 33.33     X 1 #>       2 125 33.33     X 1 #>       3 125 33.33     X 1 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   0 124   1 #>     3   0   0 125 #> Classification error = 0.0053  #> Brier score          = 0.0073  #>  #> Test confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   1 122   2 #>     3   0   1 124 #> Classification error = 0.0133  #> Brier score          = 0.0089  plot(triMclustDA, what = \"scatterplot\")  plot(triMclustDA, what = \"classification\")  plot(triMclustDA, what = \"classification\", newdata = triModal[even])  plot(triMclustDA, what = \"train&test\", newdata = triModal[even])  plot(triMclustDA, what = \"error\")  plot(triMclustDA, what = \"error\", newdata = triModal[even], newclass = triClass[even])   # simulated 2D cross data data(cross) odd <- seq(from = 1, to = nrow(cross), by = 2) even <- odd + 1 crossMclustDA <- MclustDA(cross[odd,-1], cross[odd,1]) summary(crossMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df     BIC #>       -1381.404 250  9 -2812.5 #>         #> Classes   n  % Model G #>       1 125 50   XXX 1 #>       2 125 50   XXI 1 #>  #> Class prior probabilities: #>   1   2  #> 0.5 0.5  #>  #> Class = 1 #>  #> Mixing probabilities: 1  #>  #> Means: #>           [,1] #> X1  0.03982835 #> X2 -0.55982893 #>  #> Variances: #> [,,1] #>          X1       X2 #> X1 1.030302  1.81975 #> X2 1.819750 72.90428 #>  #> Class = 2 #>  #> Mixing probabilities: 1  #>  #> Means: #>          [,1] #> X1  0.2877120 #> X2 -0.1231171 #>  #> Variances: #> [,,1] #>         X1        X2 #> X1 87.3583 0.0000000 #> X2  0.0000 0.8995777 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2 #>     1 112  13 #>     2  13 112 #> Classification error = 0.104  #> Brier score          = 0.0563  summary(crossMclustDA, newdata = cross[even,-1], newclass = cross[even,1]) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df     BIC #>       -1381.404 250  9 -2812.5 #>         #> Classes   n  % Model G #>       1 125 50   XXX 1 #>       2 125 50   XXI 1 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2 #>     1 112  13 #>     2  13 112 #> Classification error = 0.104  #> Brier score          = 0.0563  #>  #> Test confusion matrix: #>      Predicted #> Class   1   2 #>     1 118   7 #>     2   5 120 #> Classification error = 0.048  #> Brier score          = 0.0298  plot(crossMclustDA, what = \"scatterplot\")  plot(crossMclustDA, what = \"classification\")  plot(crossMclustDA, what = \"classification\", newdata = cross[even,-1])  plot(crossMclustDA, what = \"train&test\", newdata = cross[even,-1])  plot(crossMclustDA, what = \"error\")  plot(crossMclustDA, what = \"error\", newdata =cross[even,-1], newclass = cross[even,1])  # }"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Dimension reduction for model-based clustering and classification — MclustDR","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"dimension reduction method visualizing clustering classification structure obtained finite mixture Gaussian densities.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"","code":"MclustDR(object, lambda = 1, normalized = TRUE, Sigma,          tol = sqrt(.Machine$double.eps))"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"object object class 'Mclust' 'MclustDA'    resulting call , respectively, Mclust    MclustDA. lambda tuning parameter range [0,1] described    Scrucca (2014). directions mostly separate estimated clusters    classes recovered using default value 1. Users can set    parameter balance relative importance information derived    cluster/class means covariances. instance, value 0.5 gives    equal importance differences means covariances among clusters/classes. normalized Logical. TRUE directions normalized unit norm. Sigma Marginal covariance matrix data. provided estimated MLE observed data. tol tolerance value.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"method aims reducing dimensionality identifying set linear combinations, ordered importance quantified associated eigenvalues, original features capture clustering classification structure contained data. Information dimension reduction subspace obtained variation group means , depending estimated mixture model, variation group covariances (see Scrucca, 2010). Observations may projected onto reduced subspace, thus providing summary plots help visualize underlying structure. method extended supervised case, .e. true classification known (see Scrucca, 2014). implementation provide formal procedure selection dimensionality. future release include one methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"object class 'MclustDR' following components: call matched call type character string specifying type model dimension reduction computed. Currently, possible values \"Mclust\" clustering, \"MclustDA\" \"EDDA\" classification. x data matrix. Sigma covariance matrix data. mixcomp numeric vector specifying mixture component data observation. class factor specifying classification data observation. model-based clustering equivalent corresponding mixture component. model-based classification known classification. G number mixture components. modelName name parameterization estimated mixture model(s). See mclustModelNames. mu matrix means mixture component. sigma array covariance matrices mixture component. pro estimated prior mixture component. M kernel matrix. lambda tuning parameter. evalues eigenvalues generalized eigen-decomposition kernel matrix. raw.evectors raw eigenvectors generalized eigen-decomposition kernel matrix, ordered according eigenvalues. basis basis estimated dimension reduction subspace. std.basis basis estimated dimension reduction subspace standardized variables unit standard deviation. numdir dimension projection subspace. dir estimated directions, .e. data projected onto estimated dimension reduction subspace.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"Scrucca, L. (2010) Dimension reduction model-based clustering. Statistics Computing, 20(4), pp. 471-484. Scrucca, L. (2014) Graphical Tools Model-based Mixture Discriminant Analysis. Advances Data Analysis Classification, 8(2), pp. 147-165.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/MclustDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dimension reduction for model-based clustering and classification — MclustDR","text":"","code":"# clustering data(diabetes) mod <- Mclust(diabetes[,-1]) summary(mod) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -2303.496 145 29 -4751.316 -4770.169 #>  #> Clustering table: #>  1  2  3  #> 81 36 28   dr <- MclustDR(mod) summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: Mclust (VVV, 3)  #>          #> Clusters  n #>        1 81 #>        2 36 #>        3 28 #>  #> Estimated basis vectors:  #>              Dir1     Dir2 #> glucose  0.764699  0.86359 #> insulin -0.643961 -0.22219 #> sspg     0.023438 -0.45260 #>  #>                Dir1      Dir2 #> Eigenvalues  1.2629   0.35218 #> Cum. %      78.1939 100.00000 plot(dr, what = \"scatterplot\")  plot(dr, what = \"evalues\")   dr <- MclustDR(mod, lambda = 0.5)  summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: Mclust (VVV, 3)  #>          #> Clusters  n #>        1 81 #>        2 36 #>        3 28 #>  #> Estimated basis vectors:  #>              Dir1     Dir2      Dir3 #> glucose -0.988671 -0.76532  0.966565 #> insulin  0.142656  0.13395 -0.252109 #> sspg    -0.046689 -0.62955 -0.046837 #>  #>                Dir1     Dir2      Dir3 #> Eigenvalues  1.3506  0.75608   0.53412 #> Cum. %      51.1440 79.77436 100.00000 plot(dr, what = \"scatterplot\")  plot(dr, what = \"evalues\")   # classification data(banknote)  da <- MclustDA(banknote[,2:7], banknote$Status, modelType = \"EDDA\") dr <- MclustDR(da) summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: EDDA  #>               #> Classes         n Model G #>   counterfeit 100   EVE 1 #>   genuine     100   EVE 1 #>  #> Estimated basis vectors:  #>                Dir1 #> Length   -0.0019694 #> Left     -0.3271436 #> Right     0.3336519 #> Bottom    0.4391097 #> Top       0.4632982 #> Diagonal -0.6117083 #>  #>                 Dir1 #> Eigenvalues   1.7081 #> Cum. %      100.0000  da <- MclustDA(banknote[,2:7], banknote$Status) dr <- MclustDR(da) summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: MclustDA  #>               #> Classes         n Model G #>   counterfeit 100   EVE 2 #>   genuine     100   XXX 1 #>  #> Estimated basis vectors:  #>              Dir1     Dir2 #> Length   -0.07016 -0.25690 #> Left     -0.36888 -0.19963 #> Right     0.29525 -0.10111 #> Bottom    0.54683  0.46254 #> Top       0.55720  0.41370 #> Diagonal -0.40290  0.70628 #>  #>                Dir1     Dir2 #> Eigenvalues  1.7188   1.0607 #> Cum. %      61.8373 100.0000"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"Implements subset selection method selecting relevant directions spanning dimension reduction subspace visualizing clustering classification structure obtained finite mixture Gaussian densities.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"","code":"MclustDRsubsel(object, G = 1:9,                        modelNames = mclust.options(\"emModelNames\"),                         ...,                        bic.stop = 0, bic.cutoff = 0,                         mindir = 1,                         verbose = interactive())"},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"object object class 'MclustDR' resulting call MclustDR. G integer vector specifying numbers mixture components clusters. modelNames vector character strings indicating models fitted. See mclustModelNames description available models. ... arguments passed Mclust MclustDA. bic.stop criterion terminate search. maximal BIC difference less bic.stop algorithm stops.    Two tipical values :  bic.cutoff value specifying select simplest ``best'' model within bic.cutoff maximum value achieved. Setting 0 (default) simply select model largest BIC difference. mindir integer value specifying minimum number directions estimated. verbose logical integer value specifying much detailed information reported iterations algorithm.    Possible values :","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"GMMDR method aims reducing dimensionality identifying set linear combinations, ordered importance quantified associated eigenvalues, original features capture clustering classification structure contained data. implemented MclustDR. MclustDRsubsel function implements greedy forward search algorithm discussed Scrucca (2010) prune set GMMDR directions. criterion used select relevant directions based BIC difference clustering model model feature proposal clustering relevance. steps following: 1. Select first feature one maximizes BIC difference best clustering model model assumes clustering, .e. single component. 2. Select next feature amongst previously included, one maximizes BIC difference. 3. Iterate previous step BIC differences inclusion feature become less bic.stop. step, search model space performed respect model parametrisation number clusters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"object class 'MclustDRsubsel' inherits 'MclustDR', components latter plus following: basisx basis estimated dimension reduction subspace expressed terms original variables. std.basisx basis estimated dimension reduction subspace expressed terms original variables standardized unit standard deviation.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"Scrucca, L. (2010) Dimension reduction model-based clustering. Statistics Computing, 20(4), pp. 471-484. Scrucca, L. (2014) Graphical Tools Model-based Mixture Discriminant Analysis. Advances Data Analysis Classification, 8(2), pp. 147-165","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/MclustDRsubsel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset selection for GMMDR directions based on BIC — MclustDRsubsel","text":"","code":"# \\donttest{ # clustering data(crabs, package = \"MASS\") x <- crabs[,4:8] class <- paste(crabs$sp, crabs$sex, sep = \"|\") mod <- Mclust(x) table(class, mod$classification) #>       #> class  1  2  3  4 #>   B|F 49  0  0  1 #>   B|M 11  0 39  0 #>   O|F  0  5  0 45 #>   O|M  0 50  0  0 dr <- MclustDR(mod) summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: Mclust (EEV, 4)  #>          #> Clusters  n #>        1 60 #>        2 55 #>        3 39 #>        4 46 #>  #> Estimated basis vectors:  #>         Dir1     Dir2     Dir3 #> FL -0.598015 -0.10316 -0.68314 #> RW -0.327540 -0.67796  0.15897 #> CL  0.002013  0.52296  0.17400 #> CW  0.538877 -0.36100 -0.24560 #> BD -0.494675  0.35484  0.64610 #>  #>                Dir1    Dir2       Dir3 #> Eigenvalues  1.5907  1.0782   0.099104 #> Cum. %      57.4678 96.4196 100.000000 plot(dr)        drs <- MclustDRsubsel(dr) summary(drs) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: Mclust (EVE, 5)  #>          #> Clusters  n #>        1 64 #>        2 36 #>        3 29 #>        4 41 #>        5 30 #>  #> Estimated basis vectors:  #>         Dir1       Dir2      Dir3 #> FL  0.659021 -0.1712004 -0.634547 #> RW  0.230063  0.8425324  0.027738 #> CL  0.037967 -0.4701147  0.254548 #> CW -0.548500  0.1994410 -0.299751 #> BD  0.458768  0.0067046  0.664783 #>  #>                Dir1     Dir2      Dir3 #> Eigenvalues  1.7179  0.99776   0.20408 #> Cum. %      58.8367 93.01017 100.00000 table(class, drs$classification) #>       #> class  1  2  3  4  5 #>   B|F 50  0  0  0  0 #>   B|M 14 36  0  0  0 #>   O|F  0  0 19  1 30 #>   O|M  0  0 10 40  0 plot(drs, what = \"scatterplot\")  plot(drs, what = \"pairs\")  plot(drs, what = \"contour\")  plot(drs, what = \"boundaries\")  plot(drs, what = \"evalues\")   # classification data(banknote) da <- MclustDA(banknote[,2:7], banknote$Status) table(banknote$Status, predict(da)$class) #>               #>               counterfeit genuine #>   counterfeit         100       0 #>   genuine               0     100 dr <- MclustDR(da) summary(dr) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: MclustDA  #>               #> Classes         n Model G #>   counterfeit 100   EVE 2 #>   genuine     100   XXX 1 #>  #> Estimated basis vectors:  #>              Dir1     Dir2 #> Length   -0.07016 -0.25690 #> Left     -0.36888 -0.19963 #> Right     0.29525 -0.10111 #> Bottom    0.54683  0.46254 #> Top       0.55720  0.41370 #> Diagonal -0.40290  0.70628 #>  #>                Dir1     Dir2 #> Eigenvalues  1.7188   1.0607 #> Cum. %      61.8373 100.0000 drs <- MclustDRsubsel(dr) summary(drs) #> -----------------------------------------------------------------  #> Dimension reduction for model-based clustering and classification  #> -----------------------------------------------------------------  #>  #> Mixture model type: MclustDA  #>               #> Classes         n Model G #>   counterfeit 100   EEE 2 #>   genuine     100   XII 1 #>  #> Estimated basis vectors:  #>              Dir1     Dir2 #> Length    0.07016 -0.25690 #> Left      0.36888 -0.19963 #> Right    -0.29525 -0.10111 #> Bottom   -0.54683  0.46254 #> Top      -0.55720  0.41370 #> Diagonal  0.40290  0.70628 #>  #>                Dir1     Dir2 #> Eigenvalues  1.7188   1.0607 #> Cum. %      61.8373 100.0000 table(banknote$Status, predict(drs)$class) #>               #>               counterfeit genuine #>   counterfeit         100       0 #>   genuine               1      99 plot(drs, what = \"scatterplot\")  plot(drs, what = \"classification\")  plot(drs, what = \"boundaries\")# }"},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":null,"dir":"Reference","previous_headings":"","what":"MclustSSC semi-supervised classification — MclustSSC","title":"MclustSSC semi-supervised classification — MclustSSC","text":"Semi-Supervised classification based Gaussian finite mixture modeling.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MclustSSC semi-supervised classification — MclustSSC","text":"","code":"MclustSSC(data, class,            G = NULL, modelNames = NULL,            prior = NULL, control = emControl(),            warn = mclust.options(\"warn\"),            verbose = interactive(),           ...)"},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MclustSSC semi-supervised classification — MclustSSC","text":"data data frame matrix giving training data. class vector giving known class labels (either numerical value      character string) observations training data.      Observations unknown class encoded NA. G integer value specifying numbers mixture components classes.      default set equal number known classes.     See examples . modelNames vector character strings indicating models fitted      EM (see description mclustModelNames).     See examples . prior default assumes prior, argument allows specification      conjugate prior means variances function      priorControl. control list control parameters EM. defaults set call     emControl(). warn logical value indicating whether certain warnings     (usually related singularity) issued     estimation fails.      default controlled mclust.options. verbose logical controlling text progress bar displayed     fitting procedure. default TRUE session      interactive, FALSE otherwise. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MclustSSC semi-supervised classification — MclustSSC","text":"object class 'MclustSSC' providing optimal (according   BIC) Gaussian mixture model semi-supervised classification. details output components follows: call matched call. data input data matrix. class input class labels (including NAs unknown labels. modelName character string specifying \"best\" estimated model. G numerical value specifying number mixture components classes \"best\" estimated model. n total number observations data. d dimension data. BIC BIC values. loglik Log-likelihood selected model. df Number estimated parameters. bic Optimal BIC value. parameters list following components: pro vector whose kth component mixing proportion         kth component mixture model. mean mean component. one component,         matrix whose kth column mean kth         component mixture model. variance list variance parameters model.         components list depend model specification.          See help file mclustVariance details.  z matrix whose [,k]th entry probability observation   test data belongs kth class. classification classification corresponding z, .e. map(z). prior prior used (). control list control parameters used EM algorithm.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MclustSSC semi-supervised classification — MclustSSC","text":"semi-supervised approach implemented MclustSSC() simple Gaussian mixture model classification first M-step observations known class labels used parameters estimation. , standard EM algorithm used updating probabiltiy class membership unlabelled data keeping fixed probabilities labelled data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MclustSSC semi-supervised classification — MclustSSC","text":"Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MclustSSC semi-supervised classification — MclustSSC","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/MclustSSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MclustSSC semi-supervised classification — MclustSSC","text":"","code":"# Simulate two overlapping groups n <- 200 pars <- list(pro = c(0.5, 0.5),              mean = matrix(c(-1,1), nrow = 2, ncol = 2, byrow = TRUE),              variance = mclustVariance(\"EII\", d = 2, G = 2)) pars$variance$sigmasq <- 1 data <- sim(\"EII\", parameters = pars, n = n, seed = 12) class <- data[,1] X <- data[,-1] clPairs(X, class, symbols = c(1,2), main = \"Full classified data\")   # Randomly remove labels cl <- class; cl[sample(1:n, size = 195)] <- NA table(cl, useNA = \"ifany\") #> cl #>    1    2 <NA>  #>    3    2  195  clPairs(X, ifelse(is.na(cl), 0, class),         symbols = c(0, 16, 17), colors = c(\"grey\", 4, 2),         main = \"Partially classified data\")   # Fit semi-supervised classification model mod_SSC  <- MclustSSC(X, cl) summary(mod_SSC, parameters = TRUE) #> ----------------------------------------------------------------  #> Gaussian finite mixture model for semi-supervised classification  #> ----------------------------------------------------------------  #>  #>  log-likelihood   n df       BIC #>       -654.5776 200  6 -1340.945 #>         #> Classes   n    % Model G #>    1      3  1.5   EII 1 #>    2      2  1.0   EII 1 #>    <NA> 195 97.5         #>  #> Mixing probabilities: #>         1         2  #> 0.5022706 0.4977294  #>  #> Means: #>            1         2 #> x1 -1.002123 0.9946794 #> x2 -1.038680 0.9812348 #>  #> Variances: #> 1  #>          x1       x2 #> x1 0.912807 0.000000 #> x2 0.000000 0.912807 #> 2  #>          x1       x2 #> x1 0.912807 0.000000 #> x2 0.000000 0.912807 #>  #> Classification summary: #>       Predicted #> Class   1  2 #>   1     3  0 #>   2     0  2 #>   <NA> 99 96  pred_SSC <- predict(mod_SSC) table(Predicted = pred_SSC$classification, Actual = class) #>          Actual #> Predicted  1  2 #>         1 91 10 #>         2  9 90  ngrid <- 50 xgrid <- seq(-3, 3, length.out = ngrid) ygrid <- seq(-4, 4.5, length.out = ngrid) xygrid <- expand.grid(xgrid, ygrid) pred_SSC  <- predict(mod_SSC, newdata = xygrid) col <- mclust.options(\"classPlotColors\")[class] pch <- class pch[!is.na(cl)] = ifelse(cl[!is.na(cl)] == 1, 19, 17) plot(X, pch = pch, col = col) contour(xgrid, ygrid, matrix(pred_SSC$z[,1], ngrid, ngrid),          add = TRUE, levels = 0.5, drawlabels = FALSE, lty = 2, lwd = 2)"},{"path":"https://mclust-org.github.io/mclust/reference/acidity.html","id":null,"dir":"Reference","previous_headings":"","what":"Acidity data — acidity","title":"Acidity data — acidity","text":"Acidity index measured sample 155 lakes Northeastern United States. Following Crawford et al. (1992, 1994), data expressed log(ANC+50), ANC acidity neutralising capacity value. data also used fit mixture gaussian distributions Richardson Green (1997), McLachlan Peel (2000, Sec. 6.6.2).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/acidity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acidity data — acidity","text":"","code":"data(acidity)"},{"path":"https://mclust-org.github.io/mclust/reference/acidity.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Acidity data — acidity","text":"https://www.stats.bris.ac.uk/~peter/mixdata","code":""},{"path":"https://mclust-org.github.io/mclust/reference/acidity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acidity data — acidity","text":"Crawford, S. L. (1994) application Laplace method finite mixture distribution. Journal American Statistical Association, 89, 259--267. Crawford, S. L., DeGroot, M. H., Kadane, J. B., Small, M. J. (1994) Modeling lake chemistry distributions: Approximate Bayesian methods estimating finite mixture model. Technometrics, 34, 441--453. McLachlan, G. Peel, D. (2000) Finite Mixture Models. Wiley, New York. Richardson, S. Green, P. J. (1997) Bayesian analysis mixtures unknown number components (discussion). Journal Royal Statistical Society, Series B, 59, 731--792.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjusted Rand Index — adjustedRandIndex","title":"Adjusted Rand Index — adjustedRandIndex","text":"Computes adjusted Rand index comparing two classifications.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjusted Rand Index — adjustedRandIndex","text":"","code":"adjustedRandIndex(x, y)"},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjusted Rand Index — adjustedRandIndex","text":"x numeric character vector class labels. y numeric character vector class labels.     length y x.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjusted Rand Index — adjustedRandIndex","text":"adjusted Rand index comparing two partitions (scalar).     index zero expected value case random partition, bounded 1 case perfect agreement two partitions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjusted Rand Index — adjustedRandIndex","text":"L. Hubert P. Arabie (1985) Comparing Partitions, Journal Classification, 2, pp. 193-218.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/adjustedRandIndex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjusted Rand Index — adjustedRandIndex","text":"","code":"a <- rep(1:3, 3) a #> [1] 1 2 3 1 2 3 1 2 3 b <- rep(c(\"A\", \"B\", \"C\"), 3) b #> [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" adjustedRandIndex(a, b) #> [1] 1  a <- sample(1:3, 9, replace = TRUE) a #> [1] 3 2 3 3 2 3 1 2 2 b <- sample(c(\"A\", \"B\", \"C\"), 9, replace = TRUE) b #> [1] \"A\" \"A\" \"B\" \"A\" \"B\" \"C\" \"C\" \"B\" \"B\" adjustedRandIndex(a, b) #> [1] 0.08695652  a <- rep(1:3, 4) a #>  [1] 1 2 3 1 2 3 1 2 3 1 2 3 b <- rep(c(\"A\", \"B\", \"C\", \"D\"), 3) b #>  [1] \"A\" \"B\" \"C\" \"D\" \"A\" \"B\" \"C\" \"D\" \"A\" \"B\" \"C\" \"D\" adjustedRandIndex(a, b) #> [1] -0.2790698  irisHCvvv <- hc(modelName = \"VVV\", data = iris[,-5]) cl3 <- hclass(irisHCvvv, 3) adjustedRandIndex(cl3,iris[,5]) #> [1] 0.7591987  irisBIC <- mclustBIC(iris[,-5]) adjustedRandIndex(summary(irisBIC,iris[,-5])$classification,iris[,5]) #> [1] 0.5681159 adjustedRandIndex(summary(irisBIC,iris[,-5],G=3)$classification,iris[,5]) #> [1] 0.9038742"},{"path":"https://mclust-org.github.io/mclust/reference/banknote.html","id":null,"dir":"Reference","previous_headings":"","what":"Swiss banknotes data — banknote","title":"Swiss banknotes data — banknote","text":"data set contains six measurements made 100 genuine 100 counterfeit old-Swiss 1000-franc bank notes.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/banknote.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swiss banknotes data — banknote","text":"","code":"data(banknote)"},{"path":"https://mclust-org.github.io/mclust/reference/banknote.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Swiss banknotes data — banknote","text":"data frame following variables: Status status banknote: genuine counterfeit Length Length bill (mm) Left Width left edge (mm) Right Width right edge (mm) Bottom Bottom margin width (mm) Top Top margin width (mm) Diagonal Length diagonal (mm)","code":""},{"path":"https://mclust-org.github.io/mclust/reference/banknote.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Swiss banknotes data — banknote","text":"Flury, B. Riedwyl, H. (1988). Multivariate Statistics: practical approach. London: Chapman & Hall, Tables 1.1 1.2, pp. 5-8.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/bic.html","id":null,"dir":"Reference","previous_headings":"","what":"BIC for Parameterized Gaussian Mixture Models — bic","title":"BIC for Parameterized Gaussian Mixture Models — bic","text":"Computes BIC (Bayesian Information Criterion) parameterized   mixture models given loglikelihood, dimension data,   number mixture components model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/bic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BIC for Parameterized Gaussian Mixture Models — bic","text":"","code":"bic(modelName, loglik, n, d, G, noise=FALSE, equalPro=FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/bic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BIC for Parameterized Gaussian Mixture Models — bic","text":"modelName character string indicating model. help file     mclustModelNames describes available models. loglik log-likelihood data set respect Gaussian mixture model     specified modelName argument. n number observations data used compute loglik. d dimension data used compute loglik. G number components Gaussian mixture model used compute     loglik. noise logical variable indicating whether model includes    optional Poisson noise component. default assume noise    component. equalPro logical variable indicating whether components     model assumed present equal proportion. default     assume unequal mixing proportions. ... Catches unused arguments indirect list call via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/bic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BIC for Parameterized Gaussian Mixture Models — bic","text":"BIC Bayesian Information Criterion given input arguments.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/bic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BIC for Parameterized Gaussian Mixture Models — bic","text":"","code":"# \\donttest{ n <- nrow(iris) d <- ncol(iris)-1 G <- 3  emEst <- me(modelName=\"VVI\", data=iris[,-5], unmap(iris[,5])) names(emEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\" \"control\"    \"loglik\"      args(bic) #> function (modelName, loglik, n, d, G, noise = FALSE, equalPro = FALSE,  #>     ...)  #> NULL bic(modelName=\"VVI\", loglik=emEst$loglik, n=n, d=d, G=G) #> [1] -744.0273 # do.call(\"bic\", emEst)    ## alternative call # }"},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":null,"dir":"Reference","previous_headings":"","what":"Component Density for Parameterized MVN Mixture Models — cdens","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"Computes component densities observations MVN mixture models   parameterized eigenvalue decomposition.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"","code":"cdens(data, modelName, parameters, logarithm = FALSE, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. parameters parameters model: mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details.  logarithm logical value indicating whether logarithm component        densities returned. default return component        densities, obtained log component densities exponentiation. warn logical value indicating whether warning issued     computations fail. default warn=FALSE. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"numeric matrix whose [,k]th entry    density log density observation component k.    densities scaled mixing proportions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"one component densities large magnitude,   may possible compute logarithm component   densities component densities due overflow.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/cdens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Component Density for Parameterized MVN Mixture Models — cdens","text":"","code":"z2 <- unmap(hclass(hcVVV(faithful),2)) # initial value for 2 class case  model <- me(modelName = \"EEE\", data = faithful, z = z2) cdens(modelName = \"EEE\", data = faithful, logarithm = TRUE,        parameters = model$parameters)[1:5,] #>         [,1]       [,2] #> 1  -4.504988 -15.570952 #> 2 -28.297451  -2.782971 #> 3  -6.042371 -11.151408 #> 4 -18.516948  -3.349049 #> 5  -2.967399 -30.134605  data(cross) odd <- seq(1, nrow(cross), by = 2) oddBIC <- mclustBIC(cross[odd,-1])  oddModel <- mclustModel(cross[odd,-1], oddBIC) ## best parameter estimates names(oddModel) #> [1] \"modelName\"  \"n\"          \"d\"          \"G\"          \"bic\"        #> [6] \"loglik\"     \"parameters\" \"z\"           even <- odd + 1 densities <- cdens(modelName = oddModel$modelName, data = cross[even,-1],                     parameters = oddModel$parameters) cbind(class = cross[even,1], densities)[1:5,] #>    class                          #> 2      1 0.014497007 1.123598e-07 #> 4      1 0.001087501 1.333448e-75 #> 6      1 0.005431090 1.180715e-02 #> 8      1 0.013545695 2.488475e-10 #> 10     1 0.001215779 9.250963e-03"},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":null,"dir":"Reference","previous_headings":"","what":"Component Density for a Parameterized MVN Mixture Model — cdensE","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"Computes component densities points parameterized MVN mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"","code":"cdensE(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensV(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensX(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEII(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVII(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEEI(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVEI(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEVI(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVVI(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEEE(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEEV(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVEV(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVVV(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEVE(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensEVV(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVEE(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensVVE(data, logarithm = FALSE, parameters, warn = NULL, ...)  cdensXII(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensXXI(data, logarithm = FALSE, parameters, warn = NULL, ...) cdensXXX(data, logarithm = FALSE, parameters, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. logarithm logical value indicating whether logarithm     component densities returned.     default return component densities,     obtained log component densities exponentiation. parameters parameters model: mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details. pro Mixing proportions components mixture.                 model includes Poisson term noise,                 one mixing proportion number                 Gaussian components.  warn logical value indicating whether warning issued     computations fail. default warn=FALSE. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"numeric matrix whose [,j]th    entry density observation component j.    densities scaled mixing proportions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"one component densities large magnitude,   may possible compute logarithm component   densities component densities due overflow.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/cdensE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Component Density for a Parameterized MVN Mixture Model — cdensE","text":"","code":"# \\donttest{ z2 <- unmap(hclass(hcVVV(faithful),2)) # initial value for 2 class case  model <- meVVV(data=faithful, z=z2) cdensVVV(data=faithful, logarithm = TRUE, parameters = model$parameters) #>           [,1]       [,2] #> 1    -4.197962 -23.327906 #> 2   -23.342333  -2.639804 #> 3    -5.369492 -16.425216 #> 4   -15.294924  -3.232768 #> 5    -3.060038 -50.710265 #> 6   -13.290054  -7.761979 #> 7    -3.699704 -57.918268 #> 8    -5.334659 -26.752622 #> 9   -22.962876  -2.412796 #> 10   -3.034001 -44.933104 #> 11  -22.934312  -2.528941 #> 12   -3.676302 -32.771717 #> 13   -2.724501 -37.562422 #> 14  -27.479203  -3.332165 #> 15   -3.170498 -55.618395 #> 16  -20.214896  -2.518439 #> 17  -21.915710  -4.216529 #> 18   -3.455892 -59.675676 #> 19  -26.760842  -3.595670 #> 20   -2.679311 -39.367492 #> 21  -24.676501  -2.687279 #> 22  -27.479203  -3.332165 #> 23   -4.858440 -20.080789 #> 24   -7.357413 -10.919858 #> 25   -3.707075 -47.408698 #> 26   -4.826034 -25.481836 #> 27  -20.944700  -2.269342 #> 28   -2.921123 -33.631614 #> 29   -3.238694 -28.304652 #> 30   -2.776193 -45.080634 #> 31   -3.466375 -39.469218 #> 32   -3.010859 -45.669805 #> 33   -6.449804 -15.147156 #> 34   -2.893828 -33.676595 #> 35   -3.472704 -26.585813 #> 36  -21.731435  -2.312102 #> 37  -25.554020  -2.900109 #> 38   -3.677658 -59.639204 #> 39  -21.329762  -3.062301 #> 40   -4.247178 -61.991292 #> 41   -2.677669 -42.761619 #> 42  -20.946033  -2.714943 #> 43   -2.993015 -51.386831 #> 44  -22.685815  -3.270025 #> 45   -3.960485 -47.302375 #> 46   -6.598464 -20.802812 #> 47   -6.211837 -25.551593 #> 48  -20.374670  -2.305713 #> 49   -3.012673 -52.862464 #> 50  -19.230203  -2.593682 #> 51   -4.415900 -57.463454 #> 52   -4.155687 -59.620152 #> 53  -22.934312  -2.528941 #> 54   -3.677658 -59.639204 #> 55  -24.193790  -2.917515 #> 56   -3.702828 -62.476248 #> 57   -4.178361 -23.158393 #> 58  -22.961895  -5.472180 #> 59   -3.220395 -49.108148 #> 60   -2.680246 -42.118651 #> 61  -16.621517  -2.671928 #> 62   -2.929064 -49.161225 #> 63  -26.881283  -3.164999 #> 64   -3.442207 -58.957948 #> 65  -21.320242  -3.337036 #> 66   -4.816504 -50.784915 #> 67   -2.736993 -36.607377 #> 68   -3.452079 -54.126106 #> 69  -17.334988  -3.949120 #> 70   -4.544447 -53.441400 #> 71   -3.052678 -34.577311 #> 72  -20.567346  -2.316439 #> 73   -2.869289 -47.303898 #> 74   -3.793379 -30.306906 #> 75  -18.780967  -3.237428 #> 76   -5.551980 -68.561758 #> 77  -18.770649  -2.736682 #> 78   -3.090617 -49.336764 #> 79   -3.201066 -28.392013 #> 80   -4.826034 -25.481836 #> 81   -3.011010 -34.787362 #> 82   -2.723047 -43.012954 #> 83   -4.062219 -33.036185 #> 84  -11.298804  -5.524240 #> 85   -3.345808 -32.488922 #> 86   -4.208793 -66.504258 #> 87   -3.076628 -30.077285 #> 88   -2.841868 -48.182626 #> 89  -22.581164  -3.203542 #> 90   -3.857276 -35.951643 #> 91  -16.678900  -2.737894 #> 92   -4.225630 -47.419501 #> 93  -24.413541  -2.615064 #> 94   -3.870686 -58.569039 #> 95  -20.629889  -4.070450 #> 96   -3.710463 -39.347779 #> 97   -3.145918 -54.839806 #> 98   -3.587831 -24.925274 #> 99  -23.891950  -2.520996 #> 100  -3.791269 -62.817662 #> 101 -13.314929  -4.015144 #> 102  -3.620549 -47.127765 #> 103 -22.563187  -2.807059 #> 104  -2.852246 -48.725153 #> 105  -2.924853 -34.554491 #> 106 -26.172906  -3.091087 #> 107  -3.211476 -56.013763 #> 108 -24.406371  -2.696018 #> 109  -3.729394 -62.392134 #> 110  -4.061563 -25.984956 #> 111  -4.136478 -54.869882 #> 112 -15.940531  -2.852310 #> 113  -4.281280 -65.752555 #> 114  -2.758530 -44.560136 #> 115 -23.139134  -3.748921 #> 116  -3.024552 -52.518067 #> 117 -20.025202  -3.417245 #> 118  -3.127196 -52.956969 #> 119 -21.540990  -3.130198 #> 120  -3.362336 -48.054637 #> 121 -16.003038  -5.076151 #> 122  -4.349739 -32.007303 #> 123  -2.792823 -38.748925 #> 124 -20.567346  -2.316439 #> 125  -3.595774 -54.494859 #> 126  -3.719606 -27.759651 #> 127 -26.996373  -3.552868 #> 128  -2.807859 -48.321385 #> 129 -17.801948  -2.616670 #> 130  -4.095762 -57.353351 #> 131 -27.507973  -3.569953 #> 132  -2.932976 -38.642050 #> 133 -13.219165  -6.598774 #> 134  -3.924297 -46.755621 #> 135 -27.188030  -3.355339 #> 136  -2.728314 -44.556354 #> 137 -23.709163  -2.491718 #> 138  -3.983323 -65.582239 #> 139 -21.075819  -2.254025 #> 140  -3.650663 -26.069747 #> 141  -2.704316 -39.618171 #> 142 -16.326223  -2.794102 #> 143  -2.847325 -49.422198 #> 144  -4.045263 -58.391303 #> 145  -2.958232 -41.064783 #> 146 -19.435158  -2.621356 #> 147  -3.068862 -52.205973 #> 148 -23.376850  -2.685890 #> 149  -6.763224 -77.891170 #> 150 -23.754624  -2.623325 #> 151  -5.104238 -67.202584 #> 152  -2.943287 -31.692611 #> 153 -13.516733  -4.266377 #> 154  -2.956467 -51.358696 #> 155  -4.605864 -19.879599 #> 156  -4.048571 -30.189017 #> 157  -2.795904 -47.949919 #> 158  -6.048704 -43.036756 #> 159 -23.754624  -2.623325 #> 160  -4.868659 -37.175298 #> 161 -24.424929  -4.196397 #> 162  -3.473474 -39.792856 #> 163 -19.516176  -2.456391 #> 164  -3.285133 -27.903995 #> 165  -5.999115 -17.754059 #> 166  -3.425381 -49.479805 #> 167 -14.207790  -3.676640 #> 168  -4.424334 -69.131072 #> 169 -22.648320  -2.350947 #> 170  -5.022950 -58.257673 #> 171 -24.420125  -2.683646 #> 172 -18.892222  -2.315269 #> 173  -3.260305 -49.672861 #> 174  -6.086198 -14.806481 #> 175  -2.757288 -37.731271 #> 176  -2.681165 -42.607500 #> 177  -3.867798 -46.141116 #> 178 -19.239233  -4.027522 #> 179  -3.625995 -35.349204 #> 180  -3.163973 -35.561099 #> 181 -21.935642  -2.425455 #> 182  -3.260305 -49.672861 #> 183  -2.841467 -40.992268 #> 184  -4.038653 -28.833247 #> 185 -22.081202  -2.412819 #> 186  -2.849526 -44.792442 #> 187  -3.225392 -36.894643 #> 188 -27.188030  -3.355339 #> 189  -2.800981 -46.048960 #> 190 -18.619497  -2.376900 #> 191  -3.484011 -58.647539 #> 192 -21.874287  -2.752047 #> 193  -4.179506 -57.580043 #> 194  -3.189917 -37.341307 #> 195  -2.996970 -30.808798 #> 196  -2.704316 -39.618171 #> 197  -6.608032 -26.436920 #> 198  -2.869070 -42.356538 #> 199 -20.000070  -2.924230 #> 200  -3.351040 -52.911852 #> 201 -17.793378  -2.672037 #> 202  -2.722907 -43.533303 #> 203  -5.032900 -42.701164 #> 204 -22.946061  -2.429771 #> 205  -3.168950 -50.499176 #> 206 -27.737489  -3.448581 #> 207  -2.870129 -42.388558 #> 208  -3.912003 -31.230266 #> 209 -24.248577  -2.673448 #> 210  -2.852246 -48.725153 #> 211 -13.414135  -6.405328 #> 212  -3.242152 -54.626111 #> 213 -24.967565  -2.741435 #> 214  -3.377164 -26.866904 #> 215  -6.924280 -15.976850 #> 216  -2.891784 -37.973694 #> 217 -17.613974  -3.401969 #> 218  -5.470209 -65.202518 #> 219 -20.568685  -2.238339 #> 220  -2.888887 -35.527396 #> 221 -24.413541  -2.615064 #> 222  -2.742433 -41.035802 #> 223 -23.974824  -2.840374 #> 224  -3.366504 -45.814869 #> 225  -2.915115 -32.036623 #> 226  -2.753490 -35.545441 #> 227  -2.802601 -34.253551 #> 228  -2.722189 -39.554079 #> 229  -4.089498 -27.945174 #> 230  -2.958889 -49.009002 #> 231  -4.055045 -32.541083 #> 232 -16.953218  -3.397325 #> 233  -3.409814 -40.685358 #> 234 -20.879977  -2.964063 #> 235  -4.097194 -50.902135 #> 236 -22.330375  -2.393566 #> 237 -22.727043  -2.478507 #> 238  -2.805091 -39.753714 #> 239  -3.018993 -31.139851 #> 240 -14.374714  -3.799218 #> 241  -3.008801 -35.278518 #> 242 -21.777249  -4.372194 #> 243  -3.983323 -65.582239 #> 244  -9.754270  -7.750691 #> 245  -3.107232 -52.380234 #> 246  -3.616466 -29.739030 #> 247 -18.892222  -2.315269 #> 248  -2.724757 -44.058193 #> 249 -16.384450  -4.578577 #> 250  -3.320311 -41.221848 #> 251 -18.901661  -2.449105 #> 252  -2.815687 -47.100028 #> 253  -4.347960 -20.388537 #> 254  -3.867798 -46.141116 #> 255  -3.979570 -41.033588 #> 256  -3.437195 -28.390477 #> 257  -3.849179 -28.079956 #> 258  -2.815687 -47.100028 #> 259 -20.185417  -2.278720 #> 260  -2.679752 -40.358850 #> 261  -3.680269 -56.644036 #> 262  -2.956702 -50.248606 #> 263 -21.366355  -2.826749 #> 264  -2.841467 -40.992268 #> 265 -27.853767  -4.245748 #> 266 -16.147464  -2.829734 #> 267  -4.204452 -55.521276 #> 268  -2.817372 -36.347359 #> 269 -24.104705  -3.678010 #> 270  -4.123883 -49.898080 #> 271 -27.361985  -3.380903 #> 272  -3.541020 -45.116720 #> attr(,\"logarithm\") #> [1] TRUE #> attr(,\"modelName\") #> [1] \"VVV\" #> attr(,\"returnCode\") #> [1] 0  data(cross) z2 <- unmap(cross[,1])  model <- meEEV(data = cross[,-1], z = z2)  EEVdensities <- cdensEEV( data = cross[,-1], parameters = model$parameters)  cbind(cross[,-1],map(EEVdensities))# } #>                X1            X2 map(EEVdensities) #> 1     1.262954285 -14.370462129                 1 #> 2    -0.326233361   4.418706353                 1 #> 3     1.329799263   3.794430288                 1 #> 4     1.272429321  16.865135087                 1 #> 5     0.414641434   9.310628915                 1 #> 6    -1.539950042   0.736292793                 2 #> 7    -0.928567035  -0.742713858                 2 #> 8    -0.294720447   5.454660878                 1 #> 9    -0.005767173  -7.986781308                 1 #> 10    2.404653389   0.948792512                 2 #> 11    0.763593461   3.175870260                 1 #> 12   -0.799009249   4.953540226                 1 #> 13   -1.147657009 -10.208978717                 1 #> 14   -0.289461574  13.161163849                 1 #> 15   -0.299215118   6.319050396                 1 #> 16   -0.411510833  22.564000336                 1 #> 17    0.252223448 -17.010244293                 1 #> 18   -0.891921127  -5.308315112                 1 #> 19    0.435683299 -15.430520672                 1 #> 20   -1.237538422  -3.788981080                 1 #> 21   -0.224267885   2.791272389                 1 #> 22    0.377395646  15.323135274                 1 #> 23    0.133336361  -3.990463239                 1 #> 24    0.804189510 -10.787373750                 1 #> 25   -0.057106774  -2.766428228                 1 #> 26    0.503607972   5.589487825                 1 #> 27    1.085769362   1.637119723                 1 #> 28   -0.690953840  11.865608381                 1 #> 29   -1.284599354  -2.690183821                 1 #> 30    0.046726172 -14.833995679                 1 #> 31   -0.235706556   8.563486227                 1 #> 32   -0.542888255 -10.018106578                 1 #> 33   -0.433310317   5.552698281                 1 #> 34   -0.649471647   4.621443448                 1 #> 35    0.726750747   3.325131934                 1 #> 36    1.151911754  15.515047175                 1 #> 37    0.992160365  -1.855301100                 1 #> 38   -0.429513109 -11.827756259                 1 #> 39    1.238304101   0.571266866                 2 #> 40   -0.279346282  -2.087797060                 1 #> 41    1.757903090   5.715542948                 1 #> 42    0.560746091  14.711798569                 1 #> 43   -0.452783973 -16.274948214                 1 #> 44   -0.832043296  -1.924973563                 1 #> 45   -1.166570547   0.633295272                 2 #> 46   -1.065590580   4.947369026                 1 #> 47   -1.563782051  -6.271411914                 1 #> 48    1.156536997   3.515093481                 1 #> 49    0.832047129   3.432701332                 1 #> 50   -0.227328691  -0.111354928                 2 #> 51    0.266137362  -1.119914878                 1 #> 52   -0.376702719  13.200701339                 1 #> 53    2.441364629   6.065358088                 1 #> 54   -0.795339117  17.607827369                 1 #> 55   -0.054877474  -2.421369111                 1 #> 56    0.250141323 -11.200963665                 1 #> 57    0.618243294  -3.561326303                 1 #> 58   -0.172623503   0.876569891                 1 #> 59   -2.223900274  -2.145482551                 2 #> 60   -1.263614385  -3.706451609                 1 #> 61    0.358728896 -14.194962440                 1 #> 62   -0.011045478  -7.175484858                 1 #> 63   -0.940649163  -9.866131045                 1 #> 64   -0.115825322   2.774778738                 1 #> 65   -0.814968709   3.103156113                 1 #> 66    0.242263481  13.856832788                 1 #> 67   -1.425098395  -2.965627731                 1 #> 68    0.365941123   8.535504157                 1 #> 69    0.248412649  -4.313300281                 1 #> 70    0.065288182 -13.633981155                 1 #> 71    0.019156392   3.910829903                 1 #> 72    0.257338377  -4.675830003                 1 #> 73   -0.649010078  -7.511031297                 1 #> 74   -0.119168762  -6.809828484                 1 #> 75    0.664135700   9.805531457                 1 #> 76    1.100969102  14.151896257                 1 #> 77    0.143771481   9.066279291                 1 #> 78   -0.117753598  -2.458421938                 1 #> 79   -0.912068367 -11.787115875                 1 #> 80   -1.437586241   2.003164478                 1 #> 81   -0.797089525  10.020898654                 1 #> 82    1.254083106   7.536549576                 1 #> 83    0.772142186   2.830650915                 1 #> 84   -0.219515627   1.999962649                 1 #> 85   -0.424810283  -7.592538509                 1 #> 86   -0.418980099   3.994247931                 1 #> 87    0.996986861   0.502173998                 2 #> 88   -0.275778029   0.611751506                 1 #> 89    1.256018817  -1.817655681                 1 #> 90    0.646674390 -10.422137286                 1 #> 91    1.299312303  -5.334689431                 1 #> 92   -0.873262112   6.894588456                 1 #> 93    0.008370960   0.350353050                 1 #> 94   -0.880871723   0.131821312                 2 #> 95    0.596259017  -1.676852712                 1 #> 96    0.119717641  12.605317446                 1 #> 97   -0.282173877   0.166370131                 2 #> 98    1.455988401   2.242764105                 1 #> 99    0.229019591   1.342986621                 1 #> 100   0.996543929  -8.669098624                 1 #> 101   0.781859185  -0.598200967                 2 #> 102  -0.776776622  11.582298370                 1 #> 103  -0.615989908   4.123127335                 1 #> 104   0.046580303 -13.068254611                 1 #> 105  -1.130385778   0.696080492                 2 #> 106   0.576718782   5.039057457                 1 #> 107  -1.280749432  -0.674519130                 2 #> 108   1.625447303   7.044279280                 1 #> 109  -0.500696596  -1.554017076                 1 #> 110   1.678297208  -9.461644006                 1 #> 111  -0.412519887   6.565061509                 1 #> 112  -0.972286836   2.363987184                 1 #> 113   0.025382868   4.892920732                 1 #> 114   0.027475337   9.369542685                 1 #> 115  -1.680182722   1.777555383                 1 #> 116   1.053750863 -14.666204586                 1 #> 117  -1.119599105   1.089362091                 1 #> 118   0.335617210 -14.736797569                 1 #> 119   0.494795767  -4.779387954                 1 #> 120   0.138052709   8.583118128                 1 #> 121  -0.118792026 -15.485855959                 1 #> 122   0.197684262   0.956885579                 1 #> 123  -1.068692711  -5.478016469                 1 #> 124  -0.803213217  -2.710772844                 1 #> 125  -1.113765136   8.785822722                 1 #> 126   1.580091684   4.104078024                 1 #> 127   1.497818761  11.649672607                 1 #> 128   0.262645459 -10.198819855                 1 #> 129  -1.232901200  -7.825143157                 1 #> 130  -0.003723534  -6.794732627                 1 #> 131   1.511672283  -1.166718152                 2 #> 132  -0.475698284  -9.016212019                 1 #> 133   0.797916438  -7.378814513                 1 #> 134  -0.974002561  -8.770972218                 1 #> 135   0.689372698   5.438784678                 1 #> 136  -0.955839103   4.939088294                 1 #> 137  -1.231707058   8.247893912                 1 #> 138  -0.956891881  23.954097300                 1 #> 139  -0.869782874  -1.622313589                 1 #> 140  -0.910680682   6.165132895                 1 #> 141   0.741276305  29.397730670                 1 #> 142   0.068511533   5.045404136                 1 #> 143  -0.323750755  -0.621155677                 1 #> 144  -1.086503047  -8.751986424                 1 #> 145  -1.015928947  -4.919279272                 1 #> 146  -0.767790185 -15.198230952                 1 #> 147  -1.119720061 -14.151354291                 1 #> 148  -0.448174237  -3.644884426                 1 #> 149   0.471736374   2.873577762                 1 #> 150  -1.180490683   0.363849135                 2 #> 151   1.470256997  -3.510086065                 1 #> 152  -1.311420592 -16.373000071                 1 #> 153  -0.096524923   5.932626392                 1 #> 154   2.369719908   4.136595054                 1 #> 155   0.890626476  14.549637031                 1 #> 156  -0.252183161 -16.705714453                 1 #> 157  -0.865763755  -2.581414949                 1 #> 158   0.582586000  15.752896998                 1 #> 159  -0.012529347   1.047722514                 1 #> 160  -0.374854762  12.458278424                 1 #> 161   0.317885735   5.167988214                 1 #> 162  -0.488805635   1.228417308                 1 #> 163   2.658658027   8.227943901                 1 #> 164   1.680278205 -16.207436862                 1 #> 165   0.779584009  -3.058925752                 1 #> 166   0.713240520   5.456381150                 1 #> 167  -0.542881937  12.070172795                 1 #> 168   0.885778374   6.905585591                 1 #> 169  -0.348594685   1.743531002                 1 #> 170  -1.008054578  10.265100215                 1 #> 171   1.883182542   0.124783240                 2 #> 172  -0.928971079  -9.947753191                 1 #> 173  -0.294196454  -0.226463752                 2 #> 174  -0.614950271  -1.473060039                 1 #> 175  -0.947075792   3.330537731                 1 #> 176   0.598975150  -3.427420825                 1 #> 177  -1.523614882   5.876571324                 1 #> 178  -0.206189002  18.552076255                 1 #> 179  -0.574295414 -16.169804432                 1 #> 180  -1.390166037   5.256694120                 1 #> 181  -0.070417383  -6.504778115                 1 #> 182  -0.430879530  -5.662481985                 1 #> 183  -0.592225373 -16.345854493                 1 #> 184   0.981116160  -2.333601885                 1 #> 185   0.532409357   3.011690461                 1 #> 186  -0.090456124 -12.844508514                 1 #> 187   0.156490492  17.447654098                 1 #> 188  -0.737311691  -6.835771919                 1 #> 189  -0.201341206 -20.508985274                 1 #> 190   1.102176595  -1.026456898                 2 #> 191  -0.016748256  21.166709991                 1 #> 192   0.161788634  14.366887229                 1 #> 193   2.024761390  11.497009599                 1 #> 194  -0.703694254   7.100737723                 1 #> 195   0.960792384   4.153188441                 1 #> 196   1.790485054  -3.942622204                 1 #> 197  -1.064165163 -13.570263083                 1 #> 198   0.017636546 -20.006515182                 1 #> 199  -0.389908629 -10.608051982                 1 #> 200  -0.490832752 -16.044842013                 1 #> 201  -1.045717652  -8.891272253                 1 #> 202  -0.896211264   6.556398195                 1 #> 203   1.269387164  -7.962164231                 1 #> 204   0.593840949 -13.845972754                 1 #> 205   0.775634319  -8.750041223                 1 #> 206   1.557370376 -15.463225713                 1 #> 207  -0.365401797   7.233817853                 1 #> 208   0.816556449 -13.516084530                 1 #> 209  -0.060634778  -1.309491640                 1 #> 210  -0.501378318   5.215127511                 1 #> 211   0.926062725  10.813730185                 1 #> 212   0.036937691  17.045197079                 1 #> 213  -1.066200174 -15.842037091                 1 #> 214  -0.238456353   8.320921224                 1 #> 215   1.495223444  -5.008879512                 1 #> 216   1.172158547  -1.625257244                 1 #> 217  -1.457707210  13.026962568                 1 #> 218   0.095056227  -5.464183076                 1 #> 219   0.847664964   6.114261873                 1 #> 220  -1.624364530  -0.842018763                 2 #> 221   1.408563357  -4.410776626                 1 #> 222  -0.541760362  12.695934450                 1 #> 223   0.278664724  -2.021164108                 1 #> 224  -0.193972745  -1.912459406                 1 #> 225   1.576158181   6.267406264                 1 #> 226  -1.475547635   8.236642547                 1 #> 227  -0.144608207  -8.310368843                 1 #> 228  -1.075010191  10.321859366                 1 #> 229   0.406542732  -5.722785388                 1 #> 230   2.229262202  -7.977989776                 1 #> 231  -1.514497008 -20.998230162                 1 #> 232  -0.061707422  -1.309417242                 1 #> 233  -0.147270790   2.852676214                 1 #> 234   1.541593069  -6.367229890                 1 #> 235  -0.981855669  11.179400023                 1 #> 236   0.496578173   5.581369757                 1 #> 237   1.696947881   0.899127608                 2 #> 238  -0.260736309  16.269331389                 1 #> 239  -0.705928586 -13.521869810                 1 #> 240  -0.161178506   2.570764187                 1 #> 241   0.501321828   7.611362679                 1 #> 242  -1.013539670  -8.958083738                 1 #> 243   1.614752235  -2.311687121                 1 #> 244   0.005641985  -0.502704390                 1 #> 245  -2.904899060  -4.005047159                 1 #> 246  -1.107164819   0.627255927                 2 #> 247   1.547566933  -1.392045354                 2 #> 248  -0.976830350  -7.481371135                 1 #> 249  -0.101503448   6.853899171                 1 #> 250   0.042650250  -5.188562393                 1 #> 251  -0.797552249  -0.626368228                 2 #> 252  10.322980923   0.481335326                 2 #> 253   0.781313160   1.695271084                 1 #> 254  -2.655045308  -1.761226294                 2 #> 255   4.610996449   0.198013015                 2 #> 256   2.549822711   0.397349099                 2 #> 257   3.460893446   0.029225495                 2 #> 258   9.043239051   2.560273389                 2 #> 259  -2.573692121   1.257127712                 2 #> 260  -2.136059016  -0.534537686                 2 #> 261  -1.833069305  -0.625227429                 2 #> 262   9.652248051   0.913848687                 2 #> 263  17.552500071   1.007199535                 2 #> 264   8.680086602   0.719291823                 2 #> 265   9.345641296  -0.604711661                 2 #> 266  15.919862434   0.539054406                 2 #> 267  -5.144851323  -0.076830886                 2 #> 268 -13.232546008   1.849919560                 2 #> 269  -9.993298001  -0.854907551                 2 #> 270   2.289630502   0.032637295                 2 #> 271   0.210102128  -1.025059481                 1 #> 272 -24.443327651  -0.982249076                 2 #> 273  10.667603263   0.004101957                 2 #> 274  -1.977796778  -0.233427178                 2 #> 275  -0.510054846  -0.498888219                 2 #> 276   3.659080585   1.549712963                 2 #> 277 -11.784869547   0.087496917                 2 #> 278  -6.360221582   1.318701131                 2 #> 279   9.305025029  -0.981224119                 2 #> 280  17.754848707  -0.245622588                 2 #> 281   6.187725661  -1.403933837                 2 #> 282   6.644182950   1.440893147                 2 #> 283 -15.374432086  -0.981359991                 2 #> 284   9.473578117   1.474244904                 2 #> 285  10.109151981  -0.991197245                 2 #> 286  -3.191328052  -0.094497345                 2 #> 287   1.694149680  -2.875141684                 1 #> 288   8.314200246  -0.246866101                 2 #> 289  19.374307588   0.014744490                 2 #> 290  -9.987654084  -1.919087703                 2 #> 291   9.265573999  -0.287813744                 2 #> 292  12.394392748  -0.346637445                 2 #> 293   8.233299467  -1.839588585                 2 #> 294   2.642610883   0.898588941                 2 #> 295  -1.365647622  -1.212855011                 2 #> 296   1.484022958  -0.218964232                 2 #> 297   7.817196875   0.564268161                 2 #> 298  -9.702310440  -0.525434376                 2 #> 299 -11.000987714   0.744374225                 2 #> 300  -6.403002264   0.128981753                 2 #> 301 -12.816284997   1.488274257                 2 #> 302 -15.024099707  -0.662681951                 2 #> 303  12.413125191  -1.160655001                 2 #> 304  -8.277071250   0.358774234                 2 #> 305  -4.540410394  -0.194846384                 2 #> 306 -10.212586314  -0.295282008                 2 #> 307   4.614957495   0.496640424                 2 #> 308   4.751899044   0.484912788                 2 #> 309  10.694225916   0.018784501                 2 #> 310  -4.158327218   0.634774565                 2 #> 311  11.169623593   0.754444088                 2 #> 312   1.233193967   0.833589035                 2 #> 313 -11.696807150   0.965761296                 2 #> 314  10.362680483   1.293879968                 2 #> 315  13.621027301  -0.136551021                 2 #> 316   7.219240884  -0.440138688                 2 #> 317  -3.874832476  -1.227283914                 2 #> 318 -12.102308462  -0.237653070                 2 #> 319   0.336978632  -0.926858157                 1 #> 320 -12.111496103   0.411235356                 2 #> 321 -16.326038843  -0.198864577                 2 #> 322   6.336301786  -0.557449639                 2 #> 323  -2.691176974  -0.977157122                 2 #> 324  -3.590021666   0.060735249                 2 #> 325  -5.789855969  -0.597229480                 2 #> 326  11.840445493  -1.258948697                 2 #> 327 -14.264710933  -1.410047202                 2 #> 328  -4.000467824   1.101304079                 2 #> 329   5.095647701  -0.677242026                 2 #> 330   2.612931070  -0.762173508                 2 #> 331  -5.539898991  -0.291748602                 2 #> 332  -0.558070369  -0.575188529                 2 #> 333  -1.733492295  -0.443941868                 2 #> 334  15.148385537  -0.312570444                 2 #> 335   0.923164615  -0.603004426                 2 #> 336  -5.893517821  -1.093934720                 2 #> 337  10.679176797   0.714706191                 2 #> 338 -11.451327046  -0.108812263                 2 #> 339   4.842581221  -1.443797935                 2 #> 340  11.077653524   0.806123264                 2 #> 341 -10.491362671  -1.739835078                 2 #> 342   2.917885035  -0.401320309                 2 #> 343   8.557806375  -0.287582489                 2 #> 344  10.056902417  -0.938407400                 2 #> 345  13.715721419   0.287667139                 2 #> 346  17.262435687  -1.505401124                 2 #> 347   1.801595752   1.519297013                 2 #> 348  -7.624714453   0.367409356                 2 #> 349  -6.811807858   1.699862409                 2 #> 350   6.255941547   0.644196977                 2 #> 351 -14.156260870  -1.687801029                 2 #> 352   4.502104199   0.647645994                 2 #> 353 -10.394267936   0.448794227                 2 #> 354  -8.326811055   1.026302158                 2 #> 355   3.077141028   1.074978223                 2 #> 356  -5.306651663   0.458309613                 2 #> 357  -7.455945433   0.631586758                 2 #> 358  -5.973571888  -0.580466398                 2 #> 359  12.747967674   1.584192142                 2 #> 360 -12.343521084  -1.763992940                 2 #> 361   0.979746508  -1.880621970                 1 #> 362  -4.201400270  -1.291719044                 2 #> 363  26.655690270   0.909670446                 2 #> 364  -1.420444621  -1.107755682                 2 #> 365  16.374827460  -0.384123875                 2 #> 366   7.773682959   0.082734834                 2 #> 367 -14.097988979  -0.483882474                 2 #> 368   4.639103719  -2.084741125                 2 #> 369   6.265975609   1.167586964                 2 #> 370   0.228789905  -0.076825771                 2 #> 371 -17.566049711   0.530421395                 2 #> 372  20.208228628   0.004908796                 2 #> 373  -1.689634579  -0.530231430                 2 #> 374 -12.611260707   0.102202410                 2 #> 375  11.235226552   0.815459636                 2 #> 376  -2.223704074  -1.506521863                 2 #> 377   2.210035640  -1.157180172                 2 #> 378  -7.008512017   1.301554937                 2 #> 379 -16.117975627  -0.905640775                 2 #> 380  -1.507714704   0.015563481                 2 #> 381   6.758819432  -1.428005197                 2 #> 382  -0.153210630   0.687979702                 1 #> 383   0.248210766   0.594196501                 1 #> 384   1.999315324  -0.270315244                 2 #> 385   3.587686423   1.554076076                 2 #> 386  -2.353665715  -0.510742458                 2 #> 387  -2.728598617  -0.291842736                 2 #> 388  -6.602146063   1.101438165                 2 #> 389 -12.436692423   0.458665215                 2 #> 390 -12.975186359   0.851908039                 2 #> 391  -7.076791478   1.466199919                 2 #> 392  -6.682340156   0.243863295                 2 #> 393  -3.518822223   0.649421934                 2 #> 394 -10.941795563  -0.641118156                 2 #> 395  -8.013650322   0.464459771                 2 #> 396  13.484453680  -0.309200447                 2 #> 397   3.346551999   1.276020709                 2 #> 398   2.349954751  -0.047611220                 2 #> 399  -0.220894711   0.030101166                 2 #> 400  -8.259203192  -0.003580270                 2 #> 401  -5.326957960  -2.034572643                 2 #> 402  -3.338937501  -0.992819963                 2 #> 403   0.791318315   1.963858056                 1 #> 404  -0.312537103   0.706528773                 1 #> 405  16.257368421   0.039674980                 2 #> 406  -3.062124587  -0.158518590                 2 #> 407  -6.740669300  -0.162257551                 2 #> 408 -14.752231548   0.438821912                 2 #> 409  -9.010689082   0.780699292                 2 #> 410  23.361946541  -0.981205622                 2 #> 411   2.728789336  -0.141585732                 2 #> 412   8.178726494  -1.256248953                 2 #> 413   1.870649530  -0.429033676                 2 #> 414   1.602126018   0.508776266                 2 #> 415  -1.491884984  -1.446889743                 2 #> 416   5.013932580   1.019512829                 2 #> 417  12.999009631   1.178546976                 2 #> 418   8.112213546  -0.010258765                 2 #> 419  -1.998315400   0.268624871                 2 #> 420   0.955721841   1.342028872                 1 #> 421 -13.042987501  -0.583606443                 2 #> 422  10.246965512  -0.937000891                 2 #> 423  16.324422397  -1.152157056                 2 #> 424 -13.599348594  -0.975183431                 2 #> 425  -0.162781728  -0.711413598                 1 #> 426  -7.921692885   0.371912476                 2 #> 427 -10.777293894  -0.943514417                 2 #> 428   9.618830620  -0.274367308                 2 #> 429  10.500631726   0.154468494                 2 #> 430  18.269626463  -1.288653202                 2 #> 431   4.501554668   1.419102319                 2 #> 432 -16.404748009   1.307827762                 2 #> 433   4.402449548  -1.804975774                 2 #> 434  -6.245004574  -0.484069527                 2 #> 435  -1.791580607  -0.373211780                 2 #> 436   2.177586688   0.169085902                 2 #> 437   0.633172530  -1.172983603                 1 #> 438   7.147314594  -0.376196737                 2 #> 439  -5.898408265   0.783127640                 2 #> 440  -6.097185874   0.991171304                 2 #> 441   1.654366629   0.229284475                 2 #> 442   7.899374403   0.336850949                 2 #> 443  -3.530078214  -0.647231999                 2 #> 444  -6.020534746  -0.443206682                 2 #> 445  -9.091199188   1.161751761                 2 #> 446  -6.757475362   0.065051010                 2 #> 447  -2.551976970  -0.682467580                 2 #> 448 -10.492226833   1.634341658                 2 #> 449   6.221024872  -0.584849244                 2 #> 450 -18.508838677   1.129936001                 2 #> 451  -1.387570525   0.581201043                 2 #> 452 -13.004048795   0.379293067                 2 #> 453  10.945357773  -0.310740876                 2 #> 454  -4.600540233   0.886390001                 2 #> 455  10.156848815  -1.641864750                 2 #> 456  -3.776789414  -0.988563742                 2 #> 457  -1.914657611  -0.244003429                 2 #> 458  -9.185947020   0.156056926                 2 #> 459 -27.741272559   0.102051958                 2 #> 460  14.815290267  -0.287458172                 2 #> 461 -12.700926056  -0.293194886                 2 #> 462  23.086238678   0.469477058                 2 #> 463   2.930343425  -0.662588512                 2 #> 464  -5.089840368  -2.190372666                 2 #> 465   6.290088088   0.003854672                 2 #> 466   7.926435876   0.862942829                 2 #> 467  -2.049794739   0.980223359                 2 #> 468   1.226706740  -0.291724771                 2 #> 469  16.590674096  -0.061013476                 2 #> 470 -12.648525462   1.511868401                 2 #> 471  -0.441747634  -0.643609065                 1 #> 472   7.147390560  -0.130950479                 2 #> 473 -12.726211639   0.485211453                 2 #> 474 -16.109346268  -0.645182435                 2 #> 475  12.189575992  -0.463956220                 2 #> 476  -6.729900347   0.567249697                 2 #> 477  -9.337072301  -0.723407834                 2 #> 478  -0.325549223   0.455884554                 1 #> 479  -4.989155458  -1.197934626                 2 #> 480  -5.029800765  -2.018180550                 2 #> 481 -12.778860448   0.619723405                 2 #> 482  -8.171638687  -0.132857466                 2 #> 483   7.628697851  -0.434960740                 2 #> 484   4.495167897  -0.521754179                 2 #> 485  -5.740429658   0.992288426                 2 #> 486  21.739546330  -1.085422408                 2 #> 487  13.328173125   0.959832414                 2 #> 488  -6.650835828  -1.039010541                 2 #> 489  -0.879886196  -0.137841967                 2 #> 490 -29.127471591  -0.214708418                 2 #> 491   8.613572923   0.573718585                 2 #> 492   5.034007572  -1.776449315                 2 #> 493  -4.479306416  -0.256392295                 2 #> 494  -1.745822786  -0.138550636                 2 #> 495   0.777014412   0.557684974                 2 #> 496   9.157567844   1.122346289                 2 #> 497  -8.729262206  -0.982147207                 2 #> 498   9.597171614   0.326905556                 2 #> 499   6.799582393   0.447826608                 2 #> 500  -6.329270648   1.183724120                 2"},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"Compute cumulative density function (cdf) quantiles estimated one-dimensional Gaussian mixture fitted using densityMclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"","code":"cdfMclust(object, data, ngrid = 100, ...) quantileMclust(object, p, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"object densityMclust model object. data numeric vector evaluation points. ngrid number points regular grid used evaluation points data provided. p numeric vector probabilities. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"cdf evaluated points given optional argument  data. provided, regular grid length ngrid evaluation points used. quantiles computed using bisection linear search algorithm.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"cdfMclust returns list x y values providing, respectively, evaluation points estimated cdf. quantileMclust returns vector quantiles.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/cdfMclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution and Quantiles for a univariate Gaussian mixture \n  distribution — cdfMclust","text":"","code":"# \\donttest{ x <- c(rnorm(100), rnorm(100, 3, 2)) dens <- densityMclust(x, plot = FALSE) summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust V (univariate, unequal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC      ICL #>       -424.0276 200  5 -874.5469 -942.139 #>  #> Mixing probabilities: #>         1         2  #> 0.4813092 0.5186908  #>  #> Means: #>          1          2  #> -0.0617169  2.8923878  #>  #> Variances: #>         1         2  #> 0.8938594 4.3252118  cdf <- cdfMclust(dens) str(cdf) #> List of 2 #>  $ x: num [1:100] -3.8 -3.66 -3.52 -3.38 -3.25 ... #>  $ y: num [1:100] 0.000357 0.000458 0.000591 0.000766 0.001 ... q <- quantileMclust(dens, p = c(0.01, 0.1, 0.5, 0.9, 0.99)) cbind(quantile = q, cdf = cdfMclust(dens, q)$y) #>        quantile  cdf #> [1,] -2.1730968 0.01 #> [2,] -0.9526056 0.10 #> [3,]  0.9295521 0.50 #> [4,]  4.6968529 0.90 #> [5,]  7.1950392 0.99 plot(cdf, type = \"l\", xlab = \"x\", ylab = \"CDF\") points(q, cdfMclust(dens, q)$y, pch = 20, col = \"red3\")   par(mfrow = c(2,2)) dens.waiting <- densityMclust(faithful$waiting) plot(cdfMclust(dens.waiting), type = \"l\",       xlab = dens.waiting$varname, ylab = \"CDF\") dens.eruptions <- densityMclust(faithful$eruptions) plot(cdfMclust(dens.eruptions), type = \"l\",       xlab = dens.eruptions$varname, ylab = \"CDF\")  par(mfrow = c(1,1)) # }"},{"path":"https://mclust-org.github.io/mclust/reference/chevron.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated minefield data — chevron","title":"Simulated minefield data — chevron","text":"set simulated bivariate minefield data   (1104 observations).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/chevron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated minefield data — chevron","text":"","code":"data(chevron)"},{"path":"https://mclust-org.github.io/mclust/reference/chevron.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated minefield data — chevron","text":". Dasgupta . E. Raftery (1998).   Detecting features spatial point processes clutter via model-based   clustering.    Journal American Statistical Association 93:294-302. C. Fraley .E. Raftery (1998).   Computer Journal 41:578-588. G. J. McLachlan D. Peel (2000).   Finite Mixture Models, Wiley, pages 110-112.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Scatter Plots showing Classification — clPairs","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"Creates scatter plot pair variables given data. Observations different classes represented different colors symbols.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"","code":"clPairs(data, classification,          symbols = NULL, colors = NULL, cex = NULL,         labels = dimnames(data)[[2]], cex.labels = 1.5,          gap = 0.2, grid = FALSE, ...)  clPairsLegend(x, y, class, col, pch, cex, box = TRUE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. classification numeric character vector representing classification observations    (rows) data. symbols Either integer character vector assigning plotting symbol     unique class classification. Elements symbols     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotColors\"). cex vector numerical values specifying size plotting  \t\tsymbol unique class classification. Values  \t\tcex correspond classes order appearance  \t\tsequence observations (order used function unique).      default cex = 1 classes used. labels vector character strings labelling variables. default     use column dimension names data. cex.labels numerical value specifying size text labels. gap argument specifying distance subplots (see pairs). grid logical specifying grid lines added panels (see grid). x,y x y co-ordinates respect graphic device      plotting region coordinates par(\"usr\" = c(0,1,0,1)). class class labels. box logical, TRUE box drawn around current plot figure. col, pch colors plotting symbols appearing legend. ... clPairs call may additional arguments passed pairs.      clPairsLegend call may additional arguments passed legend.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"function clPairs() draws scatter plots current graphics device combination variables data. Observations different classifications labeled different symbols. function clPairsLegend() can used add legend. See examples .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"function clPairs() invisibly returns list following components: class character vector class labels. col vector colors used class. pch vector plotting symbols used class.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/clPairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Scatter Plots showing Classification — clPairs","text":"","code":"clPairs(iris[,1:4], cl = iris$Species)   clp <- clPairs(iris[,1:4], cl = iris$Species, lower.panel = NULL) clPairsLegend(0.1, 0.4, class = clp$class,                col = clp$col, pch = clp$pch,                title = \"Iris data\")"},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification error — classError","title":"Classification error — classError","text":"Computes errore rate given classification relative known classes, location misclassified data points.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification error — classError","text":"","code":"classError(classification, class)"},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification error — classError","text":"classification numeric, character vector factor specifying predicted class      labels. Must length class. class numeric, character vector factor known true class labels.      Must length classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classification error — classError","text":"list following two components: misclassified indexes misclassified data points minimum error     mapping predicted classification known true classes. errorRate error rate corresponding minimum error mapping      predicted classification known true classes.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Classification error — classError","text":"one mapping predicted classification known    truth corresponds minimum number classification errors,   one possible set misclassified observations returned.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/classError.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classification error — classError","text":"","code":"(a <- rep(1:3, 3)) #> [1] 1 2 3 1 2 3 1 2 3 (b <- rep(c(\"A\", \"B\", \"C\"), 3)) #> [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" classError(a, b) #> $misclassified #> integer(0) #>  #> $errorRate #> [1] 0 #>   (a <- sample(1:3, 9, replace = TRUE)) #> [1] 1 2 1 1 3 2 2 2 3 (b <- sample(c(\"A\", \"B\", \"C\"), 9, replace = TRUE)) #> [1] \"C\" \"B\" \"B\" \"A\" \"C\" \"C\" \"A\" \"B\" \"A\" classError(a, b) #> $misclassified #> [1] 3 5 6 7 9 #>  #> $errorRate #> [1] 0.5555556 #>   class <- factor(c(5,5,5,2,5,3,1,2,1,1), levels = 1:5) probs <- matrix(c(0.15, 0.01, 0.08, 0.23, 0.01, 0.23, 0.59, 0.02, 0.38, 0.45,                    0.36, 0.05, 0.30, 0.46, 0.15, 0.13, 0.06, 0.19, 0.27, 0.17,                    0.40, 0.34, 0.18, 0.04, 0.47, 0.34, 0.32, 0.01, 0.03, 0.11,                    0.04, 0.04, 0.09, 0.05, 0.28, 0.27, 0.02, 0.03, 0.12, 0.25,                    0.05, 0.56, 0.35, 0.22, 0.09, 0.03, 0.01, 0.75, 0.20, 0.02),                 nrow = 10, ncol = 5) cbind(class, probs, map = map(probs)) #>       class                          map #>  [1,]     5 0.15 0.36 0.40 0.04 0.05   3 #>  [2,]     5 0.01 0.05 0.34 0.04 0.56   5 #>  [3,]     5 0.08 0.30 0.18 0.09 0.35   5 #>  [4,]     2 0.23 0.46 0.04 0.05 0.22   2 #>  [5,]     5 0.01 0.15 0.47 0.28 0.09   3 #>  [6,]     3 0.23 0.13 0.34 0.27 0.03   3 #>  [7,]     1 0.59 0.06 0.32 0.02 0.01   1 #>  [8,]     2 0.02 0.19 0.01 0.03 0.75   5 #>  [9,]     1 0.38 0.27 0.03 0.12 0.20   1 #> [10,]     1 0.45 0.17 0.11 0.25 0.02   1 classError(map(probs), class) #> $misclassified #> [1] 2 3 8 #>  #> $errorRate #> [1] 0.3 #>"},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"simple procedure improve estimation class prior probabilities training data reflect true priori probabilities target classes. EM algorithm used described Saerens et al (2002).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"","code":"classPriorProbs(object, newdata = object$data,                  itmax = 1e3, eps = sqrt(.Machine$double.eps))"},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"object object class 'MclustDA' resulting call MclustDA. newdata data frame matrix giving data. missing train data obtained call MclustDA used. itmax integer value specifying maximal number EM iterations. eps scalar specifying tolerance associated deciding    terminate EM iterations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"estimation procedure employes EM algorithm described Saerens et al (2002).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"vector class prior estimates can used predict.MclustDA improve predictions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"Saerens, M., Latinne, P. Decaestecker, C. (2002) Adjusting outputs classifier new priori probabilities: simple procedure, Neural computation, 14 (1), 21--41.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/classPriorProbs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of class prior probabilities by EM algorithm — classPriorProbs","text":"","code":"# \\donttest{ # generate data from a mixture f(x) = 0.9 * N(0,1) + 0.1 * N(3,1) n <- 10000 mixpro <- c(0.9, 0.1) class <- factor(sample(0:1, size = n, prob = mixpro, replace = TRUE)) x <- ifelse(class == 1, rnorm(n, mean = 3, sd = 1),                          rnorm(n, mean = 0, sd = 1))  hist(x[class==0], breaks = 11, xlim = range(x), main = \"\", xlab = \"x\",       col = adjustcolor(\"dodgerblue2\", alpha.f = 0.5), border = \"white\") hist(x[class==1], breaks = 11, add = TRUE,      col = adjustcolor(\"red3\", alpha.f = 0.5), border = \"white\") box()   # generate training data from a balanced case-control sample, i.e. # f(x) = 0.5 * N(0,1) + 0.5 * N(3,1) n_train <- 1000 class_train <- factor(sample(0:1, size = n_train, prob = c(0.5, 0.5), replace = TRUE)) x_train <- ifelse(class_train == 1, rnorm(n_train, mean = 3, sd = 1),                                      rnorm(n_train, mean = 0, sd = 1))  hist(x_train[class_train==0], breaks = 11, xlim = range(x_train),       main = \"\", xlab = \"x\",       col = adjustcolor(\"dodgerblue2\", alpha.f = 0.5), border = \"white\") hist(x_train[class_train==1], breaks = 11, add = TRUE,      col = adjustcolor(\"red3\", alpha.f = 0.5), border = \"white\") box()   # fit a MclustDA model mod <- MclustDA(x_train, class_train) summary(mod, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood    n df       BIC #>       -1942.376 1000  4 -3912.383 #>         #> Classes   n    % Model G #>       0 524 52.4     X 1 #>       1 476 47.6     X 1 #>  #> Class prior probabilities: #>     0     1  #> 0.524 0.476  #>  #> Class = 0 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] -0.03369754 #>  #> Variances: #> [1] 0.9532879 #>  #> Class = 1 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] 2.955709 #>  #> Variances: #> [1] 1.059664 #>  #> Training confusion matrix: #>      Predicted #> Class   0   1 #>     0 488  36 #>     1  29 447 #> Classification error = 0.065  #> Brier score          = 0.0492   # test set performance pred <- predict(mod, newdata = x) classError(pred$classification, class)$error #> [1] 0.0688 BrierScore(pred$z, class) #> [1] 0.05133817  # compute performance over a grid of prior probs priorProp <- seq(0.01, 0.99, by = 0.01) CE <- BS <- rep(as.double(NA), length(priorProp)) for(i in seq(priorProp)) {   pred <- predict(mod, newdata = x, prop = c(1-priorProp[i], priorProp[i]))   CE[i] <- classError(pred$classification, class = class)$error   BS[i] <- BrierScore(pred$z, class) }  # estimate the optimal class prior probs (priorProbs <- classPriorProbs(mod, x)) #>         0         1  #> 0.8852142 0.1147858  pred <- predict(mod, newdata = x, prop = priorProbs) # compute performance at the estimated class prior probs classError(pred$classification, class = class)$error #> [1] 0.0352 BrierScore(pred$z, class) #> [1] 0.02658523  matplot(priorProp, cbind(CE,BS), type = \"l\", lty = 1, lwd = 2,         xlab = \"Class prior probability\", ylab = \"\", ylim = c(0,max(CE,BS)),          panel.first =            { abline(h = seq(0,1,by=0.05), col = \"grey\", lty = 3)             abline(v = seq(0,1,by=0.05), col = \"grey\", lty = 3)            }) abline(v = mod$prop[2], lty = 2)              # training prop abline(v = mean(class==1), lty = 4)           # test prop (usually unknown)  abline(v = priorProbs[2], lty = 3, lwd = 2)      # estimated prior probs legend(\"topleft\", legend = c(\"ClassError\", \"BrierScore\"),        col = 1:2, lty = 1, lwd = 2, inset = 0.02)   # Summary of results: priorProp[which.min(CE)] # best prior of class 1 according to classification error #> [1] 0.11 priorProp[which.min(BS)] # best prior of class 1 according to Brier score #> [1] 0.09 priorProbs               # optimal estimated class prior probabilities #>         0         1  #> 0.8852142 0.1147858  # }"},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi-internals.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal clustCombi functions — clustCombi-internal","title":"Internal clustCombi functions — clustCombi-internal","text":"Internal functions intended called directly users.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":null,"dir":"Reference","previous_headings":"","what":"Combining Gaussian Mixture Components for Clustering — clustCombi","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"Provides hierarchy combined clusterings EM/BIC Gaussian mixture solution one class, following methodology proposed article cited references.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"","code":"clustCombi(object = NULL, data = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"object object returned Mclust giving optimal (according BIC) parameters, conditional probabilities, log-likelihood, together associated classification uncertainty. provided, data argument must specified. data numeric vector, matrix, data frame observations. Categorical variables allowed. matrix data frame, rows correspond observations columns correspond variables. object argument provided, function Mclust applied given data fit mixture model. ... Optional arguments passed called functions. Notably, argument (numbers components BIC computed; models fitted EM; initialization parameters EM algorithm, etc.) passed Mclust case object = NULL. Please see Mclust documentation details.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"Mclust provides Gaussian mixture fitted data maximum likelihood EM algorithm, model number components selected according BIC. corresponding components hierarchically combined according entropy criterion, following methodology described article cited references section. solutions numbers classes one selected BIC one returned clustCombi class object.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"list class clustCombi giving hierarchy combined solutions number components selected BIC one. details output components follows: classification list data classifications obtained combined solution hierarchy MAP assignment combiM list matrices. combiM[[K]] matrix used combine components (K+1)-classes solution get K-classes solution. Please see examples. combiz list matrices. combiz[[K]] matrix whose [,k]th entry probability observation data belongs kth class according K-classes combined solution. MclustOutput list class Mclust. Output call Mclust function (provided user result call Mclust function) used initiate combined solutions hierarchy: please see Mclust function documentation details.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/clustCombi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combining Gaussian Mixture Components for Clustering — clustCombi","text":"","code":"data(Baudry_etal_2010_JCGS_examples)  # run Mclust using provided data output <- clustCombi(data = ex4.1)  # \\donttest{ # or run Mclust and then clustcombi on the returned object mod <- Mclust(ex4.1) output <- clustCombi(mod) # }  output #> 'clustCombi' object: #>  Mclust model: (EEV,6) #>  Available object components: classification combiM combiz MclustOutput  #>  Combining matrix (K+1 classes -> K classes): <object_name>$combiM[[K]] #>  Classification for K classes: <object_name>$classification[[K]] summary(output) #> ---------------------------------------------------- #> Combining Gaussian mixture components for clustering  #> ---------------------------------------------------- #>  #> Mclust model name: EEV  #> Number of components: 6  #>  #> Combining steps: #>  #>   Step | Classes combined at this step | Class labels after this step #> -------|-------------------------------|----------------------------- #>    0   |              ---              | 1 2 3 4 5 6  #>    1   |             3 & 4             | 1 2 3 5 6  #>    2   |             1 & 6             | 1 2 3 5  #>    3   |             3 & 5             | 1 2 3  #>    4   |             1 & 2             | 1 3  #>    5   |             1 & 3             | 1   # \\donttest{ # run Mclust using provided data and any further optional argument provided output <- clustCombi(data = ex4.1, modelName = \"EEV\", G = 1:15) # }  # plot the hierarchy of combined solutions plot(output, what = \"classification\")        # plot some \"entropy plots\" which may help one to select the number of classes plot(output, what = \"entropy\")    # plot the tree structure obtained from combining mixture components plot(output, what = \"tree\")    # the selected model and number of components obtained from Mclust using BIC output$MclustOutput  #> 'Mclust' model object: (EEV,6)  #>  #> Available components:  #>  [1] \"call\"           \"data\"           \"modelName\"      \"n\"              #>  [5] \"d\"              \"G\"              \"BIC\"            \"loglik\"         #>  [9] \"df\"             \"bic\"            \"icl\"            \"hypvol\"         #> [13] \"parameters\"     \"z\"              \"classification\" \"uncertainty\"     # the matrix whose [i,k]th entry is the probability that i-th observation in  # the data belongs to the k-th class according to the BIC solution head( output$combiz[[output$MclustOutput$G]] )  #>              [,1]          [,2]         [,3]          [,4]          [,5] #> [1,] 2.828057e-02  2.256054e-24 8.867772e-86 7.080395e-102 8.459454e-122 #> [2,] 9.727840e-01  1.741462e-24 3.144224e-61  2.073383e-81  3.054390e-90 #> [3,] 3.755348e-35  9.994220e-01 3.470709e-14 8.677331e-117  1.448932e-80 #> [4,] 1.853089e-42  1.068300e-81 1.112008e-01  8.887403e-01  5.893101e-05 #> [5,] 3.845124e-35  4.648777e-94 1.034554e-03  9.983910e-01  5.744098e-04 #> [6,] 1.036548e-17 8.888312e-226 4.272575e-72  1.859291e-14  1.000000e+00 #>               [,6] #> [1,]  9.717194e-01 #> [2,]  2.721601e-02 #> [3,]  5.779845e-04 #> [4,] 4.526171e-103 #> [5,] 3.969503e-109 #> [6,] 2.716310e-154 # the matrix whose [i,k]th entry is the probability that i-th observation in  # the data belongs to the k-th class according to the first combined solution head( output$combiz[[output$MclustOutput$G-1]] )  #>              [,1]          [,2]         [,3]          [,4]          [,5] #> [1,] 2.828057e-02  2.256054e-24 8.867772e-86 8.459454e-122  9.717194e-01 #> [2,] 9.727840e-01  1.741462e-24 3.144224e-61  3.054390e-90  2.721601e-02 #> [3,] 3.755348e-35  9.994220e-01 3.470709e-14  1.448932e-80  5.779845e-04 #> [4,] 1.853089e-42  1.068300e-81 9.999411e-01  5.893101e-05 4.526171e-103 #> [5,] 3.845124e-35  4.648777e-94 9.994256e-01  5.744098e-04 3.969503e-109 #> [6,] 1.036548e-17 8.888312e-226 1.859291e-14  1.000000e+00 2.716310e-154 # the matrix describing how to merge the 6-classes solution to get the  # 5-classes solution output$combiM[[5]]  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    0    0    0    0    0 #> [2,]    0    1    0    0    0    0 #> [3,]    0    0    1    1    0    0 #> [4,]    0    0    0    0    1    0 #> [5,]    0    0    0    0    0    1 # for example the following code returns the label of the class (in the  # 5-classes combined solution) to which the 4th class (in the 6-classes # solution) is assigned. Only two classes in the (K+1)-classes solution  # are assigned the same class in the K-classes solution: the two which  # are merged at this step  output$combiM[[5]]  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    0    0    0    0    0 #> [2,]    0    1    0    0    0    0 #> [3,]    0    0    1    1    0    0 #> [4,]    0    0    0    0    1    0 #> [5,]    0    0    0    0    0    1 # recover the 5-classes soft clustering from the 6-classes soft clustering  # and the 6 -> 5 combining matrix all( output$combiz[[5]] == t( output$combiM[[5]] %*% t(output$combiz[[6]]) ) )  #> [1] TRUE # the hard clustering under the 5-classes solution head( output$classification[[5]] ) #> [1] 5 1 2 3 3 4"},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"Return optimal number clusters combining mixture components based entropy method discussed reference given .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"","code":"clustCombiOptim(object, reg = 2, plot = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"object object class 'clustCombi' resulting call clustCombi. reg number parts piecewise linear regression entropy plots.    Choose 2 two-segment piecewise linear regression model (.e. 1 change-point), 3 three-segment piecewise linear regression model (.e. 3 change-points). plot Logical, TRUE entropy plot also produced. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"function returns list following components: numClusters.combi estimated number clusters. z.combi matrix whose [,k]th entry probability observation data belongs kth cluster. cluster.combi clustering labels.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/clustCombiOptim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal number of clusters obtained by combining mixture components — clustCombiOptim","text":"","code":"data(Baudry_etal_2010_JCGS_examples) output <- clustCombi(data = ex4.1)  combiOptim <- clustCombiOptim(output) str(combiOptim) #> List of 3 #>  $ numClusters.combi: int 4 #>  $ z.combi          : num [1:600, 1:4] 1.00 1.00 5.78e-04 1.85e-42 3.85e-35 ... #>  $ cluster.combi    : num [1:600] 1 1 2 3 3 4 4 3 3 2 ...  # plot optimal clustering with alpha color transparency proportional to uncertainty zmax <- apply(combiOptim$z.combi, 1, max) col <- mclust.options(\"classPlotColors\")[combiOptim$cluster.combi] vadjustcolor <- Vectorize(adjustcolor) alphacol = (zmax - 1/combiOptim$numClusters.combi)/(1-1/combiOptim$numClusters.combi) col <- vadjustcolor(col, alpha.f = alphacol) plot(ex4.1, col = col, pch = mclust.options(\"classPlotSymbols\")[combiOptim$cluster.combi])"},{"path":"https://mclust-org.github.io/mclust/reference/combMat.html","id":null,"dir":"Reference","previous_headings":"","what":"Combining Matrix — combMat","title":"Combining Matrix — combMat","text":"Create combining matrix","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combMat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combining Matrix — combMat","text":"","code":"combMat(K, l1, l2)"},{"path":"https://mclust-org.github.io/mclust/reference/combMat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combining Matrix — combMat","text":"K original number classes: matrix define combining K (K-1) classes. l1 Label one two classes combined. l2 Label class combined.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combMat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combining Matrix — combMat","text":"z vector (length K) whose kth entry probability observation belongs kth class K-classes classification, combiM %*% z vector (length K-1) whose kth entry probability observation belongs kth class K-1-classes classification obtained merging classes l1 l2 initial classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combMat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Combining Matrix — combMat","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"Plot classifications corresponding successive combined solutions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"","code":"combiPlot(data, z, combiM, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"data data. z matrix whose [,k]th entry probability observation data belongs kth class, initial solution (ie combining). Typically, one returned Mclust/BIC. combiM \"combining matrix\" (provided clustCombi), ie matrix whose kth row contains zeros, columns corresponding labels classes initial solution merged together get combined solution. ... arguments passed Mclust plot functions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"Plot classifications obtained MAP matrix t(combiM %*% t(z)), matrix whose [,k]th entry probability observation data belongs kth class, according combined solution obtained merging (according combiM) initial solution described z.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/combiPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Classifications Corresponding to Successive Combined Solutions — combiPlot","text":"","code":"# \\donttest{ data(Baudry_etal_2010_JCGS_examples) MclustOutput <- Mclust(ex4.1)   MclustOutput$G # Mclust/BIC selected 6 classes #> [1] 6  par(mfrow=c(2,2))  combiM0 <- diag(6) # is the identity matrix # no merging: plot the initial solution, given by z combiPlot(ex4.1, MclustOutput$z, combiM0, cex = 3)  title(\"No combining\")  combiM1 <- combMat(6, 1, 2) # let's merge classes labeled 1 and 2 combiM1 #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    1    0    0    0    0 #> [2,]    0    0    1    0    0    0 #> [3,]    0    0    0    1    0    0 #> [4,]    0    0    0    0    1    0 #> [5,]    0    0    0    0    0    1 combiPlot(ex4.1, MclustOutput$z, combiM1) title(\"Combine 1 and 2\")  # let's merge classes labeled 1 and 2, and then components labeled (in this  # new 5-classes combined solution) 1 and 2 combiM2 <- combMat(5, 1, 2) %*% combMat(6, 1, 2)  combiM2  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    1    1    0    0    0 #> [2,]    0    0    0    1    0    0 #> [3,]    0    0    0    0    1    0 #> [4,]    0    0    0    0    0    1 combiPlot(ex4.1, MclustOutput$z, combiM2) title(\"Combine 1, 2 and then 1 and 2 again\")  plot(0,0,type=\"n\", xlab = \"\", ylab = \"\", axes = FALSE) legend(\"center\", legend = 1:6,        col = mclust.options(\"classPlotColors\"),         pch = mclust.options(\"classPlotSymbols\"),         title = \"Class labels:\")# }"},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Tree structure obtained from combining mixture components — combiTree","title":"Tree structure obtained from combining mixture components — combiTree","text":"method implemented clustCombi can used combining Gaussian mixture components clustering. provides hierarchical structure can graphically represented tree.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tree structure obtained from combining mixture components — combiTree","text":"","code":"combiTree(object, type = c(\"triangle\", \"rectangle\"),                   yaxis = c(\"entropy\", \"step\"),                    edgePar = list(col = \"darkgray\", lwd = 2),                    ...)"},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tree structure obtained from combining mixture components — combiTree","text":"object object class 'clustCombi' resulting call clustCombi. type string specifying dendrogram's type. Possible values \"triangle\" (default), \"rectangle\". yaxis string specifying quantity used draw vertical axis. Possible values \"entropy\" (default), \"step\". edgePar list plotting parameters. See dendrogram. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tree structure obtained from combining mixture components — combiTree","text":"function always draw tree invisibly returns object class 'dendrogram' fine tuning.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tree structure obtained from combining mixture components — combiTree","text":"L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/combiTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tree structure obtained from combining mixture components — combiTree","text":"","code":"# \\donttest{ data(Baudry_etal_2010_JCGS_examples) output <- clustCombi(data = ex4.1)  combiTree(output)  combiTree(output, type = \"rectangle\")  combiTree(output, yaxis = \"step\")  combiTree(output, type = \"rectangle\", yaxis = \"step\")  # }"},{"path":"https://mclust-org.github.io/mclust/reference/coordProj.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","title":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","text":"Plots coordinate projections given multidimensional data   parameters MVN mixture model data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/coordProj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","text":"","code":"coordProj(data, dimens = c(1,2), parameters = NULL, z = NULL,           classification = NULL, truth = NULL, uncertainty = NULL,            what = c(\"classification\", \"error\", \"uncertainty\"),           addEllipses = TRUE, fillEllipses = mclust.options(\"fillEllipses\"),           symbols = NULL, colors = NULL, scale = FALSE,            xlim = NULL, ylim = NULL, cex = 1, PCH = \".\", main = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/coordProj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","text":"data numeric matrix data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. dimens vector length 2 giving integer dimensions     desired coordinate projections. default     c(1,2), first     dimension plotted second. parameters named list giving parameters MCLUST model,       used produce superimposing ellipses plot.       relevant components follows: mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  z matrix [,k]th entry gives   probability observation belonging kth class.    Used compute classification   uncertainty arguments available. classification numeric character vector representing classification   observations (rows) data. present argument z         ignored. truth numeric character vector giving known   classification data point.   classification   z also present,    used displaying classification errors. uncertainty numeric vector values (0,1) giving   uncertainty data point. present argument z         ignored. Choose one following three options: \"classification\"     (default), \"error\", \"uncertainty\". addEllipses logical indicating whether add ellipses axes      corresponding within-cluster covariances case      \"classification\" \"uncertainty\" plots. fillEllipses logical specifying whether fill ellipses transparent     colors addEllipses = TRUE. symbols Either integer character vector assigning plotting symbol     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotColors\"). scale logical variable indicating whether two chosen     dimensions plotted scale,     thus preserve shape distribution.     Default: scale=FALSE xlim, ylim Arguments specifying bounds ordinate, abscissa plot.     may useful comparing plots. cex numerical value specifying size plotting symbols.      default value 1. PCH argument specifying symbol used classification     specified data. default value small dot \".\". main logical variable NULL indicating whether add title     plot identifying dimensions used. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/coordProj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","text":"plot showing two-dimensional coordinate projection data, together location  mixture components, classification, uncertainty, /classification errors.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/coordProj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate projections of multidimensional data modeled by an MVN mixture. — coordProj","text":"","code":"# \\donttest{ est <- meVVV(iris[,-5], unmap(iris[,5])) par(pty = \"s\", mfrow = c(1,1)) coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,           what = \"classification\", main = TRUE)   coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,           truth = iris[,5], what = \"error\", main = TRUE)   coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,           what = \"uncertainty\", main = TRUE)   # }"},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"Compute efficiently (via Fortran code) means, covariance scattering matrices conditioning weighted indicator matrix","code":""},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"","code":"covw(X, Z, normalize = TRUE)"},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"X \\((n x p)\\) data matrix, \\(n\\) observations \\(p\\) variables. Z \\((n x G)\\) matrix weights, \\(G\\) number groups. normalize logical indicating rows Z normalized sum one.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"list following components: mean \\((p x G)\\) matrix weighted means. S \\((p x p x G)\\) array weighted covariance matrices. W \\((p x p x G)\\) array weighted scattering matrices.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"M. Fop L. Scrucca","code":""},{"path":"https://mclust-org.github.io/mclust/reference/covw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted means, covariance and scattering matrices conditioning on a weighted matrix — covw","text":"","code":"# Z as an indicator matrix X <- iris[,1:4] Z <- unmap(iris$Species) str(covw(X, Z)) #> List of 3 #>  $ mean: num [1:4, 1:3] 5.006 3.428 1.462 0.246 5.936 ... #>  $ S   : num [1:4, 1:4, 1:3] 0.1218 0.0972 0.016 0.0101 0.0972 ... #>  $ W   : num [1:4, 1:4, 1:3] 6.088 4.862 0.801 0.506 4.862 ... # Z as a matrix of weights mod <- Mclust(X, G = 3, modelNames = \"VVV\") str(covw(X, mod$z)) #> List of 3 #>  $ mean: num [1:4, 1:3] 5.006 3.428 1.462 0.246 5.915 ... #>  $ S   : num [1:4, 1:4, 1:3] 0.1218 0.0972 0.016 0.0101 0.0972 ... #>  $ W   : num [1:4, 1:4, 1:3] 6.088 4.862 0.801 0.506 4.862 ..."},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":null,"dir":"Reference","previous_headings":"","what":"Discriminant coordinates data projection — crimcoords","title":"Discriminant coordinates data projection — crimcoords","text":"Compute discriminant coordinates crimcoords obtained projecting observed data multiple groups onto discriminant subspace. optimal projection subspace given linear transformation original variables maximizes ratio -groups covariance (represents groups separation) pooled within-group covariance (represents within-group dispersion).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discriminant coordinates data projection — crimcoords","text":"","code":"crimcoords(data, classification,             numdir = NULL,             unbiased = FALSE,             ...)  # S3 method for crimcoords summary(object, numdir, ...)  # S3 method for crimcoords plot(x, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discriminant coordinates data projection — crimcoords","text":"data numeric vector, matrix, data frame observations. Categorical   variables allowed. matrix data frame, rows   correspond observations columns correspond variables. classification vector (numerical, character string, factor) giving  \tgroups classification (either known class labels estimated  \tclusters) observed data. numdir integer value specifying number directions  \tdiscriminant subspace return. provided, maximal number \tdirections returned (given number non-null  \teigenvalues, minimum among number variables number \tgroups minus one).  \tHowever, since effectiveness discriminant coordinates  \thighlighting separation groups decreasing, might useful \tprovide smaller value, say 2 3. unbiased logical specifying unbiased estimates used  \t-groups within-groups covariances. default \tunbiased = FALSE MLE estimates used. \tNote use unbiased MLE estimates changes  \teigenvalues eigenvectors generalized eigendecomposition  \tconstant proportionality, discriminant coordinates  \tcrimcoords essentially . object, x object class crimcoords returned crimcoords() function. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discriminant coordinates data projection — crimcoords","text":"list class crimcoords following components: means matrix within-groups means. B -groups covariance matrix. W pooled within-groups covariance matrix. evalues vector eigenvalues. basis matrix eigenvectors specifying basis  discriminant subspace. projection matrix projected data points onto discriminant subspace. classification vector giving groups classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Discriminant coordinates data projection — crimcoords","text":"Gnanadesikan, R. (1977) Methods Statistical Data Analysis Multivariate Observations. John Wiley 1& Sons, Sec. 4.2. Flury, B. (1997) First Course Multivariate Statistics. Springer, Sec. 7.3.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Discriminant coordinates data projection — crimcoords","text":"Luca Scrucca luca.scrucca@unipg.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/crimcoords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Discriminant coordinates data projection — crimcoords","text":"","code":"# discriminant coordinates for the iris data using known classes  data(\"iris\") CRIMCOORDS = crimcoords(iris[,-5], iris$Species) summary(CRIMCOORDS) #> -------------------------------------  #> Discriminant coordinates (crimcoords)  #> -------------------------------------  #>  #> Estimated basis vectors:  #>              crimcoords1 crimcoords2 #> Sepal.Length     -0.8378    0.024347 #> Sepal.Width      -1.5501    2.186497 #> Petal.Length      2.2236   -0.941383 #> Petal.Width       2.8390    2.868013 #>  #>             crimcoords1 crimcoords2 #> Eigenvalues    1609.596       14.27 #> Cum. %           99.121      100.00 plot(CRIMCOORDS)   # banknote data data(\"banknote\")  # discriminant coordinate on known classes  CRIMCOORDS = crimcoords(banknote[,-1], banknote$Status) summary(CRIMCOORDS) #> -------------------------------------  #> Discriminant coordinates (crimcoords)  #> -------------------------------------  #>  #> Estimated basis vectors:  #>          crimcoords1 #> Length     0.0050364 #> Left       0.8366262 #> Right     -0.8532702 #> Bottom    -1.1229645 #> Top       -1.1848235 #> Diagonal   1.5643624 #>  #>             crimcoords1 #> Eigenvalues      1218.4 #> Cum. %            100.0 plot(CRIMCOORDS)   #  discriminant coordinates on estimated clusters mod = Mclust(banknote[,-1]) CRIMCOORDS = crimcoords(banknote[,-1], mod$classification) summary(CRIMCOORDS) #> -------------------------------------  #> Discriminant coordinates (crimcoords)  #> -------------------------------------  #>  #> Estimated basis vectors:  #>          crimcoords1 crimcoords2 #> Length       0.41771     -0.4252 #> Left         0.98024     -0.8729 #> Right       -1.11061     -1.1215 #> Bottom      -1.55068      1.6469 #> Top         -1.55732      1.5712 #> Diagonal     0.90221      2.3650 #>  #>             crimcoords1 crimcoords2 #> Eigenvalues     849.225      177.33 #> Cum. %           82.725      100.00 plot(CRIMCOORDS)  plot(CRIMCOORDS$projection, type = \"n\") text(CRIMCOORDS$projection, cex = 0.8,      labels = strtrim(banknote$Status, 2),       col = mclust.options(\"classPlotColors\")[1:mod$G][mod$classification])"},{"path":"https://mclust-org.github.io/mclust/reference/cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Cross Data — cross","title":"Simulated Cross Data — cross","text":"500 3 matrix first column classification remaining columns two data simulation two crossed elliptical Gaussians.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Cross Data — cross","text":"","code":"data(cross)"},{"path":"https://mclust-org.github.io/mclust/reference/cross.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Cross Data — cross","text":"","code":"# This dataset was created as follows # \\donttest{ n <- 250  set.seed(0) cross <- rbind(matrix(rnorm(n*2), n, 2) %*% diag(c(1,9)),                matrix(rnorm(n*2), n, 2) %*% diag(c(1,9))[,2:1]) cross <- cbind(c(rep(1,n),rep(2,n)), cross) # }"},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"MclustDA cross-validation — cvMclustDA","title":"MclustDA cross-validation — cvMclustDA","text":"V-fold cross-validation classification models based Gaussian  finite mixture modelling.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MclustDA cross-validation — cvMclustDA","text":"","code":"cvMclustDA(object, nfold = 10,             prop = object$prop,            verbose = interactive(),             ...)"},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MclustDA cross-validation — cvMclustDA","text":"object object class 'MclustDA' resulting call      MclustDA. nfold integer specifying number folds (defaul 10-fold CV      used). prop vector class prior probabilities, provided default     class proportions training data. verbose logical controlling text progress bar displayed      cross-validation procedure. default TRUE      session interactive, FALSE otherwise. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MclustDA cross-validation — cvMclustDA","text":"function implements V-fold cross-validation classification  models fitted MclustDA.  Classification error Brier score metrics returned, metrics can computed using output returned function (see Examples section ).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MclustDA cross-validation — cvMclustDA","text":"function returns list following components: classification factor cross-validated class labels. z matrix containing cross-validated probabilites class assignment. ce cross-validation classification error. se.ce standard error cross-validated classification error. brier cross-validation Brier score. se.brier standard error cross-validated Brier score.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MclustDA cross-validation — cvMclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/cvMclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MclustDA cross-validation — cvMclustDA","text":"","code":"# \\donttest{ # Iris data Class <- iris$Species X <- iris[,1:4]  ## EDDA model with common covariance (essentially equivalent to linear discriminant analysis) irisEDDA <- MclustDA(X, Class, modelType = \"EDDA\", modelNames = \"EEE\") cv <- cvMclustDA(irisEDDA)                         # 10-fold CV (default) str(cv) #> List of 6 #>  $ classification: Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... #>  $ z             : num [1:150, 1:3] 1 1 1 1 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"setosa\" \"versicolor\" \"virginica\" #>  $ ce            : num 0.02 #>  $ se.ce         : num 0.0102 #>  $ brier         : num 0.0187 #>  $ se.brier      : num 0.00703 cv <- cvMclustDA(irisEDDA, nfold = length(Class))  # LOO-CV str(cv) #> List of 6 #>  $ classification: Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... #>  $ z             : num [1:150, 1:3] 1 1 1 1 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"setosa\" \"versicolor\" \"virginica\" #>  $ ce            : num 0.02 #>  $ se.ce         : num 0.0115 #>  $ brier         : num 0.017 #>  $ se.brier      : num 0.00824  ## MclustDA model selected by BIC irisMclustDA <- MclustDA(X, Class) cv <- cvMclustDA(irisMclustDA)                     # 10-fold CV (default) str(cv) #> List of 6 #>  $ classification: Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... #>  $ z             : num [1:150, 1:3] 1 1 1 1 1 1 1 1 1 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"setosa\" \"versicolor\" \"virginica\" #>  $ ce            : num 0.02 #>  $ se.ce         : num 0.0102 #>  $ brier         : num 0.0174 #>  $ se.brier      : num 0.00712  # Banknote data data(\"banknote\") Class <- banknote$Status X <- banknote[,2:7]  ## EDDA model selected by BIC banknoteEDDA <- MclustDA(X, Class, modelType = \"EDDA\") cv <- cvMclustDA(banknoteEDDA)                     # 10-fold CV (default) str(cv) #> List of 6 #>  $ classification: Factor w/ 2 levels \"counterfeit\",..: 2 2 2 2 2 2 2 2 2 2 ... #>  $ z             : num [1:200, 1:2] 2.45e-06 5.47e-25 4.80e-23 1.20e-24 7.38e-21 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:2] \"counterfeit\" \"genuine\" #>  $ ce            : num 0.005 #>  $ se.ce         : num 0.005 #>  $ brier         : num 0.00499 #>  $ se.brier      : num 0.00494  (ConfusionMatrix <- table(Pred = cv$classification, Class)) #>              Class #> Pred          counterfeit genuine #>   counterfeit         100       1 #>   genuine               0      99 TP <- ConfusionMatrix[1,1] FP <- ConfusionMatrix[1,2] FN <- ConfusionMatrix[2,1] TN <- ConfusionMatrix[2,2] (Sensitivity <- TP/(TP+FN)) #> [1] 1 (Specificity <- TN/(FP+TN)) #> [1] 0.99 # }"},{"path":"https://mclust-org.github.io/mclust/reference/decomp2sigma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert mixture component covariances to matrix form — decomp2sigma","title":"Convert mixture component covariances to matrix form — decomp2sigma","text":"Converts covariances parameterization  eigenvalue decomposition    cholesky factorization representation 3-D array.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/decomp2sigma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert mixture component covariances to matrix form — decomp2sigma","text":"","code":"decomp2sigma(d, G, scale, shape, orientation, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/decomp2sigma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert mixture component covariances to matrix form — decomp2sigma","text":"d dimension data. G number components mixture model. scale Either G-vector giving scale covariance (    dth root determinant) component     mixture model, single numeric value scale     component. shape Either G d matrix kth column     shape covariance matrix (normalized     determinant 1) kth component, d-vector     giving common shape components. orientation Either d d G array whose [,,k]th     entry orthonomal matrix whose columns eigenvectors     covariance matrix kth component,     d d orthonormal matrix mixture components common     orientation. orientation component decomp can     omitted spherical diagonal models, principal     components parallel coordinate axes     orientation matrix identity. ... Catches unused arguments indirect list call via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/decomp2sigma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert mixture component covariances to matrix form — decomp2sigma","text":"3-D array whose [,,k]th component    covariance matrix kth component MVN mixture model.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/decomp2sigma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert mixture component covariances to matrix form — decomp2sigma","text":"","code":"meEst <- meVEV(iris[,-5], unmap(iris[,5]))  names(meEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\" \"control\"    \"loglik\"     meEst$parameters$variance #> $modelName #> [1] \"VEV\" #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.13321144  0.10939010   0.01919074  0.01158562 #> Sepal.Width    0.10939010  0.15495729   0.01209929  0.01001100 #> Petal.Length   0.01919074  0.01209929   0.02827503  0.00581811 #> Petal.Width    0.01158562  0.01001100   0.00581811  0.01069593 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.22571809  0.07613379   0.14689790  0.04335743 #> Sepal.Width    0.07613379  0.08024536   0.07371576  0.03435377 #> Petal.Length   0.14689790  0.07371576   0.16611738  0.04951832 #> Petal.Width    0.04335743  0.03435377   0.04951832  0.03337836 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.42945746  0.10782916   0.33457182  0.06541484 #> Sepal.Width    0.10782916  0.11595505   0.08903504  0.06133241 #> Petal.Length   0.33457182  0.08903504   0.36427088  0.08711121 #> Petal.Width    0.06541484  0.06133241   0.08711121  0.08666116 #>  #>  #> $scale #> [1] 0.03748690 0.05792051 0.11417100 #>  #> $shape #> [1] 6.8586562 1.0115190 0.6265407 0.2300581 #>  #> $orientation #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  -0.66907840   0.5978840   -0.4399628 -0.03607712 #> Sepal.Width   -0.73414783  -0.6206734    0.2746075 -0.01955027 #> Petal.Length  -0.09654390   0.4900556    0.8324495 -0.23990129 #> Petal.Width   -0.06356359   0.1309379    0.1950675  0.96992969 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.7058553  -0.6603954   0.24389224 -0.07850316 #> Sepal.Width     0.3292982   0.5666772   0.68428027  0.31968755 #> Petal.Length    0.5956635   0.3576279  -0.68509739  0.21892660 #> Petal.Width     0.1962550   0.3389057   0.05402459 -0.91853594 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   -0.7104631 -0.30095824   -0.5382163  -0.3391010 #> Sepal.Width    -0.2167218  0.71570645   -0.4318489   0.5042841 #> Petal.Length   -0.6483892 -0.07068137    0.6545951   0.3822313 #> Petal.Width    -0.1669287  0.62625279    0.3087637  -0.6961374 #>  #>   dec <- meEst$parameters$variance decomp2sigma(d=dec$d, G=dec$G, shape=dec$shape, scale=dec$scale,              orientation = dec$orientation) #> , , 1 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.13321144 0.10939010 0.01919074 0.01158562 #> [2,] 0.10939010 0.15495729 0.01209929 0.01001100 #> [3,] 0.01919074 0.01209929 0.02827503 0.00581811 #> [4,] 0.01158562 0.01001100 0.00581811 0.01069593 #>  #> , , 2 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.22571809 0.07613379 0.14689790 0.04335743 #> [2,] 0.07613379 0.08024536 0.07371576 0.03435377 #> [3,] 0.14689790 0.07371576 0.16611738 0.04951832 #> [4,] 0.04335743 0.03435377 0.04951832 0.03337836 #>  #> , , 3 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.42945746 0.10782916 0.33457182 0.06541484 #> [2,] 0.10782916 0.11595505 0.08903504 0.06133241 #> [3,] 0.33457182 0.08903504 0.36427088 0.08711121 #> [4,] 0.06541484 0.06133241 0.08711121 0.08666116 #>  #> attr(,\"modelName\") #> [1] \"VEV\" # \\donttest{ do.call(\"decomp2sigma\", dec)  ## alternative call #> , , 1 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.13321144 0.10939010 0.01919074 0.01158562 #> [2,] 0.10939010 0.15495729 0.01209929 0.01001100 #> [3,] 0.01919074 0.01209929 0.02827503 0.00581811 #> [4,] 0.01158562 0.01001100 0.00581811 0.01069593 #>  #> , , 2 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.22571809 0.07613379 0.14689790 0.04335743 #> [2,] 0.07613379 0.08024536 0.07371576 0.03435377 #> [3,] 0.14689790 0.07371576 0.16611738 0.04951832 #> [4,] 0.04335743 0.03435377 0.04951832 0.03337836 #>  #> , , 3 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.42945746 0.10782916 0.33457182 0.06541484 #> [2,] 0.10782916 0.11595505 0.08903504 0.06133241 #> [3,] 0.33457182 0.08903504 0.36427088 0.08711121 #> [4,] 0.06541484 0.06133241 0.08711121 0.08666116 #>  #> attr(,\"modelName\") #> [1] \"VEV\" # }"},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":null,"dir":"Reference","previous_headings":"","what":"Default conjugate prior for Gaussian mixtures — defaultPrior","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"Default conjugate prior specification Gaussian mixtures.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"","code":"defaultPrior(data, G, modelName, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. G number mixture components. modelName character string indicating model: \"E\": equal variance  (univariate) \"V\": variable variance (univariate)\"EII\": spherical, equal volume \"VII\": spherical, unequal volume \"EEI\": diagonal, equal volume shape\"VEI\": diagonal, varying volume, equal shape\"EVI\": diagonal, equal volume, varying shape \"VVI\": diagonal, varying volume shape \"EEE\": ellipsoidal, equal volume, shape, orientation \"EEV\": ellipsoidal, equal volume equal shape\"VEV\": ellipsoidal, equal shape \"VVV\": ellipsoidal, varying volume, shape, orientation.      description models provided help      mclustModelNames. Note multivariate case      10 14 models may used conjunction prior, .e.     available MCLUST version 4.4. ... One following: dof degrees freedom prior variance.          default d + 2, d         dimension data. scale scale parameter prior variance.          default var(data)/G^(2/d),         d dimension data. shrinkage shrinkage parameter prior mean.          default value 0.01.          0 NA, prior assumed mean. mean mean parameter prior.          default value colMeans(data).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"list giving prior degrees freedom, scale, shrinkage, mean.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"defaultPrior function whose default output   default prior specification EM within MCLUST.   Furthermore, defaultPrior can used template specify    alternative parameters conjugate prior.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"C. Fraley . E. Raftery (2002).   Model-based clustering, discriminant analysis, density estimation.   Journal American Statistical Association 97:611-631. C. Fraley . E. Raftery (2005, revised 2009).   Bayesian regularization normal mixture estimation model-based   clustering.   Technical Report, Department Statistics, University Washington. C. Fraley . E. Raftery (2007).   Bayesian regularization normal mixture estimation model-based   clustering. Journal Classification 24:155-181.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/defaultPrior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default conjugate prior for Gaussian mixtures — defaultPrior","text":"","code":"# default prior irisBIC <- mclustBIC(iris[,-5], prior = priorControl()) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.8136 -587.403843 -592.51283 #> BIC diff    0.0000   -6.590289  -11.69928 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   # equivalent to previous example irisBIC <- mclustBIC(iris[,-5],                       prior = priorControl(functionName = \"defaultPrior\")) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.8136 -587.403843 -592.51283 #> BIC diff    0.0000   -6.590289  -11.69928 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   # no prior on the mean; default prior on variance irisBIC <- mclustBIC(iris[,-5], prior = priorControl(shrinkage = 0)) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.2861 -586.792195 -592.07132 #> BIC diff    0.0000   -6.506112  -11.78523 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   # equivalent to previous example irisBIC <- mclustBIC(iris[,-5], prior =                      priorControl(functionName=\"defaultPrior\", shrinkage=0)) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.2861 -586.792195 -592.07132 #> BIC diff    0.0000   -6.506112  -11.78523 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   defaultPrior( iris[-5], G = 3, modelName = \"VVV\") #> $shrinkage #> [1] 0.01 #>  #> $mean #> Sepal.Length  Sepal.Width Petal.Length  Petal.Width  #>     5.843333     3.057333     3.758000     1.199333  #>  #> $dof #> [1] 6 #>  #> $scale #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.39588533 -0.02449928    0.7357264  0.29806902 #> Sepal.Width   -0.02449928  0.10968467   -0.1903272 -0.07022853 #> Petal.Length   0.73572636 -0.19032720    1.7991839  0.74802043 #> Petal.Width    0.29806902 -0.07022853    0.7480204  0.33544412 #>"},{"path":"https://mclust-org.github.io/mclust/reference/dens.html","id":null,"dir":"Reference","previous_headings":"","what":"Density for Parameterized MVN Mixtures — dens","title":"Density for Parameterized MVN Mixtures — dens","text":"Computes densities observations parameterized MVN mixtures.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density for Parameterized MVN Mixtures — dens","text":"","code":"dens(data, modelName, parameters, logarithm = FALSE, warn=NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/dens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density for Parameterized MVN Mixtures — dens","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. parameters parameters model: pro vector mixing proportions components mixture. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details.  logarithm logical value indicating whether logarithm component        densities returned. default return component        densities, obtained log component densities exponentiation. warn logical value indicating whether warning issued     computations fail. default warn=FALSE. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density for Parameterized MVN Mixtures — dens","text":"numeric vector whose ith component density  ith observation data MVN mixture specified    parameters.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/dens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density for Parameterized MVN Mixtures — dens","text":"","code":"# \\donttest{ faithfulModel <- Mclust(faithful) Dens <- dens(modelName = faithfulModel$modelName, data = faithful,              parameters = faithfulModel$parameters) Dens #>   [1] 0.0122707769 0.0250791544 0.0043706519 0.0138530357 0.0382956210 #>   [6] 0.0002669332 0.0202191254 0.0040575505 0.0301848769 0.0325465898 #>  [11] 0.0276869342 0.0127084049 0.0362272836 0.0126473322 0.0340433096 #>  [16] 0.0275448001 0.0053347162 0.0232973040 0.0107378357 0.0408143520 #>  [21] 0.0238107781 0.0126473322 0.0072401212 0.0004615756 0.0203636678 #>  [26] 0.0066803862 0.0348709952 0.0258863865 0.0209955144 0.0477227189 #>  [31] 0.0206531762 0.0391333267 0.0014780594 0.0257972930 0.0167084263 #>  [36] 0.0332636318 0.0187479804 0.0175051886 0.0163036777 0.0109972466 #>  [41] 0.0474204872 0.0227110075 0.0415680246 0.0137115191 0.0158266993 #>  [46] 0.0012729444 0.0010299378 0.0336507731 0.0409197701 0.0251395735 #>  [51] 0.0086303933 0.0127443256 0.0276869342 0.0175051886 0.0195757229 #>  [56] 0.0158547822 0.0099200538 0.0015967934 0.0333010021 0.0448831115 #>  [61] 0.0239559246 0.0428496246 0.0149845645 0.0234478154 0.0124655190 #>  [66] 0.0057207553 0.0340808379 0.0254708050 0.0064351071 0.0084682320 #>  [71] 0.0220153547 0.0332770111 0.0459430980 0.0104506735 0.0132065431 #>  [76] 0.0014619324 0.0217586659 0.0378862342 0.0205889086 0.0066803862 #>  [81] 0.0250386851 0.0438577789 0.0085574647 0.0017709761 0.0168201235 #>  [86] 0.0088830496 0.0218162889 0.0476014546 0.0138720624 0.0099493552 #>  [91] 0.0221772274 0.0094489614 0.0250152660 0.0146789904 0.0059518823 #>  [96] 0.0162549604 0.0355225683 0.0172825304 0.0275228747 0.0139559513 #> [101] 0.0071018356 0.0183366060 0.0203532755 0.0463634341 0.0251129031 #> [106] 0.0154593959 0.0327309413 0.0238013515 0.0166081728 0.0125494369 #> [111] 0.0124071667 0.0205249659 0.0088890790 0.0477608953 0.0087337354 #> [116] 0.0404200470 0.0118739090 0.0365574562 0.0153237485 0.0254418777 #> [121] 0.0028285242 0.0062235544 0.0367698291 0.0332770111 0.0228631638 #> [126] 0.0152445746 0.0096078262 0.0485643201 0.0257527006 0.0138710618 #> [131] 0.0095366375 0.0275045523 0.0007572071 0.0128224853 0.0119541984 #> [136] 0.0467697878 0.0282281324 0.0109926682 0.0352702703 0.0171467325 #> [141] 0.0384053159 0.0211703981 0.0475772253 0.0122779718 0.0355556985 #> [146] 0.0244886753 0.0386518809 0.0228345796 0.0004696987 0.0254619048 #> [151] 0.0025750274 0.0244958403 0.0051819355 0.0434023375 0.0082005926 #> [156] 0.0080988362 0.0492461255 0.0011143717 0.0254619048 0.0037325233 #> [161] 0.0051808630 0.0155405861 0.0288468099 0.0205963766 0.0021521139 #> [166] 0.0271890898 0.0092240733 0.0060951894 0.0322175567 0.0054955650 #> [171] 0.0230753789 0.0332492684 0.0320539198 0.0021292353 0.0330200275 #> [176] 0.0459247107 0.0171264585 0.0068465199 0.0125125545 0.0226037644 #> [181] 0.0302872440 0.0320539198 0.0340958190 0.0112216922 0.0300605795 #> [186] 0.0444833129 0.0188389127 0.0119541984 0.0451826484 0.0318305057 #> [191] 0.0224060120 0.0222103090 0.0109726952 0.0197480537 0.0234588094 #> [196] 0.0384053159 0.0012583227 0.0405029646 0.0188536746 0.0287510417 #> [201] 0.0232604940 0.0449585388 0.0031753778 0.0302271931 0.0351137802 #> [206] 0.0110771907 0.0405130102 0.0110738013 0.0232544418 0.0463634341 #> [211] 0.0005925546 0.0315289486 0.0220102694 0.0184806555 0.0009023966 #> [216] 0.0325656419 0.0126143782 0.0032201571 0.0358732599 0.0288218671 #> [221] 0.0250152660 0.0388430888 0.0209701825 0.0278737826 0.0252166485 #> [226] 0.0313864902 0.0290215102 0.0403560942 0.0079947124 0.0430006133 #> [231] 0.0084615742 0.0127969899 0.0172641330 0.0179025070 0.0125562378 #> [236] 0.0312429480 0.0289616059 0.0382686642 0.0232927036 0.0079999951 #> [241] 0.0256640045 0.0046569310 0.0109926682 0.0002941915 0.0372016212 #> [246] 0.0151319087 0.0332492684 0.0459498689 0.0034327330 0.0255597331 #> [251] 0.0297690462 0.0461172111 0.0107096177 0.0171264585 0.0093189544 #> [256] 0.0183858540 0.0101940749 0.0461172111 0.0344591262 0.0429864494 #> [261] 0.0190147184 0.0425259106 0.0205065804 0.0340958190 0.0047576298 #> [266] 0.0205470761 0.0113825738 0.0292875446 0.0085827041 0.0117658465 #> [271] 0.0117107647 0.0232041075  ## alternative call do.call(\"dens\", faithfulModel)# } #>   [1] 0.0122707769 0.0250791544 0.0043706519 0.0138530357 0.0382956210 #>   [6] 0.0002669332 0.0202191254 0.0040575505 0.0301848769 0.0325465898 #>  [11] 0.0276869342 0.0127084049 0.0362272836 0.0126473322 0.0340433096 #>  [16] 0.0275448001 0.0053347162 0.0232973040 0.0107378357 0.0408143520 #>  [21] 0.0238107781 0.0126473322 0.0072401212 0.0004615756 0.0203636678 #>  [26] 0.0066803862 0.0348709952 0.0258863865 0.0209955144 0.0477227189 #>  [31] 0.0206531762 0.0391333267 0.0014780594 0.0257972930 0.0167084263 #>  [36] 0.0332636318 0.0187479804 0.0175051886 0.0163036777 0.0109972466 #>  [41] 0.0474204872 0.0227110075 0.0415680246 0.0137115191 0.0158266993 #>  [46] 0.0012729444 0.0010299378 0.0336507731 0.0409197701 0.0251395735 #>  [51] 0.0086303933 0.0127443256 0.0276869342 0.0175051886 0.0195757229 #>  [56] 0.0158547822 0.0099200538 0.0015967934 0.0333010021 0.0448831115 #>  [61] 0.0239559246 0.0428496246 0.0149845645 0.0234478154 0.0124655190 #>  [66] 0.0057207553 0.0340808379 0.0254708050 0.0064351071 0.0084682320 #>  [71] 0.0220153547 0.0332770111 0.0459430980 0.0104506735 0.0132065431 #>  [76] 0.0014619324 0.0217586659 0.0378862342 0.0205889086 0.0066803862 #>  [81] 0.0250386851 0.0438577789 0.0085574647 0.0017709761 0.0168201235 #>  [86] 0.0088830496 0.0218162889 0.0476014546 0.0138720624 0.0099493552 #>  [91] 0.0221772274 0.0094489614 0.0250152660 0.0146789904 0.0059518823 #>  [96] 0.0162549604 0.0355225683 0.0172825304 0.0275228747 0.0139559513 #> [101] 0.0071018356 0.0183366060 0.0203532755 0.0463634341 0.0251129031 #> [106] 0.0154593959 0.0327309413 0.0238013515 0.0166081728 0.0125494369 #> [111] 0.0124071667 0.0205249659 0.0088890790 0.0477608953 0.0087337354 #> [116] 0.0404200470 0.0118739090 0.0365574562 0.0153237485 0.0254418777 #> [121] 0.0028285242 0.0062235544 0.0367698291 0.0332770111 0.0228631638 #> [126] 0.0152445746 0.0096078262 0.0485643201 0.0257527006 0.0138710618 #> [131] 0.0095366375 0.0275045523 0.0007572071 0.0128224853 0.0119541984 #> [136] 0.0467697878 0.0282281324 0.0109926682 0.0352702703 0.0171467325 #> [141] 0.0384053159 0.0211703981 0.0475772253 0.0122779718 0.0355556985 #> [146] 0.0244886753 0.0386518809 0.0228345796 0.0004696987 0.0254619048 #> [151] 0.0025750274 0.0244958403 0.0051819355 0.0434023375 0.0082005926 #> [156] 0.0080988362 0.0492461255 0.0011143717 0.0254619048 0.0037325233 #> [161] 0.0051808630 0.0155405861 0.0288468099 0.0205963766 0.0021521139 #> [166] 0.0271890898 0.0092240733 0.0060951894 0.0322175567 0.0054955650 #> [171] 0.0230753789 0.0332492684 0.0320539198 0.0021292353 0.0330200275 #> [176] 0.0459247107 0.0171264585 0.0068465199 0.0125125545 0.0226037644 #> [181] 0.0302872440 0.0320539198 0.0340958190 0.0112216922 0.0300605795 #> [186] 0.0444833129 0.0188389127 0.0119541984 0.0451826484 0.0318305057 #> [191] 0.0224060120 0.0222103090 0.0109726952 0.0197480537 0.0234588094 #> [196] 0.0384053159 0.0012583227 0.0405029646 0.0188536746 0.0287510417 #> [201] 0.0232604940 0.0449585388 0.0031753778 0.0302271931 0.0351137802 #> [206] 0.0110771907 0.0405130102 0.0110738013 0.0232544418 0.0463634341 #> [211] 0.0005925546 0.0315289486 0.0220102694 0.0184806555 0.0009023966 #> [216] 0.0325656419 0.0126143782 0.0032201571 0.0358732599 0.0288218671 #> [221] 0.0250152660 0.0388430888 0.0209701825 0.0278737826 0.0252166485 #> [226] 0.0313864902 0.0290215102 0.0403560942 0.0079947124 0.0430006133 #> [231] 0.0084615742 0.0127969899 0.0172641330 0.0179025070 0.0125562378 #> [236] 0.0312429480 0.0289616059 0.0382686642 0.0232927036 0.0079999951 #> [241] 0.0256640045 0.0046569310 0.0109926682 0.0002941915 0.0372016212 #> [246] 0.0151319087 0.0332492684 0.0459498689 0.0034327330 0.0255597331 #> [251] 0.0297690462 0.0461172111 0.0107096177 0.0171264585 0.0093189544 #> [256] 0.0183858540 0.0101940749 0.0461172111 0.0344591262 0.0429864494 #> [261] 0.0190147184 0.0425259106 0.0205065804 0.0340958190 0.0047576298 #> [266] 0.0205470761 0.0113825738 0.0292875446 0.0085827041 0.0117658465 #> [271] 0.0117107647 0.0232041075"},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"Diagnostic plots density estimation. available one-dimensional case.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"","code":"densityMclust.diagnostic(object, type = c(\"cdf\", \"qq\"),                           col = c(\"black\", \"black\"),                           lwd = c(2,1), lty = c(1,1),                           legend = TRUE, grid = TRUE,                           ...)"},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"object object class 'mclustDensity' obtained call densityMclust function. type type graph requested: \"cdf\" = plot estimated CDF versus empirical distribution function. \"qq\" = Q-Q plot sample quantiles versus quantiles obtained inverse estimated cdf.  col pair values color used plotting, respectively, estimated CDF empirical cdf. lwd pair values line width used plotting, respectively, estimated CDF empirical cdf. lty pair values line type used plotting, respectively, estimated CDF empirical cdf. legend logical indicating legend must added plot fitted CDF vs empirical CDF. grid logical indicating grid added plot. ... Additional arguments.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"two diagnostic plots density estimation one-dimensional case discussed Loader (1999, pp- 87-90).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"Loader C. (1999), Local Regression Likelihood. New York, Springer. Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.diagnostic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diagnostic plots for mclustDensity estimation — densityMclust.diagnostic","text":"","code":"# \\donttest{ x <- faithful$waiting dens <- densityMclust(x, plot = FALSE) plot(dens, x, what = \"diagnostic\")   # or densityMclust.diagnostic(dens, type = \"cdf\")  densityMclust.diagnostic(dens, type = \"qq\")  # }"},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Density Estimation via Model-Based Clustering — densityMclust","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"Produces density estimate data point using Gaussian finite    mixture model Mclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"","code":"densityMclust(data, ..., plot = TRUE)"},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. ... Additional arguments Mclust function.      particular, setting arguments G modelNames      allow specify number mixture components type     model fitted. default \"optimal\" model selected based     BIC criterion. plot logical value specifying estimated density      plotted. contols resulting graph see associated      plot.densityMclust method.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"object class densityMclust, inherits  Mclust. contains components described  Mclust additional element: density density evaluated input data computed estimated model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317. Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"Revised version Luca Scrucca based    original code C. Fraley .E. Raftery.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/densityMclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density Estimation via Model-Based Clustering — densityMclust","text":"","code":"dens <- densityMclust(faithful$waiting)  summary(dens) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust E (univariate, equal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1034.002 272  4 -2090.427 -2099.576 summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust E (univariate, equal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1034.002 272  4 -2090.427 -2099.576 #>  #> Mixing probabilities: #>         1         2  #> 0.3609461 0.6390539  #>  #> Means: #>        1        2  #> 54.61675 80.09239  #>  #> Variances: #>        1        2  #> 34.44093 34.44093  plot(dens, what = \"BIC\", legendArgs = list(x = \"topright\"))  plot(dens, what = \"density\", data = faithful$waiting)   dens <- densityMclust(faithful, modelNames = \"EEE\", G = 3, plot = FALSE) summary(dens) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 #>  #> Mixing probabilities: #>         1         2         3  #> 0.1656784 0.3563696 0.4779520  #>  #> Means: #>                [,1]      [,2]      [,3] #> eruptions  3.793066  2.037596  4.463245 #> waiting   77.521051 54.491158 80.833439 #>  #> Variances: #> [,,1] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,2] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,3] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 plot(dens, what = \"density\", data = faithful,       drawlabels = FALSE, points.pch = 20)  plot(dens, what = \"density\", type = \"hdr\")  plot(dens, what = \"density\", type = \"hdr\", prob = c(0.1, 0.9))  plot(dens, what = \"density\", type = \"hdr\", data = faithful)  plot(dens, what = \"density\", type = \"persp\")   # \\donttest{ dens <- densityMclust(iris[,1:4], G = 2)  summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Mixing probabilities: #>         1         2  #> 0.3333319 0.6666681  #>  #> Means: #>                   [,1]     [,2] #> Sepal.Length 5.0060022 6.261996 #> Sepal.Width  3.4280049 2.871999 #> Petal.Length 1.4620007 4.905992 #> Petal.Width  0.2459998 1.675997 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.15065114  0.13080115   0.02084463  0.01309107 #> Sepal.Width    0.13080115  0.17604529   0.01603245  0.01221458 #> Petal.Length   0.02084463  0.01603245   0.02808260  0.00601568 #> Petal.Width    0.01309107  0.01221458   0.00601568  0.01042365 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.4000438  0.10865444    0.3994018  0.14368256 #> Sepal.Width     0.1086544  0.10928077    0.1238904  0.07284384 #> Petal.Length    0.3994018  0.12389040    0.6109024  0.25738990 #> Petal.Width     0.1436826  0.07284384    0.2573899  0.16808182 plot(dens, what = \"density\", data = iris[,1:4],       col = \"slategrey\", drawlabels = FALSE, nlevels = 7)  plot(dens, what = \"density\", type = \"hdr\", data = iris[,1:4])  plot(dens, what = \"density\", type = \"persp\", col = grey(0.9))  # }"},{"path":"https://mclust-org.github.io/mclust/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Diabetes Data (flawed) — diabetes","title":"Diabetes Data (flawed) — diabetes","text":"data set contains three measurements made 145 non-obese adult patients classified three groups.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diabetes Data (flawed) — diabetes","text":"","code":"data(diabetes)"},{"path":"https://mclust-org.github.io/mclust/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Diabetes Data (flawed) — diabetes","text":"data frame following variables: class type diabete: Normal, Overt, Chemical. glucose Area plasma glucose curve three hour oral glucose tolerance test (OGTT). insulin Area plasma insulin curve three hour oral glucose tolerance test (OGTT). sspg Steady state plasma glucose.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/diabetes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diabetes Data (flawed) — diabetes","text":"dataset flawed (compare reference) provided backward compatibility. 5-variable version Reaven Miller data available package rrcov. glucose sspg columns dataset identical fpg insulin columns, respectively rrcov version. insulin column dataset differs glucose column rrcov version one entry: observation 104 value 45 insulin column data, 455 corresponding glucose column rrcov version.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/diabetes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Diabetes Data (flawed) — diabetes","text":"Reaven, G. M. Miller, R. G. (1979). attempt define nature chemical diabetes using multidimensional analysis. Diabetologia 16:17-24.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dmvnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of multivariate Gaussian distribution — dmvnorm","title":"Density of multivariate Gaussian distribution — dmvnorm","text":"Efficiently computes density observations generic multivariate Gaussian distribution.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dmvnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of multivariate Gaussian distribution — dmvnorm","text":"","code":"dmvnorm(data, mean, sigma, log = FALSE)"},{"path":"https://mclust-org.github.io/mclust/reference/dmvnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of multivariate Gaussian distribution — dmvnorm","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. mean vector means variable. sigma positive definite covariance matrix. log logical value indicating whether logarithm densities      returned.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dmvnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of multivariate Gaussian distribution — dmvnorm","text":"numeric vector whose ith element gives density  ith observation data multivariate Gaussian  \tdistribution parameters mean sigma.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/dmvnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of multivariate Gaussian distribution — dmvnorm","text":"","code":"# univariate ngrid <- 101 x <- seq(-5, 5, length = ngrid) dens <- dmvnorm(x, mean = 1, sigma = 5) plot(x, dens, type = \"l\")   # bivariate ngrid <- 101 x1 <- x2 <- seq(-5, 5, length = ngrid) mu <- c(1,0) sigma <- matrix(c(1,0.5,0.5,2), 2, 2) dens <- dmvnorm(as.matrix(expand.grid(x1, x2)), mu, sigma) dens <- matrix(dens, ngrid, ngrid) image(x1, x2, dens) contour(x1, x2, dens, add = TRUE)"},{"path":"https://mclust-org.github.io/mclust/reference/dupPartition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition the data by grouping together duplicated data — dupPartition","title":"Partition the data by grouping together duplicated data — dupPartition","text":"Duplicated data grouped together form basic partition can used start hierarchical agglomeration.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dupPartition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition the data by grouping together duplicated data — dupPartition","text":"","code":"dupPartition(data)"},{"path":"https://mclust-org.github.io/mclust/reference/dupPartition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition the data by grouping together duplicated data — dupPartition","text":"data numeric vector, matrix, data frame observations.     matrix data frame, rows correspond observations (\\(n\\))     columns correspond variables (\\(d\\)).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/dupPartition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition the data by grouping together duplicated data — dupPartition","text":"vector indices indicating partition.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/dupPartition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition the data by grouping together duplicated data — dupPartition","text":"","code":"# \\donttest{ dupPartition(iris[,1:4]) #>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 #>  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36 #>  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54 #>  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72 #>  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 #>  [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 #> [109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 #> [127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 102 143 #> [145] 144 145 146 147 148 149 dupPartition(iris) #>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 #>  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36 #>  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54 #>  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72 #>  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 #>  [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 #> [109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 #> [127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 102 143 #> [145] 144 145 146 147 148 149 dupPartition(iris$Species) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3 # }"},{"path":"https://mclust-org.github.io/mclust/reference/em.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","title":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","text":"Implements EM algorithm parameterized Gaussian mixture models,   starting expectation step.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/em.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","text":"","code":"em(data, modelName, parameters, prior = NULL, control = emControl(),    warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/em.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. parameters names list giving parameters model.      components follows: pro Mixing proportions components mixture.                 model includes Poisson term noise,                 one mixing proportion number                 Gaussian components. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details. Vinv estimate reciprocal hypervolume data region.               set NULL negative value, default determined                applying function hypvol data.               Used pro includes additional               mixing proportion noise component.  prior Specification conjugate prior means variances.       default assumes prior. control list control parameters EM. defaults set call         emControl(). warn logical value indicating whether warning issued     computations fail. default warn=FALSE. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/em.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","text":"list including following components: modelName character string identifying model (input argument). n number observations data. d dimension data. G number mixture components. z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  loglik log likelihood data mixture model. control list control parameters EM used. prior specification conjugate prior means variances used,      NULL prior used. Attributes: \"info\" Information iteration.\"WARNING\" appropriate warning problems        encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/em.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm starting with E-step for parameterized Gaussian mixture models — em","text":"","code":"# \\donttest{ msEst <- mstep(modelName = \"EEE\", data = iris[,-5],                 z = unmap(iris[,5])) names(msEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\"  em(modelName = msEst$modelName, data = iris[,-5],    parameters = msEst$parameters) #> $modelName #> [1] \"EEE\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                [,1]         [,2]         [,3] #>   [1,] 1.000000e+00 5.669389e-22 2.970668e-42 #>   [2,] 1.000000e+00 7.125511e-18 2.890550e-37 #>   [3,] 1.000000e+00 2.209921e-19 5.645717e-39 #>   [4,] 1.000000e+00 1.944369e-16 4.493925e-35 #>   [5,] 1.000000e+00 2.969620e-22 1.819554e-42 #>   [6,] 1.000000e+00 7.746074e-21 1.005427e-39 #>   [7,] 1.000000e+00 2.519429e-18 5.970904e-37 #>   [8,] 1.000000e+00 5.638578e-20 1.231056e-39 #>   [9,] 1.000000e+00 2.778048e-15 1.088991e-33 #>  [10,] 1.000000e+00 1.193692e-18 1.753502e-38 #>  [11,] 1.000000e+00 1.635161e-23 3.372329e-44 #>  [12,] 1.000000e+00 2.937431e-18 3.124729e-37 #>  [13,] 1.000000e+00 1.517011e-18 1.969537e-38 #>  [14,] 1.000000e+00 1.843982e-19 1.764184e-39 #>  [15,] 1.000000e+00 6.849292e-30 1.303566e-52 #>  [16,] 1.000000e+00 3.245264e-27 7.704284e-48 #>  [17,] 1.000000e+00 1.264758e-24 7.386154e-45 #>  [18,] 1.000000e+00 6.462169e-21 1.584880e-40 #>  [19,] 1.000000e+00 2.203157e-22 2.328338e-42 #>  [20,] 1.000000e+00 5.749059e-22 1.456245e-41 #>  [21,] 1.000000e+00 1.272471e-19 2.601003e-39 #>  [22,] 1.000000e+00 3.035910e-20 4.610963e-39 #>  [23,] 1.000000e+00 1.681457e-24 2.334188e-45 #>  [24,] 1.000000e+00 1.247580e-14 1.126055e-31 #>  [25,] 1.000000e+00 2.033636e-15 2.214427e-33 #>  [26,] 1.000000e+00 2.297938e-16 2.933735e-35 #>  [27,] 1.000000e+00 6.480706e-17 6.730469e-35 #>  [28,] 1.000000e+00 2.066760e-21 1.569681e-41 #>  [29,] 1.000000e+00 1.082360e-21 4.850018e-42 #>  [30,] 1.000000e+00 1.529968e-16 4.000996e-35 #>  [31,] 1.000000e+00 2.920907e-16 6.532168e-35 #>  [32,] 1.000000e+00 2.112491e-19 2.006593e-38 #>  [33,] 1.000000e+00 1.833782e-26 6.732546e-48 #>  [34,] 1.000000e+00 3.568839e-28 6.559131e-50 #>  [35,] 1.000000e+00 1.360613e-17 9.355103e-37 #>  [36,] 1.000000e+00 1.748091e-21 6.118695e-42 #>  [37,] 1.000000e+00 1.848029e-24 8.856622e-46 #>  [38,] 1.000000e+00 6.322278e-23 1.239791e-43 #>  [39,] 1.000000e+00 6.778306e-17 9.552703e-36 #>  [40,] 1.000000e+00 2.323565e-20 3.386508e-40 #>  [41,] 1.000000e+00 1.772656e-21 2.999433e-41 #>  [42,] 1.000000e+00 1.458475e-11 3.636199e-29 #>  [43,] 1.000000e+00 3.158065e-18 2.712042e-37 #>  [44,] 1.000000e+00 1.817425e-15 3.227861e-32 #>  [45,] 1.000000e+00 4.013405e-17 1.057569e-34 #>  [46,] 1.000000e+00 1.970937e-16 5.605941e-35 #>  [47,] 1.000000e+00 4.461935e-22 5.242944e-42 #>  [48,] 1.000000e+00 4.744169e-18 3.942102e-37 #>  [49,] 1.000000e+00 3.968032e-23 1.225902e-43 #>  [50,] 1.000000e+00 2.952916e-20 3.803732e-40 #>  [51,] 4.352061e-18 9.999271e-01 7.285356e-05 #>  [52,] 1.462104e-19 9.991833e-01 8.167043e-04 #>  [53,] 4.326581e-22 9.969243e-01 3.075740e-03 #>  [54,] 3.588876e-22 9.997272e-01 2.727797e-04 #>  [55,] 8.685517e-23 9.968195e-01 3.180529e-03 #>  [56,] 8.313347e-23 9.983021e-01 1.697924e-03 #>  [57,] 3.067079e-22 9.793448e-01 2.065525e-02 #>  [58,] 5.113810e-14 9.999999e-01 1.031644e-07 #>  [59,] 1.272609e-19 9.999241e-01 7.588810e-05 #>  [60,] 8.975128e-21 9.992664e-01 7.336194e-04 #>  [61,] 3.442085e-18 9.999991e-01 8.743942e-07 #>  [62,] 5.603197e-20 9.990125e-01 9.874887e-04 #>  [63,] 9.656653e-18 9.999995e-01 4.518974e-07 #>  [64,] 1.491160e-23 9.942156e-01 5.784381e-03 #>  [65,] 5.275521e-14 9.999981e-01 1.854263e-06 #>  [66,] 4.551187e-17 9.999694e-01 3.064952e-05 #>  [67,] 5.482635e-24 9.671064e-01 3.289363e-02 #>  [68,] 3.956205e-16 9.999994e-01 6.381923e-07 #>  [69,] 5.338555e-27 9.786346e-01 2.136543e-02 #>  [70,] 2.149035e-17 9.999977e-01 2.333318e-06 #>  [71,] 2.269907e-28 1.338383e-01 8.661617e-01 #>  [72,] 1.564633e-16 9.999930e-01 6.999013e-06 #>  [73,] 1.862337e-28 8.664919e-01 1.335081e-01 #>  [74,] 4.204653e-22 9.996599e-01 3.400895e-04 #>  [75,] 1.496225e-17 9.999834e-01 1.663712e-05 #>  [76,] 4.048066e-18 9.999412e-01 5.881490e-05 #>  [77,] 1.811813e-22 9.990449e-01 9.551325e-04 #>  [78,] 9.733911e-27 7.032941e-01 2.967059e-01 #>  [79,] 4.207095e-23 9.914214e-01 8.578608e-03 #>  [80,] 1.686652e-11 1.000000e+00 1.168802e-08 #>  [81,] 1.691014e-17 9.999979e-01 2.062222e-06 #>  [82,] 1.705135e-15 9.999998e-01 2.029185e-07 #>  [83,] 2.383037e-16 9.999970e-01 2.965664e-06 #>  [84,] 4.543859e-32 1.255609e-01 8.744391e-01 #>  [85,] 8.944225e-25 9.290885e-01 7.091151e-02 #>  [86,] 7.853508e-21 9.883971e-01 1.160287e-02 #>  [87,] 5.759078e-21 9.985336e-01 1.466369e-03 #>  [88,] 7.047203e-23 9.997609e-01 2.391093e-04 #>  [89,] 4.510692e-18 9.999302e-01 6.984723e-05 #>  [90,] 7.703797e-21 9.998338e-01 1.662373e-04 #>  [91,] 6.639378e-23 9.993841e-01 6.159223e-04 #>  [92,] 6.134157e-22 9.979127e-01 2.087322e-03 #>  [93,] 5.814465e-18 9.999918e-01 8.248956e-06 #>  [94,] 2.678609e-14 9.999999e-01 8.822342e-08 #>  [95,] 5.126445e-21 9.996812e-01 3.187501e-04 #>  [96,] 1.410433e-17 9.999784e-01 2.163084e-05 #>  [97,] 2.670627e-19 9.998703e-01 1.296855e-04 #>  [98,] 2.540730e-18 9.999627e-01 3.733285e-05 #>  [99,] 8.473985e-11 1.000000e+00 1.640967e-08 #> [100,] 5.099820e-19 9.999235e-01 7.651826e-05 #> [101,] 8.752565e-53 1.844658e-09 1.000000e+00 #> [102,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [103,] 1.986727e-42 2.318538e-05 9.999768e-01 #> [104,] 1.180532e-38 7.486688e-04 9.992513e-01 #> [105,] 3.099804e-46 9.518578e-07 9.999990e-01 #> [106,] 1.307361e-48 7.687368e-07 9.999992e-01 #> [107,] 9.267670e-34 2.246431e-02 9.775357e-01 #> [108,] 4.933987e-42 1.873452e-04 9.998127e-01 #> [109,] 4.505583e-42 2.970581e-04 9.997029e-01 #> [110,] 1.055915e-46 6.784148e-08 9.999999e-01 #> [111,] 2.974828e-32 7.725660e-03 9.922743e-01 #> [112,] 1.617173e-37 1.493449e-03 9.985066e-01 #> [113,] 5.629068e-39 1.532789e-04 9.998467e-01 #> [114,] 7.280330e-41 1.177402e-04 9.998823e-01 #> [115,] 3.555665e-46 3.558495e-07 9.999996e-01 #> [116,] 1.471997e-40 1.075125e-05 9.999892e-01 #> [117,] 1.771439e-35 4.654684e-03 9.953453e-01 #> [118,] 7.138648e-45 8.218517e-07 9.999992e-01 #> [119,] 1.899015e-58 1.906714e-09 1.000000e+00 #> [120,] 5.082160e-33 2.972470e-01 7.027530e-01 #> [121,] 6.864466e-43 3.648876e-06 9.999964e-01 #> [122,] 8.039862e-38 3.586891e-04 9.996413e-01 #> [123,] 3.747574e-49 1.512670e-06 9.999985e-01 #> [124,] 2.931140e-31 9.409549e-02 9.059045e-01 #> [125,] 8.774784e-40 4.563353e-05 9.999544e-01 #> [126,] 2.005765e-36 2.684624e-03 9.973154e-01 #> [127,] 8.506186e-30 1.616826e-01 8.383174e-01 #> [128,] 4.664639e-30 8.868082e-02 9.113192e-01 #> [129,] 4.765225e-44 8.543916e-06 9.999915e-01 #> [130,] 5.127429e-32 1.448711e-01 8.551289e-01 #> [131,] 2.089865e-41 2.206495e-04 9.997794e-01 #> [132,] 1.902049e-36 4.134090e-04 9.995866e-01 #> [133,] 8.931905e-46 1.825407e-06 9.999982e-01 #> [134,] 2.029625e-28 7.432053e-01 2.567947e-01 #> [135,] 3.219380e-35 7.082646e-02 9.291735e-01 #> [136,] 4.365673e-45 2.536647e-06 9.999975e-01 #> [137,] 3.772459e-45 2.458322e-07 9.999998e-01 #> [138,] 2.894065e-35 3.983245e-03 9.960168e-01 #> [139,] 2.370290e-29 1.236116e-01 8.763884e-01 #> [140,] 2.331576e-36 6.383548e-04 9.993616e-01 #> [141,] 3.151247e-45 5.888272e-07 9.999994e-01 #> [142,] 5.807134e-36 2.983685e-04 9.997016e-01 #> [143,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [144,] 5.118189e-46 5.166787e-07 9.999995e-01 #> [145,] 1.083147e-46 9.508309e-08 9.999999e-01 #> [146,] 3.855859e-39 4.781458e-05 9.999522e-01 #> [147,] 8.908459e-36 6.189358e-03 9.938106e-01 #> [148,] 4.421495e-35 2.180277e-03 9.978197e-01 #> [149,] 2.042704e-41 3.621223e-06 9.999964e-01 #> [150,] 1.040288e-33 9.114476e-03 9.908855e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3295007 0.3371660 #>  #> $parameters$mean #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.942084 6.574643 #> Sepal.Width  3.428 2.760894 2.980580 #> Petal.Length 1.462 4.258301 5.538974 #> Petal.Width  0.246 1.319158 2.024730 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"EEE\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #>  #> $parameters$variance$Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> $parameters$variance$cholSigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   -0.5136917  -0.1749630  -0.33008613 -0.07655157 #> Sepal.Width     0.0000000   0.2852391  -0.02303675  0.05830775 #> Petal.Length    0.0000000   0.0000000  -0.27728959 -0.06505353 #> Petal.Width     0.0000000   0.0000000   0.00000000  0.16204228 #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $control #> $control$eps #> [1] 2.220446e-16 #>  #> $control$tol #> [1] 1.000000e-05 1.490116e-08 #>  #> $control$itmax #> [1] 2147483647 2147483647 #>  #> $control$equalPro #> [1] FALSE #>  #>  #> $loglik #> [1] -256.3541 #>  #> attr(,\"info\") #>  iterations       error  #> 4.00000e+00 1.76651e-06  #> attr(,\"returnCode\") #> [1] 0  do.call(\"em\", c(list(data = iris[,-5]), msEst))   ## alternative call #> $modelName #> [1] \"EEE\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                [,1]         [,2]         [,3] #>   [1,] 1.000000e+00 5.669389e-22 2.970668e-42 #>   [2,] 1.000000e+00 7.125511e-18 2.890550e-37 #>   [3,] 1.000000e+00 2.209921e-19 5.645717e-39 #>   [4,] 1.000000e+00 1.944369e-16 4.493925e-35 #>   [5,] 1.000000e+00 2.969620e-22 1.819554e-42 #>   [6,] 1.000000e+00 7.746074e-21 1.005427e-39 #>   [7,] 1.000000e+00 2.519429e-18 5.970904e-37 #>   [8,] 1.000000e+00 5.638578e-20 1.231056e-39 #>   [9,] 1.000000e+00 2.778048e-15 1.088991e-33 #>  [10,] 1.000000e+00 1.193692e-18 1.753502e-38 #>  [11,] 1.000000e+00 1.635161e-23 3.372329e-44 #>  [12,] 1.000000e+00 2.937431e-18 3.124729e-37 #>  [13,] 1.000000e+00 1.517011e-18 1.969537e-38 #>  [14,] 1.000000e+00 1.843982e-19 1.764184e-39 #>  [15,] 1.000000e+00 6.849292e-30 1.303566e-52 #>  [16,] 1.000000e+00 3.245264e-27 7.704284e-48 #>  [17,] 1.000000e+00 1.264758e-24 7.386154e-45 #>  [18,] 1.000000e+00 6.462169e-21 1.584880e-40 #>  [19,] 1.000000e+00 2.203157e-22 2.328338e-42 #>  [20,] 1.000000e+00 5.749059e-22 1.456245e-41 #>  [21,] 1.000000e+00 1.272471e-19 2.601003e-39 #>  [22,] 1.000000e+00 3.035910e-20 4.610963e-39 #>  [23,] 1.000000e+00 1.681457e-24 2.334188e-45 #>  [24,] 1.000000e+00 1.247580e-14 1.126055e-31 #>  [25,] 1.000000e+00 2.033636e-15 2.214427e-33 #>  [26,] 1.000000e+00 2.297938e-16 2.933735e-35 #>  [27,] 1.000000e+00 6.480706e-17 6.730469e-35 #>  [28,] 1.000000e+00 2.066760e-21 1.569681e-41 #>  [29,] 1.000000e+00 1.082360e-21 4.850018e-42 #>  [30,] 1.000000e+00 1.529968e-16 4.000996e-35 #>  [31,] 1.000000e+00 2.920907e-16 6.532168e-35 #>  [32,] 1.000000e+00 2.112491e-19 2.006593e-38 #>  [33,] 1.000000e+00 1.833782e-26 6.732546e-48 #>  [34,] 1.000000e+00 3.568839e-28 6.559131e-50 #>  [35,] 1.000000e+00 1.360613e-17 9.355103e-37 #>  [36,] 1.000000e+00 1.748091e-21 6.118695e-42 #>  [37,] 1.000000e+00 1.848029e-24 8.856622e-46 #>  [38,] 1.000000e+00 6.322278e-23 1.239791e-43 #>  [39,] 1.000000e+00 6.778306e-17 9.552703e-36 #>  [40,] 1.000000e+00 2.323565e-20 3.386508e-40 #>  [41,] 1.000000e+00 1.772656e-21 2.999433e-41 #>  [42,] 1.000000e+00 1.458475e-11 3.636199e-29 #>  [43,] 1.000000e+00 3.158065e-18 2.712042e-37 #>  [44,] 1.000000e+00 1.817425e-15 3.227861e-32 #>  [45,] 1.000000e+00 4.013405e-17 1.057569e-34 #>  [46,] 1.000000e+00 1.970937e-16 5.605941e-35 #>  [47,] 1.000000e+00 4.461935e-22 5.242944e-42 #>  [48,] 1.000000e+00 4.744169e-18 3.942102e-37 #>  [49,] 1.000000e+00 3.968032e-23 1.225902e-43 #>  [50,] 1.000000e+00 2.952916e-20 3.803732e-40 #>  [51,] 4.352061e-18 9.999271e-01 7.285356e-05 #>  [52,] 1.462104e-19 9.991833e-01 8.167043e-04 #>  [53,] 4.326581e-22 9.969243e-01 3.075740e-03 #>  [54,] 3.588876e-22 9.997272e-01 2.727797e-04 #>  [55,] 8.685517e-23 9.968195e-01 3.180529e-03 #>  [56,] 8.313347e-23 9.983021e-01 1.697924e-03 #>  [57,] 3.067079e-22 9.793448e-01 2.065525e-02 #>  [58,] 5.113810e-14 9.999999e-01 1.031644e-07 #>  [59,] 1.272609e-19 9.999241e-01 7.588810e-05 #>  [60,] 8.975128e-21 9.992664e-01 7.336194e-04 #>  [61,] 3.442085e-18 9.999991e-01 8.743942e-07 #>  [62,] 5.603197e-20 9.990125e-01 9.874887e-04 #>  [63,] 9.656653e-18 9.999995e-01 4.518974e-07 #>  [64,] 1.491160e-23 9.942156e-01 5.784381e-03 #>  [65,] 5.275521e-14 9.999981e-01 1.854263e-06 #>  [66,] 4.551187e-17 9.999694e-01 3.064952e-05 #>  [67,] 5.482635e-24 9.671064e-01 3.289363e-02 #>  [68,] 3.956205e-16 9.999994e-01 6.381923e-07 #>  [69,] 5.338555e-27 9.786346e-01 2.136543e-02 #>  [70,] 2.149035e-17 9.999977e-01 2.333318e-06 #>  [71,] 2.269907e-28 1.338383e-01 8.661617e-01 #>  [72,] 1.564633e-16 9.999930e-01 6.999013e-06 #>  [73,] 1.862337e-28 8.664919e-01 1.335081e-01 #>  [74,] 4.204653e-22 9.996599e-01 3.400895e-04 #>  [75,] 1.496225e-17 9.999834e-01 1.663712e-05 #>  [76,] 4.048066e-18 9.999412e-01 5.881490e-05 #>  [77,] 1.811813e-22 9.990449e-01 9.551325e-04 #>  [78,] 9.733911e-27 7.032941e-01 2.967059e-01 #>  [79,] 4.207095e-23 9.914214e-01 8.578608e-03 #>  [80,] 1.686652e-11 1.000000e+00 1.168802e-08 #>  [81,] 1.691014e-17 9.999979e-01 2.062222e-06 #>  [82,] 1.705135e-15 9.999998e-01 2.029185e-07 #>  [83,] 2.383037e-16 9.999970e-01 2.965664e-06 #>  [84,] 4.543859e-32 1.255609e-01 8.744391e-01 #>  [85,] 8.944225e-25 9.290885e-01 7.091151e-02 #>  [86,] 7.853508e-21 9.883971e-01 1.160287e-02 #>  [87,] 5.759078e-21 9.985336e-01 1.466369e-03 #>  [88,] 7.047203e-23 9.997609e-01 2.391093e-04 #>  [89,] 4.510692e-18 9.999302e-01 6.984723e-05 #>  [90,] 7.703797e-21 9.998338e-01 1.662373e-04 #>  [91,] 6.639378e-23 9.993841e-01 6.159223e-04 #>  [92,] 6.134157e-22 9.979127e-01 2.087322e-03 #>  [93,] 5.814465e-18 9.999918e-01 8.248956e-06 #>  [94,] 2.678609e-14 9.999999e-01 8.822342e-08 #>  [95,] 5.126445e-21 9.996812e-01 3.187501e-04 #>  [96,] 1.410433e-17 9.999784e-01 2.163084e-05 #>  [97,] 2.670627e-19 9.998703e-01 1.296855e-04 #>  [98,] 2.540730e-18 9.999627e-01 3.733285e-05 #>  [99,] 8.473985e-11 1.000000e+00 1.640967e-08 #> [100,] 5.099820e-19 9.999235e-01 7.651826e-05 #> [101,] 8.752565e-53 1.844658e-09 1.000000e+00 #> [102,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [103,] 1.986727e-42 2.318538e-05 9.999768e-01 #> [104,] 1.180532e-38 7.486688e-04 9.992513e-01 #> [105,] 3.099804e-46 9.518578e-07 9.999990e-01 #> [106,] 1.307361e-48 7.687368e-07 9.999992e-01 #> [107,] 9.267670e-34 2.246431e-02 9.775357e-01 #> [108,] 4.933987e-42 1.873452e-04 9.998127e-01 #> [109,] 4.505583e-42 2.970581e-04 9.997029e-01 #> [110,] 1.055915e-46 6.784148e-08 9.999999e-01 #> [111,] 2.974828e-32 7.725660e-03 9.922743e-01 #> [112,] 1.617173e-37 1.493449e-03 9.985066e-01 #> [113,] 5.629068e-39 1.532789e-04 9.998467e-01 #> [114,] 7.280330e-41 1.177402e-04 9.998823e-01 #> [115,] 3.555665e-46 3.558495e-07 9.999996e-01 #> [116,] 1.471997e-40 1.075125e-05 9.999892e-01 #> [117,] 1.771439e-35 4.654684e-03 9.953453e-01 #> [118,] 7.138648e-45 8.218517e-07 9.999992e-01 #> [119,] 1.899015e-58 1.906714e-09 1.000000e+00 #> [120,] 5.082160e-33 2.972470e-01 7.027530e-01 #> [121,] 6.864466e-43 3.648876e-06 9.999964e-01 #> [122,] 8.039862e-38 3.586891e-04 9.996413e-01 #> [123,] 3.747574e-49 1.512670e-06 9.999985e-01 #> [124,] 2.931140e-31 9.409549e-02 9.059045e-01 #> [125,] 8.774784e-40 4.563353e-05 9.999544e-01 #> [126,] 2.005765e-36 2.684624e-03 9.973154e-01 #> [127,] 8.506186e-30 1.616826e-01 8.383174e-01 #> [128,] 4.664639e-30 8.868082e-02 9.113192e-01 #> [129,] 4.765225e-44 8.543916e-06 9.999915e-01 #> [130,] 5.127429e-32 1.448711e-01 8.551289e-01 #> [131,] 2.089865e-41 2.206495e-04 9.997794e-01 #> [132,] 1.902049e-36 4.134090e-04 9.995866e-01 #> [133,] 8.931905e-46 1.825407e-06 9.999982e-01 #> [134,] 2.029625e-28 7.432053e-01 2.567947e-01 #> [135,] 3.219380e-35 7.082646e-02 9.291735e-01 #> [136,] 4.365673e-45 2.536647e-06 9.999975e-01 #> [137,] 3.772459e-45 2.458322e-07 9.999998e-01 #> [138,] 2.894065e-35 3.983245e-03 9.960168e-01 #> [139,] 2.370290e-29 1.236116e-01 8.763884e-01 #> [140,] 2.331576e-36 6.383548e-04 9.993616e-01 #> [141,] 3.151247e-45 5.888272e-07 9.999994e-01 #> [142,] 5.807134e-36 2.983685e-04 9.997016e-01 #> [143,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [144,] 5.118189e-46 5.166787e-07 9.999995e-01 #> [145,] 1.083147e-46 9.508309e-08 9.999999e-01 #> [146,] 3.855859e-39 4.781458e-05 9.999522e-01 #> [147,] 8.908459e-36 6.189358e-03 9.938106e-01 #> [148,] 4.421495e-35 2.180277e-03 9.978197e-01 #> [149,] 2.042704e-41 3.621223e-06 9.999964e-01 #> [150,] 1.040288e-33 9.114476e-03 9.908855e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3295007 0.3371660 #>  #> $parameters$mean #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.942084 6.574643 #> Sepal.Width  3.428 2.760894 2.980580 #> Petal.Length 1.462 4.258301 5.538974 #> Petal.Width  0.246 1.319158 2.024730 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"EEE\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #>  #> $parameters$variance$Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> $parameters$variance$cholSigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   -0.5136917  -0.1749630  -0.33008613 -0.07655157 #> Sepal.Width     0.0000000   0.2852391  -0.02303675  0.05830775 #> Petal.Length    0.0000000   0.0000000  -0.27728959 -0.06505353 #> Petal.Width     0.0000000   0.0000000   0.00000000  0.16204228 #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $control #> $control$eps #> [1] 2.220446e-16 #>  #> $control$tol #> [1] 1.000000e-05 1.490116e-08 #>  #> $control$itmax #> [1] 2147483647 2147483647 #>  #> $control$equalPro #> [1] FALSE #>  #>  #> $loglik #> [1] -256.3541 #>  #> attr(,\"info\") #>  iterations       error  #> 4.00000e+00 1.76651e-06  #> attr(,\"returnCode\") #> [1] 0 # }"},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Set control values for use with the EM algorithm — emControl","title":"Set control values for use with the EM algorithm — emControl","text":"Supplies list values including tolerances singularity   convergence assessment, use functions involving EM within MCLUST.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set control values for use with the EM algorithm — emControl","text":"","code":"emControl(eps, tol, itmax, equalPro)"},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set control values for use with the EM algorithm — emControl","text":"eps scalar tolerance associated deciding terminate     computations due computational singularity     covariances. Smaller values eps allow computations     proceed nearer singularity. default relative machine     precision .Machine$double.eps, approximately     \\(2e-16\\) IEEE-compliant machines. tol vector length two giving relative convergence tolerances      log-likelihood parameter convergence inner loop models     iterative M-step (\"VEI\", \"VEE\", \"EVE\", \"VVE\", \"VEV\"), respectively.     default c(1.e-5, sqrt(.Machine$double.eps)).     one number supplied, used tolerance      outer iterations tolerance inner     iterations default. itmax vector length two giving integer limits number EM     iterations number iterations inner loop     models iterative M-step (\"VEI\", \"VEE\", \"EVE\", \"VVE\", \"VEV\"),     respectively. default      c(.Machine$integer.max, .Machine$integer.max)      allowing termination completely governed tol.      one number supplied, used iteration     limit outer iteration . equalPro Logical variable indicating whether mixing proportions     equal model. Default: equalPro = FALSE.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set control values for use with the EM algorithm — emControl","text":"named list names names arguments   values values supplied arguments.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set control values for use with the EM algorithm — emControl","text":"emControl provided assigning values defaults   EM within MCLUST.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/emControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set control values for use with the EM algorithm — emControl","text":"","code":"irisBIC <- mclustBIC(iris[,-5], control = emControl(tol = 1.e-6)) summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2        VEV,3      VVV,2 #> BIC      -561.7285 -562.5508708 -574.01783 #> BIC diff    0.0000   -0.8224087  -12.28937 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100"},{"path":"https://mclust-org.github.io/mclust/reference/emE.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","title":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","text":"Implements EM algorithm parameterized Gaussian mixture model,   starting expectation step.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/emE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","text":"","code":"emE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emX(data, prior = NULL, warn = NULL, ...) emEII(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVII(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEEI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVEI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEVI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVVI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEEE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVEE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEVE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVVE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEEV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVEV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emEVV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emVVV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...) emXII(data, prior = NULL, warn = NULL, ...) emXXI(data, prior = NULL, warn = NULL, ...) emXXX(data, prior = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/emE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. parameters parameters model: pro Mixing proportions components mixture.                one mixing proportion number                Gaussian components mixture model includes                Poisson noise term. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details. Vinv estimate reciprocal hypervolume data region.              default determined applying function  hypvol               data. Used pro includes additional               mixing proportion noise component.  prior default assumes prior, argument allows specification     conjugate prior means variances function     priorControl. control list control parameters EM. defaults set call     emControl(). warn logical value indicating whether warning issued     whenever singularity encountered.     default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/emE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","text":"list including following components: modelName character string identifying model (input argument). z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters  pro vector whose kth component mixing proportion               kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  loglik log likelihood data mixture model. Attributes: \"info\" Information iteration.\"WARNING\" appropriate warning problems        encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/emE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm starting with E-step for a parameterized Gaussian mixture model — emE","text":"","code":"# \\donttest{ msEst <- mstepEEE(data = iris[,-5], z = unmap(iris[,5])) names(msEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\"  emEEE(data = iris[,-5], parameters = msEst$parameters)# } #> $modelName #> [1] \"EEE\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                [,1]         [,2]         [,3] #>   [1,] 1.000000e+00 5.669389e-22 2.970668e-42 #>   [2,] 1.000000e+00 7.125511e-18 2.890550e-37 #>   [3,] 1.000000e+00 2.209921e-19 5.645717e-39 #>   [4,] 1.000000e+00 1.944369e-16 4.493925e-35 #>   [5,] 1.000000e+00 2.969620e-22 1.819554e-42 #>   [6,] 1.000000e+00 7.746074e-21 1.005427e-39 #>   [7,] 1.000000e+00 2.519429e-18 5.970904e-37 #>   [8,] 1.000000e+00 5.638578e-20 1.231056e-39 #>   [9,] 1.000000e+00 2.778048e-15 1.088991e-33 #>  [10,] 1.000000e+00 1.193692e-18 1.753502e-38 #>  [11,] 1.000000e+00 1.635161e-23 3.372329e-44 #>  [12,] 1.000000e+00 2.937431e-18 3.124729e-37 #>  [13,] 1.000000e+00 1.517011e-18 1.969537e-38 #>  [14,] 1.000000e+00 1.843982e-19 1.764184e-39 #>  [15,] 1.000000e+00 6.849292e-30 1.303566e-52 #>  [16,] 1.000000e+00 3.245264e-27 7.704284e-48 #>  [17,] 1.000000e+00 1.264758e-24 7.386154e-45 #>  [18,] 1.000000e+00 6.462169e-21 1.584880e-40 #>  [19,] 1.000000e+00 2.203157e-22 2.328338e-42 #>  [20,] 1.000000e+00 5.749059e-22 1.456245e-41 #>  [21,] 1.000000e+00 1.272471e-19 2.601003e-39 #>  [22,] 1.000000e+00 3.035910e-20 4.610963e-39 #>  [23,] 1.000000e+00 1.681457e-24 2.334188e-45 #>  [24,] 1.000000e+00 1.247580e-14 1.126055e-31 #>  [25,] 1.000000e+00 2.033636e-15 2.214427e-33 #>  [26,] 1.000000e+00 2.297938e-16 2.933735e-35 #>  [27,] 1.000000e+00 6.480706e-17 6.730469e-35 #>  [28,] 1.000000e+00 2.066760e-21 1.569681e-41 #>  [29,] 1.000000e+00 1.082360e-21 4.850018e-42 #>  [30,] 1.000000e+00 1.529968e-16 4.000996e-35 #>  [31,] 1.000000e+00 2.920907e-16 6.532168e-35 #>  [32,] 1.000000e+00 2.112491e-19 2.006593e-38 #>  [33,] 1.000000e+00 1.833782e-26 6.732546e-48 #>  [34,] 1.000000e+00 3.568839e-28 6.559131e-50 #>  [35,] 1.000000e+00 1.360613e-17 9.355103e-37 #>  [36,] 1.000000e+00 1.748091e-21 6.118695e-42 #>  [37,] 1.000000e+00 1.848029e-24 8.856622e-46 #>  [38,] 1.000000e+00 6.322278e-23 1.239791e-43 #>  [39,] 1.000000e+00 6.778306e-17 9.552703e-36 #>  [40,] 1.000000e+00 2.323565e-20 3.386508e-40 #>  [41,] 1.000000e+00 1.772656e-21 2.999433e-41 #>  [42,] 1.000000e+00 1.458475e-11 3.636199e-29 #>  [43,] 1.000000e+00 3.158065e-18 2.712042e-37 #>  [44,] 1.000000e+00 1.817425e-15 3.227861e-32 #>  [45,] 1.000000e+00 4.013405e-17 1.057569e-34 #>  [46,] 1.000000e+00 1.970937e-16 5.605941e-35 #>  [47,] 1.000000e+00 4.461935e-22 5.242944e-42 #>  [48,] 1.000000e+00 4.744169e-18 3.942102e-37 #>  [49,] 1.000000e+00 3.968032e-23 1.225902e-43 #>  [50,] 1.000000e+00 2.952916e-20 3.803732e-40 #>  [51,] 4.352061e-18 9.999271e-01 7.285356e-05 #>  [52,] 1.462104e-19 9.991833e-01 8.167043e-04 #>  [53,] 4.326581e-22 9.969243e-01 3.075740e-03 #>  [54,] 3.588876e-22 9.997272e-01 2.727797e-04 #>  [55,] 8.685517e-23 9.968195e-01 3.180529e-03 #>  [56,] 8.313347e-23 9.983021e-01 1.697924e-03 #>  [57,] 3.067079e-22 9.793448e-01 2.065525e-02 #>  [58,] 5.113810e-14 9.999999e-01 1.031644e-07 #>  [59,] 1.272609e-19 9.999241e-01 7.588810e-05 #>  [60,] 8.975128e-21 9.992664e-01 7.336194e-04 #>  [61,] 3.442085e-18 9.999991e-01 8.743942e-07 #>  [62,] 5.603197e-20 9.990125e-01 9.874887e-04 #>  [63,] 9.656653e-18 9.999995e-01 4.518974e-07 #>  [64,] 1.491160e-23 9.942156e-01 5.784381e-03 #>  [65,] 5.275521e-14 9.999981e-01 1.854263e-06 #>  [66,] 4.551187e-17 9.999694e-01 3.064952e-05 #>  [67,] 5.482635e-24 9.671064e-01 3.289363e-02 #>  [68,] 3.956205e-16 9.999994e-01 6.381923e-07 #>  [69,] 5.338555e-27 9.786346e-01 2.136543e-02 #>  [70,] 2.149035e-17 9.999977e-01 2.333318e-06 #>  [71,] 2.269907e-28 1.338383e-01 8.661617e-01 #>  [72,] 1.564633e-16 9.999930e-01 6.999013e-06 #>  [73,] 1.862337e-28 8.664919e-01 1.335081e-01 #>  [74,] 4.204653e-22 9.996599e-01 3.400895e-04 #>  [75,] 1.496225e-17 9.999834e-01 1.663712e-05 #>  [76,] 4.048066e-18 9.999412e-01 5.881490e-05 #>  [77,] 1.811813e-22 9.990449e-01 9.551325e-04 #>  [78,] 9.733911e-27 7.032941e-01 2.967059e-01 #>  [79,] 4.207095e-23 9.914214e-01 8.578608e-03 #>  [80,] 1.686652e-11 1.000000e+00 1.168802e-08 #>  [81,] 1.691014e-17 9.999979e-01 2.062222e-06 #>  [82,] 1.705135e-15 9.999998e-01 2.029185e-07 #>  [83,] 2.383037e-16 9.999970e-01 2.965664e-06 #>  [84,] 4.543859e-32 1.255609e-01 8.744391e-01 #>  [85,] 8.944225e-25 9.290885e-01 7.091151e-02 #>  [86,] 7.853508e-21 9.883971e-01 1.160287e-02 #>  [87,] 5.759078e-21 9.985336e-01 1.466369e-03 #>  [88,] 7.047203e-23 9.997609e-01 2.391093e-04 #>  [89,] 4.510692e-18 9.999302e-01 6.984723e-05 #>  [90,] 7.703797e-21 9.998338e-01 1.662373e-04 #>  [91,] 6.639378e-23 9.993841e-01 6.159223e-04 #>  [92,] 6.134157e-22 9.979127e-01 2.087322e-03 #>  [93,] 5.814465e-18 9.999918e-01 8.248956e-06 #>  [94,] 2.678609e-14 9.999999e-01 8.822342e-08 #>  [95,] 5.126445e-21 9.996812e-01 3.187501e-04 #>  [96,] 1.410433e-17 9.999784e-01 2.163084e-05 #>  [97,] 2.670627e-19 9.998703e-01 1.296855e-04 #>  [98,] 2.540730e-18 9.999627e-01 3.733285e-05 #>  [99,] 8.473985e-11 1.000000e+00 1.640967e-08 #> [100,] 5.099820e-19 9.999235e-01 7.651826e-05 #> [101,] 8.752565e-53 1.844658e-09 1.000000e+00 #> [102,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [103,] 1.986727e-42 2.318538e-05 9.999768e-01 #> [104,] 1.180532e-38 7.486688e-04 9.992513e-01 #> [105,] 3.099804e-46 9.518578e-07 9.999990e-01 #> [106,] 1.307361e-48 7.687368e-07 9.999992e-01 #> [107,] 9.267670e-34 2.246431e-02 9.775357e-01 #> [108,] 4.933987e-42 1.873452e-04 9.998127e-01 #> [109,] 4.505583e-42 2.970581e-04 9.997029e-01 #> [110,] 1.055915e-46 6.784148e-08 9.999999e-01 #> [111,] 2.974828e-32 7.725660e-03 9.922743e-01 #> [112,] 1.617173e-37 1.493449e-03 9.985066e-01 #> [113,] 5.629068e-39 1.532789e-04 9.998467e-01 #> [114,] 7.280330e-41 1.177402e-04 9.998823e-01 #> [115,] 3.555665e-46 3.558495e-07 9.999996e-01 #> [116,] 1.471997e-40 1.075125e-05 9.999892e-01 #> [117,] 1.771439e-35 4.654684e-03 9.953453e-01 #> [118,] 7.138648e-45 8.218517e-07 9.999992e-01 #> [119,] 1.899015e-58 1.906714e-09 1.000000e+00 #> [120,] 5.082160e-33 2.972470e-01 7.027530e-01 #> [121,] 6.864466e-43 3.648876e-06 9.999964e-01 #> [122,] 8.039862e-38 3.586891e-04 9.996413e-01 #> [123,] 3.747574e-49 1.512670e-06 9.999985e-01 #> [124,] 2.931140e-31 9.409549e-02 9.059045e-01 #> [125,] 8.774784e-40 4.563353e-05 9.999544e-01 #> [126,] 2.005765e-36 2.684624e-03 9.973154e-01 #> [127,] 8.506186e-30 1.616826e-01 8.383174e-01 #> [128,] 4.664639e-30 8.868082e-02 9.113192e-01 #> [129,] 4.765225e-44 8.543916e-06 9.999915e-01 #> [130,] 5.127429e-32 1.448711e-01 8.551289e-01 #> [131,] 2.089865e-41 2.206495e-04 9.997794e-01 #> [132,] 1.902049e-36 4.134090e-04 9.995866e-01 #> [133,] 8.931905e-46 1.825407e-06 9.999982e-01 #> [134,] 2.029625e-28 7.432053e-01 2.567947e-01 #> [135,] 3.219380e-35 7.082646e-02 9.291735e-01 #> [136,] 4.365673e-45 2.536647e-06 9.999975e-01 #> [137,] 3.772459e-45 2.458322e-07 9.999998e-01 #> [138,] 2.894065e-35 3.983245e-03 9.960168e-01 #> [139,] 2.370290e-29 1.236116e-01 8.763884e-01 #> [140,] 2.331576e-36 6.383548e-04 9.993616e-01 #> [141,] 3.151247e-45 5.888272e-07 9.999994e-01 #> [142,] 5.807134e-36 2.983685e-04 9.997016e-01 #> [143,] 2.587892e-38 6.236363e-04 9.993764e-01 #> [144,] 5.118189e-46 5.166787e-07 9.999995e-01 #> [145,] 1.083147e-46 9.508309e-08 9.999999e-01 #> [146,] 3.855859e-39 4.781458e-05 9.999522e-01 #> [147,] 8.908459e-36 6.189358e-03 9.938106e-01 #> [148,] 4.421495e-35 2.180277e-03 9.978197e-01 #> [149,] 2.042704e-41 3.621223e-06 9.999964e-01 #> [150,] 1.040288e-33 9.114476e-03 9.908855e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3295007 0.3371660 #>  #> $parameters$mean #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.942084 6.574643 #> Sepal.Width  3.428 2.760894 2.980580 #> Petal.Length 1.462 4.258301 5.538974 #> Petal.Width  0.246 1.319158 2.024730 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"EEE\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #>  #> $parameters$variance$Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960 #>  #> $parameters$variance$cholSigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   -0.5136917  -0.1749630  -0.33008613 -0.07655157 #> Sepal.Width     0.0000000   0.2852391  -0.02303675  0.05830775 #> Petal.Length    0.0000000   0.0000000  -0.27728959 -0.06505353 #> Petal.Width     0.0000000   0.0000000   0.00000000  0.16204228 #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $control #> $control$eps #> [1] 2.220446e-16 #>  #> $control$tol #> [1] 1.000000e-05 1.490116e-08 #>  #> $control$itmax #> [1] 2147483647 2147483647 #>  #> $control$equalPro #> [1] FALSE #>  #>  #> $loglik #> [1] -256.3541 #>  #> attr(,\"info\") #>  iterations       error  #> 4.00000e+00 1.76651e-06  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Entropy Plots — entPlot","title":"Plot Entropy Plots — entPlot","text":"Plot \"entropy plots\" help select number classes hierarchy combined clusterings.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Entropy Plots — entPlot","text":"","code":"entPlot(z, combiM, abc = c(\"standard\", \"normalized\"), reg = 2, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Entropy Plots — entPlot","text":"z matrix whose [,k]th entry probability observation data belongs kth class, initial solution (ie combining). Typically, one returned Mclust/BIC. combiM list \"combining matrices\" (provided clustCombi), ie combiM[[K]] matrix whose kth row contains zeros, columns corresponding labels classes (K+1)-classes solution merged get K-classes combined solution. combiM must contain matrices K = number classes z one. abc Choose one : \"standard\", \"normalized\", specify whether number observations involved combining step taken account scale plots . reg number parts piecewise linear regression entropy plots. Choose one : 2 (1 change-point), 3 (2 change-points). ... graphical arguments passed plot functions.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Entropy Plots — entPlot","text":"Please see article cited references details. clear elbow \"entropy plot\" suggest user consider corresponding number(s) class(es).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Entropy Plots — entPlot","text":"abc = \"standard\", plots entropy number clusters difference entropy successive combined solutions number clusters.  abc = \"normalized\", plots entropy cumulated number observations involved successive combining steps difference entropy successive combined solutions divided number observations involved corresponding combining step number clusters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Entropy Plots — entPlot","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Entropy Plots — entPlot","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/entPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Entropy Plots — entPlot","text":"","code":"# \\donttest{ data(Baudry_etal_2010_JCGS_examples) # run Mclust to get the MclustOutput output <- clustCombi(data = ex4.2, modelNames = \"VII\")   entPlot(output$MclustOutput$z, output$combiM, reg = c(2,3))    # legend: in red, the single-change-point piecewise linear regression; #         in blue, the two-change-point piecewise linear regression. # }"},{"path":"https://mclust-org.github.io/mclust/reference/errorBars.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw error bars on a plot — errorBars","title":"Draw error bars on a plot — errorBars","text":"Draw error bars x upper lower. horizontal = FALSE (default) bars drawn vertically, otherwise horizontally.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/errorBars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw error bars on a plot — errorBars","text":"","code":"errorBars(x, upper, lower, width = 0.1, code = 3, angle = 90, horizontal = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/errorBars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw error bars on a plot — errorBars","text":"x vector values bars must drawn. upper vector upper values bars must end. lower vector lower values bars must start. width value specifying width end-point segment. code integer code specifying kind arrows drawn. details see arrows. angle value specifying angle arrow edge. details see arrows. horizontal logical specifying bars drawn vertically (default) horizontally. ... arguments passed arrows.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/errorBars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw error bars on a plot — errorBars","text":"","code":"par(mfrow=c(2,2)) # Create a simple example dataset x <- 1:5 n <- c(10, 15, 12, 6, 3) se <- c(1, 1.2, 2, 1, .5) # upper and lower bars b <- barplot(n, ylim = c(0, max(n)*1.5)) errorBars(b, lower = n-se, upper = n+se, lwd = 2, col = \"red3\") # one side bars b <- barplot(n, ylim = c(0, max(n)*1.5)) errorBars(b, lower = n, upper = n+se, lwd = 2, col = \"red3\", code = 1) #  plot(x, n, ylim = c(0, max(n)*1.5), pch = 0) errorBars(x, lower = n-se, upper = n+se, lwd = 2, col = \"red3\") # dotchart(n, labels = x, pch = 19, xlim = c(0, max(n)*1.5)) errorBars(x, lower = n-se, upper = n+se, col = \"red3\", horizontal = TRUE)"},{"path":"https://mclust-org.github.io/mclust/reference/estep.html","id":null,"dir":"Reference","previous_headings":"","what":"E-step for parameterized Gaussian mixture models. — estep","title":"E-step for parameterized Gaussian mixture models. — estep","text":"Implements expectation step EM algorithm parameterized Gaussian   mixture models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/estep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-step for parameterized Gaussian mixture models. — estep","text":"","code":"estep(data, modelName, parameters, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/estep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-step for parameterized Gaussian mixture models. — estep","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. parameters names list giving parameters model.      components follows: pro Mixing proportions components mixture.                 model includes Poisson term noise,                 one mixing proportion number                 Gaussian components. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details. Vinv estimate reciprocal hypervolume data region.               set NULL negative value, default determined               applying function hypvol data.               Used pro includes additional               mixing proportion noise component.  warn logical value indicating whether warning issued     computations fail. default warn=FALSE. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/estep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-step for parameterized Gaussian mixture models. — estep","text":"list including following components: modelName character string identifying model (input argument). z matrix whose [,k]th entry conditional probability     ith observation belonging kth component     mixture. parameters input parameters. loglik log-likelihood data mixture model. Attributes \"WARNING\": appropriate warning problems       encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/estep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-step for parameterized Gaussian mixture models. — estep","text":"","code":"# \\donttest{ msEst <- mstep(modelName = \"VVV\", data = iris[,-5], z = unmap(iris[,5])) names(msEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\"  estep(modelName = msEst$modelName, data = iris[,-5],       parameters = msEst$parameters)# } #> $modelName #> [1] \"VVV\" #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                 [,1]         [,2]         [,3] #>   [1,]  1.000000e+00 1.531298e-26 4.631660e-42 #>   [2,]  1.000000e+00 3.341913e-19 2.782813e-35 #>   [3,]  1.000000e+00 5.970550e-22 6.659211e-37 #>   [4,]  1.000000e+00 3.629271e-19 2.069429e-32 #>   [5,]  1.000000e+00 9.920165e-28 3.097629e-42 #>   [6,]  1.000000e+00 4.473024e-27 2.035241e-41 #>   [7,]  1.000000e+00 1.023721e-21 5.400089e-35 #>   [8,]  1.000000e+00 3.951048e-24 1.188427e-38 #>   [9,]  1.000000e+00 6.348304e-17 2.222620e-30 #>  [10,]  1.000000e+00 3.282086e-21 1.202430e-35 #>  [11,]  1.000000e+00 1.619962e-29 2.944164e-45 #>  [12,]  1.000000e+00 7.891556e-23 2.286635e-35 #>  [13,]  1.000000e+00 2.172110e-20 1.922311e-35 #>  [14,]  1.000000e+00 1.830223e-20 8.325932e-35 #>  [15,]  1.000000e+00 1.347076e-37 5.789535e-57 #>  [16,]  1.000000e+00 2.707999e-38 1.150952e-53 #>  [17,]  1.000000e+00 1.194101e-30 1.742225e-47 #>  [18,]  1.000000e+00 6.948699e-25 1.025185e-40 #>  [19,]  1.000000e+00 5.504880e-28 4.538366e-44 #>  [20,]  1.000000e+00 2.069605e-28 1.972755e-42 #>  [21,]  1.000000e+00 7.479277e-23 3.988370e-38 #>  [22,]  1.000000e+00 5.032153e-25 1.181412e-39 #>  [23,]  1.000000e+00 7.912651e-28 1.053516e-42 #>  [24,]  1.000000e+00 5.071504e-16 1.408708e-30 #>  [25,]  1.000000e+00 5.079161e-20 5.211806e-30 #>  [26,]  1.000000e+00 9.462960e-18 6.946195e-33 #>  [27,]  1.000000e+00 8.007503e-20 3.118746e-34 #>  [28,]  1.000000e+00 5.238689e-26 2.393533e-41 #>  [29,]  1.000000e+00 2.981616e-25 9.025368e-42 #>  [30,]  1.000000e+00 6.305750e-20 1.248894e-32 #>  [31,]  1.000000e+00 7.474435e-19 1.745401e-32 #>  [32,]  1.000000e+00 1.143232e-21 6.109943e-39 #>  [33,]  1.000000e+00 1.712290e-37 3.848459e-49 #>  [34,]  1.000000e+00 4.783083e-39 6.903779e-54 #>  [35,]  1.000000e+00 8.338572e-20 8.305829e-35 #>  [36,]  1.000000e+00 2.989188e-23 1.006538e-40 #>  [37,]  1.000000e+00 6.887941e-28 1.135265e-46 #>  [38,]  1.000000e+00 3.867251e-29 2.455633e-42 #>  [39,]  1.000000e+00 1.417061e-18 2.036480e-32 #>  [40,]  1.000000e+00 2.473260e-24 1.859072e-39 #>  [41,]  1.000000e+00 3.020988e-25 3.902559e-41 #>  [42,]  1.000000e+00 2.560802e-10 2.997338e-26 #>  [43,]  1.000000e+00 7.792261e-21 5.097178e-34 #>  [44,]  1.000000e+00 4.049190e-17 8.149856e-31 #>  [45,]  1.000000e+00 2.350953e-22 5.235460e-34 #>  [46,]  1.000000e+00 1.246886e-17 3.033197e-33 #>  [47,]  1.000000e+00 1.560647e-29 3.679695e-42 #>  [48,]  1.000000e+00 4.767026e-21 1.084422e-34 #>  [49,]  1.000000e+00 2.532098e-29 1.912018e-44 #>  [50,]  1.000000e+00 1.942649e-23 4.162666e-39 #>  [51,]  4.427741e-92 9.999635e-01 3.651562e-05 #>  [52,]  1.492993e-83 9.996963e-01 3.036808e-04 #>  [53,] 2.323794e-104 9.985558e-01 1.444189e-03 #>  [54,]  3.820558e-64 9.974857e-01 2.514348e-03 #>  [55,]  2.529967e-92 9.975986e-01 2.401407e-03 #>  [56,]  3.438709e-79 9.895919e-01 1.040812e-02 #>  [57,]  9.128977e-94 9.951481e-01 4.851888e-03 #>  [58,]  5.148001e-34 9.999951e-01 4.872649e-06 #>  [59,]  1.880560e-86 9.998169e-01 1.830687e-04 #>  [60,]  1.542139e-60 9.941598e-01 5.840159e-03 #>  [61,]  2.992578e-42 9.999480e-01 5.203024e-05 #>  [62,]  1.708982e-72 9.987050e-01 1.295008e-03 #>  [63,]  3.769219e-61 9.999887e-01 1.133958e-05 #>  [64,]  1.085898e-90 9.892610e-01 1.073895e-02 #>  [65,]  9.208897e-47 9.999914e-01 8.648146e-06 #>  [66,]  4.247145e-79 9.999894e-01 1.063020e-05 #>  [67,]  1.205637e-83 9.747235e-01 2.527649e-02 #>  [68,]  6.402952e-58 9.998866e-01 1.133547e-04 #>  [69,]  5.514687e-92 8.146259e-01 1.853741e-01 #>  [70,]  9.644338e-55 9.999704e-01 2.957058e-05 #>  [71,] 8.144832e-106 3.284513e-01 6.715487e-01 #>  [72,]  5.073314e-62 9.999918e-01 8.225435e-06 #>  [73,] 4.134551e-107 6.987624e-01 3.012376e-01 #>  [74,]  4.817238e-86 9.735004e-01 2.649958e-02 #>  [75,]  2.448343e-73 9.999831e-01 1.685110e-05 #>  [76,]  9.080831e-80 9.999734e-01 2.661419e-05 #>  [77,] 3.308249e-100 9.986285e-01 1.371485e-03 #>  [78,] 6.162406e-115 8.630616e-01 1.369384e-01 #>  [79,]  3.606949e-85 9.927366e-01 7.263396e-03 #>  [80,]  1.827587e-39 9.999999e-01 6.520517e-08 #>  [81,]  5.062737e-52 9.999754e-01 2.463634e-05 #>  [82,]  1.118752e-46 9.999953e-01 4.706239e-06 #>  [83,]  5.410273e-56 9.999908e-01 9.231469e-06 #>  [84,] 1.930587e-116 1.473576e-01 8.526424e-01 #>  [85,]  1.417725e-83 9.454001e-01 5.459993e-02 #>  [86,]  4.017430e-84 9.963529e-01 3.647118e-03 #>  [87,]  2.333373e-94 9.994678e-01 5.322498e-04 #>  [88,]  4.416063e-83 9.990213e-01 9.787027e-04 #>  [89,]  1.824762e-62 9.997972e-01 2.027893e-04 #>  [90,]  9.617210e-63 9.990635e-01 9.364656e-04 #>  [91,]  1.267274e-73 9.817631e-01 1.823689e-02 #>  [92,]  1.366483e-85 9.972534e-01 2.746587e-03 #>  [93,]  2.483385e-60 9.999664e-01 3.362787e-05 #>  [94,]  8.736184e-35 9.999970e-01 2.980291e-06 #>  [95,]  1.632088e-68 9.987856e-01 1.214423e-03 #>  [96,]  3.007660e-63 9.997647e-01 2.352778e-04 #>  [97,]  4.649893e-67 9.996298e-01 3.702063e-04 #>  [98,]  2.213572e-72 9.999435e-01 5.649197e-05 #>  [99,]  4.667070e-28 9.999995e-01 5.312475e-07 #> [100,]  2.415298e-64 9.997932e-01 2.068042e-04 #> [101,] 5.431127e-203 2.210439e-09 1.000000e+00 #> [102,] 1.642385e-128 3.822927e-04 9.996177e-01 #> [103,] 2.935239e-181 4.340914e-05 9.999566e-01 #> [104,] 1.281149e-148 5.160913e-03 9.948391e-01 #> [105,] 8.739248e-178 1.967500e-06 9.999980e-01 #> [106,] 1.169524e-228 1.454416e-06 9.999985e-01 #> [107,]  3.059959e-95 3.396516e-03 9.966035e-01 #> [108,] 1.199215e-196 3.541718e-05 9.999646e-01 #> [109,] 1.063382e-166 1.059411e-04 9.998941e-01 #> [110,] 1.856330e-207 4.601010e-08 1.000000e+00 #> [111,] 1.697668e-129 5.349751e-03 9.946502e-01 #> [112,] 8.800846e-140 8.088253e-04 9.991912e-01 #> [113,] 9.146951e-158 5.195774e-05 9.999480e-01 #> [114,] 1.691089e-130 1.177827e-06 9.999988e-01 #> [115,] 1.529536e-156 1.686232e-13 1.000000e+00 #> [116,] 8.247834e-156 4.558397e-08 1.000000e+00 #> [117,] 6.788928e-143 3.037798e-02 9.696220e-01 #> [118,] 2.930198e-228 2.149645e-04 9.997850e-01 #> [119,] 9.079687e-265 8.879452e-11 1.000000e+00 #> [120,] 2.303150e-113 3.790989e-02 9.620901e-01 #> [121,] 3.843003e-177 3.783066e-07 9.999996e-01 #> [122,] 9.595809e-124 1.976052e-05 9.999802e-01 #> [123,] 9.581470e-236 2.100380e-07 9.999998e-01 #> [124,] 1.065022e-115 2.567755e-02 9.743225e-01 #> [125,] 1.850244e-164 7.609181e-04 9.992391e-01 #> [126,] 1.221324e-172 6.521046e-03 9.934790e-01 #> [127,] 7.743971e-110 5.265561e-02 9.473444e-01 #> [128,] 3.432568e-112 1.442112e-01 8.557888e-01 #> [129,] 1.151967e-163 4.572452e-06 9.999954e-01 #> [130,] 3.706143e-157 1.797263e-02 9.820274e-01 #> [131,] 6.470511e-190 1.243961e-04 9.998756e-01 #> [132,] 3.730831e-201 8.236967e-03 9.917630e-01 #> [133,] 6.157428e-169 1.310745e-07 9.999999e-01 #> [134,] 2.506178e-113 6.022880e-01 3.977120e-01 #> [135,] 3.266558e-138 1.780195e-04 9.998220e-01 #> [136,] 2.569119e-207 8.589823e-08 9.999999e-01 #> [137,] 8.687854e-175 3.751507e-08 1.000000e+00 #> [138,] 2.183741e-141 4.651619e-02 9.534838e-01 #> [139,] 1.312185e-107 1.339905e-01 8.660095e-01 #> [140,] 9.141262e-152 1.555449e-04 9.998445e-01 #> [141,] 2.098453e-178 6.704480e-10 1.000000e+00 #> [142,] 2.368114e-148 4.059502e-09 1.000000e+00 #> [143,] 1.642385e-128 3.822927e-04 9.996177e-01 #> [144,] 1.224376e-187 6.897983e-07 9.999993e-01 #> [145,] 8.404700e-188 1.144473e-10 1.000000e+00 #> [146,] 1.099698e-153 2.083183e-09 1.000000e+00 #> [147,] 5.133200e-127 1.360843e-04 9.998639e-01 #> [148,] 1.472988e-136 9.106700e-04 9.990893e-01 #> [149,] 1.208779e-158 8.694131e-07 9.999991e-01 #> [150,] 2.673436e-121 5.663609e-02 9.433639e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3333333 0.3333333 #>  #> $parameters$mean #>               [,1]  [,2]  [,3] #> Sepal.Length 5.006 5.936 6.588 #> Sepal.Width  3.428 2.770 2.974 #> Petal.Length 1.462 4.260 5.552 #> Petal.Width  0.246 1.326 2.026 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VVV\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.121764    0.097232     0.016028    0.010124 #> Sepal.Width      0.097232    0.140816     0.011464    0.009112 #> Petal.Length     0.016028    0.011464     0.029556    0.005948 #> Petal.Width      0.010124    0.009112     0.005948    0.010884 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.261104     0.08348      0.17924    0.054664 #> Sepal.Width      0.083480     0.09650      0.08100    0.040380 #> Petal.Length     0.179240     0.08100      0.21640    0.071640 #> Petal.Width      0.054664     0.04038      0.07164    0.038324 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.396256    0.091888     0.297224    0.048112 #> Sepal.Width      0.091888    0.101924     0.069952    0.046676 #> Petal.Length     0.297224    0.069952     0.298496    0.047848 #> Petal.Width      0.048112    0.046676     0.047848    0.073924 #>  #>  #> $parameters$variance$cholsigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length  Petal.Width #> Sepal.Length    -0.348947  -0.2786440 -0.045932479 -0.029013003 #> Sepal.Width      0.000000   0.2513434 -0.005310709  0.004088826 #> Petal.Length     0.000000   0.0000000 -0.165583827 -0.028004398 #> Petal.Width      0.000000   0.0000000  0.000000000  0.096131581 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.5109834   0.1633713   0.35077463  0.10697804 #> Sepal.Width     0.0000000  -0.2642155  -0.08967492 -0.08668251 #> Petal.Length    0.0000000   0.0000000   0.29208829  0.09018359 #> Petal.Width     0.0000000   0.0000000   0.00000000 -0.10598473 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   -0.6294887  -0.1459724 -0.472167346 -0.07643029 #> Sepal.Width     0.0000000  -0.2839297 -0.003622656 -0.12509889 #> Petal.Length    0.0000000   0.0000000  0.274847001  0.04113898 #> Petal.Width     0.0000000   0.0000000  0.000000000 -0.22525600 #>  #>  #>  #>  #> $loglik #> [1] -182.9208 #>  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/estepE.html","id":null,"dir":"Reference","previous_headings":"","what":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","title":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","text":"Implements expectation step EM algorithm    parameterized Gaussian mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/estepE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","text":"","code":"estepE(data, parameters, warn = NULL, ...) estepV(data, parameters, warn = NULL, ...) estepEII(data, parameters, warn = NULL, ...) estepVII(data, parameters, warn = NULL, ...) estepEEI(data, parameters, warn = NULL, ...) estepVEI(data, parameters, warn = NULL, ...) estepEVI(data, parameters, warn = NULL, ...) estepVVI(data, parameters, warn = NULL, ...) estepEEE(data, parameters, warn = NULL, ...) estepEEV(data, parameters, warn = NULL, ...) estepVEV(data, parameters, warn = NULL, ...) estepVVV(data, parameters, warn = NULL, ...) estepEVE(data, parameters, warn = NULL, ...) estepEVV(data, parameters, warn = NULL, ...) estepVEE(data, parameters, warn = NULL, ...) estepVVE(data, parameters, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/estepE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. parameters parameters model: pro Mixing proportions components mixture.                model includes Poisson term noise,                one mixing proportion number                Gaussian components. mu mean component. one component,               matrix whose columns means  components. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region.               supplied set negative value, default               determined applying function hypvol data.               Used pro includes additional               mixing proportion noise component.  warn logical value indicating whether certain warnings issued.     default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/estepE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","text":"list including following components: modelName Character string identifying model. z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters input parameters. loglik logliklihood data mixture model. Attribute \"WARNING\": appropriate warning problems       encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/estepE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-step in the EM algorithm for a parameterized Gaussian mixture model. — estepE","text":"","code":"# \\donttest{ msEst <- mstepEII(data = iris[,-5], z = unmap(iris[,5])) names(msEst) #> [1] \"modelName\"  \"prior\"      \"n\"          \"d\"          \"G\"          #> [6] \"z\"          \"parameters\"  estepEII(data = iris[,-5], parameters = msEst$parameters)# } #> $modelName #> [1] \"EII\" #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                [,1]         [,2]         [,3] #>   [1,] 1.000000e+00 2.803384e-16 2.385590e-34 #>   [2,] 1.000000e+00 7.327699e-16 1.308337e-34 #>   [3,] 1.000000e+00 1.323453e-17 5.432319e-37 #>   [4,] 1.000000e+00 4.734701e-16 6.206020e-35 #>   [5,] 1.000000e+00 9.644772e-17 6.074008e-35 #>   [6,] 1.000000e+00 3.745645e-13 7.110633e-29 #>   [7,] 1.000000e+00 3.962220e-17 5.263751e-36 #>   [8,] 1.000000e+00 1.530343e-15 1.745542e-33 #>   [9,] 1.000000e+00 5.012695e-17 8.729744e-37 #>  [10,] 1.000000e+00 1.493770e-15 4.553180e-34 #>  [11,] 1.000000e+00 4.946353e-15 4.909613e-32 #>  [12,] 1.000000e+00 2.874117e-15 3.251952e-33 #>  [13,] 1.000000e+00 1.898603e-16 1.366666e-35 #>  [14,] 1.000000e+00 2.965476e-20 1.765968e-41 #>  [15,] 1.000000e+00 5.679989e-17 3.628138e-34 #>  [16,] 1.000000e+00 6.232567e-15 1.539704e-30 #>  [17,] 1.000000e+00 2.030556e-16 1.196559e-33 #>  [18,] 1.000000e+00 5.792085e-16 7.888847e-34 #>  [19,] 1.000000e+00 1.838770e-12 7.077675e-28 #>  [20,] 1.000000e+00 1.007591e-15 4.932475e-33 #>  [21,] 1.000000e+00 8.003305e-13 2.988659e-29 #>  [22,] 1.000000e+00 3.239263e-15 2.212908e-32 #>  [23,] 1.000000e+00 4.293936e-21 1.455266e-41 #>  [24,] 1.000000e+00 1.684971e-12 6.043532e-29 #>  [25,] 1.000000e+00 8.089809e-13 1.237726e-29 #>  [26,] 1.000000e+00 5.879016e-14 9.233078e-32 #>  [27,] 1.000000e+00 4.281258e-14 2.980294e-31 #>  [28,] 1.000000e+00 3.431956e-15 1.078274e-32 #>  [29,] 1.000000e+00 8.148416e-16 9.369497e-34 #>  [30,] 1.000000e+00 3.725137e-15 2.067596e-33 #>  [31,] 1.000000e+00 1.082762e-14 8.120565e-33 #>  [32,] 1.000000e+00 7.954596e-14 1.340679e-30 #>  [33,] 1.000000e+00 1.170395e-16 5.229103e-34 #>  [34,] 1.000000e+00 1.545756e-16 1.980569e-33 #>  [35,] 1.000000e+00 3.086285e-15 1.505679e-33 #>  [36,] 1.000000e+00 1.316358e-17 8.441335e-37 #>  [37,] 1.000000e+00 5.208699e-16 1.073153e-33 #>  [38,] 1.000000e+00 2.498955e-17 6.344799e-36 #>  [39,] 1.000000e+00 4.915683e-18 4.121235e-38 #>  [40,] 1.000000e+00 2.858709e-15 5.053241e-33 #>  [41,] 1.000000e+00 4.731249e-17 1.745341e-35 #>  [42,] 1.000000e+00 4.189706e-16 3.337718e-36 #>  [43,] 1.000000e+00 2.030322e-18 2.239061e-38 #>  [44,] 1.000000e+00 1.174537e-13 2.402226e-30 #>  [45,] 1.000000e+00 3.840153e-12 9.692964e-28 #>  [46,] 1.000000e+00 8.104734e-16 1.494506e-34 #>  [47,] 1.000000e+00 3.196024e-15 2.328846e-32 #>  [48,] 1.000000e+00 4.643069e-17 2.929807e-36 #>  [49,] 1.000000e+00 2.647914e-15 1.695928e-32 #>  [50,] 1.000000e+00 3.633460e-16 1.516762e-34 #>  [51,] 4.414980e-22 3.552072e-01 6.447928e-01 #>  [52,] 1.058716e-18 9.643661e-01 3.563387e-02 #>  [53,] 1.636093e-24 9.729657e-02 9.027034e-01 #>  [54,] 2.934788e-13 9.999989e-01 1.061514e-06 #>  [55,] 1.418016e-20 9.269163e-01 7.308372e-02 #>  [56,] 6.343133e-17 9.996119e-01 3.881470e-04 #>  [57,] 2.880441e-20 8.010121e-01 1.989879e-01 #>  [58,] 8.884593e-05 9.999112e-01 4.919936e-11 #>  [59,] 5.157533e-20 9.481313e-01 5.186869e-02 #>  [60,] 3.557001e-11 9.999997e-01 3.315240e-07 #>  [61,] 1.889301e-07 9.999998e-01 2.501339e-10 #>  [62,] 2.902400e-15 9.997677e-01 2.323394e-04 #>  [63,] 7.313376e-14 9.999980e-01 2.017871e-06 #>  [64,] 8.929576e-20 9.771962e-01 2.280376e-02 #>  [65,] 4.113055e-09 9.999999e-01 1.162238e-07 #>  [66,] 1.420914e-18 9.695112e-01 3.048878e-02 #>  [67,] 6.717402e-17 9.991564e-01 8.435834e-04 #>  [68,] 3.551802e-13 9.999960e-01 3.972232e-06 #>  [69,] 4.586821e-20 9.961084e-01 3.891551e-03 #>  [70,] 1.064136e-11 9.999996e-01 3.545649e-07 #>  [71,] 8.183483e-21 8.135526e-01 1.864474e-01 #>  [72,] 6.299772e-14 9.999708e-01 2.918159e-05 #>  [73,] 3.889743e-23 7.726455e-01 2.273545e-01 #>  [74,] 2.487187e-19 9.921199e-01 7.880054e-03 #>  [75,] 5.333824e-17 9.983183e-01 1.681674e-03 #>  [76,] 1.728900e-18 9.826147e-01 1.738533e-02 #>  [77,] 5.532435e-23 4.900301e-01 5.099699e-01 #>  [78,] 6.253220e-26 4.638985e-02 9.536101e-01 #>  [79,] 3.533406e-18 9.957718e-01 4.228244e-03 #>  [80,] 3.378235e-08 1.000000e+00 1.222238e-08 #>  [81,] 8.372344e-11 9.999999e-01 8.373227e-08 #>  [82,] 1.133646e-09 1.000000e+00 2.195897e-08 #>  [83,] 3.573559e-12 9.999982e-01 1.792814e-06 #>  [84,] 4.604035e-24 5.142138e-01 4.857862e-01 #>  [85,] 2.345187e-16 9.996486e-01 3.514185e-04 #>  [86,] 1.545648e-17 9.866927e-01 1.330734e-02 #>  [87,] 1.499551e-21 5.950215e-01 4.049785e-01 #>  [88,] 1.071821e-18 9.988635e-01 1.136484e-03 #>  [89,] 5.293950e-13 9.999898e-01 1.023051e-05 #>  [90,] 7.105513e-13 9.999986e-01 1.396314e-06 #>  [91,] 1.238318e-15 9.999678e-01 3.223258e-05 #>  [92,] 9.214775e-19 9.888907e-01 1.110928e-02 #>  [93,] 3.504393e-13 9.999963e-01 3.724099e-06 #>  [94,] 3.056837e-05 9.999694e-01 6.648361e-11 #>  [95,] 2.144228e-14 9.999838e-01 1.615563e-05 #>  [96,] 8.934438e-14 9.999764e-01 2.359935e-05 #>  [97,] 2.779082e-14 9.999671e-01 3.293310e-05 #>  [98,] 1.863063e-16 9.992991e-01 7.008920e-04 #>  [99,] 5.368673e-03 9.946313e-01 1.595603e-11 #> [100,] 1.170520e-13 9.999879e-01 1.205306e-05 #> [101,] 9.342372e-40 7.331981e-07 9.999993e-01 #> [102,] 1.355795e-24 3.827313e-01 6.172687e-01 #> [103,] 1.415993e-40 5.197756e-07 9.999995e-01 #> [104,] 7.078729e-32 1.098448e-03 9.989016e-01 #> [105,] 3.935241e-37 1.071799e-05 9.999893e-01 #> [106,] 3.078989e-51 1.334794e-10 1.000000e+00 #> [107,] 1.370446e-16 9.999492e-01 5.076321e-05 #> [108,] 7.578449e-45 3.159087e-08 1.000000e+00 #> [109,] 1.221627e-36 5.811402e-05 9.999419e-01 #> [110,] 1.046280e-44 3.956327e-09 1.000000e+00 #> [111,] 1.775399e-27 9.010916e-03 9.909891e-01 #> [112,] 1.518738e-29 7.823942e-03 9.921761e-01 #> [113,] 2.041398e-34 6.231995e-05 9.999377e-01 #> [114,] 5.660664e-24 6.529490e-01 3.470510e-01 #> [115,] 7.166625e-27 4.895157e-02 9.510484e-01 #> [116,] 5.879819e-31 6.051577e-04 9.993948e-01 #> [117,] 1.789429e-31 9.501963e-04 9.990498e-01 #> [118,] 2.364301e-52 7.544743e-12 1.000000e+00 #> [119,] 7.542749e-57 4.302226e-12 1.000000e+00 #> [120,] 1.181638e-23 8.890101e-01 1.109899e-01 #> [121,] 4.869149e-38 2.102690e-06 9.999979e-01 #> [122,] 3.284881e-22 8.215690e-01 1.784310e-01 #> [123,] 1.223858e-52 7.611372e-11 1.000000e+00 #> [124,] 5.342028e-24 3.865481e-01 6.134519e-01 #> [125,] 6.054033e-36 1.127952e-05 9.999887e-01 #> [126,] 2.085175e-40 4.388139e-07 9.999996e-01 #> [127,] 1.763260e-22 6.698002e-01 3.301998e-01 #> [128,] 9.097872e-23 5.007794e-01 4.992206e-01 #> [129,] 4.988533e-34 1.984470e-04 9.998016e-01 #> [130,] 3.019952e-37 8.392597e-06 9.999916e-01 #> [131,] 1.422424e-43 8.290819e-08 9.999999e-01 #> [132,] 1.174192e-48 1.088190e-10 1.000000e+00 #> [133,] 1.508646e-34 1.239971e-04 9.998760e-01 #> [134,] 1.254623e-24 2.841190e-01 7.158810e-01 #> [135,] 2.771605e-29 2.548075e-02 9.745192e-01 #> [136,] 9.024027e-47 2.580492e-09 1.000000e+00 #> [137,] 2.490666e-34 3.296144e-05 9.999670e-01 #> [138,] 7.025706e-31 1.283507e-03 9.987165e-01 #> [139,] 1.751245e-21 7.873985e-01 2.126015e-01 #> [140,] 1.493664e-33 8.353069e-05 9.999165e-01 #> [141,] 1.420120e-36 8.621217e-06 9.999914e-01 #> [142,] 5.196881e-31 4.407646e-04 9.995592e-01 #> [143,] 1.355795e-24 3.827313e-01 6.172687e-01 #> [144,] 5.782379e-40 5.741210e-07 9.999994e-01 #> [145,] 5.062652e-38 1.718831e-06 9.999983e-01 #> [146,] 2.055977e-31 5.095741e-04 9.994904e-01 #> [147,] 7.527149e-26 1.785571e-01 8.214429e-01 #> [148,] 6.202938e-29 4.995365e-03 9.950046e-01 #> [149,] 5.809956e-31 4.638463e-04 9.995362e-01 #> [150,] 4.398339e-24 2.979812e-01 7.020188e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3333333 0.3333333 #>  #> $parameters$mean #>               [,1]  [,2]  [,3] #> Sepal.Length 5.006 5.936 6.588 #> Sepal.Width  3.428 2.770 2.974 #> Petal.Length 1.462 4.260 5.552 #> Petal.Width  0.246 1.326 2.026 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"EII\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.148829    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.148829     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.148829    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.148829 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.148829    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.148829     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.148829    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.148829 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.148829    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.148829     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.148829    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.148829 #>  #>  #> $parameters$variance$Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.148829    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.148829     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.148829    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.148829 #>  #> $parameters$variance$sigmasq #> [1] 0.148829 #>  #> $parameters$variance$scale #> [1] 0.148829 #>  #>  #>  #> $loglik #> [1] -414.698 #>  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"Starting density estimate obtained fitted Gaussian finite mixture model, cluster cores identified connected components given density level. cluster cores identified, remaining observations allocated cluster cores probability cluster membership highest.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"","code":"gmmhd(object,        ngrid = min(round((log(nrow(data)))*10), nrow(data)),        dr = list(d = 3, lambda = 1, cumEvalues = NULL, mindir = 2),       classify = list(G = 1:5,                        modelNames = mclust.options(\"emModelNames\")[-c(8, 10)]),       ...)  # S3 method for gmmhd plot(x, what = c(\"mode\", \"cores\", \"clusters\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"object object returned Mclust. ngrid integer specifying number grid points used compute density levels. dr list parameters used dimension reduction step. classify list parameters used classification step. x object class 'gmmhd' returned function gmmhd. string specifying type plot produced. See Examples section. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"Model-based clustering associates component finite mixture distribution group cluster. underlying implicit assumption one--one correspondence exists mixture components clusters. However, single Gaussian density may sufficient, two mixture components needed reasonably approximate distribution within homogeneous group observations. function implements methodology proposed Scrucca (2016) based identification high density regions underlying density function. Starting estimated Gaussian finite mixture model, corresponding density estimate used identify cluster cores, .e. data points form core clusters.  cluster cores obtained connected components given density level \\(c\\). mode function gives number connected components level \\(c\\) varied.  cluster cores identified, remaining observations allocated cluster cores probability cluster membership highest. method usually improves identification non-Gaussian clusters compared fully parametric approach. Furthermore, enables identification clusters obtained merging mixture components, can straightforwardly extended cases higher dimensionality.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"list class gmmhd following components: Mclust input object class \"Mclust\" representing estimated Gaussian finite mixture model. MclustDA object class \"MclustDA\" containing model used classification step. MclustDR object class \"MclustDR\" containing dimension reduction step performed, otherwise NULL. x data used algorithm. can input data projection preliminary dimension reduction step performed. density density estimated input Gaussian finite mixture model evaluated input data. con list connected components step. nc vector giving number connected components (.e. modes) step. pn Vector values uniform grid proportions length ngrid. qn Vector density quantiles corresponding proportions pn. pc Vector empirical proportions corresponding quantiles qn. clusterCores Vector cluster cores numerical labels; NAs indicate observation belong cluster core. clusterCores Vector numerical labels giving final clustering. numClusters integer giving number clusters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"Scrucca, L. (2016) Identifying connected components Gaussian finite mixture models clustering. Computational Statistics & Data Analysis, 93, 5-17.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"Luca Scrucca luca.scrucca@unipg.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/gmmhd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifying Connected Components in Gaussian Finite Mixture Models for Clustering — gmmhd","text":"","code":"# \\donttest{ data(faithful) mod <- Mclust(faithful) summary(mod) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 #>  #> Clustering table: #>   1   2   3  #>  40  97 135  plot(as.densityMclust(mod), faithful, what = \"density\",       points.pch = mclust.options(\"classPlotSymbols\")[mod$classification],       points.col = mclust.options(\"classPlotColors\")[mod$classification])   GMMHD <- gmmhd(mod) summary(GMMHD) #> --------------------------------------------------------- #> GMM with high-density connected components for clustering  #> --------------------------------------------------------- #>  #> Initial model:  Mclust (EEE,3) #>  #> Cluster cores: #>    1    2 <NA>  #>  166   91   15  #>  #> Final clustering: #>   1   2  #> 178  94   plot(GMMHD, what = \"mode\")  plot(GMMHD, what = \"cores\")  plot(GMMHD, what = \"clusters\")  # }"},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based Agglomerative Hierarchical Clustering — hc","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"Agglomerative hierarchical clustering based maximum likelihood criteria    Gaussian mixture models parameterized eigenvalue decomposition.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"","code":"hc(data,    modelName = \"VVV\",      use = \"VARS\",    partition = dupPartition(data),     minclus = 1, ...)     # S3 method for hc as.hclust(x, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations (\\(n\\))     columns correspond variables (\\(d\\)). modelName character string indicating model used model-based agglomerative hierarchical clustering.     Possible models : \"E\" equal variance (one-dimensional); \"V\" spherical, variable variance (one-dimensional); \"EII\" spherical, equal volume; \"VII\" spherical, unequal volume; \"EEE\" ellipsoidal, equal volume, shape, orientation; \"VVV\" ellipsoidal, varying volume, shape, orientation (default). hc() used initialization EM algorithm default taken mclust.options(\"hcModelName\"). See mclust.options. use character string specifying type input variables/data transformation used model-based agglomerative hierarchical clustering.     Possible values : \"VARS\" original variables (default); \"STD\" standardized variables (centered scaled); \"SPH\" sphered variables (centered, scaled uncorrelated)       computed using SVD; \"PCS\" principal components computed using SVD centered      variables (.e. using covariance matrix); \"PCR\" principal components computed using SVD standardized      (center scaled) variables (.e. using correlation matrix); \"SVD\" scaled SVD transformation. hc() used initialization EM algorithm default taken mclust.options(\"hcUse\"). See mclust.options.     details see Scrucca Raftery (2015). partition numeric character vector representing partition     observations (rows) data.      provided, group merges start partition.      Otherwise, observation assumed cluster      start agglomeration.     Starting version 5.4.8, default function     dupPartition used start duplicated     observations group, thereby keeping duplicates      group throughout modelling process. minclus number indicating number clusters stop     agglomeration. default stop observations     merged single cluster. ... Arguments method-specific hc functions. See example     hcE. x object class 'hc' resulting call hc().","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"function hc() returns numeric two-column matrix    ith row gives minimum index observations    two clusters merged ith stage agglomerative    hierarchical clustering. Several informations also returned   attributes. method .hclust.hc() can used convert input    object class 'hc' class 'hclust'.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"models memory usage order square   number groups initial partition fast execution.   models, equal variance \"EEE\",   admit fast algorithm usual agglomerative   hierarchical clustering paradigm.    use less memory much slower execute.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"modelName = \"E\" (univariate equal variances)   modelName = \"EII\" (multivariate equal spherical   covariances), underlying model   Ward's method hierarchical clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"Banfield J. D. Raftery . E. (1993).   Model-based Gaussian non-Gaussian Clustering.   Biometrics, 49:803-821. Fraley C. (1998).   Algorithms model-based Gaussian hierarchical clustering.   SIAM Journal Scientific Computing, 20:270-281. Fraley C. Raftery . E. (2002).   Model-based clustering, discriminant analysis, density estimation.   Journal American Statistical Association, 97:611-631. Scrucca L. Raftery . E. (2015).   Improved initialisation model-based clustering using Gaussian hierarchical partitions.    Advances Data Analysis Classification, 9/4:447-460.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based Agglomerative Hierarchical Clustering — hc","text":"","code":"hcTree <- hc(modelName = \"VVV\", data = iris[,-5]) hcTree #> Call: #> hc(data = iris[, -5], modelName = \"VVV\")  #>  #> Model-Based Agglomerative Hierarchical Clustering  #> Model name        = VVV  #> Use               = VARS  #> Number of objects = 150  cl <- hclass(hcTree,c(2,3)) table(cl[,\"2\"]) #>  #>   1   2  #>  50 100  table(cl[,\"3\"]) #>  #>  1  2  3  #> 50 64 36   # \\donttest{ clPairs(iris[,-5], classification = cl[,\"2\"])  clPairs(iris[,-5], classification = cl[,\"3\"])  # }"},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based Hierarchical Clustering — hcE","title":"Model-based Hierarchical Clustering — hcE","text":"Agglomerative hierarchical clustering based maximum likelihood   Gaussian mixture model parameterized eigenvalue decomposition.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based Hierarchical Clustering — hcE","text":"","code":"hcE(data, partition = NULL, minclus=1, ...) hcV(data, partition = NULL, minclus = 1, alpha = 1, ...) hcEII(data, partition = NULL, minclus = 1, ...) hcVII(data, partition = NULL, minclus = 1, alpha = 1, ...) hcEEE(data, partition = NULL, minclus = 1, ...) hcVVV(data, partition = NULL, minclus = 1, alpha = 1, beta = 1, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based Hierarchical Clustering — hcE","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. partition numeric character vector representing partition     observations (rows) data. provided, group merges     start partition. Otherwise, observation assumed     cluster start agglomeration. minclus number indicating number clusters stop     agglomeration. default stop observations     merged single cluster. alpha, beta Additional tuning parameters needed initializatiion models.      details, see Fraley 1998. defaults provided usually adequate. ... Catch unused arguments .call call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based Hierarchical Clustering — hcE","text":"numeric two-column matrix ith row gives minimum    index observations two clusters merged  ith stage agglomerative hierarchical clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model-based Hierarchical Clustering — hcE","text":"models memory usage order square   number groups initial partition fast execution.   models, equal variance \"EEE\",   admit fast algorithm usual agglomerative   hierachical clustering paradigm.    use less memory much slower execute.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-based Hierarchical Clustering — hcE","text":"J. D. Banfield . E. Raftery (1993).   Model-based Gaussian non-Gaussian Clustering.   Biometrics 49:803-821. C. Fraley (1998).   Algorithms model-based Gaussian hierarchical clustering.   SIAM Journal Scientific Computing 20:270-281. C. Fraley . E. Raftery (2002).   Model-based clustering, discriminant analysis, density estimation.   Journal American Statistical Association 97:611-631.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hcE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based Hierarchical Clustering — hcE","text":"","code":"hcTree <- hcEII(data = iris[,-5]) cl <- hclass(hcTree,c(2,3))  # \\donttest{ par(pty = \"s\", mfrow = c(1,1)) clPairs(iris[,-5],cl=cl[,\"2\"])  clPairs(iris[,-5],cl=cl[,\"3\"])   par(mfrow = c(1,2)) dimens <- c(1,2) coordProj(iris[,-5], classification=cl[,\"2\"], dimens=dimens) coordProj(iris[,-5], classification=cl[,\"3\"], dimens=dimens)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/hcRandomPairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Random hierarchical structure — hcRandomPairs","title":"Random hierarchical structure — hcRandomPairs","text":"Create hierarchical structure using random hierarchical partition data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcRandomPairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random hierarchical structure — hcRandomPairs","text":"","code":"hcRandomPairs(data, seed = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/hcRandomPairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random hierarchical structure — hcRandomPairs","text":"data numeric matrix data frame observations.     matrix data frame, rows correspond observations     columns correspond variables. seed Optional single value, interpreted integer, specifying seed random partition. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hcRandomPairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random hierarchical structure — hcRandomPairs","text":"numeric two-column matrix ith row gives minimum    index observations two clusters merged  ith stage random agglomerative hierarchical clustering.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hcRandomPairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random hierarchical structure — hcRandomPairs","text":"","code":"data <- iris[,1:4] randPairs <- hcRandomPairs(data) str(randPairs) #>  int [1:2, 1:149] 75 106 20 61 52 104 54 142 73 78 ... #>  - attr(*, \"initialPartition\")= int [1:150] 1 2 3 4 5 6 7 8 9 10 ... #>  - attr(*, \"dimensions\")= num [1:2] 150 2 # start model-based clustering from a random partition mod <- Mclust(data, initialization = list(hcPairs = randPairs)) summary(mod) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 2 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -214.3547 150 29 -574.0178 -574.0191 #>  #> Clustering table: #>   1   2  #> 100  50"},{"path":"https://mclust-org.github.io/mclust/reference/hclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Classifications from Hierarchical Agglomeration — hclass","title":"Classifications from Hierarchical Agglomeration — hclass","text":"Determines classifications corresponding different numbers groups   given merge pairs hierarchical agglomeration.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classifications from Hierarchical Agglomeration — hclass","text":"","code":"hclass(hcPairs, G)"},{"path":"https://mclust-org.github.io/mclust/reference/hclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classifications from Hierarchical Agglomeration — hclass","text":"hcPairs numeric two-column matrix ith row gives minimum      index observations two clusters merged     ith stage agglomerative hierarchical clustering. G integer vector integers giving number clusters     corresponding classfications wanted.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classifications from Hierarchical Agglomeration — hclass","text":"matrix length(G) columns, column    corresponding classification. Columns indexed character   representation integers G.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hclass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classifications from Hierarchical Agglomeration — hclass","text":"","code":"hcTree <- hc(modelName=\"VVV\", data = iris[,-5]) cl <- hclass(hcTree,c(2,3))  # \\donttest{ par(pty = \"s\", mfrow = c(1,1)) clPairs(iris[,-5],cl=cl[,\"2\"])  clPairs(iris[,-5],cl=cl[,\"3\"])  # }"},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Highest Density Region (HDR) Levels — hdrlevels","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"Compute levels Highest Density Regions (HDRs) density probability levels.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"","code":"hdrlevels(density, prob)"},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"density vector density values computed set (observed) evaluation points. prob vector probability levels range \\([0,1]\\).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"function returns vector density values corresponding HDRs given probability levels.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"Hyndman (1996), let \\(f(x)\\) density function random  variable \\(X\\). \\(100(1-\\alpha)\\%\\) HDR subset  \\(R(f_\\alpha)\\) sample space \\(X\\) $$ R(f_\\alpha) = {x : f(x) \\ge f_\\alpha } $$ \\(f_\\alpha\\) largest constant  \\( Pr( X \\R(f_\\alpha)) \\ge 1-\\alpha \\)","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"Rob J. Hyndman (1996) Computing Graphing Highest Density Regions. American Statistician, 50(2):120-126.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"L. Scrucca","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hdrlevels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Highest Density Region (HDR) Levels — hdrlevels","text":"","code":"# Example: univariate Gaussian x <- rnorm(1000) f <- dnorm(x) a <- c(0.5, 0.25, 0.1) (f_a <- hdrlevels(f, prob = 1-a)) #>       50%       75%       90%  #> 0.3200053 0.2098644 0.1016923   plot(x, f) abline(h = f_a, lty = 2) text(max(x), f_a, labels = paste0(\"f_\", a), pos = 3)   mean(f > f_a[1]) #> [1] 0.5 range(x[which(f > f_a[1])]) #> [1] -0.6618501  0.6610135 qnorm(1-a[1]/2) #> [1] 0.6744898  mean(f > f_a[2]) #> [1] 0.75 range(x[which(f > f_a[2])]) #> [1] -1.121584  1.132708 qnorm(1-a[2]/2) #> [1] 1.150349  mean(f > f_a[3]) #> [1] 0.9 range(x[which(f > f_a[3])]) #> [1] -1.652819  1.650853 qnorm(1-a[3]/2) #> [1] 1.644854  # Example 2: univariate Gaussian mixture set.seed(1) cl <- sample(1:2, size = 1000, prob = c(0.7, 0.3), replace = TRUE) x <- ifelse(cl == 1,              rnorm(1000, mean = 0, sd = 1),             rnorm(1000, mean = 4, sd = 1)) f <- 0.7*dnorm(x, mean = 0, sd = 1) + 0.3*dnorm(x, mean = 4, sd = 1)  a <- 0.25 (f_a <- hdrlevels(f, prob = 1-a)) #>        75%  #> 0.09291342   plot(x, f) abline(h = f_a, lty = 2) text(max(x), f_a, labels = paste0(\"f_\", a), pos = 3)   mean(f > f_a) #> [1] 0.75  # find the regions of HDR ord <- order(x) f <- f[ord] x <- x[ord] x_a <- x[f > f_a] j <- which.max(diff(x_a)) region1 <- x_a[c(1,j)] region2 <- x_a[c(j+1,length(x_a))] plot(x, f, type = \"l\") abline(h = f_a, lty = 2) abline(v = region1, lty = 3, col = 2) abline(v = region2, lty = 3, col = 3)"},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":null,"dir":"Reference","previous_headings":"","what":"Aproximate Hypervolume for Multivariate Data — hypvol","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":"Computes simple approximation hypervolume multivariate   data set.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":"","code":"hypvol(data, reciprocal=FALSE)"},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. reciprocal logical variable indicating whether reciprocal     hypervolume desired rather hypervolume .     default return hypervolume.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":"Returns minimum hypervolume computed simple variable bounds   computed variable bounds principal component scores.   Used default hypervolume parameter noise    component observations designated noise  Mclust mclustBIC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":". Dasgupta . E. Raftery (1998).   Detecting features spatial point processes clutter via model-based   clustering.    Journal American Statistical Association 93:294-302. C. Fraley .E. Raftery (1998).   Computer Journal 41:578-588. C. Fraley . E. Raftery (2002).   Model-based clustering, discriminant analysis, density estimation.   Journal American Statistical Association 97:611-631.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/hypvol.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aproximate Hypervolume for Multivariate Data — hypvol","text":"","code":"hypvol(iris[,-5]) #> [1] 27.2412"},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":null,"dir":"Reference","previous_headings":"","what":"ICL for an estimated Gaussian Mixture Model — icl","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"Computes ICL (Integrated Complete-data Likelihood) criterion Gaussian Mixture Model fitted Mclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"","code":"icl(object, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"object object class 'Mclust' resulting call Mclust. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"ICL given input MCLUST model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"Biernacki, C., Celeux, G., Govaert, G. (2000).    Assessing mixture model clustering integrated completed likelihood.   IEEE Trans. Pattern Analysis Machine Intelligence, 22 (7), 719-725.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/icl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ICL for an estimated Gaussian Mixture Model — icl","text":"","code":"mod <- Mclust(iris[,1:4]) icl(mod) #> [1] -561.7289"},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing data imputation via the mix package — imputeData","title":"Missing data imputation via the mix package — imputeData","text":"Imputes missing data using mix package.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing data imputation via the mix package — imputeData","text":"","code":"imputeData(data, categorical = NULL, seed = NULL, verbose = interactive())"},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Missing data imputation via the mix package — imputeData","text":"data numeric vector, matrix, data frame observations containing     missing values. Categorical variables allowed. matrix     data frame, rows correspond observations columns     correspond variables. categorical logical vectors whose ith entry TRUE     ith variable column data interpreted     categorical FALSE otherwise. default assume     variable interpreted categorical factor. seed seed function rngseed used initialize     random number generator mix. default, seed     chosen uniformly interval (.Machine$integer.max/1024,     .Machine$integer.max). verbose logical, TRUE reports info iterations algorithm.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Missing data imputation via the mix package — imputeData","text":"dataset dimensions data missing values   filled .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Missing data imputation via the mix package — imputeData","text":"Schafer J. L. (1997). Analysis Imcomplete Multivariate Data, Chapman Hall.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/imputeData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Missing data imputation via the mix package — imputeData","text":"","code":"# \\donttest{ # Note that package 'mix' must be installed data(stlouis, package = \"mix\")   # impute the continuos variables in the stlouis data stlimp <- imputeData(stlouis[,-(1:3)])  # plot imputed values imputePairs(stlouis[,-(1:3)], stlimp)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"Creates scatter plot pair variables given data,   allowing display imputations missing values different   colors symbols non missing values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"","code":"imputePairs(data, dataImp,              symbols = c(1,16), colors = c(\"black\", \"red\"), labels,             panel = points, ..., lower.panel = panel, upper.panel = panel,              diag.panel = NULL, text.panel = textPanel, label.pos = 0.5 +              has.diag/3, cex.labels = NULL, font.labels = 1, row1attop = TRUE,              gap = 0.2)"},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"data numeric vector, matrix, data frame observations containing     missing values. Categorical variables allowed. matrix     data frame, rows correspond observations columns     correspond variables. dataImp dataset data missing values imputed. symbols Either integer character vector assigning plotting symbols     nonmissing data impued  values, respectively. default     closed circle nonmissing data     open circle imputed values. colors Either integer character vector assigning colors     nonmissing data impued  values, respectively. default      black nonmissing data red imputed values. labels function pairs. panel function pairs. ... function pairs. lower.panel function pairs. upper.panel function pairs. diag.panel function pairs. text.panel function pairs. label.pos function pairs. cex.labels function pairs. font.labels function pairs. row1attop function pairs. gap function pairs.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"pairs plot displaying location missing nonmissing values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"Schafer J. L. (1997). Analysis Imcomplete Multivariate Data, Chapman Hall.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/imputePairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Scatter Plots showing Missing Data Imputations — imputePairs","text":"","code":"# \\donttest{ # Note that package 'mix' must be installed data(stlouis, package = \"mix\")   # impute the continuos variables in the stlouis data stlimp <- imputeData(stlouis[,-(1:3)])  # plot imputed values imputePairs(stlouis[,-(1:3)], stlimp)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood of a Mclust object — logLik.Mclust","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"Returns log-likelihood 'Mclust' object.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"","code":"# S3 method for Mclust logLik(object, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"object object class 'Mclust' resulting call Mclust. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"Returns object class 'logLik' element providing maximized log-likelihood, arguments giving number (estimated) parameters model (\"df\") sample size (\"nobs\").","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/logLik.Mclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood of a Mclust object — logLik.Mclust","text":"","code":"# \\donttest{ irisMclust <- Mclust(iris[,1:4]) summary(irisMclust) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Clustering table: #>   1   2  #>  50 100  logLik(irisMclust) #> 'log Lik.' -215.726 (df=26) # }"},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood of a MclustDA object — logLik.MclustDA","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"Returns log-likelihood MclustDA object.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"","code":"# S3 method for MclustDA logLik(object, data, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"object object class 'MclustDA' resulting call MclustDA. data data log-likelihood must computed. missing, observed data 'MclustDA' object used. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"Returns object class 'logLik' element providing maximized log-likelihood, arguments giving number (estimated) parameters model (\"df\") sample size (\"nobs\").","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/logLik.MclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood of a MclustDA object — logLik.MclustDA","text":"","code":"# \\donttest{ irisMclustDA <- MclustDA(iris[,1:4], iris$Species) summary(irisMclustDA) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -172.8135 150 47 -581.1269 #>              #> Classes       n     % Model G #>   setosa     50 33.33   EEE 2 #>   versicolor 50 33.33   XXX 1 #>   virginica  50 33.33   XXX 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         50          0         0 #>   versicolor      0         48         2 #>   virginica       0          1        49 #> Classification error = 0.02  #> Brier score          = 0.0116  logLik(irisMclustDA) #> 'log Lik.' -172.8135 (df=47) # }"},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log sum of exponentials — logsumexp","title":"Log sum of exponentials — logsumexp","text":"Efficient implementation (via Fortran) log-sum-exp function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log sum of exponentials — logsumexp","text":"","code":"logsumexp(x, v = NULL)"},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log sum of exponentials — logsumexp","text":"x matrix dimension \\(n \\times k\\) numerical values. vector provided, converted single-row matrix. v optional vector length \\(k\\) numerical values added row x matrix. provided, vector zeros used.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log sum of exponentials — logsumexp","text":"Given matrix x, row \\(x_{[]} = [x_1, \\dots, x_k]\\) (\\(=1,\\dots,n\\)), log-sum-exp (LSE) function calculates $$ \\text{LSE}(x_{[]}) = \\log \\sum_{j=1}^k \\exp(x_j + v_j) = m + \\log \\sum_{j=1}^k \\exp(x_j + v_j - m) $$ \\(m = \\max(x_1+v_1, \\dots, x_k+v_k)\\).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log sum of exponentials — logsumexp","text":"Returns vector values length equal number rows x.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Log sum of exponentials — logsumexp","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log sum of exponentials — logsumexp","text":"","code":"x = matrix(rnorm(15), 5, 3) v = log(c(0.5, 0.3, 0.2)) logsumexp(x, v) #> [1] -0.6711947 -0.6393459  0.5306414 -0.1252858  0.8242612"},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":null,"dir":"Reference","previous_headings":"","what":"Majority vote — majorityVote","title":"Majority vote — majorityVote","text":"function compute majority vote (say plurality) label vector labels, breaking ties random.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Majority vote — majorityVote","text":"","code":"majorityVote(x)"},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Majority vote — majorityVote","text":"x vector values, either numerical .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Majority vote — majorityVote","text":"list following components: table table votes unique value x. ind integer specifying unique value x corresponds majority vote. majority string specifying majority vote label.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Majority vote — majorityVote","text":"L. Scrucca","code":""},{"path":"https://mclust-org.github.io/mclust/reference/majorityVote.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Majority vote — majorityVote","text":"","code":"x <- c(\"A\", \"C\", \"A\", \"B\", \"C\", \"B\", \"A\") majorityVote(x) #> $table #> x #> A B C  #> 3 2 2  #>  #> $ind #> [1] 1 #>  #> $majority #> [1] \"A\" #>"},{"path":"https://mclust-org.github.io/mclust/reference/map.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification given Probabilities — map","title":"Classification given Probabilities — map","text":"Converts matrix row sums 1 integer vector    specifying row column index maximum.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification given Probabilities — map","text":"","code":"map(z, warn = mclust.options(\"warn\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification given Probabilities — map","text":"z matrix (example matrix conditional     probabilities  row sums 1     produced E-step EM algorithm). warn logical variable indicating whether warning     issued columns z row     attains maximum. ... Provided allow lists elements arguments can     passed indirect list calls .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classification given Probabilities — map","text":"integer vector one entry row z,   -th value column index  -th row z attains maximum.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classification given Probabilities — map","text":"","code":"emEst <- me(modelName = \"VVV\", data = iris[,-5], z = unmap(iris[,5]))  map(emEst$z) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 2 #>  [75] 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3"},{"path":"https://mclust-org.github.io/mclust/reference/mapClass.html","id":null,"dir":"Reference","previous_headings":"","what":"Correspondence between classifications — mapClass","title":"Correspondence between classifications — mapClass","text":"Best correspondence classes given two vectors viewed   alternative classifications object.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mapClass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correspondence between classifications — mapClass","text":"","code":"mapClass(a, b)"},{"path":"https://mclust-org.github.io/mclust/reference/mapClass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correspondence between classifications — mapClass","text":"numeric character vector class labels. b numeric character vector class labels.     Must length     .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mapClass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correspondence between classifications — mapClass","text":"list two named elements,  aTOb  bTOa lists.    aTOb list component corresponding   unique element , gives   element elements b result closest class correspondence. bTOa list component corresponding   unique element b, gives   element elements result closest class correspondence.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mapClass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correspondence between classifications — mapClass","text":"","code":"a <- rep(1:3, 3) a #> [1] 1 2 3 1 2 3 1 2 3 b <- rep(c(\"A\", \"B\", \"C\"), 3) b #> [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" mapClass(a, b) #> $aTOb #> $aTOb$`1` #> [1] \"A\" #>  #> $aTOb$`2` #> [1] \"B\" #>  #> $aTOb$`3` #> [1] \"C\" #>  #>  #> $bTOa #> $bTOa$A #> [1] 1 #>  #> $bTOa$B #> [1] 2 #>  #> $bTOa$C #> [1] 3 #>  #>  a <- sample(1:3, 9, replace = TRUE) a #> [1] 2 3 2 3 2 1 3 3 1 b <- sample(c(\"A\", \"B\", \"C\"), 9, replace = TRUE) b #> [1] \"C\" \"A\" \"A\" \"C\" \"B\" \"C\" \"B\" \"A\" \"B\" mapClass(a, b) #> $aTOb #> $aTOb$`1` #> [1] \"B\" #>  #> $aTOb$`2` #> [1] \"A\" #>  #> $aTOb$`3` #> [1] \"A\" #>  #>  #> $bTOa #> $bTOa$A #> [1] 3 #>  #> $bTOa$B #> [1] 1 #>  #> $bTOa$C #> [1] 1 #>  #>"},{"path":"https://mclust-org.github.io/mclust/reference/mclust-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated Functions in mclust package — mclust-deprecated","title":"Deprecated Functions in mclust package — mclust-deprecated","text":"functions provided compatibility older versions mclust   package , may removed eventually.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated Functions in mclust package — mclust-deprecated","text":"","code":"cv.MclustDA(...) cv1EMtrain(data, labels, modelNames=NULL) bicEMtrain(data, labels, modelNames=NULL)"},{"path":"https://mclust-org.github.io/mclust/reference/mclust-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated Functions in mclust package — mclust-deprecated","text":"... pass arguments . data numeric vector matrix observations. labels Labels element row dataset. modelNames Vector model names tested.                     default select available model names.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclust-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal MCLUST functions — mclust-internal","title":"Internal MCLUST functions — mclust-internal","text":"Internal functions intended called directly users.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","text":"Gaussian finite mixture models estimated via EM algorithm model-based clustering, classification, density estimation, including Bayesian regularization dimension reduction.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","text":"quick introduction mclust see vignette quick tour mclust. See also: Mclust clustering; MclustDA supervised classification; MclustSSC semi-supervised classification; densityMclust density estimation.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","text":"Chris Fraley, Adrian Raftery Luca Scrucca. Maintainer: Luca Scrucca luca.scrucca@unipg.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","text":"Scrucca L., Fraley C., Murphy T. B. Raftery . E. (2023) Model-Based Clustering, Classification, Density Estimation Using mclust R. Chapman & Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/ Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317. Fraley C. Raftery . E. (2002) Model-based clustering, discriminant analysis density estimation, Journal American Statistical Association, 97/458, pp. 611-631.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation — mclust-package","text":"","code":"# \\donttest{ # Clustering mod1 <- Mclust(iris[,1:4]) summary(mod1) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Clustering table: #>   1   2  #>  50 100  plot(mod1,  what = c(\"BIC\", \"classification\"))    # Classification data(banknote) mod2 <- MclustDA(banknote[,2:7], banknote$Status) summary(mod2) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -646.0801 200 66 -1641.849 #>               #> Classes         n  % Model G #>   counterfeit 100 50   EVE 2 #>   genuine     100 50   XXX 1 #>  #> Training confusion matrix: #>              Predicted #> Class         counterfeit genuine #>   counterfeit         100       0 #>   genuine               0     100 #> Classification error = 0  #> Brier score          = 0  plot(mod2)      # Density estimation mod3 <- densityMclust(faithful$waiting)  summary(mod3) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust E (univariate, equal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1034.002 272  4 -2090.427 -2099.576 # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Default values for use with MCLUST package — mclust.options","title":"Default values for use with MCLUST package — mclust.options","text":"Set retrieve default values use MCLUST package.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default values for use with MCLUST package — mclust.options","text":"","code":"mclust.options(...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default values for use with MCLUST package — mclust.options","text":"... one arguments provided name = value form, argument may given.  Available arguments described Details section .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default values for use with MCLUST package — mclust.options","text":"mclust.options() provided assigning retrieving default values used various functions MCLUST. Available options : emModelNames vector 3-character strings associated multivariate      models EM estimation available MCLUST.      current default multivariate mixture models     supported MCLUST.     help file mclustModelNames describes      available models. hcModelName character string specifying multivariate model used model-based agglomerative hierarchical clustering initialization EM algorithm.     available models following: \"EII\" spherical, equal volume; \"EEE\" ellipsoidal, equal volume, shape, orientation; \"VII\" spherical, unequal volume; \"VVV\" ellipsoidal, varying volume, shape, orientation (default).  hcUse character string specifying type input variables/transformation used model-based agglomerative hierarchical clustering initialization EM algorithm.     Possible values : \"VARS\" original variables; \"STD\" standardized variables (centered scaled); \"SPH\" sphered variables (centered, scaled uncorrelated)       computed using SVD; \"PCS\" principal components computed using SVD centered      variables (.e. using covariance matrix); \"PCR\" principal components computed using SVD standardized      (center scaled) variables (.e. using correlation matrix); \"SVD\" scaled SVD transformation (default); \"RND\" transformation applied random hierarchical structure returned (see hcRandomPairs). details see Scrucca Raftery (2015), Scrucca et al. (2016). subset value specifying maximal sample size used model-based      hierarchical clustering start EM algorithm.      data sample size exceeds value, random sample drawn size     specified subset. fillEllipses logical value specifying whether fill transparent     colors ellipses corresponding within-cluster covariances case     \"classification\" plot 'Mclust' objects,     \"scatterplot\" graphs 'MclustDA' objects. bicPlotSymbols vector whose entries correspond graphics symbols plotting      BIC values output Mclust mclustBIC.      displayed legend appears lower right     BIC plots. bicPlotColors vector whose entries correspond colors plotting      BIC curves output Mclust     mclustBIC.      displayed legend appears lower right     BIC plots. classPlotSymbols vector whose entries either integers corresponding graphics      symbols single characters indicating classifications     plotting data. Classes assigned symbols given order. classPlotColors vector whose entries correspond colors indicating      classifications plotting data. Classes assigned colors      given order. warn logical value indicating whether issue certain warnings.     warnings situations      singularities encountered.      default warn = FALSE. parameter values set via call function remain effect rest session, affecting subsequent behaviour functions given parameters relevant.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default values for use with MCLUST package — mclust.options","text":"argument list empty function returns current list values.   argument list empty, returned list invisible.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Default values for use with MCLUST package — mclust.options","text":"Scrucca L. Raftery . E. (2015) Improved initialisation model-based clustering using Gaussian hierarchical partitions. Advances Data Analysis Classification, 9/4, pp. 447-460. Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default values for use with MCLUST package — mclust.options","text":"","code":"opt <- mclust.options() # save default values irisBIC <- mclustBIC(iris[,-5]) summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2        VEV,3      VVV,2 #> BIC      -561.7285 -562.5522369 -574.01783 #> BIC diff    0.0000   -0.8237748  -12.28937 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   mclust.options(emModelNames = c(\"EII\", \"EEI\", \"EEE\")) irisBIC <- mclustBIC(iris[,-5]) summary(irisBIC, iris[,-5]) #> Best BIC values: #>              EEE,5       EEE,6      EEE,7 #> BIC      -604.8131 -609.854322 -632.49473 #> BIC diff    0.0000   -5.041255  -27.68166 #>  #> Classification table for model (EEE,5):  #>  #>  1  2  3  4  5  #>  6 44 49 35 16   mclust.options(opt)    # restore default values mclust.options() #> $emModelNames #>  [1] \"EII\" \"VII\" \"EEI\" \"VEI\" \"EVI\" \"VVI\" \"EEE\" \"VEE\" \"EVE\" \"VVE\" \"EEV\" \"VEV\" #> [13] \"EVV\" \"VVV\" #>  #> $hcModelName #> [1] \"VVV\" #>  #> $hcUse #> [1] \"SVD\" #>  #> $subset #> [1] 2000 #>  #> $fillEllipses #> [1] FALSE #>  #> $bicPlotSymbols #> EII VII EEI EVI VEI VVI EEE VEE EVE VVE EEV VEV EVV VVV   E   V  #>  17   2  16  10  13   1  15   8   5   9  12   7  14   0  17   2  #>  #> $bicPlotColors #>       EII       VII       EEI       EVI       VEI       VVI       EEE       VEE  #>    \"gray\"   \"black\" \"#218B21\" \"#41884F\" \"#508476\" \"#58819C\" \"#597DC3\" \"#5178EA\"  #>       EVE       VVE       EEV       VEV       EVV       VVV         E         V  #> \"#716EE7\" \"#9B60B8\" \"#B2508B\" \"#C03F60\" \"#C82A36\" \"#CC0000\"    \"gray\"   \"black\"  #>  #> $classPlotSymbols #>  [1] 16  0 17  3 15  4  1  8  2  7  5  9  6 10 11 18 12 13 14 #>  #> $classPlotColors #>  [1] \"dodgerblue2\"    \"red3\"           \"green3\"         \"slateblue\"      #>  [5] \"darkorange\"     \"skyblue1\"       \"violetred4\"     \"forestgreen\"    #>  [9] \"steelblue4\"     \"slategrey\"      \"brown\"          \"black\"          #> [13] \"darkseagreen\"   \"darkgoldenrod3\" \"olivedrab\"      \"royalblue\"      #> [17] \"tomato4\"        \"cyan2\"          \"springgreen2\"   #>  #> $warn #> [1] FALSE #>   oldpar <- par(mfrow = c(2,1), no.readonly = TRUE) n <- with(mclust.options(),            max(sapply(list(bicPlotSymbols, bicPlotColors),length))) plot(seq(n), rep(1,n), ylab = \"\", xlab = \"\", yaxt = \"n\",       pch = mclust.options(\"bicPlotSymbols\"),       col = mclust.options(\"bicPlotColors\")) title(\"mclust.options(\\\"bicPlotSymbols\\\") \\n mclust.options(\\\"bicPlotColors\\\")\") n <- with(mclust.options(),            max(sapply(list(classPlotSymbols, classPlotColors),length))) plot(seq(n), rep(1,n), ylab = \"\", xlab = \"\", yaxt = \"n\",       pch = mclust.options(\"classPlotSymbols\"),       col = mclust.options(\"classPlotColors\")) title(\"mclust.options(\\\"classPlotSymbols\\\") \\n mclust.options(\\\"classPlotColors\\\")\")  par(oldpar)"},{"path":"https://mclust-org.github.io/mclust/reference/mclust1Dplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","title":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","text":"Plot one-dimensional data given parameters MVN mixture model    data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust1Dplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","text":"","code":"mclust1Dplot(data, parameters = NULL, z = NULL,               classification = NULL, truth = NULL, uncertainty = NULL,               what = c(\"classification\", \"density\", \"error\", \"uncertainty\"),              symbols = NULL, colors = NULL, ngrid = length(data),               xlab = NULL, ylab = NULL,               xlim = NULL, ylim = NULL,              cex = 1, main = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclust1Dplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","text":"data numeric vector observations.     Categorical variables allowed. parameters named list giving parameters MCLUST model,      used produce superimposing ellipses plot.      relevant components follows: pro Mixing proportions components mixture.                one mixing proportion number                Gaussian components mixture model includes                Poisson noise term. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  z matrix [,k]th entry gives         probability observation belonging kth class.         Used compute classification         uncertainty arguments available. classification numeric character vector representing classification         observations (rows) data. present argument z         ignored. truth numeric character vector giving known         classification data point.         classification z also present,         used displaying classification errors. uncertainty numeric vector values (0,1) giving         uncertainty data point. present argument z         ignored. Choose one following options: \"classification\"     (default), \"density\", \"error\", \"uncertainty\". symbols Either integer character vector assigning plotting symbol     unique class classification. Elements symbols     correspond classes classification order     appearance observations (order used      function unique). default use single plotting     symbol |. Classes delineated showing separate     lines whole data. colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance observations      (order used function unique).     default given mclust.options(\"classPlotColors\"). ngrid Number grid points use density computation interval     spanned data. default length data set. xlab, ylab argument specifying label axes. xlim, ylim argument specifying bounds plot.     may useful comparing plots. cex argument specifying size plotting symbols.      default value 1. main logical variable NULL indicating whether add title     plot identifying dimensions used. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust1Dplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","text":"plot showing location mixture components, classification, uncertainty, density /classification errors. Points different classes shown separated levels whole data.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclust1Dplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot one-dimensional data modeled by an MVN mixture. — mclust1Dplot","text":"","code":"# \\donttest{ n <- 250 ## create artificial data set.seed(1) y <- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5)) yclass <- c(rep(1,n), rep(2,n), rep(3,n))  yModel <- Mclust(y)  mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z,               what = \"classification\")   mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z,               what = \"error\", truth = yclass)   mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z,               what = \"density\")   mclust1Dplot(y, z = yModel$z, parameters = yModel$parameters,             what = \"uncertainty\")   # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclust2Dplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","title":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","text":"Plot two-dimensional data given parameters MVN mixture model    data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust2Dplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","text":"","code":"mclust2Dplot(data, parameters = NULL, z = NULL,              classification = NULL, truth = NULL, uncertainty = NULL,              what = c(\"classification\", \"uncertainty\", \"error\"),               addEllipses = TRUE, fillEllipses = mclust.options(\"fillEllipses\"),              symbols = NULL, colors = NULL,               xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,              scale = FALSE, cex  = 1, PCH = \".\",              main = FALSE, swapAxes = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclust2Dplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","text":"data numeric matrix data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables.      case data two dimensional, two columns. parameters named list giving parameters MCLUST model,       used produce superimposing ellipses plot.       relevant components follows: pro Mixing proportions components mixture.                one mixing proportion number                Gaussian components mixture model includes                Poisson noise term. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  z matrix [,k]th entry gives         probability observation belonging kth class.          Used compute classification         uncertainty arguments available. classification numeric character vector representing classification         observations (rows) data. present argument z         ignored. truth numeric character vector giving known         classification data point.         classification         z also present,          used displaying classification errors. uncertainty numeric vector values (0,1) giving         uncertainty data point. present argument z         ignored. Choose one following three options: \"classification\"     (default), \"error\", \"uncertainty\". addEllipses logical indicating whether add ellipses axes      corresponding within-cluster covariances. fillEllipses logical specifying whether fill ellipses transparent     colors addEllipses = TRUE. symbols Either integer character vector assigning plotting symbol     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotColors\"). xlim, ylim Optional argument specifying bounds ordinate, abscissa plot.     may useful comparing plots. xlab, ylab Optional argument specifying labels x-axis y-axis. scale logical variable indicating whether two chosen     dimensions plotted scale,     thus preserve shape distribution.     Default: scale=FALSE cex argument specifying size plotting symbols.      default value 1. PCH argument specifying symbol used classificatiion     specified data. default value small dot \".\". main logical variable NULL indicating whether add title      plot identifying dimensions used. swapAxes logical variable indicating whether axes swapped     plot. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclust2Dplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","text":"plot showing data, together location mixture components, classification, uncertainty, /classification errors.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclust2Dplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot two-dimensional data modelled by an MVN mixture — mclust2Dplot","text":"","code":"# \\donttest{ faithfulModel <- Mclust(faithful)  mclust2Dplot(faithful, parameters=faithfulModel$parameters,               z=faithfulModel$z, what = \"classification\", main = TRUE)   mclust2Dplot(faithful, parameters=faithfulModel$parameters,               z=faithfulModel$z, what = \"uncertainty\", main = TRUE)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBIC.html","id":null,"dir":"Reference","previous_headings":"","what":"BIC for Model-Based Clustering — mclustBIC","title":"BIC for Model-Based Clustering — mclustBIC","text":"BIC parameterized Gaussian mixture models fitted EM algorithm initialized model-based hierarchical clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BIC for Model-Based Clustering — mclustBIC","text":"","code":"mclustBIC(data, G = NULL, modelNames = NULL,            prior = NULL, control = emControl(),            initialization = list(hcPairs = NULL,                                  subset = NULL,                                  noise = NULL),            Vinv = NULL, warn = mclust.options(\"warn\"),            x = NULL, verbose = interactive(),            ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BIC for Model-Based Clustering — mclustBIC","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. G integer vector specifying numbers mixture components     (clusters) BIC calculated.      default G=1:9, unless argument x specified,      case default taken values associated      x. modelNames vector character strings indicating models fitted      EM phase clustering. help file     mclustModelNames describes available models.     default : c(\"E\", \"V\") univariate data mclust.options(\"emModelNames\") multivariate data (n > d) c(\"EII\", \"VII\", \"EEI\", \"EVI\", \"VEI\", \"VVI\") spherical diagonal models multivariate data (n <= d) unless argument x specified, case     default taken values associated x. prior default assumes prior, argument allows specification      conjugate prior means variances function      priorControl. control list control parameters EM. defaults set call     emControl(). initialization list containing zero following components: hcPairs matrix merge pairs hierarchical clustering produced     function hc.      multivariate data, default compute hierarchical      agglomerative clustering tree applying function hc      model specified mclust.options(\"hcModelName\"),     data transformation set mclust.options(\"hcUse\").     input subset indicated subset argument      used initial clustering.     hierarchical clustering results used start EM     algorithm given partition.     univariate data, default use quantiles start EM     algorithm. However, hierarchical clustering also used      calling hc model specified \"V\" \"E\". subset logical numeric vector specifying subset data     used initial hierarchical clustering phase.     default subset used unless number observations exceeds      value specified mclust.options(\"subset\").      subset argument ignored hcPairs provided.     Note guarantee exact reproducibility results seed must      specified (see set.seed). noise logical numeric vector indicating initial guess     observations noise data. numeric entries     correspond row indexes data. supplied, noise     term added model estimation.  Vinv estimate reciprocal hypervolume data region.     default determined applying function hypvol data.      Used initial guess observations noise      supplied. warn logical value indicating whether certain warnings     (usually related singularity) issued      estimation fails.       default controlled mclust.options. x object class 'mclustBIC'. supplied, mclustBIC      use settings x produce another object      class 'mclustBIC', G modelNames      specified arguments. Models already computed      x recomputed. arguments mclustBIC       except data, G modelName      ignored values set specified attributes      x.       Defaults G modelNames taken x. verbose logical controlling text progress bar displayed     fitting procedure. default TRUE session      interactive, FALSE otherwise. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BIC for Model-Based Clustering — mclustBIC","text":"Return object class 'mclustBIC' containing Bayesian Information Criterion specified mixture models numbers clusters.  Auxiliary information returned attributes. corresponding print method shows matrix values top models according BIC criterion.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustBIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BIC for Model-Based Clustering — mclustBIC","text":"","code":"irisBIC <- mclustBIC(iris[,-5]) irisBIC #> Bayesian Information Criterion (BIC):  #>          EII        VII        EEI        VEI        EVI        VVI       EEE #> 1 -1804.0854 -1804.0854 -1522.1202 -1522.1202 -1522.1202 -1522.1202 -829.9782 #> 2 -1123.4117 -1012.2352 -1042.9679  -956.2823 -1007.3082  -857.5515 -688.0972 #> 3  -878.7650  -853.8144  -813.0504  -779.1566  -797.8342  -744.6382 -632.9647 #> 4  -893.6140  -812.6048  -827.4036  -748.4529  -837.5452  -751.0198 -646.0258 #> 5  -782.6441  -742.6083  -741.9185  -688.3463  -766.8158  -711.4502 -604.8131 #> 6  -715.7136  -705.7811  -693.7908  -676.1697  -774.0673  -707.2901 -609.8543 #> 7  -731.8821  -698.5413  -713.1823  -680.7377  -813.5220  -766.6500 -632.4947 #> 8  -725.0805  -701.4806  -691.4133  -679.4640  -740.4068  -764.1969 -639.2640 #> 9  -694.5205  -700.0276  -696.2607  -702.0143  -767.8044  -755.8290 -653.0878 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 #> 2 -656.3270 -657.2263 -605.1841 -644.5997 -561.7285 -658.3306 -574.0178 #> 3 -605.3982 -666.5491 -636.4259 -644.7810 -562.5522 -656.0359 -580.8396 #> 4 -604.8371 -705.5435 -639.7078 -699.8684 -602.0104 -725.2925 -630.6000 #> 5        NA -723.7199 -632.2056 -652.2959 -634.2890        NA -676.6061 #> 6 -609.5584 -661.9497 -664.8224 -664.4537 -679.5116        NA -754.7938 #> 7        NA -699.5102 -690.6108 -709.9530 -704.7699 -809.8276 -806.9277 #> 8 -654.8237 -700.4277 -709.9392 -735.4463 -712.8788 -831.7520 -830.6373 #> 9        NA -729.6651 -734.2997 -758.9348 -748.8237 -882.4391 -883.6931 #>  #> Top 3 models based on the BIC criterion:  #>     VEV,2     VEV,3     VVV,2  #> -561.7285 -562.5522 -574.0178  plot(irisBIC)   # \\donttest{ subset <- sample(1:nrow(iris), 100) irisBIC <- mclustBIC(iris[,-5], initialization=list(subset = subset)) irisBIC #> Bayesian Information Criterion (BIC):  #>          EII        VII        EEI        VEI        EVI        VVI       EEE #> 1 -1804.0854 -1804.0854 -1522.1202 -1522.1202 -1522.1202 -1522.1202 -829.9782 #> 2 -1123.4117 -1012.2352 -1042.9679  -956.2823 -1007.3082  -857.5515 -688.0972 #> 3  -878.7659  -853.8165  -813.0533  -779.1559  -797.8342  -744.6368 -632.9660 #> 4  -784.3112  -783.8307  -735.4850  -716.5264  -732.5176  -705.0711 -591.4084 #> 5  -782.6521  -742.6090  -741.9032  -688.3482  -766.9567  -701.0654 -604.8035 #> 6  -715.7154  -705.7822  -693.7986  -676.1748  -722.1504  -696.9013 -615.4926 #> 7  -712.0972  -708.7218  -671.6761  -666.8674  -704.1598  -703.6990 -617.6082 #> 8  -725.0789  -701.4827  -691.4089  -679.4849  -740.4069  -763.6683 -639.2614 #> 9  -733.3455  -715.6034  -700.3356  -696.7088         NA         NA -646.0805 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 -829.9782 #> 2 -656.3270 -657.2263 -605.1837 -644.5997 -561.7285 -658.3306 -574.0178 #> 3 -605.3979 -616.9866 -598.5722 -617.7016 -562.5518 -621.5195 -580.8401 #> 4 -611.9257 -648.3776 -618.0512 -645.1510 -583.8280 -661.5276 -650.2903 #> 5        NA -680.9392 -636.3978 -692.2011 -627.1185 -728.5995 -665.6503 #> 6 -609.3415 -681.3988 -679.8025 -651.3897 -680.4273 -733.8353 -734.6344 #> 7 -616.0475 -677.4451 -684.8859 -686.0076 -701.0669 -761.7705 -759.0121 #> 8 -626.1436 -709.8801 -712.8556 -728.4795 -737.0126 -821.8125 -822.0800 #> 9        NA        NA        NA -768.6726 -752.7622        NA        NA #>  #> Top 3 models based on the BIC criterion:  #>     VEV,2     VEV,3     VVV,2  #> -561.7285 -562.5518 -574.0178  plot(irisBIC)   irisBIC1 <- mclustBIC(iris[,-5], G=seq(from=1,to=9,by=2),                      modelNames=c(\"EII\", \"EEI\", \"EEE\")) irisBIC1 #> Bayesian Information Criterion (BIC):  #>          EII        EEI       EEE #> 1 -1804.0854 -1522.1202 -829.9782 #> 3  -878.7650  -813.0504 -632.9647 #> 5  -782.6441  -741.9185 -604.8131 #> 7  -731.8821  -713.1823 -632.4947 #> 9  -694.5205  -696.2607 -653.0878 #>  #> Top 3 models based on the BIC criterion:  #>     EEE,5     EEE,7     EEE,3  #> -604.8131 -632.4947 -632.9647  plot(irisBIC1)  irisBIC2  <- mclustBIC(iris[,-5], G=seq(from=2,to=8,by=2),                         modelNames=c(\"VII\", \"VVI\", \"VVV\"), x= irisBIC1) irisBIC2 #> Bayesian Information Criterion (BIC):  #>          VII       VVI       VVV #> 2 -1012.2352 -857.5515 -574.0178 #> 4  -812.6048 -751.0198 -630.6000 #> 6  -705.7811 -707.2901 -754.7938 #> 8  -701.4806 -764.1969 -830.6373 #>  #> Top 3 models based on the BIC criterion:  #>     VVV,2     VVV,4     VII,8  #> -574.0178 -630.6000 -701.4806  plot(irisBIC2)  # }  nNoise <- 450 set.seed(0) poissonNoise <- apply(apply( iris[,-5], 2, range), 2, function(x, n)                        runif(n, min = x[1]-.1, max = x[2]+.1), n = nNoise) set.seed(0) noiseInit <- sample(c(TRUE,FALSE),size=nrow(iris)+nNoise,replace=TRUE,                     prob=c(3,1)) irisNdata <- rbind(iris[,-5], poissonNoise) irisNbic <- mclustBIC(data = irisNdata, G = 1:5,                       initialization = list(noise = noiseInit)) irisNbic #> Bayesian Information Criterion (BIC):  #>         EII       VII       EEI       VEI       EVI       VVI       EEE #> 1 -5977.328 -5977.328 -5970.295 -5970.295 -5970.295 -5970.295 -5818.060 #> 2 -5825.418 -5811.834 -5793.901 -5794.428 -5793.223 -5771.583 -5729.552 #> 3 -5784.436 -5776.384 -5759.590 -5758.183 -5760.461 -5761.447 -5680.523 #> 4 -5742.152 -5800.378 -5783.724 -5735.333 -5800.756 -5806.164 -5700.137 #> 5 -5762.520 -5785.749 -5747.083 -5767.262 -5781.001 -5835.520 -5708.260 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -5818.060 -5818.031 -5818.031 -5818.060 -5818.060 -5818.060 -5818.060 #> 2 -5701.834 -5712.321 -5691.272 -5703.614 -5668.290 -5716.434 -5681.315 #> 3 -5676.189 -5729.474 -5719.089 -5728.321 -5735.599 -5760.094 -5742.833 #> 4 -5704.279 -5726.343 -5764.130 -5776.571 -5790.380 -5845.565 -5823.840 #> 5 -5721.212 -5783.338 -5802.206 -5808.419 -5834.126 -5874.462 -5892.635 #>  #> Top 3 models based on the BIC criterion:  #>     VEV,2     VEE,3     EEE,3  #> -5668.290 -5676.189 -5680.523  plot(irisNbic)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBICupdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","title":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","text":"Update BIC (Bayesian Information Criterion) parameterized Gaussian  mixture models taking best BIC results returned mclustBIC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBICupdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","text":"","code":"mclustBICupdate(BIC, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBICupdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","text":"BIC Object class 'mclustBIC' containing    BIC values returned call mclustBIC. ... objects class 'mclustBIC' merged.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBICupdate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","text":"object class 'mclustBIC' containing best values obtained merging input arguments. Attributes also updated according best BIC found, calling Mclust resulting ouput return corresponding best model (see example).","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustBICupdate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update BIC values for parameterized Gaussian mixture models — mclustBICupdate","text":"","code":"# \\donttest{ data(galaxies, package = \"MASS\")  galaxies <- galaxies / 1000  # use several random starting points BIC <- NULL for(j in 1:100) {   rBIC <- mclustBIC(galaxies, verbose = FALSE,                     initialization = list(hcPairs = hcRandomPairs(galaxies)))   BIC <- mclustBICupdate(BIC, rBIC) } pickBIC(BIC) #>       V,3       V,5       V,4  #> -441.6122 -441.8364 -443.3891  plot(BIC)   mod <- Mclust(galaxies, x = BIC) summary(mod) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust V (univariate, unequal variance) model with 3 components:  #>  #>  log-likelihood  n df       BIC       ICL #>       -203.1792 82  8 -441.6122 -441.6126 #>  #> Clustering table: #>  1  2  3  #> 72  7  3  # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"Perform likelihood ratio test (LRT) assessing number mixture components specific finite mixture model parameterisation. observed significance approximated using (parametric) bootstrap likelihood ratio test statistic (LRTS).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"","code":"mclustBootstrapLRT(data, modelName = NULL, nboot = 999, level = 0.05, maxG = NULL,                     verbose = interactive(), ...)                     # S3 method for mclustBootstrapLRT print(x, ...)  # S3 method for mclustBootstrapLRT plot(x, G = 1, hist.col = \"grey\", hist.border = \"lightgrey\", breaks = \"Scott\",      col = \"forestgreen\", lwd = 2, lty = 3, main = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. modelName character string indicating mixture model fitted.    help file mclustModelNames describes available models. nboot number bootstrap replications use (default 999). level significance level used terminate sequential bootstrap procedure. maxG maximum number mixture components \\(G\\) test. provided   procedure stopped test significant specified level. verbose logical controlling text progress bar displayed bootstrap procedure. default TRUE session interactive, FALSE otherwise. ... arguments passed methods. particular, see optional arguments  mclustBIC. x 'mclustBootstrapLRT' object. G value specifying number components plot             bootstrap distribution. hist.col colour used fill bars histogram. hist.border color border around bars histogram. breaks See argument function hist. col, lwd, lty color, line width line type used represent observed LRT statistic. main title graph.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"implemented algorithm computing LRT observed significance using bootstrap following. Let \\(G_0\\) number mixture components null hypothesis versus \\(G_1 = G_0+1\\) alternative. Bootstrap samples drawn simulating data null hypothesis. , p-value may approximated using eq. (13) McLachlan Rathnayake (2014). Equivalently, using notation Davison Hinkley (1997) may computed $$\\textnormal{p-value} = \\frac{1 + \\#\\{LRT^*_b \\ge LRTS_{obs}\\}}{B+1}$$  \\(B\\) = number bootstrap samples  \\(LRT_{obs}\\) = LRTS computed observed data \\(LRT^*_b\\) = LRTS computed \\(b\\)th bootstrap sample.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"object class 'mclustBootstrapLRT' following components: G vector number components tested null hypothesis. modelName character string specifying mixture model provided                     function call (see ). obs observed values LRTS. boot matrix dimension nboot x number components tested                containing bootstrap values LRTS. p.value vector p-values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"Davison, . Hinkley, D. (1997) Bootstrap Methods Applications. Cambridge University Press. McLachlan G.J. (1987) bootstrapping likelihood ratio test statistic number components normal mixture. Applied Statistics, 36, 318-324. McLachlan, G.J. Peel, D. (2000) Finite Mixture Models. Wiley. McLachlan, G.J. Rathnayake, S. (2014) number components Gaussian mixture model. Wiley Interdisciplinary Reviews: Data Mining Knowledge Discovery, 4(5), pp. 341-355.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustBootstrapLRT.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap Likelihood Ratio Test for the Number of Mixture Components — mclustBootstrapLRT","text":"","code":"# \\donttest{ data(faithful) faithful.boot = mclustBootstrapLRT(faithful, model = \"VVV\") faithful.boot #> -------------------------------------------------------------  #> Bootstrap sequential LRT for the number of mixture components  #> -------------------------------------------------------------  #> Model        = VVV  #> Replications = 999  #>                LRTS bootstrap p-value #> 1 vs 2   319.065354             0.001 #> 2 vs 3     6.130516             0.560 plot(faithful.boot, G = 1)  plot(faithful.boot, G = 2)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":null,"dir":"Reference","previous_headings":"","what":"ICL Criterion for Model-Based Clustering — mclustICL","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"ICL (Integrated Complete-data Likelihood) parameterized Gaussian mixture models fitted EM algorithm initialized model-based hierarchical clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"","code":"mclustICL(data, G = NULL, modelNames = NULL,            initialization = list(hcPairs = NULL,                                  subset = NULL,                                  noise = NULL),            x = NULL, ...)  # S3 method for mclustICL summary(object, G, modelNames, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. G integer vector specifying numbers mixture components     (clusters) criteria calculated.      default G = 1:9. modelNames vector character strings indicating models fitted      EM phase clustering. help file      mclustModelNames describes available models.     default : c(\"E\", \"V\") univariate data mclust.options(\"emModelNames\") multivariate data (n > d) c(\"EII\", \"VII\", \"EEI\", \"EVI\", \"VEI\", \"VVI\") spherical diagonal models multivariate data (n <= d)  initialization list containing zero following components: hcPairs matrix merge pairs hierarchical clustering produced     function hc. multivariate data, default compute     hierarchical clustering tree applying function hc     modelName = \"VVV\" data subset indicated     subset argument.     hierarchical clustering results start EM.     univariate data, default use quantiles start EM. subset logical numeric vector specifying subset data     used initial hierarchical clustering phase.  x object class 'mclustICL'. supplied, mclustICL      use settings x produce another object      class 'mclustICL', G modelNames      specified arguments. Models already computed      x recomputed. arguments mclustICL       except data, G modelName      ignored values set specified attributes      x.       Defaults G modelNames taken x. ... Futher arguments used call Mclust.      See also mclustBIC. object integer vector specifying numbers mixture components     (clusters) criteria calculated.      default G = 1:9.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"Returns object class 'mclustICL' containing ICL criterion  specified mixture models numbers clusters. corresponding print method shows matrix values top models according ICL criterion. summary method shows top models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"Biernacki, C., Celeux, G., Govaert, G. (2000).  Assessing mixture model clustering integrated completed likelihood. IEEE Trans. Pattern Analysis Machine Intelligence, 22 (7), 719-725. Scrucca L., Fop M., Murphy T. B. Raftery . E. (2016) mclust 5: clustering, classification density estimation using Gaussian finite mixture models, R Journal, 8/1, pp. 289-317.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustICL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ICL Criterion for Model-Based Clustering — mclustICL","text":"","code":"data(faithful) faithful.ICL <- mclustICL(faithful) faithful.ICL #> Integrated Complete-data Likelihood (ICL) criterion:  #>         EII       VII       EEI       VEI       EVI       VVI       EEE #> 1 -4024.721 -4024.721 -3055.835 -3055.835 -3055.835 -3055.835 -2607.623 #> 2 -3455.814 -3460.903 -2356.273 -2350.728 -2353.254 -2346.161 -2326.710 #> 3 -3422.758 -3360.264 -2359.458 -2377.306 -2367.537 -2387.744 -2357.824 #> 4 -3265.796 -3272.457 -2371.996 -2413.391 -2402.189 -2436.318 -2468.261 #> 5 -3190.702 -3151.887 -2394.022 -2486.702 -2412.390 -2445.754 -2478.220 #> 6 -3117.441 -3061.335 -2423.024 -2486.795 -2446.878 -2472.624 -2456.239 #> 7 -3022.312 -2995.759 -2476.203 -2519.776 -2446.706 -2496.750 -2464.343 #> 8 -3007.364 -2953.728 -2488.504 -2513.529 -2492.319 -2509.675 -2502.177 #> 9 -2989.092 -2933.144 -2499.876 -2540.432 -2515.042 -2528.602 -2547.111 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 #> 2 -2323.396 -2325.768 -2320.763 -2330.000 -2325.727 -2328.163 -2322.697 #> 3 -2376.466 -2412.034 -2427.038 -2372.365 -2405.333 -2380.322 -2385.244 #> 4 -2452.689 -2459.430 -2440.279 -2414.165 -2419.889 -2385.843 -2407.555 #> 5 -2472.038 -2444.255 -2478.628 -2431.096 -2490.222 -2423.174 -2474.493 #> 6 -2503.936 -2504.770 -2489.104 -2449.583 -2481.393 -2483.772 -2491.597 #> 7 -2466.783 -2499.326 -2496.300 -2465.693 -2506.829 -2490.131 -2519.470 #> 8 -2479.790 -2526.028 -2516.572 -2489.431 -2539.783 -2497.812 -2556.115 #> 9 -2499.921 -2545.663 -2541.675 -2542.877 -2566.735 -2528.600 -2587.235 #>  #> Top 3 models based on the ICL criterion:  #>     VVE,2     VVV,2     VEE,2  #> -2320.763 -2322.697 -2323.396  summary(faithful.ICL) #> Best ICL values: #>              VVE,2        VVV,2       VEE,2 #> ICL      -2320.763 -2322.697467 -2323.39551 #> ICL diff     0.000    -1.934645    -2.63269 plot(faithful.ICL)  # \\donttest{ # compare with faithful.BIC <- mclustBIC(faithful) faithful.BIC #> Bayesian Information Criterion (BIC):  #>         EII       VII       EEI       VEI       EVI       VVI       EEE #> 1 -4024.721 -4024.721 -3055.835 -3055.835 -3055.835 -3055.835 -2607.623 #> 2 -3452.998 -3458.305 -2354.601 -2350.607 -2352.618 -2346.065 -2325.220 #> 3 -3377.701 -3336.598 -2323.014 -2332.687 -2332.205 -2342.366 -2314.316 #> 4 -3230.264 -3242.826 -2323.673 -2331.284 -2334.749 -2343.486 -2331.223 #> 5 -3149.394 -3129.080 -2327.059 -2350.230 -2347.564 -2351.017 -2360.659 #> 6 -3081.414 -3038.171 -2338.205 -2360.578 -2357.660 -2373.469 -2347.352 #> 7 -2990.367 -2973.374 -2356.454 -2368.513 -2372.851 -2394.696 -2369.330 #> 8 -2978.100 -2935.082 -2364.140 -2384.740 -2389.064 -2413.705 -2376.104 #> 9 -2953.359 -2919.415 -2372.790 -2398.223 -2407.224 -2432.708 -2389.609 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 -2607.623 #> 2 -2322.972 -2324.273 -2320.433 -2329.115 -2325.416 -2327.598 -2322.192 #> 3 -2322.103 -2342.319 -2336.271 -2325.322 -2329.648 -2339.983 -2349.696 #> 4 -2340.173 -2361.821 -2362.487 -2351.523 -2361.084 -2344.686 -2351.493 #> 5 -2347.337 -2351.828 -2368.937 -2356.856 -2368.101 -2364.900 -2379.388 #> 6 -2372.287 -2366.482 -2386.537 -2366.087 -2386.323 -2384.117 -2387.016 #> 7 -2371.175 -2379.810 -2402.220 -2379.071 -2401.270 -2398.703 -2412.440 #> 8 -2390.391 -2403.934 -2425.956 -2392.988 -2425.426 -2414.962 -2442.018 #> 9 -2406.732 -2414.089 -2448.208 -2407.500 -2446.726 -2438.876 -2460.398 #>  #> Top 3 models based on the BIC criterion:  #>     EEE,3     VVE,2     VEE,3  #> -2314.316 -2320.433 -2322.103  plot(faithful.BIC)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclustLoglik.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","title":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","text":"Compute maximal log-likelihood table BIC values contained 'mclustBIC' object returned function mclustBIC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustLoglik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","text":"","code":"mclustLoglik(object, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustLoglik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","text":"object object class 'mclustBIC' containing    BIC values returned call mclustBIC. ... Catches unused arguments indirect list call via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustLoglik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","text":"object class 'mclustLoglik' containing maximal log-likelihood values Gaussian mixture models provided input.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustLoglik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-likelihood from a table of BIC values for parameterized Gaussian mixture models — mclustLoglik","text":"","code":"# \\donttest{ BIC <- mclustBIC(iris[,1:4]) mclustLoglik(BIC) #> Log-likelihood:  #>         EII       VII       EEI       VEI       EVI       VVI       EEE #> 1 -889.5161 -889.5161 -741.0175 -741.0175 -741.0175 -741.0175 -379.9146 #> 2 -536.6527 -478.5591 -488.9148 -443.0667 -463.5690 -386.1853 -296.4476 #> 3 -401.8027 -384.3168 -361.4295 -339.4719 -338.7895 -307.1808 -256.3547 #> 4 -396.7007 -348.6801 -356.0795 -309.0882 -338.6024 -287.8238 -250.3587 #> 5 -328.6891 -298.6500 -300.8103 -264.0030 -283.1952 -245.4911 -217.2257 #> 6 -282.6973 -265.2044 -264.2199 -242.8828 -266.7784 -220.8632 -207.2198 #> 7 -278.2550 -246.5526 -261.3891 -230.1349 -266.4632 -227.9953 -206.0134 #> 8 -262.3275 -232.9904 -237.9780 -214.4661 -209.8631 -204.2209 -196.8715 #> 9 -234.5210 -217.2319 -227.8751 -210.7094 -203.5193 -177.4891 -191.2567 #>         VEE       EVE       VVE       EEV       VEV       EVV       VVV #> 1 -379.9146 -379.9146 -379.9146 -379.9146 -379.9146 -379.9146 -379.9146 #> 2 -278.0572 -273.4962 -244.9697 -259.6669 -215.7260 -259.0164 -214.3547 #> 3 -237.5609 -258.1150 -238.0428 -232.1991 -186.0740 -222.7946 -180.1858 #> 4 -222.2484 -257.5697 -217.1359 -232.1843 -175.7393 -222.3485 -167.4862 #> 5        NA -246.6153 -190.8369 -180.8395 -161.8148        NA -152.9095 #> 6 -194.5452 -195.6877 -184.5974 -159.3600 -154.3623        NA -154.4236 #> 7        NA -194.4254 -174.9438 -154.5511 -136.9276 -159.3927 -142.9108 #> 8 -187.1141 -174.8416 -162.0602 -139.7393 -110.9183 -135.2804 -117.1858 #> 9        NA -169.4178 -151.6925 -123.9250  -98.8269 -125.5495 -106.1340 # }"},{"path":"https://mclust-org.github.io/mclust/reference/mclustModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Best model based on BIC — mclustModel","title":"Best model based on BIC — mclustModel","text":"Determines best model clustering via mclustBIC   given set model parameterizations numbers components.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best model based on BIC — mclustModel","text":"","code":"mclustModel(data, BICvalues, G, modelNames, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best model based on BIC — mclustModel","text":"data matrix vector observations used generate `object'. BICvalues 'mclustBIC' object,      result applying mclustBIC      data. G vector integers giving numbers mixture components (clusters)     best model according BIC selected     (.character(G) must subset row names       BICvalues).     default select best model numbers      mixture components used obtain BICvalues. modelNames vector integers giving model parameterizations     best model according BIC selected     (.character(model) must subset column names       BICvalues).     default select best model parameterizations     used obtain BICvalues. ... used. generic/method consistency.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Best model based on BIC — mclustModel","text":"list giving optimal (according BIC) parameters,   conditional probabilities z, log-likelihood,   together associated classification uncertainty. details output components follows: modelName character string indicating model. help file     mclustModelNames describes available models. n number observations data. d dimension data. G number components Gaussian mixture model corresponding     optimal BIC. bic optimal BIC value. loglik log-likelihood corresponding optimal BIC. parameters list following components: pro vector whose kth component mixing proportion               kth component mixture model.               missing, equal proportions assumed. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  z matrix whose [,k]th entry probability observation     test data belongs kth class.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Best model based on BIC — mclustModel","text":"","code":"irisBIC <- mclustBIC(iris[,-5]) mclustModel(iris[,-5], irisBIC) #> $modelName #> [1] \"VEV\" #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 2 #>  #> $bic #> [1] -561.7285 #>  #> $loglik #> [1] -215.726 #>  #> $parameters #> $parameters$pro #> [1] 0.3333319 0.6666681 #>  #> $parameters$mean #>                   [,1]     [,2] #> Sepal.Length 5.0060022 6.261996 #> Sepal.Width  3.4280049 2.871999 #> Petal.Length 1.4620007 4.905992 #> Petal.Width  0.2459998 1.675997 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VEV\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 2 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.15065114  0.13080115   0.02084463  0.01309107 #> Sepal.Width    0.13080115  0.17604529   0.01603245  0.01221458 #> Petal.Length   0.02084463  0.01603245   0.02808260  0.00601568 #> Petal.Width    0.01309107  0.01221458   0.00601568  0.01042365 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.4000438  0.10865444    0.3994018  0.14368256 #> Sepal.Width     0.1086544  0.10928077    0.1238904  0.07284384 #> Petal.Length    0.3994018  0.12389040    0.6109024  0.25738990 #> Petal.Width     0.1436826  0.07284384    0.2573899  0.16808182 #>  #>  #> $parameters$variance$scale #> [1] 0.0377238 0.1330765 #>  #> $parameters$variance$shape #> [1] 7.9106959 0.9228733 0.6299550 0.2174371 #>  #> $parameters$variance$orientation #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  -0.66908566   0.5978655   -0.4399773 -0.03607204 #> Sepal.Width   -0.73414108  -0.6206713    0.2746297 -0.01955857 #> Petal.Length  -0.09654297   0.4900812    0.8324338 -0.23990403 #> Petal.Width   -0.06356659   0.1309366    0.1950707  0.96992903 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.5565148  0.75863444 -0.006116263  -0.3387148 #> Sepal.Width     0.1865004  0.02937396 -0.901899502   0.3884997 #> Petal.Length    0.7428959 -0.33350461  0.344100463   0.4674134 #> Petal.Width     0.3218923 -0.55891469 -0.261026344  -0.7182374 #>  #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $z #>                 [,1]         [,2] #>   [1,]  1.000000e+00 2.513256e-11 #>   [2,]  9.999999e-01 5.556629e-08 #>   [3,]  1.000000e+00 3.635567e-09 #>   [4,]  9.999999e-01 8.612037e-08 #>   [5,]  1.000000e+00 8.504814e-12 #>   [6,]  1.000000e+00 1.400416e-12 #>   [7,]  1.000000e+00 2.971743e-09 #>   [8,]  1.000000e+00 4.053088e-10 #>   [9,]  9.999993e-01 6.585467e-07 #>  [10,]  9.999999e-01 7.276067e-08 #>  [11,]  1.000000e+00 1.189599e-12 #>  [12,]  1.000000e+00 3.285947e-09 #>  [13,]  9.999999e-01 1.034990e-07 #>  [14,]  9.999998e-01 1.791935e-07 #>  [15,]  1.000000e+00 2.623274e-16 #>  [16,]  1.000000e+00 1.665011e-18 #>  [17,]  1.000000e+00 2.857132e-14 #>  [18,]  1.000000e+00 3.517596e-11 #>  [19,]  1.000000e+00 2.111154e-12 #>  [20,]  1.000000e+00 9.845182e-13 #>  [21,]  1.000000e+00 6.254470e-09 #>  [22,]  1.000000e+00 1.579205e-11 #>  [23,]  1.000000e+00 1.159139e-10 #>  [24,]  9.999995e-01 4.953933e-07 #>  [25,]  9.999989e-01 1.061700e-06 #>  [26,]  9.999994e-01 5.954046e-07 #>  [27,]  1.000000e+00 6.015651e-09 #>  [28,]  1.000000e+00 5.309896e-11 #>  [29,]  1.000000e+00 1.021530e-10 #>  [30,]  9.999999e-01 6.263700e-08 #>  [31,]  9.999998e-01 1.604474e-07 #>  [32,]  1.000000e+00 6.134473e-10 #>  [33,]  1.000000e+00 5.534184e-15 #>  [34,]  1.000000e+00 3.165137e-17 #>  [35,]  1.000000e+00 3.683247e-08 #>  [36,]  1.000000e+00 1.058361e-09 #>  [37,]  1.000000e+00 9.055560e-12 #>  [38,]  1.000000e+00 2.144971e-11 #>  [39,]  9.999999e-01 1.445739e-07 #>  [40,]  1.000000e+00 3.176730e-10 #>  [41,]  1.000000e+00 3.224240e-11 #>  [42,]  9.997974e-01 2.025712e-04 #>  [43,]  1.000000e+00 2.424854e-08 #>  [44,]  9.999997e-01 3.077601e-07 #>  [45,]  1.000000e+00 2.213493e-09 #>  [46,]  9.999999e-01 9.248798e-08 #>  [47,]  1.000000e+00 2.393976e-12 #>  [48,]  1.000000e+00 1.123879e-08 #>  [49,]  1.000000e+00 1.458995e-12 #>  [50,]  1.000000e+00 6.608732e-10 #>  [51,]  5.013996e-97 1.000000e+00 #>  [52,]  1.064131e-88 1.000000e+00 #>  [53,] 2.002769e-110 1.000000e+00 #>  [54,]  2.021014e-68 1.000000e+00 #>  [55,]  5.251038e-98 1.000000e+00 #>  [56,]  5.873800e-85 1.000000e+00 #>  [57,] 4.044755e-100 1.000000e+00 #>  [58,]  3.692996e-36 1.000000e+00 #>  [59,]  1.711073e-91 1.000000e+00 #>  [60,]  2.496491e-65 1.000000e+00 #>  [61,]  1.718670e-44 1.000000e+00 #>  [62,]  1.255500e-77 1.000000e+00 #>  [63,]  1.580921e-64 1.000000e+00 #>  [64,]  6.715502e-97 1.000000e+00 #>  [65,]  3.284253e-50 1.000000e+00 #>  [66,]  2.488880e-83 1.000000e+00 #>  [67,]  5.063871e-90 1.000000e+00 #>  [68,]  2.134991e-62 1.000000e+00 #>  [69,]  9.313637e-99 1.000000e+00 #>  [70,]  5.368204e-58 1.000000e+00 #>  [71,] 1.593168e-114 1.000000e+00 #>  [72,]  1.544262e-65 1.000000e+00 #>  [73,] 1.093577e-114 1.000000e+00 #>  [74,]  1.254390e-92 1.000000e+00 #>  [75,]  2.218319e-77 1.000000e+00 #>  [76,]  4.064949e-84 1.000000e+00 #>  [77,] 5.126083e-106 1.000000e+00 #>  [78,] 8.081566e-123 1.000000e+00 #>  [79,]  5.062549e-91 1.000000e+00 #>  [80,]  8.744165e-42 1.000000e+00 #>  [81,]  5.434987e-55 1.000000e+00 #>  [82,]  2.182395e-49 1.000000e+00 #>  [83,]  3.129395e-59 1.000000e+00 #>  [84,] 3.734291e-125 1.000000e+00 #>  [85,]  2.775862e-90 1.000000e+00 #>  [86,]  2.764222e-90 1.000000e+00 #>  [87,] 7.510173e-100 1.000000e+00 #>  [88,]  5.994677e-88 1.000000e+00 #>  [89,]  8.912310e-67 1.000000e+00 #>  [90,]  7.231734e-67 1.000000e+00 #>  [91,]  3.262253e-79 1.000000e+00 #>  [92,]  2.747440e-91 1.000000e+00 #>  [93,]  8.120502e-64 1.000000e+00 #>  [94,]  8.983340e-37 1.000000e+00 #>  [95,]  4.355364e-73 1.000000e+00 #>  [96,]  7.803931e-68 1.000000e+00 #>  [97,]  1.572709e-71 1.000000e+00 #>  [98,]  1.267390e-76 1.000000e+00 #>  [99,]  1.592626e-30 1.000000e+00 #> [100,]  1.810229e-68 1.000000e+00 #> [101,] 2.738152e-219 1.000000e+00 #> [102,] 3.179495e-138 1.000000e+00 #> [103,] 6.128766e-193 1.000000e+00 #> [104,] 2.393731e-159 1.000000e+00 #> [105,] 1.229207e-190 1.000000e+00 #> [106,] 1.049682e-242 1.000000e+00 #> [107,] 4.074631e-103 1.000000e+00 #> [108,] 1.165356e-208 1.000000e+00 #> [109,] 1.375100e-177 1.000000e+00 #> [110,] 1.922118e-221 1.000000e+00 #> [111,] 5.753408e-139 1.000000e+00 #> [112,] 1.661327e-149 1.000000e+00 #> [113,] 2.522136e-168 1.000000e+00 #> [114,] 3.502666e-140 1.000000e+00 #> [115,] 3.351376e-168 1.000000e+00 #> [116,] 6.720655e-167 1.000000e+00 #> [117,] 5.175344e-153 1.000000e+00 #> [118,] 1.008251e-242 1.000000e+00 #> [119,] 7.666712e-282 1.000000e+00 #> [120,] 2.119278e-121 1.000000e+00 #> [121,] 5.006541e-189 1.000000e+00 #> [122,] 2.454880e-133 1.000000e+00 #> [123,] 9.319185e-250 1.000000e+00 #> [124,] 3.324456e-124 1.000000e+00 #> [125,] 4.943602e-176 1.000000e+00 #> [126,] 1.245399e-183 1.000000e+00 #> [127,] 3.204034e-118 1.000000e+00 #> [128,] 6.332105e-121 1.000000e+00 #> [129,] 2.764556e-175 1.000000e+00 #> [130,] 4.206125e-167 1.000000e+00 #> [131,] 2.582052e-201 1.000000e+00 #> [132,] 4.979621e-213 1.000000e+00 #> [133,] 5.636391e-181 1.000000e+00 #> [134,] 1.534458e-121 1.000000e+00 #> [135,] 6.800824e-148 1.000000e+00 #> [136,] 1.586542e-219 1.000000e+00 #> [137,] 4.923324e-188 1.000000e+00 #> [138,] 1.132434e-151 1.000000e+00 #> [139,] 3.529233e-116 1.000000e+00 #> [140,] 7.067477e-162 1.000000e+00 #> [141,] 1.221522e-190 1.000000e+00 #> [142,] 5.085741e-158 1.000000e+00 #> [143,] 3.179495e-138 1.000000e+00 #> [144,] 9.761103e-201 1.000000e+00 #> [145,] 5.525864e-201 1.000000e+00 #> [146,] 7.088920e-164 1.000000e+00 #> [147,] 7.438019e-136 1.000000e+00 #> [148,] 3.252601e-146 1.000000e+00 #> [149,] 1.122150e-170 1.000000e+00 #> [150,] 8.593381e-131 1.000000e+00 #>  #> attr(,\"class\") #> [1] \"mclustModel\" mclustModel(iris[,-5], irisBIC, G = 1:6, modelNames = c(\"VII\", \"VVI\", \"VVV\")) #> $modelName #> [1] \"VVV\" #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 2 #>  #> $bic #> [1] -574.0178 #>  #> $loglik #> [1] -214.3547 #>  #> $parameters #> $parameters$pro #> [1] 0.3333291 0.6666709 #>  #> $parameters$mean #>                   [,1]     [,2] #> Sepal.Length 5.0060064 6.261989 #> Sepal.Width  3.4280142 2.871996 #> Petal.Length 1.4620020 4.905977 #> Petal.Width  0.2459993 1.675991 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VVV\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 2 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.12176231 0.097226044  0.016027170 0.010124469 #> Sepal.Width    0.09722604 0.140801778  0.011461848 0.009112879 #> Petal.Length   0.01602717 0.011461848  0.029556040 0.005948185 #> Petal.Width    0.01012447 0.009112879  0.005948185 0.010884100 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.4349729  0.12094155    0.4488654  0.16550230 #> Sepal.Width     0.1209416  0.10961737    0.1413800  0.07923243 #> Petal.Length    0.4488654  0.14138003    0.6748420  0.28587362 #> Petal.Width     0.1655023  0.07923243    0.2858736  0.17863487 #>  #>  #> $parameters$variance$cholsigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length  Petal.Width #> Sepal.Length   -0.3489446  -0.2786289  -0.04593042 -0.029014550 #> Sepal.Width     0.0000000   0.2513319  -0.00531447  0.004092543 #> Petal.Length    0.0000000   0.0000000  -0.16558440 -0.028005560 #> Petal.Width     0.0000000   0.0000000   0.00000000  0.096131137 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.6595247   0.1833768   0.68058911   0.2509418 #> Sepal.Width     0.0000000   0.2756634   0.06013044   0.1204931 #> Petal.Length    0.0000000   0.0000000  -0.45609737  -0.2364409 #> Petal.Width     0.0000000   0.0000000   0.00000000  -0.2126975 #>  #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $z #>                 [,1]         [,2] #>   [1,]  1.000000e+00 2.179894e-11 #>   [2,]  9.999999e-01 7.812157e-08 #>   [3,]  1.000000e+00 4.901731e-09 #>   [4,]  9.999999e-01 1.329205e-07 #>   [5,]  1.000000e+00 6.909601e-12 #>   [6,]  1.000000e+00 8.337540e-13 #>   [7,]  1.000000e+00 3.054481e-09 #>   [8,]  1.000000e+00 3.980511e-10 #>   [9,]  9.999985e-01 1.512753e-06 #>  [10,]  9.999999e-01 9.028445e-08 #>  [11,]  1.000000e+00 8.462320e-13 #>  [12,]  1.000000e+00 3.143054e-09 #>  [13,]  9.999998e-01 1.533242e-07 #>  [14,]  9.999996e-01 3.856414e-07 #>  [15,]  1.000000e+00 1.071648e-16 #>  [16,]  1.000000e+00 7.735086e-19 #>  [17,]  1.000000e+00 1.400778e-14 #>  [18,]  1.000000e+00 2.966321e-11 #>  [19,]  1.000000e+00 1.468305e-12 #>  [20,]  1.000000e+00 6.429245e-13 #>  [21,]  1.000000e+00 5.071850e-09 #>  [22,]  1.000000e+00 1.039716e-11 #>  [23,]  1.000000e+00 8.130753e-11 #>  [24,]  9.999996e-01 3.782611e-07 #>  [25,]  9.999993e-01 6.606676e-07 #>  [26,]  9.999992e-01 7.672190e-07 #>  [27,]  1.000000e+00 5.214441e-09 #>  [28,]  1.000000e+00 4.525101e-11 #>  [29,]  1.000000e+00 8.997348e-11 #>  [30,]  9.999999e-01 7.741922e-08 #>  [31,]  9.999998e-01 2.151977e-07 #>  [32,]  1.000000e+00 4.496760e-10 #>  [33,]  1.000000e+00 2.358894e-15 #>  [34,]  1.000000e+00 1.540121e-17 #>  [35,]  1.000000e+00 4.874255e-08 #>  [36,]  1.000000e+00 1.041329e-09 #>  [37,]  1.000000e+00 5.611454e-12 #>  [38,]  1.000000e+00 1.650417e-11 #>  [39,]  9.999997e-01 2.967315e-07 #>  [40,]  1.000000e+00 3.015350e-10 #>  [41,]  1.000000e+00 2.652560e-11 #>  [42,]  9.993722e-01 6.278412e-04 #>  [43,]  1.000000e+00 3.744704e-08 #>  [44,]  9.999998e-01 1.536195e-07 #>  [45,]  1.000000e+00 1.009277e-09 #>  [46,]  9.999999e-01 1.346885e-07 #>  [47,]  1.000000e+00 1.491418e-12 #>  [48,]  1.000000e+00 1.593775e-08 #>  [49,]  1.000000e+00 1.055513e-12 #>  [50,]  1.000000e+00 7.010884e-10 #>  [51,]  1.028184e-91 1.000000e+00 #>  [52,]  4.118505e-83 1.000000e+00 #>  [53,] 4.254815e-104 1.000000e+00 #>  [54,]  5.533854e-64 1.000000e+00 #>  [55,]  3.727474e-92 1.000000e+00 #>  [56,]  5.295789e-79 1.000000e+00 #>  [57,]  1.821162e-93 1.000000e+00 #>  [58,]  9.420780e-34 1.000000e+00 #>  [59,]  3.558122e-86 1.000000e+00 #>  [60,]  1.460888e-60 1.000000e+00 #>  [61,]  8.911083e-42 1.000000e+00 #>  [62,]  2.262077e-72 1.000000e+00 #>  [63,]  7.500913e-61 1.000000e+00 #>  [64,]  1.711672e-90 1.000000e+00 #>  [65,]  9.052760e-47 1.000000e+00 #>  [66,]  1.382354e-78 1.000000e+00 #>  [67,]  2.067665e-83 1.000000e+00 #>  [68,]  2.407041e-58 1.000000e+00 #>  [69,]  8.428344e-93 1.000000e+00 #>  [70,]  2.777254e-54 1.000000e+00 #>  [71,] 2.860975e-106 1.000000e+00 #>  [72,]  1.594952e-61 1.000000e+00 #>  [73,] 1.521401e-107 1.000000e+00 #>  [74,]  1.474621e-86 1.000000e+00 #>  [75,]  8.345281e-73 1.000000e+00 #>  [76,]  2.992676e-79 1.000000e+00 #>  [77,] 5.093954e-100 1.000000e+00 #>  [78,] 2.339534e-115 1.000000e+00 #>  [79,]  5.839041e-85 1.000000e+00 #>  [80,]  2.920437e-39 1.000000e+00 #>  [81,]  1.690054e-51 1.000000e+00 #>  [82,]  2.604584e-46 1.000000e+00 #>  [83,]  1.837805e-55 1.000000e+00 #>  [84,] 1.328964e-116 1.000000e+00 #>  [85,]  2.228873e-83 1.000000e+00 #>  [86,]  7.605550e-84 1.000000e+00 #>  [87,]  5.785348e-94 1.000000e+00 #>  [88,]  7.563474e-83 1.000000e+00 #>  [89,]  5.492330e-62 1.000000e+00 #>  [90,]  2.101525e-62 1.000000e+00 #>  [91,]  1.260017e-73 1.000000e+00 #>  [92,]  3.129421e-85 1.000000e+00 #>  [93,]  8.807567e-60 1.000000e+00 #>  [94,]  1.915922e-34 1.000000e+00 #>  [95,]  4.525684e-68 1.000000e+00 #>  [96,]  4.922630e-63 1.000000e+00 #>  [97,]  1.435982e-66 1.000000e+00 #>  [98,]  7.246796e-72 1.000000e+00 #>  [99,]  1.570401e-28 1.000000e+00 #> [100,]  7.753220e-64 1.000000e+00 #> [101,] 1.715600e-203 1.000000e+00 #> [102,] 2.063080e-128 1.000000e+00 #> [103,] 4.144542e-181 1.000000e+00 #> [104,] 1.802435e-148 1.000000e+00 #> [105,] 9.595656e-178 1.000000e+00 #> [106,] 2.450871e-228 1.000000e+00 #> [107,]  3.858134e-95 1.000000e+00 #> [108,] 4.501334e-196 1.000000e+00 #> [109,] 2.115792e-166 1.000000e+00 #> [110,] 2.850242e-207 1.000000e+00 #> [111,] 7.896941e-130 1.000000e+00 #> [112,] 8.635475e-140 1.000000e+00 #> [113,] 1.065583e-157 1.000000e+00 #> [114,] 2.995927e-130 1.000000e+00 #> [115,] 6.014984e-156 1.000000e+00 #> [116,] 1.855013e-155 1.000000e+00 #> [117,] 6.112142e-143 1.000000e+00 #> [118,] 5.557076e-228 1.000000e+00 #> [119,] 4.071437e-265 1.000000e+00 #> [120,] 1.582251e-113 1.000000e+00 #> [121,] 6.551920e-177 1.000000e+00 #> [122,] 1.497616e-123 1.000000e+00 #> [123,] 3.260843e-235 1.000000e+00 #> [124,] 3.221091e-116 1.000000e+00 #> [125,] 2.126742e-164 1.000000e+00 #> [126,] 1.750926e-172 1.000000e+00 #> [127,] 1.827616e-110 1.000000e+00 #> [128,] 1.157196e-112 1.000000e+00 #> [129,] 1.541398e-163 1.000000e+00 #> [130,] 2.818306e-157 1.000000e+00 #> [131,] 1.280706e-189 1.000000e+00 #> [132,] 5.515772e-201 1.000000e+00 #> [133,] 8.508603e-169 1.000000e+00 #> [134,] 1.229485e-113 1.000000e+00 #> [135,] 1.419650e-137 1.000000e+00 #> [136,] 4.920802e-207 1.000000e+00 #> [137,] 1.319075e-174 1.000000e+00 #> [138,] 2.047411e-141 1.000000e+00 #> [139,] 3.924939e-108 1.000000e+00 #> [140,] 7.842830e-152 1.000000e+00 #> [141,] 4.784736e-178 1.000000e+00 #> [142,] 4.379310e-148 1.000000e+00 #> [143,] 2.063080e-128 1.000000e+00 #> [144,] 1.527640e-187 1.000000e+00 #> [145,] 1.865711e-187 1.000000e+00 #> [146,] 2.781164e-153 1.000000e+00 #> [147,] 4.075976e-127 1.000000e+00 #> [148,] 1.085405e-136 1.000000e+00 #> [149,] 2.104379e-158 1.000000e+00 #> [150,] 2.032250e-121 1.000000e+00 #>  #> attr(,\"class\") #> [1] \"mclustModel\""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":null,"dir":"Reference","previous_headings":"","what":"MCLUST Model Names — mclustModelNames","title":"MCLUST Model Names — mclustModelNames","text":"Description model names used MCLUST package.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCLUST Model Names — mclustModelNames","text":"","code":"mclustModelNames(model)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCLUST Model Names — mclustModelNames","text":"model string specifying model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCLUST Model Names — mclustModelNames","text":"following models available package mclust: univariate mixture \"E\" equal variance (one-dimensional) \"V\" variable/unqual variance (one-dimensional) multivariate mixture \"EII\" spherical, equal volume \"VII\" spherical, unequal volume \"EEI\" diagonal, equal volume shape \"VEI\" diagonal, varying volume, equal shape \"EVI\" diagonal, equal volume, varying shape \"VVI\" diagonal, varying volume shape \"EEE\" ellipsoidal, equal volume, shape, orientation \"VEE\" ellipsoidal, equal shape orientation (*) \"EVE\" ellipsoidal, equal volume orientation (*) \"VVE\" ellipsoidal, equal orientation (*) \"EEV\" ellipsoidal, equal volume equal shape \"VEV\" ellipsoidal, equal shape \"EVV\" ellipsoidal, equal volume (*) \"VVV\" ellipsoidal, varying volume, shape, orientation single component \"X\" univariate normal \"XII\" spherical multivariate normal \"XXI\" diagonal multivariate normal \"XXX\" ellipsoidal multivariate normal (*) new models mclust version >= 5.0.0.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCLUST Model Names — mclustModelNames","text":"Returns list following components: model character string indicating model (input). type description indicated model (see Details section).","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mclustModelNames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCLUST Model Names — mclustModelNames","text":"","code":"mclustModelNames(\"E\") #> $model #> [1] \"E\" #>  #> $type #> [1] \"univariate, equal variance\" #>  mclustModelNames(\"EEE\") #> $model #> [1] \"EEE\" #>  #> $type #> [1] \"ellipsoidal, equal volume, shape and orientation\" #>  mclustModelNames(\"VVV\") #> $model #> [1] \"VVV\" #>  #> $type #> [1] \"ellipsoidal, varying volume, shape, and orientation\" #>  mclustModelNames(\"XXI\") #> $model #> [1] \"XXI\" #>  #> $type #> [1] \"diagonal multivariate normal\" #>"},{"path":"https://mclust-org.github.io/mclust/reference/mclustVariance.html","id":null,"dir":"Reference","previous_headings":"","what":"Template for variance specification for parameterized Gaussian mixture models — mclustVariance","title":"Template for variance specification for parameterized Gaussian mixture models — mclustVariance","text":"Specification variance parameters various types    Gaussian mixture models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustVariance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Template for variance specification for parameterized Gaussian mixture models — mclustVariance","text":"","code":"mclustVariance(modelName, d = NULL, G = 2)"},{"path":"https://mclust-org.github.io/mclust/reference/mclustVariance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Template for variance specification for parameterized Gaussian mixture models — mclustVariance","text":"modelName character string specifying model. d integer specifying dimension data. G integer specifying number components mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mclustVariance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Template for variance specification for parameterized Gaussian mixture models — mclustVariance","text":"variance component parameters list output e.g. mstep input e.g. estep may contain one following arguments, depending model: modelName character string indicating model. d dimension data. G number components mixture model. sigmasq one-dimensional models (\"E\", \"V\") spherical   models (\"EII\", \"VII\"). either vector whose   kth component variance kth component    mixture model (\"V\" \"VII\"), scalar giving    common variance components mixture model (\"E\"   \"EII\"). Sigma equal variance models \"EII\", \"EEI\",   \"EEE\".    d d  matrix giving common covariance     components  mixture model. cholSigma equal variance model \"EEE\".    d d upper triangular matrix giving    Cholesky factor common covariance     components  mixture model. sigma multidimensional mixture models.   d d G matrix array whose   [,,k]th entry covariance matrix   kth component mixture model. cholsigma unconstrained covariance mixture model \"VVV\".    d d G matrix array whose   [,,k]th entry upper triangular Cholesky factor   covariance matrix kth component    mixture model. scale diagonal models \"EEI\", \"EVI\", \"VEI\",      \"VVI\" constant-shape models \"EEV\" \"VEV\".     Either G-vector giving scale covariance (    dth root determinant) component     mixture model, single numeric value scale     component. shape diagonal models \"EEI\", \"EVI\", \"VEI\",      \"VVI\" constant-shape models \"EEV\" \"VEV\".     Either G d matrix kth     column shape covariance matrix (normalized     determinant 1) kth component,     d-vector giving common shape components. orientation constant-shape models \"EEV\" \"VEV\".       Either d d G array whose       [,,k]th entry orthonomal matrix whose       columns eigenvectors covariance matrix       kth component, d d       orthonormal matrix mixture components       common orientation. orientation component       needed spherical diagonal models, since       principal components parallel coordinate axes        orientation matrix identity. cases, value -1 used placeholder unknown nonzero entries.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm starting with M-step for parameterized MVN mixture models — me","title":"EM algorithm starting with M-step for parameterized MVN mixture models — me","text":"Implements EM algorithm MVN mixture models parameterized   eignevalue decomposition, starting maximization step.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm starting with M-step for parameterized MVN mixture models — me","text":"","code":"me(data, modelName, z, prior = NULL, control = emControl(),     Vinv = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/me.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm starting with M-step for parameterized MVN mixture models — me","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. z matrix whose [,k]th entry initial estimate     conditional probability ith observation belonging     kth component mixture. prior Specification conjugate prior means variances.     See help file priorControl information.     default assumes prior. control list control parameters EM. defaults set call     emControl(). Vinv model include noise term, Vinv estimate      reciprocal hypervolume data region. set negative value     0, model include noise term reciprocal hypervolume     estimated function hypvol.     default assume noise term model     setting Vinv=NULL. warn logical value indicating whether certain warnings      (usually related singularity) issued     estimation fails. default set mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm starting with M-step for parameterized MVN mixture models — me","text":"list including following components: modelName character string identifying model (input argument). n number observations data. d dimension data. G number mixture components. z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  loglik log likelihood data mixture model. control list control parameters EM used. prior specification conjugate prior means variances used,      NULL prior used. Attributes: \"info\" Information iteration.\"WARNING\" appropriate warning problems encountered        computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/me.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm starting with M-step for parameterized MVN mixture models — me","text":"","code":"# \\donttest{ me(modelName = \"VVV\", data = iris[,-5], z = unmap(iris[,5]))# } #> $modelName #> [1] \"VVV\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                 [,1]         [,2]         [,3] #>   [1,]  1.000000e+00 1.340380e-44 1.861339e-34 #>   [2,]  1.000000e+00 2.201405e-31 6.676298e-28 #>   [3,]  1.000000e+00 1.896748e-36 1.102178e-29 #>   [4,]  1.000000e+00 3.488647e-32 6.409600e-26 #>   [5,]  1.000000e+00 4.393475e-47 7.745885e-35 #>   [6,]  1.000000e+00 1.278514e-45 9.141846e-35 #>   [7,]  1.000000e+00 1.725033e-36 1.528128e-28 #>   [8,]  1.000000e+00 1.013323e-40 1.687173e-31 #>   [9,]  1.000000e+00 6.118503e-28 6.204452e-24 #>  [10,]  1.000000e+00 3.941874e-36 2.494386e-28 #>  [11,]  1.000000e+00 4.448705e-50 1.929162e-37 #>  [12,]  1.000000e+00 3.292550e-39 7.578657e-29 #>  [13,]  1.000000e+00 2.565267e-34 5.452124e-28 #>  [14,]  1.000000e+00 9.106612e-35 1.909555e-27 #>  [15,]  1.000000e+00 3.125165e-63 1.593148e-47 #>  [16,]  1.000000e+00 1.896077e-64 4.876149e-46 #>  [17,]  1.000000e+00 5.596191e-50 1.021588e-39 #>  [18,]  1.000000e+00 6.308031e-41 2.149597e-33 #>  [19,]  1.000000e+00 2.370660e-47 1.329559e-36 #>  [20,]  1.000000e+00 4.052147e-48 1.898553e-35 #>  [21,]  1.000000e+00 3.784797e-39 8.212299e-31 #>  [22,]  1.000000e+00 2.257628e-41 6.202577e-33 #>  [23,]  1.000000e+00 6.419874e-48 7.020340e-35 #>  [24,]  1.000000e+00 6.639759e-26 1.443374e-24 #>  [25,]  1.000000e+00 7.175865e-36 2.846195e-24 #>  [26,]  1.000000e+00 1.227836e-29 6.692266e-26 #>  [27,]  1.000000e+00 1.658055e-32 6.789689e-28 #>  [28,]  1.000000e+00 6.872462e-44 7.516822e-34 #>  [29,]  1.000000e+00 4.516919e-42 6.057310e-34 #>  [30,]  1.000000e+00 6.438483e-34 2.970895e-26 #>  [31,]  1.000000e+00 9.491263e-32 6.566490e-26 #>  [32,]  1.000000e+00 1.359677e-34 1.377621e-31 #>  [33,]  1.000000e+00 1.807081e-66 1.923514e-41 #>  [34,]  1.000000e+00 2.640245e-67 1.082266e-45 #>  [35,]  1.000000e+00 6.866910e-33 9.278292e-28 #>  [36,]  1.000000e+00 5.302053e-38 1.312420e-32 #>  [37,]  1.000000e+00 3.083368e-46 5.787644e-38 #>  [38,]  1.000000e+00 1.102357e-50 7.771785e-35 #>  [39,]  1.000000e+00 8.786404e-31 1.026566e-25 #>  [40,]  1.000000e+00 6.077402e-41 4.042171e-32 #>  [41,]  1.000000e+00 1.877063e-41 1.037298e-33 #>  [42,]  1.000000e+00 3.904478e-15 2.495765e-19 #>  [43,]  1.000000e+00 2.822962e-35 2.367557e-27 #>  [44,]  1.000000e+00 1.608040e-27 5.055302e-25 #>  [45,]  1.000000e+00 3.082923e-39 2.560673e-28 #>  [46,]  1.000000e+00 4.000241e-28 2.471836e-26 #>  [47,]  1.000000e+00 2.987492e-51 3.564570e-35 #>  [48,]  1.000000e+00 2.344766e-35 6.084895e-28 #>  [49,]  1.000000e+00 7.194407e-50 8.191014e-37 #>  [50,]  1.000000e+00 5.327318e-39 1.230925e-31 #>  [51,]  3.032539e-92 9.997227e-01 2.773164e-04 #>  [52,]  1.150038e-83 9.986288e-01 1.371182e-03 #>  [53,] 1.797174e-104 9.944941e-01 5.505859e-03 #>  [54,]  1.115012e-63 9.320826e-01 6.791742e-02 #>  [55,]  4.881945e-92 9.705411e-01 2.945894e-02 #>  [56,]  2.954459e-79 9.685784e-01 3.142162e-02 #>  [57,]  8.550867e-94 9.865626e-01 1.343744e-02 #>  [58,]  3.765759e-34 9.998441e-01 1.558591e-04 #>  [59,]  1.336478e-86 9.986175e-01 1.382503e-03 #>  [60,]  1.747387e-60 9.669572e-01 3.304278e-02 #>  [61,]  3.021885e-42 9.982058e-01 1.794178e-03 #>  [62,]  1.635100e-72 9.927992e-01 7.200848e-03 #>  [63,]  4.079064e-61 9.991369e-01 8.630789e-04 #>  [64,]  1.012713e-90 9.670966e-01 3.290342e-02 #>  [65,]  7.559543e-47 9.997995e-01 2.005120e-04 #>  [66,]  3.050597e-79 9.998767e-01 1.232632e-04 #>  [67,]  1.489175e-83 9.246757e-01 7.532431e-02 #>  [68,]  8.933659e-58 9.965960e-01 3.404046e-03 #>  [69,]  3.934648e-92 2.925580e-03 9.970744e-01 #>  [70,]  7.242827e-55 9.995024e-01 4.975685e-04 #>  [71,] 7.707744e-106 5.397566e-02 9.460243e-01 #>  [72,]  3.850909e-62 9.998443e-01 1.556841e-04 #>  [73,] 4.713812e-107 4.325311e-02 9.567469e-01 #>  [74,]  3.438056e-86 9.136402e-01 8.635976e-02 #>  [75,]  1.817276e-73 9.997824e-01 2.176209e-04 #>  [76,]  6.615926e-80 9.997244e-01 2.755883e-04 #>  [77,] 3.767869e-100 9.879246e-01 1.207544e-02 #>  [78,] 1.254096e-114 3.361880e-01 6.638120e-01 #>  [79,]  4.845433e-85 9.646654e-01 3.533460e-02 #>  [80,]  2.507098e-39 9.999864e-01 1.363479e-05 #>  [81,]  3.878089e-52 9.995100e-01 4.900484e-04 #>  [82,]  8.943244e-47 9.998196e-01 1.803552e-04 #>  [83,]  4.112093e-56 9.998282e-01 1.717912e-04 #>  [84,] 1.761949e-116 6.973648e-03 9.930264e-01 #>  [85,]  1.873570e-83 8.494274e-01 1.505726e-01 #>  [86,]  4.330051e-84 9.873428e-01 1.265717e-02 #>  [87,]  1.827651e-94 9.975530e-01 2.447044e-03 #>  [88,]  2.149510e-82 9.204475e-01 7.955247e-02 #>  [89,]  1.777598e-62 9.985437e-01 1.456316e-03 #>  [90,]  1.223594e-62 9.899298e-01 1.007019e-02 #>  [91,]  1.057937e-73 9.412283e-01 5.877173e-02 #>  [92,]  1.119977e-85 9.910150e-01 8.985033e-03 #>  [93,]  1.917546e-60 9.995110e-01 4.889726e-04 #>  [94,]  5.809300e-35 9.998832e-01 1.168043e-04 #>  [95,]  1.439348e-68 9.937569e-01 6.243104e-03 #>  [96,]  4.058872e-63 9.973306e-01 2.669419e-03 #>  [97,]  3.805944e-67 9.979620e-01 2.037953e-03 #>  [98,]  1.658725e-72 9.994971e-01 5.028802e-04 #>  [99,]  3.308948e-28 9.999418e-01 5.818736e-05 #> [100,]  1.884676e-64 9.986048e-01 1.395245e-03 #> [101,] 3.010949e-203 5.530199e-17 1.000000e+00 #> [102,] 1.753436e-128 1.077534e-07 9.999999e-01 #> [103,] 3.185553e-181 2.653929e-09 1.000000e+00 #> [104,] 1.348868e-148 4.312002e-05 9.999569e-01 #> [105,] 9.131952e-178 7.830553e-12 1.000000e+00 #> [106,] 1.376312e-228 2.727688e-11 1.000000e+00 #> [107,]  3.275601e-95 1.168041e-05 9.999883e-01 #> [108,] 1.485822e-196 1.996513e-07 9.999998e-01 #> [109,] 1.096470e-166 5.615666e-09 1.000000e+00 #> [110,] 1.838986e-207 5.153929e-13 1.000000e+00 #> [111,] 1.407473e-129 6.017637e-05 9.999398e-01 #> [112,] 7.916908e-140 1.650636e-07 9.999998e-01 #> [113,] 9.136916e-158 5.957065e-09 1.000000e+00 #> [114,] 1.956477e-130 2.233857e-12 1.000000e+00 #> [115,] 2.022253e-156 3.404704e-22 1.000000e+00 #> [116,] 9.392240e-156 1.026315e-12 1.000000e+00 #> [117,] 6.602144e-143 7.801735e-04 9.992198e-01 #> [118,] 2.748870e-228 5.421043e-06 9.999946e-01 #> [119,] 7.429637e-265 3.265440e-22 1.000000e+00 #> [120,] 1.370738e-113 5.282640e-05 9.999472e-01 #> [121,] 4.351788e-177 4.577282e-12 1.000000e+00 #> [122,] 1.054301e-123 3.279642e-09 1.000000e+00 #> [123,] 1.162139e-235 1.885723e-12 1.000000e+00 #> [124,] 6.201270e-116 5.216528e-05 9.999478e-01 #> [125,] 1.891890e-164 2.001713e-06 9.999980e-01 #> [126,] 1.323823e-172 7.420387e-04 9.992580e-01 #> [127,] 4.617100e-110 3.526679e-04 9.996473e-01 #> [128,] 2.794272e-112 5.946968e-03 9.940530e-01 #> [129,] 1.280855e-163 1.922717e-11 1.000000e+00 #> [130,] 3.061896e-157 4.726577e-03 9.952734e-01 #> [131,] 6.533587e-190 3.218376e-08 1.000000e+00 #> [132,] 4.771065e-201 6.006480e-03 9.939935e-01 #> [133,] 6.908783e-169 3.468057e-14 1.000000e+00 #> [134,] 2.744809e-113 2.199157e-01 7.800843e-01 #> [135,] 3.663047e-138 3.079362e-05 9.999692e-01 #> [136,] 2.609736e-207 1.978334e-14 1.000000e+00 #> [137,] 7.627542e-175 3.636807e-13 1.000000e+00 #> [138,] 2.136992e-141 2.459565e-03 9.975404e-01 #> [139,] 1.018504e-107 5.760480e-03 9.942395e-01 #> [140,] 8.410204e-152 7.863015e-08 9.999999e-01 #> [141,] 2.436458e-178 1.184065e-16 1.000000e+00 #> [142,] 2.086983e-148 3.695558e-14 1.000000e+00 #> [143,] 1.753436e-128 1.077534e-07 9.999999e-01 #> [144,] 1.276099e-187 4.205111e-12 1.000000e+00 #> [145,] 9.196112e-188 2.313054e-17 1.000000e+00 #> [146,] 1.126391e-153 3.179633e-15 1.000000e+00 #> [147,] 3.395534e-127 2.310806e-09 1.000000e+00 #> [148,] 1.300448e-136 1.192490e-06 9.999988e-01 #> [149,] 1.141901e-158 1.374617e-10 1.000000e+00 #> [150,] 2.488135e-121 1.722216e-03 9.982778e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.2995864 0.3670803 #>  #> $parameters$mean #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.915306 6.544949 #> Sepal.Width  3.428 2.777875 2.948818 #> Petal.Length 1.462 4.202227 5.480372 #> Petal.Width  0.246 1.297229 1.985127 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VVV\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.121764    0.097232     0.016028    0.010124 #> Sepal.Width      0.097232    0.140816     0.011464    0.009112 #> Petal.Length     0.016028    0.011464     0.029556    0.005948 #> Petal.Width      0.010124    0.009112     0.005948    0.010884 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.27533588  0.09687192   0.18477153  0.05444692 #> Sepal.Width    0.09687192  0.09262785   0.09111654  0.04299505 #> Petal.Length   0.18477153  0.09111654   0.20089896  0.06109388 #> Petal.Width    0.05444692  0.04299505   0.06109388  0.03205203 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.38707068  0.09220736   0.30268373  0.06147257 #> Sepal.Width    0.09220736  0.11034902   0.08419484  0.05595573 #> Petal.Length   0.30268373  0.08419484   0.32736949  0.07416052 #> Petal.Width    0.06147257  0.05595573   0.07416052  0.08559833 #>  #>  #> $parameters$variance$cholsigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length  Petal.Width #> Sepal.Length    -0.348947  -0.2786440 -0.045932479 -0.029013003 #> Sepal.Width      0.000000   0.2513434 -0.005310709  0.004088826 #> Petal.Length     0.000000   0.0000000 -0.165583827 -0.028004398 #> Petal.Width      0.000000   0.0000000  0.000000000  0.096131581 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.5247246   0.1846148    0.3521305  0.10376286 #> Sepal.Width     0.0000000  -0.2419612   -0.1079018 -0.09852359 #> Petal.Length    0.0000000   0.0000000    0.2554609  0.05450909 #> Petal.Width     0.0000000   0.0000000    0.0000000 -0.09277479 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     -0.62215  -0.1482076  -0.48651244 -0.09880666 #> Sepal.Width       0.00000  -0.2972937  -0.04066688 -0.13895968 #> Petal.Length      0.00000   0.0000000  -0.29836444 -0.06850276 #> Petal.Width       0.00000   0.0000000   0.00000000 -0.22766895 #>  #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $control #> $control$eps #> [1] 2.220446e-16 #>  #> $control$tol #> [1] 1.000000e-05 1.490116e-08 #>  #> $control$itmax #> [1] 2147483647 2147483647 #>  #> $control$equalPro #> [1] FALSE #>  #>  #> $loglik #> [1] -180.1859 #>  #> attr(,\"info\") #>   iterations        error  #> 1.100000e+01 4.438788e-06  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"Implements EM algorithm fitting Gaussian mixture models parameterized eigenvalue decomposition, observations weights, starting maximization step.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"","code":"me.weighted(data, modelName, z, weights = NULL, prior = NULL,              control = emControl(), Vinv = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. z matrix whose [,k]th entry initial estimate     conditional probability ith observation belonging     kth component mixture. weights vector positive weights, []th entry weight     ith observation. weights greater one,     scaled maximum weight one. prior Specification conjugate prior means variances.     See help file priorControl information.     default assumes prior. control list control parameters EM. defaults set call     emControl. Vinv model include noise term, Vinv estimate      reciprocal hypervolume data region. set negative value     0, model include noise term reciprocal hypervolume     estimated function hypvol.     default assume noise term model     setting Vinv=NULL. warn logical value indicating whether certain warnings      (usually related singularity) issued     estimation fails. default set warn using     mclust.options. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"list including following components: modelName character string identifying model (input argument). z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  loglik log-likelihood estimated mixture model. bic BIC value estimated mixture model. Attributes: \"info\" Information iteration.\"WARNING\" appropriate warning problems encountered        computations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"efficient version made available mclust \\(ge 6.1\\) using Fortran code internally.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"T. Brendan Murphy, Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/me.weighted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm with weights starting with M-step for parameterized Gaussian mixture models — me.weighted","text":"","code":"w = rexp(nrow(iris)) w = w/mean(w) c(summary(w), sum = sum(w)) #>         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.  #>   0.00206268   0.32520507   0.71293241   1.00000000   1.47179878   6.53900532  #>          sum  #> 150.00000000  z = unmap(sample(1:3, size = nrow(iris), replace = TRUE)) MEW = me.weighted(data = iris[,-5], modelName = \"VVV\",                    z = z, weights = w) str(MEW,1) #> List of 10 #>  $ modelName : chr \"VVV\" #>  $ prior     : NULL #>  $ n         : int 150 #>  $ d         : int 4 #>  $ G         : int 3 #>  $ z         : num [1:150, 1:3] 2.89e-18 6.45e-12 7.86e-15 3.23e-12 2.31e-19 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>  $ parameters:List of 3 #>  $ weights   : num [1:150] 0.0267 0.0986 0.2817 0.029 0.429 ... #>  $ loglik    : num -178 #>  $ bic       : num -275 #>  - attr(*, \"returnCode\")= num 0"},{"path":"https://mclust-org.github.io/mclust/reference/meE.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","title":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","text":"Implements EM algorithm parameterized Gaussian mixture model,   starting maximization step.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/meE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","text":"","code":"meE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meX(data, prior = NULL, warn = NULL, ...) meEII(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVII(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEEI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVEI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEVI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVVI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEEE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVEE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEVE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVVE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEEV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVEV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meEVV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meVVV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...) meXII(data, prior = NULL, warn = NULL, ...) meXXI(data, prior = NULL, warn = NULL, ...) meXXX(data, prior = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/meE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","text":"data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. z matrix whose [,k]th entry conditional probability      ith observation belonging kth component mixture. prior Specification conjugate prior means variances.     default assumes prior. control list control parameters EM. defaults set call     emControl(). Vinv estimate reciprocal hypervolume data region,     model include noise term. Set negative value zero     noise term desired, estimate unavailable ---     case function hypvol used obtain estimate.     default assume noise term model     setting Vinv=NULL. warn logical value indicating whether certain warnings     (usually related singularity) issued     estimation fails. default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/meE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","text":"list including following components: modelName character string identifying model (input argument). z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details. Vinv estimate reciprocal hypervolume data region               used computation input indicates               addition noise component model.  loglik log likelihood data mixture model. Attributes: \"info\" Information iteration.\"WARNING\" appropriate warning problems encountered        computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/meE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm starting with M-step for a parameterized Gaussian mixture model — meE","text":"","code":"meVVV(data = iris[,-5], z = unmap(iris[,5])) #> $modelName #> [1] \"VVV\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>                 [,1]         [,2]         [,3] #>   [1,]  1.000000e+00 1.340380e-44 1.861339e-34 #>   [2,]  1.000000e+00 2.201405e-31 6.676298e-28 #>   [3,]  1.000000e+00 1.896748e-36 1.102178e-29 #>   [4,]  1.000000e+00 3.488647e-32 6.409600e-26 #>   [5,]  1.000000e+00 4.393475e-47 7.745885e-35 #>   [6,]  1.000000e+00 1.278514e-45 9.141846e-35 #>   [7,]  1.000000e+00 1.725033e-36 1.528128e-28 #>   [8,]  1.000000e+00 1.013323e-40 1.687173e-31 #>   [9,]  1.000000e+00 6.118503e-28 6.204452e-24 #>  [10,]  1.000000e+00 3.941874e-36 2.494386e-28 #>  [11,]  1.000000e+00 4.448705e-50 1.929162e-37 #>  [12,]  1.000000e+00 3.292550e-39 7.578657e-29 #>  [13,]  1.000000e+00 2.565267e-34 5.452124e-28 #>  [14,]  1.000000e+00 9.106612e-35 1.909555e-27 #>  [15,]  1.000000e+00 3.125165e-63 1.593148e-47 #>  [16,]  1.000000e+00 1.896077e-64 4.876149e-46 #>  [17,]  1.000000e+00 5.596191e-50 1.021588e-39 #>  [18,]  1.000000e+00 6.308031e-41 2.149597e-33 #>  [19,]  1.000000e+00 2.370660e-47 1.329559e-36 #>  [20,]  1.000000e+00 4.052147e-48 1.898553e-35 #>  [21,]  1.000000e+00 3.784797e-39 8.212299e-31 #>  [22,]  1.000000e+00 2.257628e-41 6.202577e-33 #>  [23,]  1.000000e+00 6.419874e-48 7.020340e-35 #>  [24,]  1.000000e+00 6.639759e-26 1.443374e-24 #>  [25,]  1.000000e+00 7.175865e-36 2.846195e-24 #>  [26,]  1.000000e+00 1.227836e-29 6.692266e-26 #>  [27,]  1.000000e+00 1.658055e-32 6.789689e-28 #>  [28,]  1.000000e+00 6.872462e-44 7.516822e-34 #>  [29,]  1.000000e+00 4.516919e-42 6.057310e-34 #>  [30,]  1.000000e+00 6.438483e-34 2.970895e-26 #>  [31,]  1.000000e+00 9.491263e-32 6.566490e-26 #>  [32,]  1.000000e+00 1.359677e-34 1.377621e-31 #>  [33,]  1.000000e+00 1.807081e-66 1.923514e-41 #>  [34,]  1.000000e+00 2.640245e-67 1.082266e-45 #>  [35,]  1.000000e+00 6.866910e-33 9.278292e-28 #>  [36,]  1.000000e+00 5.302053e-38 1.312420e-32 #>  [37,]  1.000000e+00 3.083368e-46 5.787644e-38 #>  [38,]  1.000000e+00 1.102357e-50 7.771785e-35 #>  [39,]  1.000000e+00 8.786404e-31 1.026566e-25 #>  [40,]  1.000000e+00 6.077402e-41 4.042171e-32 #>  [41,]  1.000000e+00 1.877063e-41 1.037298e-33 #>  [42,]  1.000000e+00 3.904478e-15 2.495765e-19 #>  [43,]  1.000000e+00 2.822962e-35 2.367557e-27 #>  [44,]  1.000000e+00 1.608040e-27 5.055302e-25 #>  [45,]  1.000000e+00 3.082923e-39 2.560673e-28 #>  [46,]  1.000000e+00 4.000241e-28 2.471836e-26 #>  [47,]  1.000000e+00 2.987492e-51 3.564570e-35 #>  [48,]  1.000000e+00 2.344766e-35 6.084895e-28 #>  [49,]  1.000000e+00 7.194407e-50 8.191014e-37 #>  [50,]  1.000000e+00 5.327318e-39 1.230925e-31 #>  [51,]  3.032539e-92 9.997227e-01 2.773164e-04 #>  [52,]  1.150038e-83 9.986288e-01 1.371182e-03 #>  [53,] 1.797174e-104 9.944941e-01 5.505859e-03 #>  [54,]  1.115012e-63 9.320826e-01 6.791742e-02 #>  [55,]  4.881945e-92 9.705411e-01 2.945894e-02 #>  [56,]  2.954459e-79 9.685784e-01 3.142162e-02 #>  [57,]  8.550867e-94 9.865626e-01 1.343744e-02 #>  [58,]  3.765759e-34 9.998441e-01 1.558591e-04 #>  [59,]  1.336478e-86 9.986175e-01 1.382503e-03 #>  [60,]  1.747387e-60 9.669572e-01 3.304278e-02 #>  [61,]  3.021885e-42 9.982058e-01 1.794178e-03 #>  [62,]  1.635100e-72 9.927992e-01 7.200848e-03 #>  [63,]  4.079064e-61 9.991369e-01 8.630789e-04 #>  [64,]  1.012713e-90 9.670966e-01 3.290342e-02 #>  [65,]  7.559543e-47 9.997995e-01 2.005120e-04 #>  [66,]  3.050597e-79 9.998767e-01 1.232632e-04 #>  [67,]  1.489175e-83 9.246757e-01 7.532431e-02 #>  [68,]  8.933659e-58 9.965960e-01 3.404046e-03 #>  [69,]  3.934648e-92 2.925580e-03 9.970744e-01 #>  [70,]  7.242827e-55 9.995024e-01 4.975685e-04 #>  [71,] 7.707744e-106 5.397566e-02 9.460243e-01 #>  [72,]  3.850909e-62 9.998443e-01 1.556841e-04 #>  [73,] 4.713812e-107 4.325311e-02 9.567469e-01 #>  [74,]  3.438056e-86 9.136402e-01 8.635976e-02 #>  [75,]  1.817276e-73 9.997824e-01 2.176209e-04 #>  [76,]  6.615926e-80 9.997244e-01 2.755883e-04 #>  [77,] 3.767869e-100 9.879246e-01 1.207544e-02 #>  [78,] 1.254096e-114 3.361880e-01 6.638120e-01 #>  [79,]  4.845433e-85 9.646654e-01 3.533460e-02 #>  [80,]  2.507098e-39 9.999864e-01 1.363479e-05 #>  [81,]  3.878089e-52 9.995100e-01 4.900484e-04 #>  [82,]  8.943244e-47 9.998196e-01 1.803552e-04 #>  [83,]  4.112093e-56 9.998282e-01 1.717912e-04 #>  [84,] 1.761949e-116 6.973648e-03 9.930264e-01 #>  [85,]  1.873570e-83 8.494274e-01 1.505726e-01 #>  [86,]  4.330051e-84 9.873428e-01 1.265717e-02 #>  [87,]  1.827651e-94 9.975530e-01 2.447044e-03 #>  [88,]  2.149510e-82 9.204475e-01 7.955247e-02 #>  [89,]  1.777598e-62 9.985437e-01 1.456316e-03 #>  [90,]  1.223594e-62 9.899298e-01 1.007019e-02 #>  [91,]  1.057937e-73 9.412283e-01 5.877173e-02 #>  [92,]  1.119977e-85 9.910150e-01 8.985033e-03 #>  [93,]  1.917546e-60 9.995110e-01 4.889726e-04 #>  [94,]  5.809300e-35 9.998832e-01 1.168043e-04 #>  [95,]  1.439348e-68 9.937569e-01 6.243104e-03 #>  [96,]  4.058872e-63 9.973306e-01 2.669419e-03 #>  [97,]  3.805944e-67 9.979620e-01 2.037953e-03 #>  [98,]  1.658725e-72 9.994971e-01 5.028802e-04 #>  [99,]  3.308948e-28 9.999418e-01 5.818736e-05 #> [100,]  1.884676e-64 9.986048e-01 1.395245e-03 #> [101,] 3.010949e-203 5.530199e-17 1.000000e+00 #> [102,] 1.753436e-128 1.077534e-07 9.999999e-01 #> [103,] 3.185553e-181 2.653929e-09 1.000000e+00 #> [104,] 1.348868e-148 4.312002e-05 9.999569e-01 #> [105,] 9.131952e-178 7.830553e-12 1.000000e+00 #> [106,] 1.376312e-228 2.727688e-11 1.000000e+00 #> [107,]  3.275601e-95 1.168041e-05 9.999883e-01 #> [108,] 1.485822e-196 1.996513e-07 9.999998e-01 #> [109,] 1.096470e-166 5.615666e-09 1.000000e+00 #> [110,] 1.838986e-207 5.153929e-13 1.000000e+00 #> [111,] 1.407473e-129 6.017637e-05 9.999398e-01 #> [112,] 7.916908e-140 1.650636e-07 9.999998e-01 #> [113,] 9.136916e-158 5.957065e-09 1.000000e+00 #> [114,] 1.956477e-130 2.233857e-12 1.000000e+00 #> [115,] 2.022253e-156 3.404704e-22 1.000000e+00 #> [116,] 9.392240e-156 1.026315e-12 1.000000e+00 #> [117,] 6.602144e-143 7.801735e-04 9.992198e-01 #> [118,] 2.748870e-228 5.421043e-06 9.999946e-01 #> [119,] 7.429637e-265 3.265440e-22 1.000000e+00 #> [120,] 1.370738e-113 5.282640e-05 9.999472e-01 #> [121,] 4.351788e-177 4.577282e-12 1.000000e+00 #> [122,] 1.054301e-123 3.279642e-09 1.000000e+00 #> [123,] 1.162139e-235 1.885723e-12 1.000000e+00 #> [124,] 6.201270e-116 5.216528e-05 9.999478e-01 #> [125,] 1.891890e-164 2.001713e-06 9.999980e-01 #> [126,] 1.323823e-172 7.420387e-04 9.992580e-01 #> [127,] 4.617100e-110 3.526679e-04 9.996473e-01 #> [128,] 2.794272e-112 5.946968e-03 9.940530e-01 #> [129,] 1.280855e-163 1.922717e-11 1.000000e+00 #> [130,] 3.061896e-157 4.726577e-03 9.952734e-01 #> [131,] 6.533587e-190 3.218376e-08 1.000000e+00 #> [132,] 4.771065e-201 6.006480e-03 9.939935e-01 #> [133,] 6.908783e-169 3.468057e-14 1.000000e+00 #> [134,] 2.744809e-113 2.199157e-01 7.800843e-01 #> [135,] 3.663047e-138 3.079362e-05 9.999692e-01 #> [136,] 2.609736e-207 1.978334e-14 1.000000e+00 #> [137,] 7.627542e-175 3.636807e-13 1.000000e+00 #> [138,] 2.136992e-141 2.459565e-03 9.975404e-01 #> [139,] 1.018504e-107 5.760480e-03 9.942395e-01 #> [140,] 8.410204e-152 7.863015e-08 9.999999e-01 #> [141,] 2.436458e-178 1.184065e-16 1.000000e+00 #> [142,] 2.086983e-148 3.695558e-14 1.000000e+00 #> [143,] 1.753436e-128 1.077534e-07 9.999999e-01 #> [144,] 1.276099e-187 4.205111e-12 1.000000e+00 #> [145,] 9.196112e-188 2.313054e-17 1.000000e+00 #> [146,] 1.126391e-153 3.179633e-15 1.000000e+00 #> [147,] 3.395534e-127 2.310806e-09 1.000000e+00 #> [148,] 1.300448e-136 1.192490e-06 9.999988e-01 #> [149,] 1.141901e-158 1.374617e-10 1.000000e+00 #> [150,] 2.488135e-121 1.722216e-03 9.982778e-01 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.2995864 0.3670803 #>  #> $parameters$mean #>               [,1]     [,2]     [,3] #> Sepal.Length 5.006 5.915306 6.544949 #> Sepal.Width  3.428 2.777875 2.948818 #> Petal.Length 1.462 4.202227 5.480372 #> Petal.Width  0.246 1.297229 1.985127 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VVV\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.121764    0.097232     0.016028    0.010124 #> Sepal.Width      0.097232    0.140816     0.011464    0.009112 #> Petal.Length     0.016028    0.011464     0.029556    0.005948 #> Petal.Width      0.010124    0.009112     0.005948    0.010884 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.27533588  0.09687192   0.18477153  0.05444692 #> Sepal.Width    0.09687192  0.09262785   0.09111654  0.04299505 #> Petal.Length   0.18477153  0.09111654   0.20089896  0.06109388 #> Petal.Width    0.05444692  0.04299505   0.06109388  0.03205203 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.38707068  0.09220736   0.30268373  0.06147257 #> Sepal.Width    0.09220736  0.11034902   0.08419484  0.05595573 #> Petal.Length   0.30268373  0.08419484   0.32736949  0.07416052 #> Petal.Width    0.06147257  0.05595573   0.07416052  0.08559833 #>  #>  #> $parameters$variance$cholsigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length  Petal.Width #> Sepal.Length    -0.348947  -0.2786440 -0.045932479 -0.029013003 #> Sepal.Width      0.000000   0.2513434 -0.005310709  0.004088826 #> Petal.Length     0.000000   0.0000000 -0.165583827 -0.028004398 #> Petal.Width      0.000000   0.0000000  0.000000000  0.096131581 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.5247246   0.1846148    0.3521305  0.10376286 #> Sepal.Width     0.0000000  -0.2419612   -0.1079018 -0.09852359 #> Petal.Length    0.0000000   0.0000000    0.2554609  0.05450909 #> Petal.Width     0.0000000   0.0000000    0.0000000 -0.09277479 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     -0.62215  -0.1482076  -0.48651244 -0.09880666 #> Sepal.Width       0.00000  -0.2972937  -0.04066688 -0.13895968 #> Petal.Length      0.00000   0.0000000  -0.29836444 -0.06850276 #> Petal.Width       0.00000   0.0000000   0.00000000 -0.22766895 #>  #>  #>  #> $parameters$Vinv #> NULL #>  #>  #> $control #> $control$eps #> [1] 2.220446e-16 #>  #> $control$tol #> [1] 1.000000e-05 1.490116e-08 #>  #> $control$itmax #> [1] 2147483647 2147483647 #>  #> $control$equalPro #> [1] FALSE #>  #>  #> $loglik #> [1] -180.1859 #>  #> attr(,\"info\") #>   iterations        error  #> 1.100000e+01 4.438788e-06  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":null,"dir":"Reference","previous_headings":"","what":"M-step for parameterized Gaussian mixture models — mstep","title":"M-step for parameterized Gaussian mixture models — mstep","text":"Maximization step EM algorithm parameterized Gaussian   mixture models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-step for parameterized Gaussian mixture models — mstep","text":"","code":"mstep(data, modelName, z, prior = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-step for parameterized Gaussian mixture models — mstep","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. modelName character string indicating model. help file     mclustModelNames describes available models. z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture.       analyses involving noise, include     conditional probabilities noise component. prior Specification conjugate prior means variances.      default assumes prior. warn logical value indicating whether certain warnings     (usually related singularity) issued     estimation fails. default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-step for parameterized Gaussian mixture models — mstep","text":"list including following components: modelName character string identifying model (input argument). parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details.  Attributes: \"info\" models iterative M-steps        (\"VEI\" \"VEV\"), information  iteration.\"WARNING\" appropriate warning problems     encountered computations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"M-step for parameterized Gaussian mixture models — mstep","text":"function computes M-step MVN mixtures,     analyses involving noise, conditional probabilities input     exclude noise component. contrast EM algorithm, computations mstep    carried unless failure due overflow occur. impose    stricter tolerances single mstep, use   itmax component control argument set 1.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mstep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-step for parameterized Gaussian mixture models — mstep","text":"","code":"# \\donttest{ mstep(modelName = \"VII\", data = iris[,-5], z = unmap(iris[,5]))# } #> $modelName #> [1] \"VII\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>        [,1] [,2] [,3] #>   [1,]    1    0    0 #>   [2,]    1    0    0 #>   [3,]    1    0    0 #>   [4,]    1    0    0 #>   [5,]    1    0    0 #>   [6,]    1    0    0 #>   [7,]    1    0    0 #>   [8,]    1    0    0 #>   [9,]    1    0    0 #>  [10,]    1    0    0 #>  [11,]    1    0    0 #>  [12,]    1    0    0 #>  [13,]    1    0    0 #>  [14,]    1    0    0 #>  [15,]    1    0    0 #>  [16,]    1    0    0 #>  [17,]    1    0    0 #>  [18,]    1    0    0 #>  [19,]    1    0    0 #>  [20,]    1    0    0 #>  [21,]    1    0    0 #>  [22,]    1    0    0 #>  [23,]    1    0    0 #>  [24,]    1    0    0 #>  [25,]    1    0    0 #>  [26,]    1    0    0 #>  [27,]    1    0    0 #>  [28,]    1    0    0 #>  [29,]    1    0    0 #>  [30,]    1    0    0 #>  [31,]    1    0    0 #>  [32,]    1    0    0 #>  [33,]    1    0    0 #>  [34,]    1    0    0 #>  [35,]    1    0    0 #>  [36,]    1    0    0 #>  [37,]    1    0    0 #>  [38,]    1    0    0 #>  [39,]    1    0    0 #>  [40,]    1    0    0 #>  [41,]    1    0    0 #>  [42,]    1    0    0 #>  [43,]    1    0    0 #>  [44,]    1    0    0 #>  [45,]    1    0    0 #>  [46,]    1    0    0 #>  [47,]    1    0    0 #>  [48,]    1    0    0 #>  [49,]    1    0    0 #>  [50,]    1    0    0 #>  [51,]    0    1    0 #>  [52,]    0    1    0 #>  [53,]    0    1    0 #>  [54,]    0    1    0 #>  [55,]    0    1    0 #>  [56,]    0    1    0 #>  [57,]    0    1    0 #>  [58,]    0    1    0 #>  [59,]    0    1    0 #>  [60,]    0    1    0 #>  [61,]    0    1    0 #>  [62,]    0    1    0 #>  [63,]    0    1    0 #>  [64,]    0    1    0 #>  [65,]    0    1    0 #>  [66,]    0    1    0 #>  [67,]    0    1    0 #>  [68,]    0    1    0 #>  [69,]    0    1    0 #>  [70,]    0    1    0 #>  [71,]    0    1    0 #>  [72,]    0    1    0 #>  [73,]    0    1    0 #>  [74,]    0    1    0 #>  [75,]    0    1    0 #>  [76,]    0    1    0 #>  [77,]    0    1    0 #>  [78,]    0    1    0 #>  [79,]    0    1    0 #>  [80,]    0    1    0 #>  [81,]    0    1    0 #>  [82,]    0    1    0 #>  [83,]    0    1    0 #>  [84,]    0    1    0 #>  [85,]    0    1    0 #>  [86,]    0    1    0 #>  [87,]    0    1    0 #>  [88,]    0    1    0 #>  [89,]    0    1    0 #>  [90,]    0    1    0 #>  [91,]    0    1    0 #>  [92,]    0    1    0 #>  [93,]    0    1    0 #>  [94,]    0    1    0 #>  [95,]    0    1    0 #>  [96,]    0    1    0 #>  [97,]    0    1    0 #>  [98,]    0    1    0 #>  [99,]    0    1    0 #> [100,]    0    1    0 #> [101,]    0    0    1 #> [102,]    0    0    1 #> [103,]    0    0    1 #> [104,]    0    0    1 #> [105,]    0    0    1 #> [106,]    0    0    1 #> [107,]    0    0    1 #> [108,]    0    0    1 #> [109,]    0    0    1 #> [110,]    0    0    1 #> [111,]    0    0    1 #> [112,]    0    0    1 #> [113,]    0    0    1 #> [114,]    0    0    1 #> [115,]    0    0    1 #> [116,]    0    0    1 #> [117,]    0    0    1 #> [118,]    0    0    1 #> [119,]    0    0    1 #> [120,]    0    0    1 #> [121,]    0    0    1 #> [122,]    0    0    1 #> [123,]    0    0    1 #> [124,]    0    0    1 #> [125,]    0    0    1 #> [126,]    0    0    1 #> [127,]    0    0    1 #> [128,]    0    0    1 #> [129,]    0    0    1 #> [130,]    0    0    1 #> [131,]    0    0    1 #> [132,]    0    0    1 #> [133,]    0    0    1 #> [134,]    0    0    1 #> [135,]    0    0    1 #> [136,]    0    0    1 #> [137,]    0    0    1 #> [138,]    0    0    1 #> [139,]    0    0    1 #> [140,]    0    0    1 #> [141,]    0    0    1 #> [142,]    0    0    1 #> [143,]    0    0    1 #> [144,]    0    0    1 #> [145,]    0    0    1 #> [146,]    0    0    1 #> [147,]    0    0    1 #> [148,]    0    0    1 #> [149,]    0    0    1 #> [150,]    0    0    1 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3333333 0.3333333 #>  #> $parameters$mean #>               [,1]  [,2]  [,3] #> Sepal.Length 5.006 5.936 6.588 #> Sepal.Width  3.428 2.770 2.974 #> Petal.Length 1.462 4.260 5.552 #> Petal.Width  0.246 1.326 2.026 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VII\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.075755    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.075755     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.075755    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.075755 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.153082    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.153082     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.153082    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.153082 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length      0.21765     0.00000      0.00000     0.00000 #> Sepal.Width       0.00000     0.21765      0.00000     0.00000 #> Petal.Length      0.00000     0.00000      0.21765     0.00000 #> Petal.Width       0.00000     0.00000      0.00000     0.21765 #>  #>  #> $parameters$variance$sigmasq #> [1] 0.075755 0.153082 0.217650 #>  #> $parameters$variance$scale #> [1] 0.075755 0.153082 0.217650 #>  #>  #>  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":null,"dir":"Reference","previous_headings":"","what":"M-step for a parameterized Gaussian mixture model — mstepE","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"Maximization step EM algorithm parameterized Gaussian   mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"","code":"mstepE( data, z, prior = NULL, warn = NULL, ...) mstepV( data, z, prior = NULL, warn = NULL, ...) mstepEII( data, z, prior = NULL, warn = NULL, ...) mstepVII( data, z, prior = NULL, warn = NULL, ...) mstepEEI( data, z, prior = NULL, warn = NULL, ...) mstepVEI( data, z, prior = NULL, warn = NULL, control = NULL, ...) mstepEVI( data, z, prior = NULL, warn = NULL, ...) mstepVVI( data, z, prior = NULL, warn = NULL, ...) mstepEEE( data, z, prior = NULL, warn = NULL, ...) mstepEEV( data, z, prior = NULL, warn = NULL, ...) mstepVEV( data, z, prior = NULL, warn = NULL, control = NULL,...) mstepVVV( data, z, prior = NULL, warn = NULL, ...) mstepEVE( data, z, prior = NULL, warn = NULL, control = NULL, ...) mstepEVV( data, z, prior = NULL, warn = NULL, ...) mstepVEE( data, z, prior = NULL, warn = NULL, control = NULL, ...) mstepVVE( data, z, prior = NULL, warn = NULL, control = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture.       analyses involving noise, include     conditional probabilities noise component. prior Specification conjugate prior means variances.     default assumes prior. warn logical value indicating whether certain warnings     (usually related singularity) issued     estimation fails. default given mclust.options(\"warn\"). control Values controlling termination models \"VEI\" \"VEV\"      iterative M-step. list components     named itmax tol. components can length 1      2; latter case, mstep use second value,      assumption first applies outer iteration (     function ).     default uses default values function emControl,     sets limit  number iterations, relative tolerance      sqrt(.Machine$double.eps) successive iterates. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"list including following components: modelName character string identifying model (input argument). parameters  pro vector whose kth component mixing proportion                kth component mixture model.               model includes Poisson term noise,                one mixing proportion number                Gaussian components. mean mean component. one component,               matrix whose kth column mean kth                component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance                details.  Attributes: \"info\" models iterative M-steps        (\"VEI\" \"VEV\"), information iteration.\"WARNING\" appropriate warning problems     encountered computations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"function computes M-step MVN mixtures,     analyses involving noise, conditional probabilities input     exclude noise component. contrast EM algorithm, computations mstep    carried unless failure due overflow occur. impose    stricter tolerances single mstep, use   itmax component control argument set 1.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mstepE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-step for a parameterized Gaussian mixture model — mstepE","text":"","code":"# \\donttest{ mstepVII(data = iris[,-5], z = unmap(iris[,5]))# } #> $modelName #> [1] \"VII\" #>  #> $prior #> NULL #>  #> $n #> [1] 150 #>  #> $d #> [1] 4 #>  #> $G #> [1] 3 #>  #> $z #>        [,1] [,2] [,3] #>   [1,]    1    0    0 #>   [2,]    1    0    0 #>   [3,]    1    0    0 #>   [4,]    1    0    0 #>   [5,]    1    0    0 #>   [6,]    1    0    0 #>   [7,]    1    0    0 #>   [8,]    1    0    0 #>   [9,]    1    0    0 #>  [10,]    1    0    0 #>  [11,]    1    0    0 #>  [12,]    1    0    0 #>  [13,]    1    0    0 #>  [14,]    1    0    0 #>  [15,]    1    0    0 #>  [16,]    1    0    0 #>  [17,]    1    0    0 #>  [18,]    1    0    0 #>  [19,]    1    0    0 #>  [20,]    1    0    0 #>  [21,]    1    0    0 #>  [22,]    1    0    0 #>  [23,]    1    0    0 #>  [24,]    1    0    0 #>  [25,]    1    0    0 #>  [26,]    1    0    0 #>  [27,]    1    0    0 #>  [28,]    1    0    0 #>  [29,]    1    0    0 #>  [30,]    1    0    0 #>  [31,]    1    0    0 #>  [32,]    1    0    0 #>  [33,]    1    0    0 #>  [34,]    1    0    0 #>  [35,]    1    0    0 #>  [36,]    1    0    0 #>  [37,]    1    0    0 #>  [38,]    1    0    0 #>  [39,]    1    0    0 #>  [40,]    1    0    0 #>  [41,]    1    0    0 #>  [42,]    1    0    0 #>  [43,]    1    0    0 #>  [44,]    1    0    0 #>  [45,]    1    0    0 #>  [46,]    1    0    0 #>  [47,]    1    0    0 #>  [48,]    1    0    0 #>  [49,]    1    0    0 #>  [50,]    1    0    0 #>  [51,]    0    1    0 #>  [52,]    0    1    0 #>  [53,]    0    1    0 #>  [54,]    0    1    0 #>  [55,]    0    1    0 #>  [56,]    0    1    0 #>  [57,]    0    1    0 #>  [58,]    0    1    0 #>  [59,]    0    1    0 #>  [60,]    0    1    0 #>  [61,]    0    1    0 #>  [62,]    0    1    0 #>  [63,]    0    1    0 #>  [64,]    0    1    0 #>  [65,]    0    1    0 #>  [66,]    0    1    0 #>  [67,]    0    1    0 #>  [68,]    0    1    0 #>  [69,]    0    1    0 #>  [70,]    0    1    0 #>  [71,]    0    1    0 #>  [72,]    0    1    0 #>  [73,]    0    1    0 #>  [74,]    0    1    0 #>  [75,]    0    1    0 #>  [76,]    0    1    0 #>  [77,]    0    1    0 #>  [78,]    0    1    0 #>  [79,]    0    1    0 #>  [80,]    0    1    0 #>  [81,]    0    1    0 #>  [82,]    0    1    0 #>  [83,]    0    1    0 #>  [84,]    0    1    0 #>  [85,]    0    1    0 #>  [86,]    0    1    0 #>  [87,]    0    1    0 #>  [88,]    0    1    0 #>  [89,]    0    1    0 #>  [90,]    0    1    0 #>  [91,]    0    1    0 #>  [92,]    0    1    0 #>  [93,]    0    1    0 #>  [94,]    0    1    0 #>  [95,]    0    1    0 #>  [96,]    0    1    0 #>  [97,]    0    1    0 #>  [98,]    0    1    0 #>  [99,]    0    1    0 #> [100,]    0    1    0 #> [101,]    0    0    1 #> [102,]    0    0    1 #> [103,]    0    0    1 #> [104,]    0    0    1 #> [105,]    0    0    1 #> [106,]    0    0    1 #> [107,]    0    0    1 #> [108,]    0    0    1 #> [109,]    0    0    1 #> [110,]    0    0    1 #> [111,]    0    0    1 #> [112,]    0    0    1 #> [113,]    0    0    1 #> [114,]    0    0    1 #> [115,]    0    0    1 #> [116,]    0    0    1 #> [117,]    0    0    1 #> [118,]    0    0    1 #> [119,]    0    0    1 #> [120,]    0    0    1 #> [121,]    0    0    1 #> [122,]    0    0    1 #> [123,]    0    0    1 #> [124,]    0    0    1 #> [125,]    0    0    1 #> [126,]    0    0    1 #> [127,]    0    0    1 #> [128,]    0    0    1 #> [129,]    0    0    1 #> [130,]    0    0    1 #> [131,]    0    0    1 #> [132,]    0    0    1 #> [133,]    0    0    1 #> [134,]    0    0    1 #> [135,]    0    0    1 #> [136,]    0    0    1 #> [137,]    0    0    1 #> [138,]    0    0    1 #> [139,]    0    0    1 #> [140,]    0    0    1 #> [141,]    0    0    1 #> [142,]    0    0    1 #> [143,]    0    0    1 #> [144,]    0    0    1 #> [145,]    0    0    1 #> [146,]    0    0    1 #> [147,]    0    0    1 #> [148,]    0    0    1 #> [149,]    0    0    1 #> [150,]    0    0    1 #>  #> $parameters #> $parameters$pro #> [1] 0.3333333 0.3333333 0.3333333 #>  #> $parameters$mean #>               [,1]  [,2]  [,3] #> Sepal.Length 5.006 5.936 6.588 #> Sepal.Width  3.428 2.770 2.974 #> Petal.Length 1.462 4.260 5.552 #> Petal.Width  0.246 1.326 2.026 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"VII\" #>  #> $parameters$variance$d #> [1] 4 #>  #> $parameters$variance$G #> [1] 3 #>  #> $parameters$variance$sigma #> , , 1 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.075755    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.075755     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.075755    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.075755 #>  #> , , 2 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.153082    0.000000     0.000000    0.000000 #> Sepal.Width      0.000000    0.153082     0.000000    0.000000 #> Petal.Length     0.000000    0.000000     0.153082    0.000000 #> Petal.Width      0.000000    0.000000     0.000000    0.153082 #>  #> , , 3 #>  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length      0.21765     0.00000      0.00000     0.00000 #> Sepal.Width       0.00000     0.21765      0.00000     0.00000 #> Petal.Length      0.00000     0.00000      0.21765     0.00000 #> Petal.Width       0.00000     0.00000      0.00000     0.21765 #>  #>  #> $parameters$variance$sigmasq #> [1] 0.075755 0.153082 0.217650 #>  #> $parameters$variance$scale #> [1] 0.075755 0.153082 0.217650 #>  #>  #>  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/mvn.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate or Multivariate Normal Fit — mvn","title":"Univariate or Multivariate Normal Fit — mvn","text":"Computes mean, covariance, log-likelihood fitting single   Gaussian given data (univariate multivariate normal).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mvn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate or Multivariate Normal Fit — mvn","text":"","code":"mvn( modelName, data, prior = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mvn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate or Multivariate Normal Fit — mvn","text":"modelName character string representing model name. can either     \"Spherical\", \"Diagonal\", \"Ellipsoidal\"      else \"X\" one-dimensional data,\"XII\" spherical Gaussian, \"XXI\" diagonal Gaussian \"XXX\" general ellipsoidal Gaussian data numeric vector, matrix, data frame observations. Categorical     variables allowed. matrix data frame, rows     correspond observations columns correspond variables. prior Specification conjugate prior means variances.       default assumes prior. warn logical value indicating whether warning issued     whenever singularity encountered.     default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mvn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate or Multivariate Normal Fit — mvn","text":"list including following components: modelName character string identifying model (input argument). parameters  mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  loglik log likelihood data mixture model. Attributes: \"WARNING\" appropriate warning problems        encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mvn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Univariate or Multivariate Normal Fit — mvn","text":"","code":"n <- 1000  set.seed(0) x <- rnorm(n, mean = -1, sd = 2) mvn(modelName = \"X\", x)  #> $modelName #> [1] \"X\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 1 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #> [1] -1.031659 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"X\" #>  #> $parameters$variance$d #> [1] 1 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$sigmasq #> [1] 3.980071 #>  #>  #>  #> $loglik #> [1] -2109.588 #>  #> attr(,\"returnCode\") #> [1] 0  mu <- c(-1, 0, 1)  set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% (2*diag(3)),             MARGIN = 2, STATS = mu, FUN = \"+\") mvn(modelName = \"XII\", x)  #> $modelName #> [1] \"XII\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.03165915 #> [2,] -0.04957289 #> [3,]  1.13628546 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XII\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$sigmasq #> [1] 3.963291 #>  #> $parameters$variance$Sigma #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #> $parameters$variance$sigma #> , , 1 #>  #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #>  #> $parameters$variance$scale #> [1] 3.963291 #>  #>  #>  #> $loglik #> [1] -6322.428 #>  #> attr(,\"returnCode\") #> [1] 0 mvn(modelName = \"Spherical\", x)  #> $modelName #> [1] \"XII\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.03165915 #> [2,] -0.04957289 #> [3,]  1.13628546 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XII\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$sigmasq #> [1] 3.963291 #>  #> $parameters$variance$Sigma #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #> $parameters$variance$sigma #> , , 1 #>  #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #>  #> $parameters$variance$scale #> [1] 3.963291 #>  #>  #>  #> $loglik #> [1] -6322.428 #>  #> attr(,\"returnCode\") #> [1] 0  set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% diag(1:3),             MARGIN = 2, STATS = mu, FUN = \"+\") mvn(modelName = \"XXI\", x) #> $modelName #> [1] \"XXI\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.01582957 #> [2,] -0.04957289 #> [3,]  1.20442820 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXI\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #>  #> $parameters$variance$scale #> [1] 3.264659 #>  #> $parameters$variance$shape #> [1] 0.3047846 1.3080448 2.5083282 #>  #>  #>  #> $loglik #> [1] -6031.548 #>  #> attr(,\"returnCode\") #> [1] 0 mvn(modelName = \"Diagonal\", x) #> $modelName #> [1] \"XXI\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.01582957 #> [2,] -0.04957289 #> [3,]  1.20442820 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXI\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #>  #> $parameters$variance$scale #> [1] 3.264659 #>  #> $parameters$variance$shape #> [1] 0.3047846 1.3080448 2.5083282 #>  #>  #>  #> $loglik #> [1] -6031.548 #>  #> attr(,\"returnCode\") #> [1] 0  Sigma <- matrix(c(9,-4,1,-4,9,4,1,4,9), 3, 3) set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% chol(Sigma),             MARGIN = 2, STATS = mu, FUN = \"+\") mvn(modelName = \"XXX\", x)  #> $modelName #> [1] \"XXX\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.04748872 #> [2,] -0.04550547 #> [3,]  1.12277306 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXX\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #> $parameters$variance$cholSigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$cholsigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #>  #>  #>  #> $loglik #> [1] -7235.154 #>  #> attr(,\"returnCode\") #> [1] 0 mvn(modelName = \"Ellipsoidal\", x)  #> $modelName #> [1] \"XXX\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.04748872 #> [2,] -0.04550547 #> [3,]  1.12277306 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXX\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #> $parameters$variance$cholSigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$cholsigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #>  #>  #>  #> $loglik #> [1] -7235.154 #>  #> attr(,\"returnCode\") #> [1] 0"},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate or Multivariate Normal Fit — mvnX","title":"Univariate or Multivariate Normal Fit — mvnX","text":"Computes mean, covariance, log-likelihood fitting single   Gaussian (univariate multivariate normal).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate or Multivariate Normal Fit — mvnX","text":"","code":"mvnX(data, prior = NULL, warn = NULL, ...) mvnXII(data, prior = NULL, warn = NULL, ...) mvnXXI(data, prior = NULL, warn = NULL, ...) mvnXXX(data, prior = NULL, warn = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate or Multivariate Normal Fit — mvnX","text":"data numeric vector, matrix, data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. prior Specification conjugate prior means variances.     default assumes prior. warn logical value indicating whether warning issued     whenever singularity encountered.     default given mclust.options(\"warn\"). ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Univariate or Multivariate Normal Fit — mvnX","text":"mvnXII computes best fitting Gaussian covariance restricted multiple identity. mvnXXI computes best fitting Gaussian covariance restricted diagonal. mvnXXX computes best fitting Gaussian ellipsoidal (unrestricted) covariance.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate or Multivariate Normal Fit — mvnX","text":"list including following components: modelName character string identifying model (input argument). parameters  mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  loglik log likelihood data mixture model. Attributes: \"WARNING\" appropriate warning problems        encountered computations.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/mvnX.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Univariate or Multivariate Normal Fit — mvnX","text":"","code":"# \\donttest{ n <- 1000  set.seed(0) x <- rnorm(n, mean = -1, sd = 2) mvnX(x)  #> $modelName #> [1] \"X\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 1 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #> [1] -1.031659 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"X\" #>  #> $parameters$variance$d #> [1] 1 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$sigmasq #> [1] 3.980071 #>  #>  #>  #> $loglik #> [1] -2109.588 #>  #> attr(,\"returnCode\") #> [1] 0  mu <- c(-1, 0, 1)  set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% (2*diag(3)),             MARGIN = 2, STATS = mu, FUN = \"+\") mvnXII(x)  #> $modelName #> [1] \"XII\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.03165915 #> [2,] -0.04957289 #> [3,]  1.13628546 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XII\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$sigmasq #> [1] 3.963291 #>  #> $parameters$variance$Sigma #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #> $parameters$variance$sigma #> , , 1 #>  #>          [,1]     [,2]     [,3] #> [1,] 3.963291 0.000000 0.000000 #> [2,] 0.000000 3.963291 0.000000 #> [3,] 0.000000 0.000000 3.963291 #>  #>  #> $parameters$variance$scale #> [1] 3.963291 #>  #>  #>  #> $loglik #> [1] -6322.428 #>  #> attr(,\"returnCode\") #> [1] 0  set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% diag(1:3),             MARGIN = 2, STATS = mu, FUN = \"+\") mvnXXI(x) #> $modelName #> [1] \"XXI\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.01582957 #> [2,] -0.04957289 #> [3,]  1.20442820 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXI\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]    [,2]     [,3] #> [1,] 0.9950176 0.00000 0.000000 #> [2,] 0.0000000 4.27032 0.000000 #> [3,] 0.0000000 0.00000 8.188836 #>  #>  #> $parameters$variance$scale #> [1] 3.264659 #>  #> $parameters$variance$shape #> [1] 0.3047846 1.3080448 2.5083282 #>  #>  #>  #> $loglik #> [1] -6031.548 #>  #> attr(,\"returnCode\") #> [1] 0  Sigma <- matrix(c(9,-4,1,-4,9,4,1,4,9), 3, 3) set.seed(0) x <- sweep(matrix(rnorm(n*3), n, 3) %*% chol(Sigma),             MARGIN = 2, STATS = mu, FUN = \"+\") mvnXXX(x)  #> $modelName #> [1] \"XXX\" #>  #> $prior #> NULL #>  #> $n #> [1] 1000 #>  #> $d #> [1] 3 #>  #> $G #> [1] 1 #>  #> $parameters #> $parameters$pro #> [1] 1 #>  #> $parameters$mean #>             [,1] #> [1,] -1.04748872 #> [2,] -0.04550547 #> [3,]  1.12277306 #>  #> $parameters$variance #> $parameters$variance$modelName #> [1] \"XXX\" #>  #> $parameters$variance$d #> [1] 3 #>  #> $parameters$variance$G #> [1] 1 #>  #> $parameters$variance$Sigma #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #> $parameters$variance$cholSigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$cholsigma #>          [,1]      [,2]       [,3] #> [1,] 2.992517 -1.365056  0.3393713 #> [2,] 0.000000 -2.776521 -1.7577291 #> [3,] 0.000000  0.000000 -2.3655833 #>  #> $parameters$variance$sigma #> , , 1 #>  #>           [,1]      [,2]     [,3] #> [1,]  8.955159 -4.084953 1.015574 #> [2,] -4.084953  9.572449 4.417112 #> [3,]  1.015574  4.417112 8.800769 #>  #>  #>  #>  #> $loglik #> [1] -7235.154 #>  #> attr(,\"returnCode\") #> [1] 0 # }"},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"Gives number estimated parameters parameterizations   Gaussian mixture model used MCLUST.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"","code":"nMclustParams(modelName, d, G, noise = FALSE, equalPro = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"modelName character string indicating model. help file     mclustModelNames describes available models. d dimension data. used models neither     shape orientation varies. G number components Gaussian mixture model used compute     loglik. noise logical variable indicating whether model includes    optional Poisson noise component. equalPro logical variable indicating whether components     model assumed present equal proportion. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"number variance parameters corresponding Gaussian mixture   model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"get total number parameters model, add G*d   means G-1 mixing proportions unequal.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/nMclustParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Estimated Parameters in Gaussian Mixture Models — nMclustParams","text":"","code":"mapply(nMclustParams, mclust.options(\"emModelNames\"), d = 2, G = 3) #> EII VII EEI VEI EVI VVI EEE VEE EVE VVE EEV VEV EVV VVV  #>   9  11  10  12  12  14  11  13  13  15  13  15  15  17"},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"Gives number variance parameters parameterizations   Gaussian mixture model used MCLUST.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"","code":"nVarParams(modelName, d, G, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"modelName character string indicating model. help file     mclustModelNames describes available models. d dimension data. used models neither     shape orientation varies. G number components Gaussian mixture model used compute     loglik. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"number variance parameters corresponding Gaussian mixture   model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"get total number parameters model, add G*d   means G-1 mixing proportions unequal.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/nVarParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Variance Parameters in Gaussian Mixture Models — nVarParams","text":"","code":"mapply(nVarParams, mclust.options(\"emModelNames\"), d = 2, G = 3) #> EII VII EEI VEI EVI VVI EEE VEE EVE VVE EEV VEV EVV VVV  #>   1   3   2   4   4   6   3   5   5   7   5   7   7   9"},{"path":"https://mclust-org.github.io/mclust/reference/partconv.html","id":null,"dir":"Reference","previous_headings":"","what":"Numeric Encoding of a Partitioning — partconv","title":"Numeric Encoding of a Partitioning — partconv","text":"Converts vector interpreted classification partitioning    numeric vector.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/partconv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numeric Encoding of a Partitioning — partconv","text":"","code":"partconv(x, consec=TRUE)"},{"path":"https://mclust-org.github.io/mclust/reference/partconv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numeric Encoding of a Partitioning — partconv","text":"x vector interpreted classification partitioning. consec Logical value indicating whether consecutive class     numbers used .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/partconv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numeric Encoding of a Partitioning — partconv","text":"Numeric encoding x.    consec = TRUE, distinct values x numbered   order appear.   consec = FALSE, distinct value x numbered   index corresponding first appearance x.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/partconv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numeric Encoding of a Partitioning — partconv","text":"","code":"partconv(iris[,5]) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3  set.seed(0) cl <- sample(LETTERS[1:9], 25, replace=TRUE) partconv(cl, consec=FALSE) #>  [1]  1  2  3  4  5  3  5  8  4 10 10 12  3  1 10 10  1  1 10 10  5  1  4  2  8 partconv(cl, consec=TRUE) #>  [1] 1 2 3 4 5 3 5 6 4 7 7 8 3 1 7 7 1 1 7 7 5 1 4 2 6"},{"path":"https://mclust-org.github.io/mclust/reference/partuniq.html","id":null,"dir":"Reference","previous_headings":"","what":"Classifies Data According to Unique Observations — partuniq","title":"Classifies Data According to Unique Observations — partuniq","text":"Gives one--one mapping unique observations rows data matrix.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/partuniq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classifies Data According to Unique Observations — partuniq","text":"","code":"partuniq(x)"},{"path":"https://mclust-org.github.io/mclust/reference/partuniq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classifies Data According to Unique Observations — partuniq","text":"x Matrix observations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/partuniq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classifies Data According to Unique Observations — partuniq","text":"vector length nrow(x) integer entries. observation  k assigned integer whenever observation first row x identical observation k (note <= k).","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/partuniq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classifies Data According to Unique Observations — partuniq","text":"","code":"set.seed(0)  mat <- data.frame(lets = sample(LETTERS[1:2],9,TRUE), nums = sample(1:2,9,TRUE)) mat #>   lets nums #> 1    B    2 #> 2    A    2 #> 3    B    1 #> 4    A    1 #> 5    A    1 #> 6    B    1 #> 7    A    1 #> 8    A    2 #> 9    A    2  ans <- partuniq(mat) ans #> [1] 1 2 3 4 4 3 4 2 2  partconv(ans,consec=TRUE) #> [1] 1 2 3 4 4 3 4 2 2"},{"path":"https://mclust-org.github.io/mclust/reference/plot.Mclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting method for Mclust model-based clustering — plot.Mclust","title":"Plotting method for Mclust model-based clustering — plot.Mclust","text":"Plots model-based clustering results, BIC, classification, uncertainty density.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.Mclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting method for Mclust model-based clustering — plot.Mclust","text":"","code":"# S3 method for Mclust plot(x, what = c(\"BIC\", \"classification\", \"uncertainty\", \"density\"),       dimens = NULL, xlab = NULL, ylab = NULL,      addEllipses = TRUE, main = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.Mclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting method for Mclust model-based clustering — plot.Mclust","text":"x Output Mclust. string specifying type graph requested. Available choices : \"BIC\" plot BIC values used choosing number clusters. \"classification\" = plot showing clustering. data two dimensions pairs plot produced, followed coordinate projection plot using specified dimens. Ellipses corresponding covariances mixture components also drawn addEllipses = TRUE. \"uncertainty\" plot classification uncertainty. data two dimensions coordinate projection plot drawn using specified dimens. \"density\" plot estimated density. data two dimensions matrix contours coordinate projection plot drawn using specified dimens. specified, interactive sessions menu choices proposed. dimens vector integers specifying dimensions coordinate projections     case \"classification\", \"uncertainty\", \"density\"     plots. xlab, ylab Optional labels x-axis y-axis. addEllipses logical indicating whether add ellipses axes      corresponding within-cluster covariances case      \"classification\" \"uncertainty\" plots. main logical NULL indicating whether add title      plot identifying type plot drawn. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.Mclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting method for Mclust model-based clustering — plot.Mclust","text":"flexibility plotting, use mclust1Dplot,   mclust2Dplot, surfacePlot, coordProj,  randProj.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.Mclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting method for Mclust model-based clustering — plot.Mclust","text":"","code":"# \\donttest{ precipMclust <- Mclust(precip) plot(precipMclust)      faithfulMclust <- Mclust(faithful) plot(faithfulMclust)      irisMclust <- Mclust(iris[,-5]) plot(irisMclust)     # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustBoostrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","title":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","text":"Plots bootstrap distribution parameters returned MclustBootstrap function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustBoostrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","text":"","code":"# S3 method for MclustBootstrap plot(x, what = c(\"pro\", \"mean\", \"var\"),       show.parest = TRUE, show.confint = TRUE,      hist.col = \"grey\", hist.border = \"lightgrey\", breaks = \"Sturges\",       col = \"forestgreen\", lwd = 2, lty = 3,       xlab = NULL, xlim = NULL, ylim = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustBoostrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","text":"x Object returned MclustBootstrap. Character string specifying mixing proportions (\"pro\"),     component means (\"mean\") component variances (\"var\")      drawn. show.parest logical specifying parameter estimate drawn vertical line. show.confint logical specifying resampling-based confidence interval drawn bottom graph. Confidence level can provided argument conf.level; see summary.MclustBootstrap. hist.col color used fill bars histograms. hist.border color border around bars histograms. breaks See argument function hist. col, lwd, lty color, line width line type used represent estimated parameters confidence intervals. xlab Optional label horizontal axis. xlim, ylim two-values vector axis range , respectively, horizontal    vertical axis. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustBoostrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","text":"plot variable/component selected parameters.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustBoostrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of bootstrap distributions for mixture model parameters — plot.MclustBootstrap","text":"","code":"# \\donttest{ data(diabetes) X <- diabetes[,-1] modClust <- Mclust(X, G = 3, modelNames = \"VVV\") bootClust <- MclustBootstrap(modClust, nboot = 99) par(mfrow = c(1,3), mar = c(4,2,2,0.5)) plot(bootClust, what = \"pro\")  par(mfrow = c(3,3), mar = c(4,2,2,0.5)) plot(bootClust, what = \"mean\")  # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"Plots model-based mixture discriminant analysis results, scatterplot training test data, classification train test data, errors.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"","code":"# S3 method for MclustDA plot(x, what = c(\"scatterplot\", \"classification\", \"train&test\", \"error\"),       newdata, newclass, dimens = NULL,       symbols, colors, main = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"x object class 'MclustDA' resulting call MclustDA. string specifying type graph requested. Available choices : \"scatterplot\" = plot training data points marked based known classification. Ellipses corresponding covariances mixture components also drawn. \"classification\" = plot data points marked based predicted classification; newdata provided test set shown otherwise training set. \"train&test\" = plot training test data points marked according type set. \"error\" = plot training set (test set newdata newclass provided) misclassified points marked. specified, interactive sessions menu choices proposed. newdata data frame matrix test data. newclass vector giving class labels observations      test data (known). dimens vector integers giving dimensions desired coordinate     projections multivariate data. default take     available dimensions plotting. symbols Either integer character vector assigning plotting symbol     unique class. Elements colors correspond classes order     appearance sequence observations (order used      function factor).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function factor).      default given mclust.options(\"classPlotColors\"). main logical, character string, NULL (default) main title.      NULL FALSE title added plot.      TRUE default title added identifying type plot drawn.     character string provided, used title. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"flexibility plotting, use mclust1Dplot,   mclust2Dplot, surfacePlot, coordProj,  randProj.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting method for MclustDA discriminant analysis — plot.MclustDA","text":"","code":"# \\donttest{ odd <- seq(from = 1, to = nrow(iris), by = 2) even <- odd + 1 X.train <- iris[odd,-5] Class.train <- iris[odd,5] X.test <- iris[even,-5] Class.test <- iris[even,5]  # common EEE covariance structure (which is essentially equivalent to linear discriminant analysis) irisMclustDA <- MclustDA(X.train, Class.train, modelType = \"EDDA\", modelNames = \"EEE\") summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>        -125.443 75 22 -345.8707 #>              #> Classes       n     % Model G #>   setosa     25 33.33   EEE 1 #>   versicolor 25 33.33   EEE 1 #>   virginica  25 33.33   EEE 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Means: #>               [,1] #> Sepal.Length 5.024 #> Sepal.Width  3.480 #> Petal.Length 1.456 #> Petal.Width  0.228 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Class = versicolor #>  #> Means: #>               [,1] #> Sepal.Length 5.992 #> Sepal.Width  2.776 #> Petal.Length 4.308 #> Petal.Width  1.352 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Class = virginica #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26418133  0.06244800   0.15935467  0.03141333 #> Sepal.Width    0.06244800  0.09630933   0.03326933  0.03222400 #> Petal.Length   0.15935467  0.03326933   0.18236800  0.04091733 #> Petal.Width    0.03141333  0.03222400   0.04091733  0.03891200 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0097  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>        -125.443 75 22 -345.8707 #>              #> Classes       n     % Model G #>   setosa     25 33.33   EEE 1 #>   versicolor 25 33.33   EEE 1 #>   virginica  25 33.33   EEE 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0097  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          2        23 #> Classification error = 0.04  #> Brier score          = 0.0243   # common covariance structure selected by BIC irisMclustDA <- MclustDA(X.train, Class.train, modelType = \"EDDA\") summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -87.93758 75 36 -331.3047 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEV 1 #>   versicolor 25 33.33   VEV 1 #>   virginica  25 33.33   VEV 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Means: #>               [,1] #> Sepal.Length 5.024 #> Sepal.Width  3.480 #> Petal.Length 1.456 #> Petal.Width  0.228 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  0.154450439 0.097646496  0.017347101 0.005327878 #> Sepal.Width   0.097646496 0.105230813  0.004066916 0.005599939 #> Petal.Length  0.017347101 0.004066916  0.041742267 0.003476241 #> Petal.Width   0.005327878 0.005599939  0.003476241 0.006454832 #>  #> Class = versicolor #>  #> Means: #>               [,1] #> Sepal.Length 5.992 #> Sepal.Width  2.776 #> Petal.Length 4.308 #> Petal.Width  1.352 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26653496  0.06976610   0.17015657  0.04336127 #> Sepal.Width    0.06976610  0.09861066   0.07509657  0.03823057 #> Petal.Length   0.17015657  0.07509657   0.19799871  0.06126251 #> Petal.Width    0.04336127  0.03823057   0.06126251  0.03627058 #>  #> Class = virginica #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.37570480 0.025364426  0.280227270  0.03871029 #> Sepal.Width    0.02536443 0.080872957  0.006413281  0.05009229 #> Petal.Length   0.28022727 0.006413281  0.309059434  0.05805268 #> Petal.Width    0.03871029 0.050092291  0.058052679  0.07540425 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          0        25 #> Classification error = 0.0133  #> Brier score          = 0.0054  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> EDDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -87.93758 75 36 -331.3047 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEV 1 #>   versicolor 25 33.33   VEV 1 #>   virginica  25 33.33   VEV 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          0        25 #> Classification error = 0.0133  #> Brier score          = 0.0054  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          2        23 #> Classification error = 0.04  #> Brier score          = 0.0297   # general covariance structure selected by BIC irisMclustDA <- MclustDA(X.train, Class.train) summary(irisMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -71.74193 75 48 -350.7233 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEI 2 #>   versicolor 25 33.33   VEE 2 #>   virginica  25 33.33   XXX 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Mixing probabilities: 0.7229143 0.2770857  #>  #> Means: #>                   [,1]      [,2] #> Sepal.Length 5.1761949 4.6269248 #> Sepal.Width  3.6366552 3.0712877 #> Petal.Length 1.4777585 1.3992323 #> Petal.Width  0.2441875 0.1857668 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.120728    0.000000   0.00000000 0.000000000 #> Sepal.Width      0.000000    0.046461   0.00000000 0.000000000 #> Petal.Length     0.000000    0.000000   0.04892923 0.000000000 #> Petal.Width      0.000000    0.000000   0.00000000 0.006358681 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.03044364  0.00000000   0.00000000 0.000000000 #> Sepal.Width    0.00000000  0.01171594   0.00000000 0.000000000 #> Petal.Length   0.00000000  0.00000000   0.01233835 0.000000000 #> Petal.Width    0.00000000  0.00000000   0.00000000 0.001603451 #>  #> Class = versicolor #>  #> Mixing probabilities: 0.2364317 0.7635683  #>  #> Means: #>                  [,1]     [,2] #> Sepal.Length 6.736465 5.761483 #> Sepal.Width  3.000982 2.706336 #> Petal.Length 4.669933 4.195931 #> Petal.Width  1.400893 1.336861 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length  0.030012918 0.008262520   0.02533959 0.008673053 #> Sepal.Width   0.008262520 0.020600060   0.01200205 0.008400168 #> Petal.Length  0.025339590 0.012002053   0.03924151 0.013788157 #> Petal.Width   0.008673053 0.008400168   0.01378816 0.007666627 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.16630011  0.04578222   0.14040543  0.04805696 #> Sepal.Width    0.04578222  0.11414392   0.06650279  0.04654492 #> Petal.Length   0.14040543  0.06650279   0.21743528  0.07639950 #> Petal.Width    0.04805696  0.04654492   0.07639950  0.04248041 #>  #> Class = virginica #>  #> Mixing probabilities: 1  #>  #> Means: #>               [,1] #> Sepal.Length 6.504 #> Sepal.Width  2.936 #> Petal.Length 5.564 #> Petal.Width  2.076 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.349184    0.019056     0.272144    0.040896 #> Sepal.Width      0.019056    0.079104     0.011296    0.048064 #> Petal.Length     0.272144    0.011296     0.285504    0.049536 #> Petal.Width      0.040896    0.048064     0.049536    0.074624 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         25         0 #>   virginica       0          0        25 #> Classification error = 0  #> Brier score          = 0.0041  summary(irisMclustDA, newdata = X.test, newclass = Class.test) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood  n df       BIC #>       -71.74193 75 48 -350.7233 #>              #> Classes       n     % Model G #>   setosa     25 33.33   VEI 2 #>   versicolor 25 33.33   VEE 2 #>   virginica  25 33.33   XXX 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         25         0 #>   virginica       0          0        25 #> Classification error = 0  #> Brier score          = 0.0041  #>  #> Test confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         25          0         0 #>   versicolor      0         24         1 #>   virginica       0          1        24 #> Classification error = 0.0267  #> Brier score          = 0.0159   plot(irisMclustDA)     plot(irisMclustDA, dimens = 3:4)     plot(irisMclustDA, dimens = 4)      plot(irisMclustDA, what = \"classification\")  plot(irisMclustDA, what = \"classification\", newdata = X.test)  plot(irisMclustDA, what = \"classification\", dimens = 3:4)  plot(irisMclustDA, what = \"classification\", newdata = X.test, dimens = 3:4)  plot(irisMclustDA, what = \"classification\", dimens = 4)  plot(irisMclustDA, what = \"classification\", dimens = 4, newdata = X.test)   plot(irisMclustDA, what = \"train&test\", newdata = X.test)  plot(irisMclustDA, what = \"train&test\", newdata = X.test, dimens = 3:4)  plot(irisMclustDA, what = \"train&test\", newdata = X.test, dimens = 4)   plot(irisMclustDA, what = \"error\")  plot(irisMclustDA, what = \"error\", dimens = 3:4)  plot(irisMclustDA, what = \"error\", dimens = 4)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test, dimens = 3:4)  plot(irisMclustDA, what = \"error\", newdata = X.test, newclass = Class.test, dimens = 4)   # simulated 1D data n <- 250  set.seed(1) triModal <- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5)) triClass <- c(rep(1,n), rep(2,n), rep(3,n)) odd <- seq(from = 1, to = length(triModal), by = 2) even <- odd + 1 triMclustDA <- MclustDA(triModal[odd], triClass[odd]) summary(triMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -942.4306 375  6 -1920.423 #>         #> Classes   n     % Model G #>       1 125 33.33     X 1 #>       2 125 33.33     X 1 #>       3 125 33.33     X 1 #>  #> Class prior probabilities: #>         1         2         3  #> 0.3333333 0.3333333 0.3333333  #>  #> Class = 1 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] -4.951981 #>  #> Variances: #> [1] 0.8268339 #>  #> Class = 2 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] -0.01814707 #>  #> Variances: #> [1] 1.201987 #>  #> Class = 3 #>  #> Mixing probabilities: 1  #>  #> Means: #> [1] 4.875429 #>  #> Variances: #> [1] 1.200321 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   0 124   1 #>     3   0   0 125 #> Classification error = 0.0053  #> Brier score          = 0.0073  summary(triMclustDA, newdata = triModal[even], newclass = triClass[even]) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -942.4306 375  6 -1920.423 #>         #> Classes   n     % Model G #>       1 125 33.33     X 1 #>       2 125 33.33     X 1 #>       3 125 33.33     X 1 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   0 124   1 #>     3   0   0 125 #> Classification error = 0.0053  #> Brier score          = 0.0073  #>  #> Test confusion matrix: #>      Predicted #> Class   1   2   3 #>     1 124   1   0 #>     2   1 122   2 #>     3   0   1 124 #> Classification error = 0.0133  #> Brier score          = 0.0089  plot(triMclustDA)     plot(triMclustDA, what = \"classification\")  plot(triMclustDA, what = \"classification\", newdata = triModal[even])  plot(triMclustDA, what = \"train&test\", newdata = triModal[even])  plot(triMclustDA, what = \"error\")  plot(triMclustDA, what = \"error\", newdata = triModal[even], newclass = triClass[even])   # simulated 2D cross data data(cross) odd <- seq(from = 1, to = nrow(cross), by = 2) even <- odd + 1 crossMclustDA <- MclustDA(cross[odd,-1], cross[odd,1]) summary(crossMclustDA, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df     BIC #>       -1381.404 250  9 -2812.5 #>         #> Classes   n  % Model G #>       1 125 50   XXX 1 #>       2 125 50   XXI 1 #>  #> Class prior probabilities: #>   1   2  #> 0.5 0.5  #>  #> Class = 1 #>  #> Mixing probabilities: 1  #>  #> Means: #>           [,1] #> X1  0.03982835 #> X2 -0.55982893 #>  #> Variances: #> [,,1] #>          X1       X2 #> X1 1.030302  1.81975 #> X2 1.819750 72.90428 #>  #> Class = 2 #>  #> Mixing probabilities: 1  #>  #> Means: #>          [,1] #> X1  0.2877120 #> X2 -0.1231171 #>  #> Variances: #> [,,1] #>         X1        X2 #> X1 87.3583 0.0000000 #> X2  0.0000 0.8995777 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2 #>     1 112  13 #>     2  13 112 #> Classification error = 0.104  #> Brier score          = 0.0563  summary(crossMclustDA, newdata = cross[even,-1], newclass = cross[even,1]) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df     BIC #>       -1381.404 250  9 -2812.5 #>         #> Classes   n  % Model G #>       1 125 50   XXX 1 #>       2 125 50   XXI 1 #>  #> Training confusion matrix: #>      Predicted #> Class   1   2 #>     1 112  13 #>     2  13 112 #> Classification error = 0.104  #> Brier score          = 0.0563  #>  #> Test confusion matrix: #>      Predicted #> Class   1   2 #>     1 118   7 #>     2   5 120 #> Classification error = 0.048  #> Brier score          = 0.0298  plot(crossMclustDA)     plot(crossMclustDA, what = \"classification\")  plot(crossMclustDA, what = \"classification\", newdata = cross[even,-1])  plot(crossMclustDA, what = \"train&test\", newdata = cross[even,-1])  plot(crossMclustDA, what = \"error\")  plot(crossMclustDA, what = \"error\", newdata =cross[even,-1], newclass = cross[even,1])  # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"Graphs data projected onto estimated subspace model-based clustering classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"","code":"# S3 method for MclustDR plot(x, dimens,       what = c(\"scatterplot\", \"pairs\", \"contour\", \"classification\",               \"boundaries\", \"density\", \"evalues\"),       symbols, colors, col.contour = gray(0.7), col.sep = grey(0.4),       ngrid = 200, nlevels = 5, asp = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"x object class 'MclustDR' resulting call MclustDR. dimens vector integers giving dimensions desired coordinate     projections multivariate data. type graph requested: \"scatterplot\" = two-dimensional plot data projected onto first two directions specified dimens data points marked according corresponding mixture component.       default, first two directions selected plotting. \"pairs\" = scatterplot matrix data projected onto estimated subspace data points marked according corresponding mixture component.          default, available directions used, unless specified dimens. \"contour\" = two-dimensional plot data projected onto first two directions specified dimens (default, first two directions) density contours classes clusters data points marked according corresponding mixture component. \"classification\" = two-dimensional plot data projected onto first two directions specified dimens (default, first two directions) classification region data points marked according corresponding mixture component. \"boundaries\" = two-dimensional plot data projected onto first two directions specified dimens (default, first two directions) uncertainty boundaries data points marked according corresponding mixture component.       uncertainty shown using greyscale darker regions indicating higher uncertainty. \"density\" = one-dimensional plot estimated density first direction specified dimens (default, first one). set box-plots estimated cluster known class also shown bottom graph. symbols Either integer character vector assigning plotting symbol     unique mixture component. Elements colors correspond classes     order appearance sequence observations (order used     function factor).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique cluster known class. Elements colors     correspond classes order appearance sequence     observations (order used function factor).      default given mclust.options(\"classPlotColors\"). col.contour color contours case = \"contour\". col.sep color classification boundaries case = \"classification\". ngrid integer specifying number grid points use evaluating classification regions. nlevels number levels use case = \"contour\". asp scatterplots \\(y/x\\) aspect ratio, see     plot.window. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"Scrucca, L. (2010) Dimension reduction model-based clustering.   Statistics Computing, 20(4), pp. 471-484.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting method for dimension reduction for model-based clustering and classification — plot.MclustDR","text":"","code":"# \\donttest{ mod <- Mclust(iris[,1:4], G = 3) dr <- MclustDR(mod, lambda = 0.5) plot(dr, what = \"evalues\")  plot(dr, what = \"pairs\")  plot(dr, what = \"scatterplot\", dimens = c(1,3))  plot(dr, what = \"contour\")  plot(dr, what = \"classification\", ngrid = 200)  plot(dr, what = \"boundaries\", ngrid = 200)  plot(dr, what = \"density\")  plot(dr, what = \"density\", dimens = 2)   data(banknote) da <- MclustDA(banknote[,2:7], banknote$Status, G = 1:3) dr <- MclustDR(da) plot(dr, what = \"evalues\")  plot(dr, what = \"pairs\")  plot(dr, what = \"contour\")  plot(dr, what = \"classification\", ngrid = 200)  plot(dr, what = \"boundaries\", ngrid = 200)  plot(dr, what = \"density\")  plot(dr, what = \"density\", dimens = 2)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustSSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","title":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","text":"Plots semi-supervised classification based Gaussian finite mixture models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustSSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","text":"","code":"# S3 method for MclustSSC plot(x, what = c(\"BIC\", \"classification\", \"uncertainty\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustSSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","text":"x object class 'MclustSSC' resulting call MclustSSC. string specifying type graph requested. Available choices : \"BIC\" = plot BIC values used model selection, .e. choosing model class covariances. \"classification\" = plot data points marked based known predicted classification. \"uncertainty\" = plot classification uncertainty. specified, interactive sessions menu choices proposed. ... arguments passed methods. See  plot.Mclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustSSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.MclustSSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting method for MclustSSC semi-supervised classification — plot.MclustSSC","text":"","code":"X <- iris[,1:4] class <- iris$Species # randomly remove class labels set.seed(123) class[sample(1:length(class), size = 120)] <- NA table(class, useNA = \"ifany\") #> class #>     setosa versicolor  virginica       <NA>  #>         10         15          5        120  clPairs(X, ifelse(is.na(class), 0, class),         symbols = c(0, 16, 17, 18), colors = c(\"grey\", 4, 2, 3),         main = \"Partially classified data\")   # Fit semi-supervised classification model mod_SSC  <- MclustSSC(X, class) summary(mod_SSC, parameters = TRUE) #> ----------------------------------------------------------------  #> Gaussian finite mixture model for semi-supervised classification  #> ----------------------------------------------------------------  #>  #>  log-likelihood   n df       BIC #>        -193.521 150 38 -577.4461 #>              #> Classes        n     % Model G #>   setosa      10  6.67   VEV 1 #>   versicolor  15 10.00   VEV 1 #>   virginica    5  3.33   VEV 1 #>   <NA>       120 80.00         #>  #> Mixing probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3876695  0.2789972  #>  #> Means: #>              setosa versicolor virginica #> Sepal.Length  5.006   6.055272  6.549251 #> Sepal.Width   3.428   2.828321  2.932692 #> Petal.Length  1.462   4.453865  5.534246 #> Petal.Width   0.246   1.396544  2.064307 #>  #> Variances: #> setosa  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.15368111  0.13158310  0.021865057 0.013501154 #> Sepal.Width    0.13158310  0.17948985  0.015459683 0.012186709 #> Petal.Length   0.02186506  0.01545968  0.029128899 0.006498098 #> Petal.Width    0.01350115  0.01218671  0.006498098 0.009759900 #> versicolor  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.29753053  0.10407744    0.2505462  0.07457733 #> Sepal.Width    0.10407744  0.10023478    0.1202666  0.05072488 #> Petal.Length   0.25054623  0.12026661    0.3560530  0.11652817 #> Petal.Width    0.07457733  0.05072488    0.1165282  0.06076865 #> virginica  #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.46326081  0.07787790   0.34315068  0.06944725 #> Sepal.Width    0.07787790  0.08041718   0.05955965  0.05271723 #> Petal.Length   0.34315068  0.05955965   0.35468725  0.06589333 #> Petal.Width    0.06944725  0.05271723   0.06589333  0.06694996 #>  #> Classification summary: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         10          0         0 #>   versicolor      0         15         0 #>   virginica       0          0         5 #>   <NA>           40         45        35  pred_SSC <- predict(mod_SSC) table(Predicted = pred_SSC$classification, Actual = class, useNA = \"ifany\") #>             Actual #> Predicted    setosa versicolor virginica <NA> #>   setosa         10          0         0   40 #>   versicolor      0         15         0   45 #>   virginica       0          0         5   35  plot(mod_SSC, what = \"BIC\")  plot(mod_SSC, what = \"classification\")  plot(mod_SSC, what = \"uncertainty\")"},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Combined Clusterings Results — plot.clustCombi","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"Plot combined clusterings results: classifications corresponding Mclust/BIC hierarchically combined classes, \"entropy plots\" help select number classes, tree structure obtained combining mixture components.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"","code":"# S3 method for clustCombi plot(x, what = c(\"classification\", \"entropy\", \"tree\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"x Object returned clustCombi function. Type plot. ... arguments passed functions: combiPlot, entPlot, combiTree. Please see corresponding documentations.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"Classifications plotted combiPlot, relies Mclust plot functions.  Entropy plots plotted entPlot may help select number classes: please see article cited references. Tree plots produced combiTree graph tree structure implied clusters combining  process.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"J.-P. Baudry, . E. Raftery, G. Celeux, K. Lo R. Gottardo (2010). Combining mixture components clustering. Journal Computational Graphical Statistics, 19(2):332-353.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"J.-P. Baudry, . E. Raftery, L. Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.clustCombi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Combined Clusterings Results — plot.clustCombi","text":"","code":"# \\donttest{ data(Baudry_etal_2010_JCGS_examples)  ## 1D Example  output <- clustCombi(data = Test1D, G=1:15)  # plots the hierarchy of combined solutions, then some \"entropy plots\" which  # may help one to select the number of classes (please see the article cited  # in the references) plot(output)                ## 2D Example  output <- clustCombi(data = ex4.1)   # plots the hierarchy of combined solutions, then some \"entropy plots\" which  # may help one to select the number of classes (please see the article cited  # in the references) plot(output)            ## 3D Example  output <- clustCombi(data = ex4.4.2)  # plots the hierarchy of combined solutions, then some \"entropy plots\" which  # may help one to select the number of classes (please see the article cited  # in the references) plot(output)       # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots for Mixture-Based Density Estimate — plot.densityMclust","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"Plotting methods object class 'mclustDensity'. Available graphs    plot BIC values density univariate bivariate data.    higher data dimensionality scatterplot matrix pairwise densities   drawn.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"","code":"# S3 method for densityMclust plot(x, data = NULL, what = c(\"BIC\", \"density\", \"diagnostic\"), ...)  plotDensityMclust1(x, data = NULL, col = gray(0.3), hist.col = \"lightgrey\",                     hist.border = \"white\",  breaks = \"Sturges\", ...)  plotDensityMclust2(x, data = NULL, nlevels = 11, levels = NULL,                     prob = c(0.25, 0.5, 0.75),                    points.pch = 1, points.col = 1, points.cex = 0.8, ...)  plotDensityMclustd(x, data = NULL, nlevels = 11, levels = NULL,                     prob = c(0.25, 0.5, 0.75),                    points.pch = 1, points.col = 1, points.cex = 0.8,                    gap = 0.2, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"x object class 'mclustDensity' obtained call            densityMclust function. data Optional data points. type graph requested: \"density\" = plot estimated density; data            also provided density plotted data points (see Details            section). \"BIC\" = plot BIC values estimated models versus                           number components. \"diagnostic\" = diagnostic plots (available            one-dimensional case, see densityMclust.diagnostic)  col color used draw density line 1-dimension    contours higher dimensions. hist.col color used fill bars histogram. hist.border color border around bars histogram. breaks See argument function hist. points.pch, points.col, points.cex character symbols, colors, magnification used plotting data points. nlevels integer, number levels used plotting contour densities. levels vector density levels draw contour lines. prob vector probability levels computing HDR. used type = \"hdr\" supersede previous nlevels levels arguments. gap Distance subplots, margin lines, matrix pairwise scatterplots. ... Additional arguments passed surfacePlot.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"function plot.densityMclust allows obtain plot   estimated density graph BIC values evaluated models. = \"density\" produced plot dependes dimensionality   data. one-dimensional data call data provided produces    plot estimated density sensible range values.    data provided density -plotted histogram   observed data. two-dimensional data arguments available accepted   surfacePlot function. particular, density can   represented \"contour\", \"hdr\", \"image\",    \"persp\" type graph.    type = \"hdr\" Highest Density Regions (HDRs) plotted    probability levels prob. See hdrlevels details. higher dimensionality scatterplot matrix pairwise projected   densities drawn.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.densityMclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots for Mixture-Based Density Estimate — plot.densityMclust","text":"","code":"# \\donttest{ dens <- densityMclust(faithful$waiting, plot = FALSE) summary(dens) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust E (univariate, equal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1034.002 272  4 -2090.427 -2099.576 summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust E (univariate, equal variance) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1034.002 272  4 -2090.427 -2099.576 #>  #> Mixing probabilities: #>         1         2  #> 0.3609461 0.6390539  #>  #> Means: #>        1        2  #> 54.61675 80.09239  #>  #> Variances: #>        1        2  #> 34.44093 34.44093  plot(dens, what = \"BIC\", legendArgs = list(x = \"topright\"))  plot(dens, what = \"density\", data = faithful$waiting)   dens <- densityMclust(faithful, plot = FALSE) summary(dens) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 #>  #> Mixing probabilities: #>         1         2         3  #> 0.1656784 0.3563696 0.4779520  #>  #> Means: #>                [,1]      [,2]      [,3] #> eruptions  3.793066  2.037596  4.463245 #> waiting   77.521051 54.491158 80.833439 #>  #> Variances: #> [,,1] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,2] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,3] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 plot(dens, what = \"density\", data = faithful,       drawlabels = FALSE, points.pch = 20)  plot(dens, what = \"density\", type = \"hdr\")  plot(dens, what = \"density\", type = \"hdr\", prob = seq(0.1, 0.9, by = 0.1))  plot(dens, what = \"density\", type = \"hdr\", data = faithful)  plot(dens, what = \"density\", type = \"persp\")   dens <- densityMclust(iris[,1:4], plot = FALSE) summary(dens, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Mixing probabilities: #>         1         2  #> 0.3333319 0.6666681  #>  #> Means: #>                   [,1]     [,2] #> Sepal.Length 5.0060022 6.261996 #> Sepal.Width  3.4280049 2.871999 #> Petal.Length 1.4620007 4.905992 #> Petal.Width  0.2459998 1.675997 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.15065114  0.13080115   0.02084463  0.01309107 #> Sepal.Width    0.13080115  0.17604529   0.01603245  0.01221458 #> Petal.Length   0.02084463  0.01603245   0.02808260  0.00601568 #> Petal.Width    0.01309107  0.01221458   0.00601568  0.01042365 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.4000438  0.10865444    0.3994018  0.14368256 #> Sepal.Width     0.1086544  0.10928077    0.1238904  0.07284384 #> Petal.Length    0.3994018  0.12389040    0.6109024  0.25738990 #> Petal.Width     0.1436826  0.07284384    0.2573899  0.16808182 plot(dens, what = \"density\", data = iris[,1:4],       col = \"slategrey\", drawlabels = FALSE, nlevels = 7)  plot(dens, what = \"density\", type = \"hdr\", data = iris[,1:4])  plot(dens, what = \"density\", type = \"persp\", col = grey(0.9))  # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":null,"dir":"Reference","previous_headings":"","what":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"Display two types dendrograms model-based hierarchical clustering    objects.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"","code":"# S3 method for hc plot(x, what=c(\"loglik\",\"merge\"), maxG=NULL, labels=FALSE, hang=0, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"x object class 'hc'. character string indicating type dendrogram displayed.     Possible options : \"loglik\" Distances dendrogram levels based           classification likelihood. \"merge\" Distances dendrogram levels uniform,                           levels correspond number clusters.  maxG maximum number clusters dendrogram.     = \"merge\", default     number clusters initial partition.     = \"loglik\", default minimnum     maximum number clusters classification loglikelihood     computed cases, maximum number clusters     classification likelihood increases increasing numbers     clusters. labels logical variable indicating whether display leaf (observation)     labels dendrogram (row names data). likely      useful number observations fairly small, since otherwise     labels crowded read.      default display leaf labels. hang hclust objects, argument fraction plot      height labels hang rest plot. negative      value cause labels hang 0.     model-based hierarchical clustering share     properties hclust, hang argment work     many instances. ... Additional plotting arguments.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"dendrogram drawn, distances based either classification   likelihood merge level (number clusters).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"plotting input share properties hclust    objects, hence plotting arguments associated hclust    can expected work .","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"modelName = \"E\" (univariate equal variances)   modelName = \"EII\" (multivariate equal spherical   covariances), underlying model   Ward's method hierarchical clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"J. D. Banfield . E. Raftery (1993).   Model-based Gaussian non-Gaussian Clustering.   Biometrics 49:803-821. C. Fraley (1998).   Algorithms model-based Gaussian hierarchical clustering.   SIAM Journal Scientific Computing 20:270-281. C. Fraley . E. Raftery (2002).   Model-based clustering, discriminant analysis, density estimation.   Journal American Statistical Association 97:611-631.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.hc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dendrograms for Model-based Agglomerative Hierarchical Clustering — plot.hc","text":"","code":"data(EuroUnemployment) hcTree <- hc(modelName = \"VVV\", data = EuroUnemployment) plot(hcTree, what = \"loglik\")  plot(hcTree, what = \"loglik\", labels = TRUE)  plot(hcTree, what = \"loglik\", maxG = 5, labels = TRUE)  plot(hcTree, what = \"merge\")  plot(hcTree, what = \"merge\", labels = TRUE)  plot(hcTree, what = \"merge\", labels = TRUE, hang = 0.1)  plot(hcTree, what = \"merge\", labels = TRUE, hang = -1)  plot(hcTree, what = \"merge\", labels = TRUE, maxG = 5)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustBIC.html","id":null,"dir":"Reference","previous_headings":"","what":"BIC Plot for Model-Based Clustering — plot.mclustBIC","title":"BIC Plot for Model-Based Clustering — plot.mclustBIC","text":"Plots BIC values returned mclustBIC function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustBIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BIC Plot for Model-Based Clustering — plot.mclustBIC","text":"","code":"# S3 method for mclustBIC plot(x, G = NULL, modelNames = NULL,       symbols = NULL, colors = NULL,       xlab = NULL, ylab = \"BIC\",       legendArgs = list(x = \"bottomright\", ncol = 2, cex = 1, inset = 0.01),       ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustBIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BIC Plot for Model-Based Clustering — plot.mclustBIC","text":"x Output mclustBIC. G One numbers components corresponding models fit x.     default plot BIC numbers components fit. modelNames One model names corresponding models fit x.     default plot BIC models fit. symbols Either integer character vector assigning plotting symbol     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotColors\"). xlab Optional label horizontal axis BIC plot. ylab Label vertical axis BIC plot. legendArgs Arguments pass legend function. Set NULL     legend. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustBIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BIC Plot for Model-Based Clustering — plot.mclustBIC","text":"plot BIC values.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustBIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BIC Plot for Model-Based Clustering — plot.mclustBIC","text":"","code":"# \\donttest{ plot(mclustBIC(precip), legendArgs =  list(x = \"bottomleft\"))   plot(mclustBIC(faithful))   plot(mclustBIC(iris[,-5]))  # }"},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustICL.html","id":null,"dir":"Reference","previous_headings":"","what":"ICL Plot for Model-Based Clustering — plot.mclustICL","title":"ICL Plot for Model-Based Clustering — plot.mclustICL","text":"Plots ICL values returned mclustICL function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustICL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICL Plot for Model-Based Clustering — plot.mclustICL","text":"","code":"# S3 method for mclustICL plot(x, ylab = \"ICL\", ...)"},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustICL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICL Plot for Model-Based Clustering — plot.mclustICL","text":"x Output mclustICL. ylab Label vertical axis plot. ... arguments passed plot.mclustBIC function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustICL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICL Plot for Model-Based Clustering — plot.mclustICL","text":"plot ICL values.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/plot.mclustICL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ICL Plot for Model-Based Clustering — plot.mclustICL","text":"","code":"# \\donttest{ data(faithful) faithful.ICL = mclustICL(faithful) plot(faithful.ICL)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"Cluster prediction multivariate observations based Gaussian finite mixture models estimated Mclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"","code":"# S3 method for Mclust predict(object, newdata, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"object object class 'Mclust' resulting call Mclust. newdata data frame matrix giving data. missing clustering data obtained call Mclust classified. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"Returns list following components: classification factor predicted cluster labels newdata. z matrix whose [,k]th entry probability             observation newdata belongs kth cluster.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/predict.Mclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster multivariate observations by Gaussian finite mixture modeling — predict.Mclust","text":"","code":"model <- Mclust(faithful)  # predict cluster for the observed data pred <- predict(model)  str(pred) #> List of 2 #>  $ classification: int [1:272] 1 2 1 2 3 2 3 1 2 3 ... #>  $ z             : num [1:272, 1:3] 9.72e-01 8.12e-13 9.97e-01 3.06e-07 1.17e-02 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"1\" \"2\" \"3\" pred$z              # equal to model$z #>                   1            2            3 #>   [1,] 9.718934e-01 1.352740e-08 2.810657e-02 #>   [2,] 8.122644e-13 1.000000e+00 6.813886e-21 #>   [3,] 9.967828e-01 2.108920e-05 3.196126e-03 #>   [4,] 3.056090e-07 9.999997e-01 1.407759e-13 #>   [5,] 1.165923e-02 1.183305e-19 9.883408e-01 #>   [6,] 3.050001e-03 9.969497e-01 3.160044e-07 #>   [7,] 2.962193e-03 3.235046e-22 9.970378e-01 #>   [8,] 9.758494e-01 1.249199e-09 2.415062e-02 #>   [9,] 4.942048e-12 1.000000e+00 1.658458e-19 #>  [10,] 5.501578e-02 2.166813e-17 9.449842e-01 #>  [11,] 1.571164e-12 1.000000e+00 1.757682e-20 #>  [12,] 7.125339e-01 2.401096e-12 2.874661e-01 #>  [13,] 1.522898e-01 1.947418e-14 8.477102e-01 #>  [14,] 1.847134e-14 1.000000e+00 1.201399e-22 #>  [15,] 2.602557e-03 2.076298e-21 9.973974e-01 #>  [16,] 5.633073e-10 1.000000e+00 1.222865e-16 #>  [17,] 7.200548e-12 1.000000e+00 3.172820e-20 #>  [18,] 1.118067e-03 8.116665e-23 9.988819e-01 #>  [19,] 6.725706e-15 1.000000e+00 1.038195e-23 #>  [20,] 1.065036e-01 3.367444e-15 8.934964e-01 #>  [21,] 2.463338e-13 1.000000e+00 2.233795e-21 #>  [22,] 1.847134e-14 1.000000e+00 1.201399e-22 #>  [23,] 9.920432e-01 4.123192e-07 7.956377e-03 #>  [24,] 9.691025e-01 3.054996e-02 3.475489e-04 #>  [25,] 8.788529e-03 7.084549e-18 9.912115e-01 #>  [26,] 9.745951e-01 2.763897e-09 2.540491e-02 #>  [27,] 3.407283e-11 1.000000e+00 1.195405e-18 #>  [28,] 3.212497e-01 9.439276e-13 6.787503e-01 #>  [29,] 7.919031e-01 1.107526e-10 2.080969e-01 #>  [30,] 2.358343e-02 1.921480e-17 9.764166e-01 #>  [31,] 6.186793e-02 7.827461e-15 9.381321e-01 #>  [32,] 1.675999e-02 1.533009e-17 9.832400e-01 #>  [33,] 9.944634e-01 2.568250e-04 5.279751e-03 #>  [34,] 4.481798e-01 7.290846e-13 5.518202e-01 #>  [35,] 7.991348e-01 7.705541e-10 2.008652e-01 #>  [36,] 2.807776e-11 1.000000e+00 1.647089e-18 #>  [37,] 2.851554e-13 1.000000e+00 5.014801e-21 #>  [38,] 7.559766e-04 1.392489e-22 9.992440e-01 #>  [39,] 1.147741e-11 1.000000e+00 1.127699e-19 #>  [40,] 1.514760e-03 1.420726e-23 9.984852e-01 #>  [41,] 4.864473e-02 1.399562e-16 9.513553e-01 #>  [42,] 2.095305e-11 1.000000e+00 3.268107e-19 #>  [43,] 8.471971e-03 6.485284e-20 9.915280e-01 #>  [44,] 1.467127e-12 1.000000e+00 7.172049e-21 #>  [45,] 8.565250e-03 1.027686e-17 9.914347e-01 #>  [46,] 9.977963e-01 8.107782e-07 2.202843e-03 #>  [47,] 7.542305e-01 3.880895e-08 2.457695e-01 #>  [48,] 2.196538e-10 1.000000e+00 2.589804e-17 #>  [49,] 4.540594e-03 2.058058e-20 9.954594e-01 #>  [50,] 3.234673e-10 1.000000e+00 1.364151e-17 #>  [51,] 8.853270e-04 2.304271e-21 9.991147e-01 #>  [52,] 2.714269e-03 9.717403e-23 9.972857e-01 #>  [53,] 1.571164e-12 1.000000e+00 1.757682e-20 #>  [54,] 7.559766e-04 1.392489e-22 9.992440e-01 #>  [55,] 2.127974e-13 1.000000e+00 9.950224e-22 #>  [56,] 5.284488e-04 1.086389e-23 9.994716e-01 #>  [57,] 9.101062e-01 2.941878e-08 8.989382e-02 #>  [58,] 3.035027e-12 1.000000e+00 6.155272e-21 #>  [59,] 7.074222e-03 8.763842e-19 9.929258e-01 #>  [60,] 6.540510e-02 2.445501e-16 9.345949e-01 #>  [61,] 3.410870e-08 1.000000e+00 1.098053e-14 #>  [62,] 1.509745e-02 4.411429e-19 9.849025e-01 #>  [63,] 2.749305e-14 1.000000e+00 1.742360e-22 #>  [64,] 1.061560e-03 1.707274e-22 9.989384e-01 #>  [65,] 1.240645e-11 1.000000e+00 1.033014e-19 #>  [66,] 4.318969e-02 3.868255e-19 9.568103e-01 #>  [67,] 1.932731e-01 4.780616e-14 8.067269e-01 #>  [68,] 2.286484e-03 1.332539e-20 9.977135e-01 #>  [69,] 1.342481e-08 1.000000e+00 8.692163e-16 #>  [70,] 2.008720e-03 8.551723e-20 9.979913e-01 #>  [71,] 4.610517e-01 3.385527e-13 5.389483e-01 #>  [72,] 5.071456e-11 1.000000e+00 1.733666e-18 #>  [73,] 1.328412e-02 2.835508e-18 9.867159e-01 #>  [74,] 4.616284e-01 5.207901e-11 5.383716e-01 #>  [75,] 7.592772e-10 1.000000e+00 2.553912e-17 #>  [76,] 8.854996e-05 7.441358e-25 9.999115e-01 #>  [77,] 6.763293e-10 1.000000e+00 3.223454e-17 #>  [78,] 7.258917e-03 6.041756e-19 9.927411e-01 #>  [79,] 7.303983e-01 1.169947e-10 2.696017e-01 #>  [80,] 9.745951e-01 2.763897e-09 2.540491e-02 #>  [81,] 2.296721e-01 3.696588e-13 7.703279e-01 #>  [82,] 5.879368e-02 1.072609e-16 9.412063e-01 #>  [83,] 2.588245e-01 5.886331e-12 7.411755e-01 #>  [84,] 1.100918e-03 9.988991e-01 9.937520e-09 #>  [85,] 3.348483e-01 4.467229e-12 6.651517e-01 #>  [86,] 3.890515e-04 4.029390e-25 9.996109e-01 #>  [87,] 6.016098e-01 2.524587e-11 3.983902e-01 #>  [88,] 1.177245e-02 1.201813e-18 9.882276e-01 #>  [89,] 1.147751e-10 1.000000e+00 2.764243e-17 #>  [90,] 5.586289e-01 1.616689e-13 4.413711e-01 #>  [91,] 2.624614e-08 1.000000e+00 6.173453e-15 #>  [92,] 7.139508e-02 5.407336e-18 9.286049e-01 #>  [93,] 6.317286e-13 1.000000e+00 1.054763e-20 #>  [94,] 8.251763e-04 4.636603e-22 9.991748e-01 #>  [95,] 5.633028e-11 1.000000e+00 4.988789e-19 #>  [96,] 6.037828e-02 1.137000e-14 9.396217e-01 #>  [97,] 3.558599e-03 3.689506e-21 9.964414e-01 #>  [98,] 8.938701e-01 3.043581e-09 1.061299e-01 #>  [99,] 9.402753e-13 1.000000e+00 1.529697e-20 #> [100,] 4.439774e-04 9.670839e-24 9.995560e-01 #> [101,] 1.665979e-05 9.999833e-01 4.392748e-11 #> [102,] 5.146737e-02 4.376120e-18 9.485326e-01 #> [103,] 4.475494e-11 1.000000e+00 5.854163e-18 #> [104,] 1.471627e-02 6.400264e-19 9.852837e-01 #> [105,] 4.181515e-01 3.253355e-13 5.818485e-01 #> [106,] 1.915831e-13 1.000000e+00 3.457826e-21 #> [107,] 2.670820e-03 1.431560e-21 9.973292e-01 #> [108,] 2.610027e-13 1.000000e+00 1.988317e-21 #> [109,] 7.616311e-04 9.184970e-24 9.992384e-01 #> [110,] 9.464002e-01 1.131278e-09 5.359983e-02 #> [111,] 1.587192e-03 1.576850e-20 9.984128e-01 #> [112,] 1.301956e-07 9.999999e-01 7.519433e-14 #> [113,] 5.324023e-04 7.165921e-25 9.994676e-01 #> [114,] 2.702041e-02 3.031389e-17 9.729796e-01 #> [115,] 8.036454e-13 1.000000e+00 2.474800e-21 #> [116,] 4.424756e-03 2.985099e-20 9.955752e-01 #> [117,] 5.101283e-09 1.000000e+00 4.316568e-15 #> [118,] 6.532596e-03 1.736927e-20 9.934674e-01 #> [119,] 8.335337e-12 1.000000e+00 7.122883e-20 #> [120,] 3.305090e-02 1.539350e-18 9.669491e-01 #> [121,] 6.770422e-06 9.999932e-01 7.257881e-11 #> [122,] 3.121312e-01 2.043738e-11 6.878688e-01 #> [123,] 1.016630e-01 7.121113e-15 8.983370e-01 #> [124,] 5.071456e-11 1.000000e+00 1.733666e-18 #> [125,] 7.057939e-03 5.691153e-21 9.929421e-01 #> [126,] 8.945755e-01 1.994239e-10 1.054245e-01 #> [127,] 2.349827e-13 1.000000e+00 6.909647e-21 #> [128,] 1.434458e-02 9.285648e-19 9.856554e-01 #> [129,] 1.371431e-08 1.000000e+00 6.589274e-15 #> [130,] 4.817023e-03 6.452448e-22 9.951830e-01 #> [131,] 8.647851e-14 1.000000e+00 1.644001e-21 #> [132,] 2.143190e-01 7.256895e-15 7.856810e-01 #> [133,] 8.656118e-04 9.991343e-01 4.236381e-08 #> [134,] 6.969308e-02 7.856501e-18 9.303069e-01 #> [135,] 6.522677e-14 1.000000e+00 8.981236e-22 #> [136,] 3.881733e-02 2.606207e-17 9.611827e-01 #> [137,] 1.294720e-12 1.000000e+00 2.421824e-20 #> [138,] 3.693752e-04 8.475181e-25 9.996306e-01 #> [139,] 5.754502e-11 1.000000e+00 3.781855e-18 #> [140,] 9.155242e-01 8.922485e-10 8.447583e-02 #> [141,] 1.271110e-01 2.548436e-15 8.728890e-01 #> [142,] 5.076795e-08 9.999999e-01 1.592479e-14 #> [143,] 1.079512e-02 3.612667e-19 9.892049e-01 #> [144,] 8.040481e-04 6.724494e-22 9.991960e-01 #> [145,] 5.074409e-02 1.006568e-15 9.492559e-01 #> [146,] 2.302645e-10 1.000000e+00 8.372484e-18 #> [147,] 4.311859e-03 4.329707e-20 9.956881e-01 #> [148,] 8.515086e-12 1.000000e+00 5.399649e-19 #> [149,] 1.115927e-04 1.702496e-28 9.998884e-01 #> [150,] 5.457239e-13 1.000000e+00 4.698339e-21 #> [151,] 1.222524e-04 1.362083e-24 9.998777e-01 #> [152,] 5.004916e-01 5.193022e-12 4.995084e-01 #> [153,] 1.045187e-05 9.999895e-01 1.235923e-11 #> [154,] 5.892098e-03 7.688890e-20 9.941079e-01 #> [155,] 9.740026e-01 6.316488e-07 2.599678e-02 #> [156,] 4.551836e-01 7.643306e-11 5.448164e-01 #> [157,] 1.398213e-02 1.347170e-18 9.860179e-01 #> [158,] 4.239136e-01 1.442305e-15 5.760864e-01 #> [159,] 5.457239e-13 1.000000e+00 4.698339e-21 #> [160,] 6.459649e-01 1.096637e-13 3.540351e-01 #> [161,] 6.732841e-11 1.000000e+00 2.337600e-17 #> [162,] 2.548501e-01 3.676249e-15 7.451499e-01 #> [163,] 2.173231e-10 1.000000e+00 9.406154e-18 #> [164,] 8.152864e-01 1.601752e-10 1.847136e-01 #> [165,] 9.833253e-01 1.778141e-05 1.665694e-02 #> [166,] 6.001466e-03 8.036682e-19 9.939985e-01 #> [167,] 2.439069e-06 9.999976e-01 2.277971e-12 #> [168,] 2.168957e-04 5.885076e-26 9.997831e-01 #> [169,] 5.236342e-12 1.000000e+00 1.476206e-19 #> [170,] 6.929452e-03 5.444971e-22 9.930705e-01 #> [171,] 1.153277e-12 1.000000e+00 3.056737e-20 #> [172,] 7.674203e-10 1.000000e+00 7.031707e-17 #> [173,] 6.158327e-03 5.540612e-19 9.938417e-01 #> [174,] 9.960389e-01 2.291304e-04 3.732014e-03 #> [175,] 2.057063e-01 1.543074e-14 7.942937e-01 #> [176,] 5.737352e-02 1.557926e-16 9.426265e-01 #> [177,] 1.138996e-02 2.643425e-17 9.886100e-01 #> [178,] 3.766471e-08 1.000000e+00 7.625111e-14 #> [179,] 5.522189e-01 2.378695e-13 4.477811e-01 #> [180,] 1.775964e-01 2.155979e-13 8.224036e-01 #> [181,] 6.354389e-12 1.000000e+00 1.071383e-19 #> [182,] 6.158327e-03 5.540612e-19 9.938417e-01 #> [183,] 1.167960e-01 7.524305e-16 8.832040e-01 #> [184,] 8.993726e-01 9.050050e-11 1.006274e-01 #> [185,] 2.597520e-11 1.000000e+00 1.798058e-18 #> [186,] 2.299299e-02 2.788361e-17 9.770070e-01 #> [187,] 3.681036e-01 4.490247e-14 6.318964e-01 #> [188,] 6.522677e-14 1.000000e+00 8.981236e-22 #> [189,] 2.988859e-02 6.832150e-18 9.701114e-01 #> [190,] 2.557641e-09 1.000000e+00 5.905644e-16 #> [191,] 1.034386e-03 2.476085e-22 9.989656e-01 #> [192,] 5.180779e-12 1.000000e+00 5.361570e-20 #> [193,] 9.085891e-04 1.588814e-21 9.990914e-01 #> [194,] 3.343315e-01 2.903181e-14 6.656685e-01 #> [195,] 5.740909e-01 1.175468e-11 4.259091e-01 #> [196,] 1.271110e-01 2.548436e-15 8.728890e-01 #> [197,] 9.902747e-01 4.224845e-09 9.725258e-03 #> [198,] 3.951356e-02 2.722420e-16 9.604864e-01 #> [199,] 1.989174e-09 1.000000e+00 9.141704e-16 #> [200,] 3.046901e-03 3.434744e-20 9.969531e-01 #> [201,] 3.554759e-09 1.000000e+00 3.494787e-16 #> [202,] 5.110452e-02 6.636923e-17 9.488955e-01 #> [203,] 3.111355e-01 8.630793e-16 6.888645e-01 #> [204,] 2.083071e-12 1.000000e+00 3.217410e-20 #> [205,] 5.453055e-03 2.346427e-19 9.945469e-01 #> [206,] 2.400481e-14 1.000000e+00 2.136891e-22 #> [207,] 3.918381e-02 2.646264e-16 9.608162e-01 #> [208,] 8.164068e-01 1.050126e-11 1.835932e-01 #> [209,] 1.588015e-12 1.000000e+00 4.839441e-20 #> [210,] 1.471627e-02 6.400264e-19 9.852837e-01 #> [211,] 8.089220e-05 9.999191e-01 7.057578e-11 #> [212,] 2.408037e-03 6.334700e-21 9.975920e-01 #> [213,] 4.244300e-13 1.000000e+00 7.272844e-21 #> [214,] 8.032694e-01 5.203791e-10 1.967306e-01 #> [215,] 9.912176e-01 2.087079e-04 8.573687e-03 #> [216,] 1.133928e-01 1.660728e-14 8.866072e-01 #> [217,] 8.841066e-08 9.999999e-01 1.427544e-13 #> [218,] 1.448983e-03 1.971190e-24 9.985510e-01 #> [219,] 6.590714e-11 1.000000e+00 3.083617e-18 #> [220,] 2.087458e-01 1.606877e-13 7.912542e-01 #> [221,] 6.317286e-13 1.000000e+00 1.054763e-20 #> [222,] 9.998566e-02 6.824912e-16 9.000143e-01 #> [223,] 2.989302e-13 1.000000e+00 1.621217e-21 #> [224,] 1.387969e-02 2.042580e-17 9.861203e-01 #> [225,] 5.069810e-01 3.534195e-12 4.930190e-01 #> [226,] 2.755283e-01 1.244176e-13 7.244717e-01 #> [227,] 3.326739e-01 4.412307e-13 6.673261e-01 #> [228,] 9.102191e-02 3.049321e-15 9.089781e-01 #> [229,] 6.328107e-01 5.584964e-10 3.671893e-01 #> [230,] 8.628811e-03 6.778307e-19 9.913712e-01 #> [231,] 2.882723e-01 9.209705e-12 7.117277e-01 #> [232,] 1.848555e-07 9.999998e-01 3.373248e-13 #> [233,] 2.041132e-01 1.522184e-15 7.958868e-01 #> [234,] 6.909142e-10 1.000000e+00 2.443606e-16 #> [235,] 2.695946e-02 1.968646e-19 9.730405e-01 #> [236,] 4.269228e-12 1.000000e+00 7.387443e-20 #> [237,] 2.207115e-12 1.000000e+00 2.863839e-20 #> [238,] 7.822194e-02 2.832627e-15 9.217781e-01 #> [239,] 6.201193e-01 7.891822e-12 3.798807e-01 #> [240,] 1.839679e-06 9.999982e-01 1.244465e-12 #> [241,] 2.044905e-01 2.342947e-13 7.955095e-01 #> [242,] 2.992473e-09 1.000000e+00 3.650333e-15 #> [243,] 3.693752e-04 8.475181e-25 9.996306e-01 #> [244,] 9.380836e-02 9.061825e-01 9.159001e-06 #> [245,] 7.568981e-03 2.827070e-20 9.924310e-01 #> [246,] 8.304147e-01 3.324163e-11 1.695853e-01 #> [247,] 7.674203e-10 1.000000e+00 7.031707e-17 #> [248,] 4.437355e-02 4.102308e-17 9.556264e-01 #> [249,] 1.112770e-07 9.999999e-01 1.216522e-14 #> [250,] 4.192277e-02 1.311454e-15 9.580772e-01 #> [251,] 2.413896e-09 1.000000e+00 6.634756e-16 #> [252,] 2.258101e-02 2.668524e-18 9.774190e-01 #> [253,] 9.752857e-01 2.854950e-07 2.471402e-02 #> [254,] 1.138996e-02 2.643425e-17 9.886100e-01 #> [255,] 2.648343e-01 1.724430e-15 7.351657e-01 #> [256,] 8.424041e-01 1.028674e-10 1.575959e-01 #> [257,] 6.388216e-01 3.787927e-10 3.611784e-01 #> [258,] 2.258101e-02 2.668524e-18 9.774190e-01 #> [259,] 9.809727e-11 1.000000e+00 4.472095e-18 #> [260,] 8.204836e-02 1.341164e-15 9.179516e-01 #> [261,] 1.275783e-03 1.947860e-21 9.987242e-01 #> [262,] 1.136386e-02 1.716631e-19 9.886361e-01 #> [263,] 1.083236e-11 1.000000e+00 1.266925e-19 #> [264,] 1.167960e-01 7.524305e-16 8.832040e-01 #> [265,] 3.968583e-13 1.000000e+00 2.185978e-20 #> [266,] 7.131699e-08 9.999999e-01 2.594669e-14 #> [267,] 1.368736e-03 9.680041e-21 9.986313e-01 #> [268,] 2.860117e-01 5.829758e-14 7.139883e-01 #> [269,] 3.688036e-11 1.000000e+00 8.066162e-18 #> [270,] 3.563232e-02 5.032974e-19 9.643677e-01 #> [271,] 4.737018e-14 1.000000e+00 5.672819e-22 #> [272,] 1.552378e-02 4.682115e-17 9.844762e-01 pred$classification # equal to  #>   [1] 1 2 1 2 3 2 3 1 2 3 2 1 3 2 3 2 2 3 2 3 2 2 1 1 3 1 2 3 1 3 3 3 1 3 1 2 2 #>  [38] 3 2 3 3 2 3 2 3 1 1 2 3 2 3 3 2 3 2 3 1 2 3 3 2 3 2 3 2 3 3 3 2 3 3 2 3 3 #>  [75] 2 3 2 3 1 1 3 3 3 2 3 3 1 3 2 1 2 3 2 3 2 3 3 1 2 3 2 3 2 3 3 2 3 2 3 1 3 #> [112] 2 3 3 2 3 2 3 2 3 2 3 3 2 3 1 2 3 2 3 2 3 2 3 2 3 2 3 2 1 3 2 3 3 3 2 3 2 #> [149] 3 2 3 1 2 3 1 3 3 3 2 1 2 3 2 1 1 3 2 3 2 3 2 2 3 1 3 3 3 2 1 3 2 3 3 1 2 #> [186] 3 3 2 3 2 3 2 3 3 1 3 1 3 2 3 2 3 3 2 3 2 3 1 2 3 2 3 2 1 1 3 2 3 2 3 2 3 #> [223] 2 3 1 3 3 3 1 3 3 2 3 2 3 2 2 3 1 2 3 2 3 2 3 1 2 3 2 3 2 3 1 3 3 1 1 3 2 #> [260] 3 3 3 2 3 2 2 3 3 2 3 2 3 plot(faithful, col = pred$classification, pch = pred$classification)   # predict cluster over a grid grid <- apply(faithful, 2, function(x) seq(min(x), max(x), length = 50)) grid <- expand.grid(eruptions = grid[,1], waiting = grid[,2]) pred <- predict(model, grid) plot(grid, col = mclust.options(\"classPlotColors\")[pred$classification], pch = 15, cex = 0.5) points(faithful, pch = model$classification)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"Classify multivariate observations based Gaussian finite mixture models estimated MclustDA.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"","code":"# S3 method for MclustDA predict(object, newdata, prop = object$prop, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"object object class 'MclustDA' resulting call MclustDA. newdata data frame matrix giving data. missing train data obtained call MclustDA classified. prop class proportions prior class probabilities belong class; default, set class proportions training data. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"Returns list following components: classification factor predicted class labels newdata. z matrix whose [,k]th entry probability             observation newdata belongs kth class.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify multivariate observations by Gaussian finite mixture modeling — predict.MclustDA","text":"","code":"# \\donttest{ odd <- seq(from = 1, to = nrow(iris), by = 2) even <- odd + 1 X.train <- iris[odd,-5] Class.train <- iris[odd,5] X.test <- iris[even,-5] Class.test <- iris[even,5]  irisMclustDA <- MclustDA(X.train, Class.train)  predTrain <- predict(irisMclustDA) predTrain #> $classification #>  [1] setosa     setosa     setosa     setosa     setosa     setosa     #>  [7] setosa     setosa     setosa     setosa     setosa     setosa     #> [13] setosa     setosa     setosa     setosa     setosa     setosa     #> [19] setosa     setosa     setosa     setosa     setosa     setosa     #> [25] setosa     versicolor versicolor versicolor versicolor versicolor #> [31] versicolor versicolor versicolor versicolor versicolor versicolor #> [37] versicolor versicolor versicolor versicolor versicolor versicolor #> [43] versicolor versicolor versicolor versicolor versicolor versicolor #> [49] versicolor versicolor virginica  virginica  virginica  virginica  #> [55] virginica  virginica  virginica  virginica  virginica  virginica  #> [61] virginica  virginica  virginica  virginica  virginica  virginica  #> [67] virginica  virginica  virginica  virginica  virginica  virginica  #> [73] virginica  virginica  virginica  #> Levels: setosa versicolor virginica #>  #> $z #>              setosa   versicolor    virginica #>  [1,]  1.000000e+00 8.738718e-25 2.855764e-40 #>  [2,]  1.000000e+00 3.763843e-20 4.191170e-35 #>  [3,]  1.000000e+00 1.192318e-25 1.628578e-40 #>  [4,]  1.000000e+00 1.750218e-18 2.283705e-32 #>  [5,]  1.000000e+00 1.977277e-15 1.394389e-28 #>  [6,]  1.000000e+00 5.467422e-29 1.537812e-44 #>  [7,]  1.000000e+00 2.759636e-19 1.532196e-33 #>  [8,]  1.000000e+00 1.403399e-37 3.948656e-57 #>  [9,]  1.000000e+00 1.272672e-27 5.020345e-46 #> [10,]  1.000000e+00 2.998149e-28 5.201993e-44 #> [11,]  1.000000e+00 1.777956e-23 1.196557e-37 #> [12,]  1.000000e+00 2.155743e-24 1.313946e-40 #> [13,]  1.000000e+00 6.685010e-20 1.573532e-29 #> [14,]  1.000000e+00 5.386284e-17 8.640940e-32 #> [15,]  1.000000e+00 6.242576e-24 4.500542e-40 #> [16,]  1.000000e+00 7.787919e-18 7.087150e-31 #> [17,]  1.000000e+00 4.607979e-36 4.867880e-49 #> [18,]  1.000000e+00 8.821491e-19 3.074362e-33 #> [19,]  1.000000e+00 6.216587e-28 3.741545e-46 #> [20,]  1.000000e+00 5.036637e-17 9.059046e-31 #> [21,]  1.000000e+00 1.521644e-22 4.556289e-39 #> [22,]  1.000000e+00 6.593237e-19 3.086722e-32 #> [23,]  1.000000e+00 1.357970e-20 2.658524e-33 #> [24,]  1.000000e+00 2.718795e-28 1.554929e-41 #> [25,]  1.000000e+00 2.177485e-28 1.601509e-43 #> [26,]  3.958805e-98 9.999991e-01 8.952163e-07 #> [27,] 1.848038e-113 9.999889e-01 1.114528e-05 #> [28,] 5.757618e-103 9.969487e-01 3.051293e-03 #> [29,] 4.092148e-111 9.974765e-01 2.523452e-03 #> [30,]  4.075046e-88 9.999924e-01 7.631479e-06 #> [31,]  3.354121e-49 9.999910e-01 8.973135e-06 #> [32,]  1.699797e-57 9.999925e-01 7.467309e-06 #> [33,]  3.171219e-60 9.999925e-01 7.452330e-06 #> [34,]  2.476277e-96 9.805847e-01 1.941534e-02 #> [35,] 4.143575e-104 9.873520e-01 1.264803e-02 #> [36,] 1.259738e-132 5.388373e-01 4.611627e-01 #> [37,] 1.516971e-113 8.572528e-01 1.427472e-01 #> [38,]  5.948781e-79 9.999966e-01 3.360240e-06 #> [39,] 5.064064e-103 9.999307e-01 6.934028e-05 #> [40,]  2.736888e-98 9.939288e-01 6.071194e-03 #> [41,]  2.886594e-56 9.999813e-01 1.867254e-05 #> [42,]  5.138169e-62 9.999875e-01 1.254357e-05 #> [43,]  1.408357e-95 9.524294e-01 4.757059e-02 #> [44,] 4.782959e-106 9.999778e-01 2.221000e-05 #> [45,]  1.234604e-70 9.997790e-01 2.209950e-04 #> [46,]  2.291561e-73 9.793616e-01 2.063839e-02 #> [47,]  2.984550e-65 9.999614e-01 3.863606e-05 #> [48,]  1.512584e-75 9.986823e-01 1.317728e-03 #> [49,]  5.358215e-74 9.995505e-01 4.494678e-04 #> [50,]  1.245663e-39 9.999997e-01 2.512703e-07 #> [51,] 7.729266e-266 6.791296e-09 1.000000e+00 #> [52,] 9.954921e-213 1.509018e-04 9.998491e-01 #> [53,] 1.897537e-218 9.106944e-06 9.999909e-01 #> [54,] 4.128232e-117 5.987163e-04 9.994013e-01 #> [55,] 3.142154e-175 1.044183e-03 9.989558e-01 #> [56,] 9.517474e-167 1.477429e-02 9.852257e-01 #> [57,] 8.912631e-196 1.682074e-04 9.998318e-01 #> [58,] 1.761936e-219 4.989459e-14 1.000000e+00 #> [59,] 4.579693e-159 8.943397e-02 9.105660e-01 #> [60,] 2.716293e-289 2.797982e-09 1.000000e+00 #> [61,] 2.332060e-229 1.500825e-06 9.999985e-01 #> [62,] 7.613591e-240 6.205542e-07 9.999994e-01 #> [63,] 7.145350e-201 4.497101e-03 9.955029e-01 #> [64,] 5.793042e-136 1.159599e-01 8.840401e-01 #> [65,] 6.507162e-199 2.002077e-05 9.999800e-01 #> [66,] 6.845274e-200 1.986525e-04 9.998013e-01 #> [67,] 8.914835e-212 5.129363e-07 9.999995e-01 #> [68,] 2.807218e-125 8.663816e-04 9.991336e-01 #> [69,] 6.459918e-236 1.247735e-07 9.999999e-01 #> [70,] 3.617450e-134 2.216457e-01 7.783543e-01 #> [71,] 3.068336e-239 2.072899e-09 1.000000e+00 #> [72,] 2.825419e-156 6.821447e-04 9.993179e-01 #> [73,] 4.602177e-257 3.672936e-10 1.000000e+00 #> [74,] 9.978143e-156 1.051037e-03 9.989490e-01 #> [75,] 4.631299e-214 2.854840e-06 9.999971e-01 #>  predTest <- predict(irisMclustDA, X.test) predTest #> $classification #>  [1] setosa     setosa     setosa     setosa     setosa     setosa     #>  [7] setosa     setosa     setosa     setosa     setosa     setosa     #> [13] setosa     setosa     setosa     setosa     setosa     setosa     #> [19] setosa     setosa     setosa     setosa     setosa     setosa     #> [25] setosa     versicolor versicolor versicolor versicolor versicolor #> [31] versicolor versicolor versicolor versicolor versicolor versicolor #> [37] versicolor versicolor versicolor versicolor versicolor virginica  #> [43] versicolor versicolor versicolor versicolor versicolor versicolor #> [49] versicolor versicolor virginica  virginica  virginica  virginica  #> [55] virginica  virginica  virginica  virginica  virginica  virginica  #> [61] virginica  virginica  virginica  virginica  virginica  virginica  #> [67] versicolor virginica  virginica  virginica  virginica  virginica  #> [73] virginica  virginica  virginica  #> Levels: setosa versicolor virginica #>  #> $z #>              setosa   versicolor    virginica #>  [1,]  1.000000e+00 2.523334e-18 6.021502e-34 #>  [2,]  1.000000e+00 2.881796e-18 3.538194e-31 #>  [3,]  1.000000e+00 1.178420e-24 4.486508e-40 #>  [4,]  1.000000e+00 2.553955e-22 1.305100e-36 #>  [5,]  1.000000e+00 4.143661e-20 1.376911e-33 #>  [6,]  1.000000e+00 5.893258e-21 2.158059e-33 #>  [7,]  1.000000e+00 1.073792e-16 6.237856e-31 #>  [8,]  1.000000e+00 1.328461e-33 9.307663e-52 #>  [9,]  1.000000e+00 1.288713e-22 7.980067e-39 #> [10,]  1.000000e+00 4.729930e-26 3.717387e-41 #> [11,]  1.000000e+00 5.586897e-22 9.882706e-38 #> [12,]  1.000000e+00 1.162587e-12 1.425626e-27 #> [13,]  1.000000e+00 9.587273e-17 4.827376e-31 #> [14,]  1.000000e+00 6.510286e-25 6.158055e-40 #> [15,]  1.000000e+00 1.467071e-18 7.029886e-31 #> [16,]  1.000000e+00 4.325261e-20 1.852521e-37 #> [17,]  1.000000e+00 6.714034e-37 2.755097e-53 #> [18,]  1.000000e+00 5.423357e-21 2.226046e-38 #> [19,]  1.000000e+00 3.761178e-27 1.810110e-40 #> [20,]  1.000000e+00 7.274004e-23 1.269579e-37 #> [21,]  9.499006e-01 5.009940e-02 9.802674e-19 #> [22,]  1.000000e+00 3.394655e-12 4.209226e-27 #> [23,]  1.000000e+00 7.027520e-15 1.734097e-30 #> [24,]  1.000000e+00 1.376843e-19 3.713174e-33 #> [25,]  1.000000e+00 2.351319e-21 9.432549e-37 #> [26,]  2.680809e-97 9.996813e-01 3.187179e-04 #> [27,]  1.795491e-74 9.992765e-01 7.234846e-04 #> [28,]  7.159623e-82 9.887687e-01 1.123129e-02 #> [29,]  9.103698e-41 9.999938e-01 6.174591e-06 #> [30,]  3.944584e-75 9.917816e-01 8.218400e-03 #> [31,]  1.988148e-89 9.989821e-01 1.017940e-03 #> [32,]  1.833995e-95 9.881890e-01 1.181101e-02 #> [33,]  7.268336e-89 9.999991e-01 9.010643e-07 #> [34,]  5.321069e-53 9.995583e-01 4.417260e-04 #> [35,]  2.461511e-57 9.999653e-01 3.471856e-05 #> [36,]  1.099304e-70 9.999884e-01 1.164699e-05 #> [37,]  3.664552e-80 9.426941e-01 5.730585e-02 #> [38,]  3.819025e-89 9.999965e-01 3.536921e-06 #> [39,] 1.479980e-132 8.652486e-01 1.347514e-01 #> [40,]  2.936411e-42 9.999999e-01 1.179693e-07 #> [41,]  2.136796e-48 9.999949e-01 5.094391e-06 #> [42,] 8.404582e-126 2.987918e-01 7.012082e-01 #> [43,] 3.826070e-104 9.990075e-01 9.925433e-04 #> [44,]  8.407400e-86 9.996890e-01 3.109789e-04 #> [45,]  1.402383e-72 9.993712e-01 6.288146e-04 #> [46,]  4.877834e-92 9.968721e-01 3.127878e-03 #> [47,]  5.372098e-42 9.999979e-01 2.059269e-06 #> [48,]  1.510319e-65 9.996610e-01 3.389848e-04 #> [49,]  1.558161e-77 9.999034e-01 9.656858e-05 #> [50,]  1.464651e-72 9.997568e-01 2.432354e-04 #> [51,] 2.825419e-156 6.821447e-04 9.993179e-01 #> [52,] 2.549967e-162 2.311842e-02 9.768816e-01 #> [53,] 1.400504e-245 5.089164e-06 9.999949e-01 #> [54,] 2.148191e-195 6.863124e-05 9.999314e-01 #> [55,] 1.275329e-274 5.468241e-07 9.999995e-01 #> [56,] 4.818859e-165 3.321108e-03 9.966789e-01 #> [57,] 9.209048e-166 2.096834e-06 9.999979e-01 #> [58,] 2.036128e-212 1.062788e-07 9.999999e-01 #> [59,] 1.025724e-258 6.938810e-03 9.930612e-01 #> [60,] 2.563761e-118 3.305876e-01 6.694124e-01 #> [61,] 2.439902e-160 1.304494e-05 9.999870e-01 #> [62,] 3.870421e-140 7.557603e-02 9.244240e-01 #> [63,] 5.110005e-180 9.441091e-03 9.905589e-01 #> [64,] 1.434938e-137 2.542019e-01 7.457981e-01 #> [65,] 4.969278e-153 5.967287e-03 9.940327e-01 #> [66,] 7.338521e-221 1.461263e-02 9.853874e-01 #> [67,] 6.517202e-117 6.762001e-01 3.237999e-01 #> [68,] 5.549239e-251 1.777694e-07 9.999998e-01 #> [69,] 9.489170e-158 1.638715e-01 8.361285e-01 #> [70,] 7.915383e-192 4.097626e-04 9.995902e-01 #> [71,] 6.964811e-207 1.427441e-08 1.000000e+00 #> [72,] 1.546248e-236 3.756445e-06 9.999962e-01 #> [73,] 1.421391e-210 6.961792e-09 1.000000e+00 #> [74,] 1.791637e-171 2.458719e-03 9.975413e-01 #> [75,] 3.574474e-143 1.192001e-01 8.807999e-01 #>  # }"},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"Classify multivariate observations dimension reduced subspace estimated Gaussian finite mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"","code":"# S3 method for MclustDR predict(object, dim = 1:object$numdir, newdata, eval.points, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"object object class 'MclustDR' resulting call MclustDR. dim dimensions reduced subspace used prediction. newdata data frame matrix giving data. missing data obtained call MclustDR used. eval.points data frame matrix giving data projected reduced subspace. provided newdata used. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"Returns list following components: dir matrix containing data projected onto dim dimensions reduced subspace. density densities mixture model data point. z matrix whose [,k]th entry probability             observation newdata belongs kth class. uncertainty uncertainty associated classification. classification vector values giving MAP classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"Scrucca, L. (2010) Dimension reduction model-based clustering.    Statistics Computing, 20(4), pp. 471-484.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling — predict.MclustDR","text":"","code":"mod = Mclust(iris[,1:4]) dr = MclustDR(mod) pred = predict(dr) str(pred) #> List of 5 #>  $ dir           : num [1:150, 1] 1.89 1.49 1.66 1.44 1.94 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr \"Dir1\" #>  $ density       : num [1:150] 0.363 0.28 0.366 0.245 0.341 ... #>  $ z             : num [1:150, 1:2] 1 1 1 1 1 ... #>  $ uncertainty   : num [1:150] 1.08e-09 3.75e-07 2.88e-08 8.46e-07 5.17e-10 ... #>  $ classification: Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...  data(banknote) mod = MclustDA(banknote[,2:7], banknote$Status) dr = MclustDR(mod) pred = predict(dr) str(pred) #> List of 5 #>  $ dir           : num [1:200, 1:2] -0.946 -1.751 -1.583 -1.742 -1.528 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:2] \"Dir1\" \"Dir2\" #>  $ density       : num [1:200] 0.137 0.277 0.169 0.31 0.462 ... #>  $ z             : num [1:200, 1:2] 1.47e-08 4.43e-16 4.83e-18 2.49e-17 1.67e-15 ... #>  $ uncertainty   : num [1:200] 1.47e-08 4.44e-16 0.00 0.00 1.78e-15 ... #>  $ classification: Factor w/ 2 levels \"counterfeit\",..: 2 2 2 2 2 2 2 2 2 2 ..."},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"Classify multivariate observations based Gaussian finite mixture models estimated MclustSSC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"","code":"# S3 method for MclustSSC predict(object, newdata, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"object object class 'MclustSSC' resulting call MclustSSC. newdata data frame matrix giving data. missing train data obtained call MclustSSC classified. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"Returns list following components: classification factor predicted class labels newdata. z matrix whose [,k]th entry probability             observation newdata belongs kth class.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/predict.MclustSSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classification of multivariate observations by semi-supervised Gaussian finite mixtures — predict.MclustSSC","text":"","code":"# \\donttest{ X <- iris[,1:4] class <- iris$Species # randomly remove class labels set.seed(123) class[sample(1:length(class), size = 120)] <- NA table(class, useNA = \"ifany\") #> class #>     setosa versicolor  virginica       <NA>  #>         10         15          5        120  clPairs(X, ifelse(is.na(class), 0, class),         symbols = c(0, 16, 17, 18), colors = c(\"grey\", 4, 2, 3),         main = \"Partially classified data\")   # Fit semi-supervised classification model mod_SSC  <- MclustSSC(X, class)  pred_SSC <- predict(mod_SSC) table(Predicted = pred_SSC$classification, Actual = class, useNA = \"ifany\") #>             Actual #> Predicted    setosa versicolor virginica <NA> #>   setosa         10          0         0   40 #>   versicolor      0         15         0   45 #>   virginica       0          0         5   35  X_new = data.frame(Sepal.Length = c(5, 8),                    Sepal.Width  = c(3.1, 4),                    Petal.Length = c(2, 5),                    Petal.Width  = c(0.5, 2)) predict(mod_SSC, newdata = X_new) #> $classification #> [1] setosa     versicolor #> Levels: setosa versicolor virginica #>  #> $z #>             setosa   versicolor    virginica #> [1,]  9.999995e-01 4.732013e-07 2.971005e-24 #> [2,] 1.919741e-120 9.996956e-01 3.044061e-04 #>  # }"},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"Compute density estimation multivariate observations based Gaussian finite mixture models estimated densityMclust.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"","code":"# S3 method for densityMclust predict(object, newdata, what = c(\"dens\", \"cdens\", \"z\"), logarithm = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"object object class 'densityMclust' resulting call densityMclust. newdata vector, data frame matrix giving data. missing density computed input data obtained call densityMclust. character string specifying retrieve: \"dens\" returns vector values mixture density; \"cdens\" returns matrix component densities mixture component (along columns); \"z\" returns matrix conditional probabilities data point belong mixture component. logarithm logical value indicating whether logarithm density component densities returned. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"Returns vector matrix densities evaluated newdata depending argument (see ).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/predict.densityMclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density estimate of multivariate observations by Gaussian finite mixture modeling — predict.densityMclust","text":"","code":"# \\donttest{ x <- faithful$waiting dens <- densityMclust(x, plot = FALSE) x0 <- seq(50, 100, by = 10) d0 <- predict(dens, x0) plot(dens, what = \"density\") points(x0, d0, pch = 20)  # }"},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Conjugate Prior for Gaussian Mixtures. — priorControl","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"Specify conjugate prior Gaussian mixtures.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"","code":"priorControl(functionName = \"defaultPrior\", ...)"},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"functionName name function specifying conjugate prior.     default function defaultPrior used,      can also used template alternative specification. ... Optional named arguments function specified functionName      together values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"list function name first component. remaining   components () consist list arguments function   assigned values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"function priorControl used specify conjugate prior     EM within MCLUST.   Note , described defaultPrior, multivariate    case 10 14 models may used conjunction prior, .e.   available MCLUST version 4.4.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"C. Fraley . E. Raftery (2007).   Bayesian regularization normal mixture estimation model-based   clustering. Journal Classification 24:155-181.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/priorControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conjugate Prior for Gaussian Mixtures. — priorControl","text":"","code":"# default prior irisBIC <- mclustBIC(iris[,-5], prior = priorControl()) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.8136 -587.403843 -592.51283 #> BIC diff    0.0000   -6.590289  -11.69928 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100   # no prior on the mean; default prior on variance irisBIC <- mclustBIC(iris[,-5], prior = priorControl(shrinkage = 0)) #> Warning: The presence of BIC values equal to NA is likely due to one or more of the mixture proportions being estimated as zero, so that the model estimated reduces to one with a smaller number of components. summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2       VEV,3      VVV,2 #> BIC      -580.2861 -586.792195 -592.07132 #> BIC diff    0.0000   -6.506112  -11.78523 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100"},{"path":"https://mclust-org.github.io/mclust/reference/randProj.html","id":null,"dir":"Reference","previous_headings":"","what":"Random projections of multidimensional data modeled by an MVN mixture — randProj","title":"Random projections of multidimensional data modeled by an MVN mixture — randProj","text":"Plots random projections given multidimensional data   parameters MVN mixture model data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randProj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random projections of multidimensional data modeled by an MVN mixture — randProj","text":"","code":"randProj(data, seeds = NULL, parameters = NULL, z = NULL,          classification = NULL, truth = NULL, uncertainty = NULL,           what = c(\"classification\", \"error\", \"uncertainty\"),          quantiles = c(0.75, 0.95),           addEllipses = TRUE, fillEllipses = mclust.options(\"fillEllipses\"),          symbols = NULL, colors = NULL, scale = FALSE,           xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,          cex = 1, PCH = \".\", main = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/randProj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random projections of multidimensional data modeled by an MVN mixture — randProj","text":"data numeric matrix data frame observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. seeds integer value vector integer values used seed      random number generation. multiple values provided, seed      produce different projection.      default, single seed drawn randomnly, call      randProj() produces different projections. parameters named list giving parameters MCLUST model,       used produce superimposing ellipses plot.       relevant components follows: mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  z matrix [,k]th entry gives   probability observation belonging kth class.    Used compute classification   uncertainty arguments available. classification numeric character vector representing classification   observations (rows) data. present argument z         ignored. truth numeric character vector giving known   classification data point.   classification   z also present,    used displaying classification errors. uncertainty numeric vector values (0,1) giving   uncertainty data point. present argument z         ignored. Choose one following three options: \"classification\"     (default), \"error\", \"uncertainty\". quantiles vector length 2 giving quantiles used plotting     uncertainty. smallest symbols correspond smallest     quantile (lowest uncertainty), medium-sized (open) symbols points     falling given quantiles, large (filled) symbols     largest quantile (highest uncertainty). default     (0.75,0.95). addEllipses logical indicating whether add ellipses axes      corresponding within-cluster covariances case      \"classification\" \"uncertainty\" plots. fillEllipses logical specifying whether fill ellipses transparent     colors addEllipses = TRUE. symbols Either integer character vector assigning plotting symbol     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotSymbols\"). colors Either integer character vector assigning color     unique class classification. Elements colors     correspond classes order appearance sequence     observations (order used function unique).      default given mclust.options(\"classPlotColors\"). scale logical variable indicating whether two chosen     dimensions plotted scale,     thus preserve shape distribution.     Default: scale=FALSE xlim, ylim Optional arguments specifying bounds ordinate, abscissa plot.     may useful comparing plots. xlab, ylab Optional arguments specifying labels , respectively, horizontal      vertical axis. cex numerical value specifying size plotting symbols.      default value 1. PCH argument specifying symbol used classificatiion     specified data. default value small dot \".\". main logical variable NULL indicating whether add title      plot identifying dimensions used. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randProj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random projections of multidimensional data modeled by an MVN mixture — randProj","text":"plot showing random two-dimensional projection data, together location  mixture components, classification, uncertainty, /classification errors. function also returns invisible list components basis, randomnly generated basis projection subspace, data, matrix projected data, mu sigma component parameters transformed projection subspace.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/randProj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random projections of multidimensional data modeled by an MVN mixture — randProj","text":"","code":"# \\donttest{ est <- meVVV(iris[,-5], unmap(iris[,5])) par(pty = \"s\", mfrow = c(1,1)) randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,           what = \"classification\", main = TRUE)     randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,           truth = iris[,5], what = \"error\", main = TRUE)     randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,           what = \"uncertainty\", main = TRUE)     # }"},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Random orthogonal matrix — randomOrthogonalMatrix","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"Generate random orthogonal basis matrix dimension \\((nrow x ncol)\\) using  method Heiberger (1978).","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"","code":"randomOrthogonalMatrix(nrow, ncol, n = nrow, d = ncol, seed = NULL)"},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"nrow number rows resulting orthogonal matrix. ncol number columns resulting orthogonal matrix. n deprecated. See nrow . d deprecated. See ncol . seed optional integer argument use set.seed()                reproducibility. default current seed used.               Reproducibility can also achieved calling set.seed()               calling function.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"use arguments n d deprecated removed future.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"orthogonal matrix dimension \\(nrow x ncol\\) column orthogonal unit lenght. latter, also called orthonormal.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"Heiberger R. (1978) Generation random orthogonal matrices. Journal Royal Statistical Society. Series C (Applied Statistics), 27(2), 199-206.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/randomOrthogonalMatrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random orthogonal matrix — randomOrthogonalMatrix","text":"","code":"B <- randomOrthogonalMatrix(10,3) zapsmall(crossprod(B)) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1"},{"path":"https://mclust-org.github.io/mclust/reference/sigma2decomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert mixture component covariances to decomposition form. — sigma2decomp","title":"Convert mixture component covariances to decomposition form. — sigma2decomp","text":"Converts set covariance matrices representation 3-D array    parameterization eigenvalue decomposition.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/sigma2decomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert mixture component covariances to decomposition form. — sigma2decomp","text":"","code":"sigma2decomp(sigma, G = NULL, tol = sqrt(.Machine$double.eps), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/sigma2decomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert mixture component covariances to decomposition form. — sigma2decomp","text":"sigma Either 3-D array whose [,,k]th component covariance matrix     kth component MVN mixture model, single covariance     matrix case components covariance. G number components mixture.      sigma 3-D array, number components     can inferred dimensions. tol Tolerance determining whether covariances equal volume,     shape, orientation. default square root relative     machine precision, sqrt(.Machine$double.eps),      1.e-8. ... Catches unused arguments indirect list call via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/sigma2decomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert mixture component covariances to decomposition form. — sigma2decomp","text":"covariance matrices mixture components decomposition form,   including following components: modelName character string indicating infered model. help file     mclustModelNames describes available models. d dimension data. G number components mixture model. scale Either G-vector giving scale covariance (    dth root determinant) component     mixture model, single numeric value scale     component. shape Either G d matrix kth     column shape covariance matrix (normalized     determinant 1) kth component, d-vector     giving common shape components. orientation Either d d G array whose     [,,k]th entry orthonomal matrix whose columns     eigenvectors covariance matrix kth component,     d d orthonormal matrix mixture     components common orientation. orientation component     decomp can omitted spherical diagonal models,     principal components parallel coordinate axes     orientation matrix identity.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/sigma2decomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert mixture component covariances to decomposition form. — sigma2decomp","text":"","code":"meEst <- meEEE(iris[,-5], unmap(iris[,5]))  names(meEst$parameters$variance) #> [1] \"modelName\" \"d\"         \"G\"         \"sigma\"     \"Sigma\"     \"cholSigma\" meEst$parameters$variance$Sigma #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.26387916  0.08987702   0.16956251  0.03932391 #> Sepal.Width    0.08987702  0.11197340   0.05118186  0.03002534 #> Petal.Length   0.16956251  0.05118186   0.18637706  0.04196406 #> Petal.Width    0.03932391  0.03002534   0.04196406  0.03974960  sigma2decomp(meEst$parameters$variance$Sigma, G = length(unique(iris[,5]))) #> $sigma #> , , 1 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.26387916 0.08987702 0.16956251 0.03932391 #> [2,] 0.08987702 0.11197340 0.05118186 0.03002534 #> [3,] 0.16956251 0.05118186 0.18637706 0.04196406 #> [4,] 0.03932391 0.03002534 0.04196406 0.03974960 #>  #> , , 2 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.26387916 0.08987702 0.16956251 0.03932391 #> [2,] 0.08987702 0.11197340 0.05118186 0.03002534 #> [3,] 0.16956251 0.05118186 0.18637706 0.04196406 #> [4,] 0.03932391 0.03002534 0.04196406 0.03974960 #>  #> , , 3 #>  #>            [,1]       [,2]       [,3]       [,4] #> [1,] 0.26387916 0.08987702 0.16956251 0.03932391 #> [2,] 0.08987702 0.11197340 0.05118186 0.03002534 #> [3,] 0.16956251 0.05118186 0.18637706 0.04196406 #> [4,] 0.03932391 0.03002534 0.04196406 0.03974960 #>  #>  #> $d #> [1] 4 #>  #> $modelName #> [1] \"EEE\" #>  #> $G #> [1] 3 #>  #> $scale #> [1] 0.08114033 #>  #> $shape #> [1] 5.4441760 1.0696919 0.6344826 0.2706384 #>  #> $orientation #>           [,1]        [,2]       [,3]       [,4] #> [1,] 0.7401980  0.01338854  0.6352049  0.2200963 #> [2,] 0.3056652 -0.87119601 -0.2316293 -0.3064868 #> [3,] 0.5783262  0.47573614 -0.5625433 -0.3503698 #> [4,] 0.1556100 -0.12047151 -0.4758232  0.8572423 #>"},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from Parameterized MVN Mixture Models — sim","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"Simulate data parameterized MVN mixture models.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"","code":"sim(modelName, parameters, n, seed = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"modelName character string indicating model. help file     mclustModelNames describes available models. parameters list following components: pro vector whose kth component mixing proportion               kth component mixture model.               missing, equal proportions assumed. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  n integer specifying number data points simulated. seed optional integer argument set.seed reproducible     random class assignment.  default current seed used.     Reproducibility can also achieved calling set.seed     calling sim. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"matrix first column classification remaining   columns n observations simulated specified MVN    mixture model. Attributes: \"modelName\" character string indicating variance        model used simulation.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"function can used indirect list call using   .call, allowing output e.g. mstep, em,   , Mclust passed directly without need   specify individual parameters arguments.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from Parameterized MVN Mixture Models — sim","text":"","code":"irisBIC <- mclustBIC(iris[,-5]) irisModel <- mclustModel(iris[,-5], irisBIC) names(irisModel) #> [1] \"modelName\"  \"n\"          \"d\"          \"G\"          \"bic\"        #> [6] \"loglik\"     \"parameters\" \"z\"          irisSim <- sim(modelName = irisModel$modelName,                 parameters = irisModel$parameters,                 n = nrow(iris))  # \\donttest{   do.call(\"sim\", irisModel) # alternative call #>        group       x1       x2       x3         x4 #>   [1,]     2 6.532836 2.375805 5.285487 2.01327710 #>   [2,]     2 6.049105 3.201455 5.677393 2.07384119 #>   [3,]     2 5.526176 2.457807 4.172286 1.18223416 #>   [4,]     1 4.900197 3.569575 1.436707 0.18754806 #>   [5,]     1 4.889839 3.132182 1.595851 0.29197285 #>   [6,]     2 5.892364 3.112100 4.884095 2.16021048 #>   [7,]     2 6.991952 2.878990 5.806907 1.66075063 #>   [8,]     2 6.777374 2.962417 6.046605 2.28083930 #>   [9,]     2 6.320879 3.068921 4.766376 1.51954776 #>  [10,]     1 4.904004 3.358537 1.211468 0.05262207 #>  [11,]     2 6.654859 3.367376 5.578925 2.08671560 #>  [12,]     2 6.086514 3.447387 4.545482 1.70261637 #>  [13,]     2 6.584607 2.569003 5.282048 1.54499898 #>  [14,]     2 5.820641 2.834722 3.567591 1.27709905 #>  [15,]     2 6.936317 2.803664 5.033749 1.61229071 #>  [16,]     2 6.187352 2.779145 4.002027 1.34937277 #>  [17,]     2 6.391023 3.439651 5.506473 1.94829994 #>  [18,]     2 5.821579 3.221585 5.698060 2.65577631 #>  [19,]     2 6.623737 2.837080 5.062102 1.59777090 #>  [20,]     2 6.145366 2.830184 3.674388 0.91072912 #>  [21,]     1 5.096752 3.333028 1.688420 0.42348554 #>  [22,]     2 6.908078 3.267487 5.170275 1.76870483 #>  [23,]     2 5.327669 2.719041 4.657410 2.02213468 #>  [24,]     2 5.609469 2.666261 3.780324 1.13129306 #>  [25,]     1 4.225739 2.531858 1.374776 0.37311121 #>  [26,]     2 6.070299 2.984665 3.993217 1.09715366 #>  [27,]     2 6.097073 2.870138 5.599883 2.16885432 #>  [28,]     2 7.241020 3.524912 7.174456 2.64273988 #>  [29,]     2 5.708818 2.845093 4.991389 1.68593333 #>  [30,]     2 6.177913 3.526097 5.449136 2.38037633 #>  [31,]     1 5.092422 3.161678 1.523155 0.15852334 #>  [32,]     2 6.440908 3.183295 4.502688 1.63328051 #>  [33,]     1 5.534734 3.471212 1.670063 0.37811446 #>  [34,]     2 6.198401 2.699261 5.225309 1.87436974 #>  [35,]     1 4.566981 2.336040 1.324451 0.24936909 #>  [36,]     2 5.915050 2.534643 4.370192 1.57655844 #>  [37,]     2 5.890212 3.093981 5.099939 1.84081081 #>  [38,]     1 5.327048 3.673121 1.652838 0.27522061 #>  [39,]     1 4.661995 3.339097 1.475636 0.22379017 #>  [40,]     2 6.608085 2.690905 4.889035 1.31232768 #>  [41,]     2 5.855174 2.817782 4.650903 1.83459692 #>  [42,]     2 4.975905 2.330940 3.311954 0.85387066 #>  [43,]     1 5.702651 4.456313 1.539543 0.39955120 #>  [44,]     2 6.731570 2.862077 5.010237 1.57612661 #>  [45,]     2 7.535891 3.307274 6.516173 2.29362621 #>  [46,]     2 7.653077 3.358806 5.503142 1.83430775 #>  [47,]     2 6.078472 2.873623 4.903889 1.62690765 #>  [48,]     2 5.279167 2.688735 3.899428 1.11836487 #>  [49,]     2 5.960505 2.582242 4.747200 1.52267717 #>  [50,]     2 5.515146 2.746771 3.585407 1.41787397 #>  [51,]     2 6.781388 2.821283 5.728834 2.33538747 #>  [52,]     1 5.462238 4.060700 1.253321 0.20323684 #>  [53,]     1 4.764209 2.850615 1.663109 0.16409540 #>  [54,]     2 6.161331 2.900146 3.717914 0.66744573 #>  [55,]     2 4.585639 2.326796 2.523156 0.64747671 #>  [56,]     2 7.133925 2.755869 6.097984 2.10875830 #>  [57,]     1 4.928552 3.233658 1.485280 0.30098015 #>  [58,]     2 6.598691 3.038344 5.577386 1.73653810 #>  [59,]     2 6.021106 2.910992 5.454228 2.21283834 #>  [60,]     1 4.759353 2.775279 1.566944 0.16900946 #>  [61,]     1 4.437030 2.735303 1.541621 0.16808344 #>  [62,]     1 4.979573 3.665843 1.374528 0.29896361 #>  [63,]     1 5.275630 4.066582 1.273517 0.31353243 #>  [64,]     2 5.713160 2.549318 4.069155 1.11177491 #>  [65,]     2 5.754929 2.467422 4.279438 1.13216629 #>  [66,]     1 4.566873 3.192958 1.291056 0.32149320 #>  [67,]     1 4.926855 3.331165 1.338714 0.28616757 #>  [68,]     2 4.794021 2.335134 3.392785 0.96291498 #>  [69,]     2 6.507700 3.004900 5.383629 1.96301480 #>  [70,]     2 5.780362 2.651567 4.416441 1.56364259 #>  [71,]     1 5.031385 3.366812 1.779487 0.42224383 #>  [72,]     1 4.962530 3.535605 1.464945 0.11857950 #>  [73,]     2 5.898920 2.852802 3.705525 1.53756132 #>  [74,]     2 6.818703 2.840126 6.090726 2.27437619 #>  [75,]     2 5.288548 2.529982 4.112109 1.31804098 #>  [76,]     1 5.802195 4.178015 1.826556 0.27199244 #>  [77,]     2 5.921354 2.493543 4.130016 1.34785726 #>  [78,]     2 6.420947 2.898328 5.797910 1.86496979 #>  [79,]     2 6.458952 3.314090 5.255110 1.97437202 #>  [80,]     1 4.858731 3.488462 1.624489 0.32400074 #>  [81,]     2 6.963479 3.244091 5.863006 1.95583643 #>  [82,]     1 5.093037 3.702605 1.521971 0.32133603 #>  [83,]     2 5.951215 2.427276 4.297973 1.30215617 #>  [84,]     2 6.829583 3.106950 5.975773 2.40391213 #>  [85,]     2 5.641438 2.526931 3.356128 0.90077805 #>  [86,]     2 6.288024 2.963692 4.877360 1.62792240 #>  [87,]     2 6.201170 2.804769 5.361528 2.13030549 #>  [88,]     2 6.271158 2.373553 5.136524 2.08767838 #>  [89,]     2 5.241830 2.769173 3.607277 1.18569794 #>  [90,]     2 6.985735 3.038542 5.751161 2.15434634 #>  [91,]     1 4.620324 3.476975 1.106740 0.16079011 #>  [92,]     2 6.767167 3.090215 5.694763 2.02499198 #>  [93,]     2 6.263140 3.054319 5.828169 2.39407921 #>  [94,]     1 4.890853 2.954173 1.641073 0.20111130 #>  [95,]     2 6.116635 3.095454 4.694514 1.44228215 #>  [96,]     2 5.891050 3.162495 4.781989 1.70128330 #>  [97,]     2 6.058281 3.198752 4.449359 1.28475161 #>  [98,]     1 4.879902 3.429815 1.312773 0.29583751 #>  [99,]     1 4.968601 3.450250 1.774141 0.43160919 #> [100,]     1 5.010378 2.956539 1.438296 0.20700475 #> [101,]     2 5.316258 2.582679 3.265963 0.91796180 #> [102,]     2 6.916629 3.070882 5.403126 1.65306395 #> [103,]     2 5.561780 2.232689 4.765539 1.80613892 #> [104,]     2 5.766475 2.613175 4.709038 1.60941695 #> [105,]     2 7.528979 3.404533 6.354226 2.40734633 #> [106,]     1 5.623476 3.934419 1.589082 0.28616437 #> [107,]     2 6.477506 3.429970 4.976219 2.02222390 #> [108,]     2 5.721206 2.648260 4.456036 1.31094270 #> [109,]     2 6.772555 3.152354 5.942773 2.65485911 #> [110,]     1 5.355299 3.716190 1.544857 0.41200711 #> [111,]     2 6.198401 2.838707 4.551736 1.40373577 #> [112,]     2 6.881108 3.021152 5.933739 1.64769360 #> [113,]     2 6.498932 2.740648 5.769536 1.96223447 #> [114,]     2 6.368108 3.002078 5.348831 2.04957091 #> [115,]     1 4.750801 3.274771 1.460229 0.33085668 #> [116,]     2 5.311770 2.693833 3.863553 1.63854074 #> [117,]     2 6.506416 2.630877 5.094374 1.77762605 #> [118,]     2 6.159973 2.868307 5.283567 2.09428781 #> [119,]     1 4.745082 3.215049 1.222188 0.38081135 #> [120,]     1 4.644811 2.899309 1.488444 0.09113547 #> [121,]     2 5.981099 3.218350 5.119496 1.97433292 #> [122,]     2 6.143804 2.813042 4.884435 1.37483985 #> [123,]     2 7.450295 2.708364 6.585552 2.05633281 #> [124,]     2 7.056963 3.257373 6.378677 2.19836001 #> [125,]     2 5.697049 3.117381 5.143878 1.93892702 #> [126,]     2 6.361328 3.286884 5.308211 1.94621680 #> [127,]     2 6.725567 2.963505 6.243579 2.12027309 #> [128,]     2 7.305078 3.398196 6.720373 2.28609688 #> [129,]     1 4.779915 3.363293 1.392099 0.12270314 #> [130,]     1 5.166262 3.373826 1.515930 0.27959597 #> [131,]     2 6.596623 2.856318 4.842815 1.90432612 #> [132,]     1 5.619808 3.694652 1.432318 0.15071819 #> [133,]     2 6.048109 3.037725 4.540285 1.61891887 #> [134,]     2 7.459785 3.150028 5.966869 2.46113041 #> [135,]     1 5.543748 4.179103 1.444573 0.28769431 #> [136,]     2 6.578133 3.042483 5.620291 2.03261254 #> [137,]     2 5.807547 2.619390 3.857629 1.21301914 #> [138,]     2 6.234816 2.807685 4.719480 1.55065418 #> [139,]     2 7.513683 3.324514 5.588693 2.02573735 #> [140,]     2 6.357053 2.729336 4.845442 1.64427754 #> [141,]     2 5.144614 2.800920 3.519301 1.23948930 #> [142,]     2 5.960814 2.848935 4.504897 1.22033432 #> [143,]     2 6.607641 3.404001 5.262087 1.92780166 #> [144,]     2 5.204303 2.971066 3.638198 1.89481477 #> [145,]     2 5.549845 2.714582 3.192257 0.88433228 #> [146,]     1 4.711185 2.832472 1.555133 0.35788407 #> [147,]     1 4.832567 3.179596 1.391590 0.15193644 #> [148,]     1 5.197880 3.757896 1.200477 0.22251791 #> [149,]     2 5.835497 2.857555 4.447573 1.91537977 #> [150,]     2 5.900522 3.359951 4.403118 1.47297650 #> attr(,\"modelName\") #> [1] \"VEV\" # }  par(pty = \"s\", mfrow = c(1,2))  dimnames(irisSim) <- list(NULL, c(\"dummy\", (dimnames(iris)[[2]])[-5]))  dimens <- c(1,2) lim1 <- apply(iris[,dimens],2,range) lim2 <- apply(irisSim[,dimens+1],2,range) lims <- apply(rbind(lim1,lim2),2,range) xlim <- lims[,1] ylim <- lims[,2]  coordProj(iris[,-5], parameters=irisModel$parameters,            classification=map(irisModel$z),            dimens=dimens, xlim=xlim, ylim=ylim)  coordProj(iris[,-5], parameters=irisModel$parameters,            classification=map(irisModel$z), truth = irisSim[,-1],           dimens=dimens, xlim=xlim, ylim=ylim)   irisModel3 <- mclustModel(iris[,-5], irisBIC, G=3) irisSim3 <- sim(modelName = irisModel3$modelName,                 parameters = irisModel3$parameters, n = 500, seed = 1) # \\donttest{  irisModel3$n <- NULL  irisSim3 <- do.call(\"sim\",c(list(n=500,seed=1),irisModel3)) # alternative call # } clPairs(irisSim3[,-1], cl = irisSim3[,1])"},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from a Parameterized MVN Mixture Model — simE","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"Simulate data parameterized MVN mixture model.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"","code":"simE(parameters, n, seed = NULL, ...) simV(parameters, n, seed = NULL, ...) simEII(parameters, n, seed = NULL, ...) simVII(parameters, n, seed = NULL, ...) simEEI(parameters, n, seed = NULL, ...) simVEI(parameters, n, seed = NULL, ...) simEVI(parameters, n, seed = NULL, ...) simVVI(parameters, n, seed = NULL, ...) simEEE(parameters, n, seed = NULL, ...) simVEE(parameters, n, seed = NULL, ...) simEVE(parameters, n, seed = NULL, ...) simVVE(parameters, n, seed = NULL, ...) simEEV(parameters, n, seed = NULL, ...) simVEV(parameters, n, seed = NULL, ...) simEVV(parameters, n, seed = NULL, ...) simVVV(parameters, n, seed = NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"parameters list following components: pro vector whose kth component mixing proportion               kth component mixture model.               missing, equal proportions assumed. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  n integer specifying number data points simulated. seed optional integer argument set.seed() reproducible     random class assignment. default current seed used.     Reproducibility can also achieved calling set.seed     calling sim. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"matrix first column classification remaining   columns n observations simulated specified MVN    mixture model. Attributes: \"modelName\" character string indicating variance        model used simulation.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"function can used indirect list call using   .call, allowing output e.g. mstep, em   , Mclust, passed directly without need   specify individual parameters arguments.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/simE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from a Parameterized MVN Mixture Model — simE","text":"","code":"# \\donttest{ d <- 2 G <- 2 scale <- 1 shape <- c(1, 9)  O1 <- diag(2) O2 <- diag(2)[,c(2,1)] O <- array(cbind(O1,O2), c(2, 2, 2)) O #> , , 1 #>  #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1 #>  #> , , 2 #>  #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #>   variance <- list(d= d, G = G, scale = scale, shape = shape, orientation = O) mu <- matrix(0, d, G) ## center at the origin simdat <- simEEV( n = 200,                    parameters = list(pro=c(1,1),mean=mu,variance=variance),                   seed = NULL)  cl <- simdat[,1]  sigma <- array(apply(O, 3, function(x,y) crossprod(x*y),                   y = sqrt(scale*shape)), c(2,2,2)) paramList <- list(mu = mu, sigma = sigma) coordProj( simdat, paramList = paramList, classification = cl) #> Warning: \"paramList\" is not a graphical parameter #> Warning: \"paramList\" is not a graphical parameter #> Warning: \"paramList\" is not a graphical parameter #> Warning: \"paramList\" is not a graphical parameter #> Warning: \"paramList\" is not a graphical parameter #> Warning: \"paramList\" is not a graphical parameter  # }"},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax function — softmax","title":"Softmax function — softmax","text":"Efficient implementation (via Fortran) softmax (aka multinomial logistic) function converting set numerical values probabilities summing 1.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax function — softmax","text":"","code":"softmax(x, v = NULL)"},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax function — softmax","text":"x matrix dimension \\(n \\times k\\) numerical values. vector provided, converted single-row matrix. v optional vector length \\(k\\) numerical values added row x matrix. provided, vector zeros used.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softmax function — softmax","text":"Given matrix x, row \\(x_{[]} = [x_1, \\dots, x_k]\\) (\\(=1,\\dots,n\\)), softmax function calculates $$ \\text{softmax}(x_{[]})_j =  \\dfrac{\\exp{x_j + v_j}}{\\sum_{l=1}^k \\exp(x_l + v_l)} \\qquad \\text{} j = 1,\\dots,k  $$","code":""},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax function — softmax","text":"Returns matrix dimension x values range \\((0,1)\\) sum 1 along rows.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Softmax function — softmax","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax function — softmax","text":"","code":"x = matrix(rnorm(15), 5, 3) v = log(c(0.5, 0.3, 0.2)) (z = softmax(x, v)) #>           [,1]       [,2]       [,3] #> [1,] 0.4039612 0.04453269 0.55150615 #> [2,] 0.5363225 0.34888841 0.11478912 #> [3,] 0.7237697 0.18876193 0.08746842 #> [4,] 0.4567840 0.52021530 0.02300074 #> [5,] 0.3457171 0.24608575 0.40819713 rowSums(z) #> [1] 1 1 1 1 1"},{"path":"https://mclust-org.github.io/mclust/reference/summary.Mclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","title":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","text":"Summary method class \"Mclust\".","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.Mclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","text":"","code":"# S3 method for Mclust summary(object, classification = TRUE, parameters = FALSE, ...) # S3 method for summary.Mclust print(x, digits = getOption(\"digits\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.Mclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","text":"object object class 'Mclust' resulting call Mclust densityMclust. x object class 'summary.Mclust', usually, result call summary.Mclust. classification Logical; TRUE table MAP classification/clustering observations printed. parameters Logical; TRUE, parameters mixture components printed. digits number significant digits use printing. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.Mclust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.Mclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing Gaussian Finite Mixture Model Fits — summary.Mclust","text":"","code":"# \\donttest{ mod1 = Mclust(iris[,1:4]) summary(mod1) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Clustering table: #>   1   2  #>  50 100  summary(mod1, parameters = TRUE, classification = FALSE) #> ----------------------------------------------------  #> Gaussian finite mixture model fitted by EM algorithm  #> ----------------------------------------------------  #>  #> Mclust VEV (ellipsoidal, equal shape) model with 2 components:  #>  #>  log-likelihood   n df       BIC       ICL #>        -215.726 150 26 -561.7285 -561.7289 #>  #> Mixing probabilities: #>         1         2  #> 0.3333319 0.6666681  #>  #> Means: #>                   [,1]     [,2] #> Sepal.Length 5.0060022 6.261996 #> Sepal.Width  3.4280049 2.871999 #> Petal.Length 1.4620007 4.905992 #> Petal.Width  0.2459998 1.675997 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length   0.15065114  0.13080115   0.02084463  0.01309107 #> Sepal.Width    0.13080115  0.17604529   0.01603245  0.01221458 #> Petal.Length   0.02084463  0.01603245   0.02808260  0.00601568 #> Petal.Width    0.01309107  0.01221458   0.00601568  0.01042365 #> [,,2] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length    0.4000438  0.10865444    0.3994018  0.14368256 #> Sepal.Width     0.1086544  0.10928077    0.1238904  0.07284384 #> Petal.Length    0.3994018  0.12389040    0.6109024  0.25738990 #> Petal.Width     0.1436826  0.07284384    0.2573899  0.16808182  mod2 = densityMclust(faithful, plot = FALSE) summary(mod2) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 summary(mod2, parameters = TRUE) #> -------------------------------------------------------  #> Density estimation via Gaussian finite mixture modeling  #> -------------------------------------------------------  #>  #> Mclust EEE (ellipsoidal, equal volume, shape and orientation) model with 3 #> components:  #>  #>  log-likelihood   n df       BIC       ICL #>       -1126.326 272 11 -2314.316 -2357.824 #>  #> Mixing probabilities: #>         1         2         3  #> 0.1656784 0.3563696 0.4779520  #>  #> Means: #>                [,1]      [,2]      [,3] #> eruptions  3.793066  2.037596  4.463245 #> waiting   77.521051 54.491158 80.833439 #>  #> Variances: #> [,,1] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,2] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 #> [,,3] #>            eruptions    waiting #> eruptions 0.07825448  0.4801979 #> waiting   0.48019785 33.7671464 # }"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustBootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","title":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","text":"Summary bootstrap distribution parameters Gaussian mixture model providing either standard errors percentile bootstrap confidence intervals.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustBootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","text":"","code":"# S3 method for MclustBootstrap summary(object, what = c(\"se\", \"ci\", \"ave\"), conf.level = 0.95, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustBootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","text":"object object class 'MclustBootstrap' returned MclustBootstrap. character string: \"se\" standard errors; \"ci\" confidence intervals; \"ave\" averages. conf.level value specifying confidence level interval. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustBootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","text":"details procedure used obtain bootstrap distribution see MclustBootstrap.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustBootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models — summary.MclustBootstrap","text":"","code":"# \\donttest{ data(diabetes) X = diabetes[,-1] modClust = Mclust(X)  bootClust = MclustBootstrap(modClust) summary(bootClust, what = \"se\") #> ----------------------------------------------------------  #> Resampling standard errors  #> ----------------------------------------------------------  #> Model                      = VVV  #> Num. of mixture components = 3  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #>  #> Mixing probabilities: #>          1          2          3  #> 0.05210496 0.05155741 0.03545805  #>  #> Means: #>                1         2        3 #> glucose 1.070074  3.353236 16.70234 #> insulin 7.654479 29.167339 65.28345 #> sspg    7.943500 30.289487 10.18746 #>  #> Variances: #> [,,1] #>          glucose   insulin     sspg #> glucose 11.39138  51.76311  51.5165 #> insulin 51.76311 502.02447 414.8644 #> sspg    51.51650 414.86443 617.9167 #> [,,2] #>           glucose   insulin      sspg #> glucose  63.29427  593.7961  432.7412 #> insulin 593.79612 7049.6150 3150.0699 #> sspg    432.74125 3150.0699 6801.4543 #> [,,3] #>           glucose   insulin      sspg #> glucose  993.9233  4144.973  651.1016 #> insulin 4144.9732 19270.113 2536.4339 #> sspg     651.1016  2536.434  498.3846 summary(bootClust, what = \"ci\") #> ----------------------------------------------------------  #> Resampling confidence intervals  #> ----------------------------------------------------------  #> Model                      = VVV  #> Num. of mixture components = 3  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #> Confidence level           = 0.95  #>  #> Mixing probabilities: #>               1         2         3 #> 2.5%  0.4451799 0.1528780 0.1310645 #> 97.5% 0.6510670 0.3618433 0.2684017 #>  #> Means: #> [,,1] #>        glucose  insulin     sspg #> 2.5%  88.98891 344.5995 150.2140 #> 97.5% 93.29347 375.8905 182.7606 #> [,,2] #>         glucose  insulin     sspg #> 2.5%   98.94606 449.8111 259.3504 #> 97.5% 112.18129 558.6397 376.0680 #> [,,3] #>        glucose   insulin      sspg #> 2.5%  199.1914  974.9909  61.89196 #> 97.5% 261.4618 1221.5805 101.83928 #>  #> Variances: #> [,,1] #>        glucose  insulin     sspg #> 2.5%  36.99433 1264.169 1509.538 #> 97.5% 81.13360 3232.756 4056.550 #> [,,2] #>         glucose   insulin     sspg #> 2.5%   88.93158  3685.515 12442.53 #> 97.5% 341.33485 29834.214 38919.10 #> [,,3] #>        glucose   insulin     sspg #> 2.5%  3392.779  46908.82 1347.520 #> 97.5% 7184.775 120836.47 3204.012  data(acidity) modDens = densityMclust(acidity, plot = FALSE) modDens = MclustBootstrap(modDens) summary(modDens, what = \"se\") #> ----------------------------------------------------------  #> Resampling standard errors  #> ----------------------------------------------------------  #> Model                      = E  #> Num. of mixture components = 2  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #>  #> Mixing probabilities: #>          1          2  #> 0.03982776 0.03982776  #>  #> Means: #>          1          2  #> 0.04577321 0.06884369  #>  #> Variances: #>          1          2  #> 0.02352405 0.02352405  summary(modDens, what = \"ci\") #> ----------------------------------------------------------  #> Resampling confidence intervals  #> ----------------------------------------------------------  #> Model                      = E  #> Num. of mixture components = 2  #> Replications               = 999  #> Type                       = nonparametric bootstrap  #> Confidence level           = 0.95  #>  #> Mixing probabilities: #>               1         2 #> 2.5%  0.5385733 0.2998957 #> 97.5% 0.7001043 0.4614267 #>  #> Means: #>              1        2 #> 2.5%  4.285412 6.185831 #> 97.5% 4.457428 6.449197 #>  #> Variances: #>               1         2 #> 2.5%  0.1408696 0.1408696 #> 97.5% 0.2322213 0.2322213 # }"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"Summary method class \"MclustDA\".","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"","code":"# S3 method for MclustDA summary(object, parameters = FALSE, newdata, newclass, ...) # S3 method for summary.MclustDA print(x, digits = getOption(\"digits\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"object object class 'MclustDA' resulting call MclustDA. x object class 'summary.MclustDA', usually, result call summary.MclustDA. parameters Logical; TRUE, parameters mixture components printed. newdata data frame matrix giving test data. newclass vector giving class labels observations      test data. digits number significant digits use printing. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"function summary.MclustDA computes returns list summary statistics estimated MclustDA EDDA model classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing discriminant analysis based on Gaussian finite mixture modeling — summary.MclustDA","text":"","code":"mod = MclustDA(data = iris[,1:4], class = iris$Species) summary(mod) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -172.8135 150 47 -581.1269 #>              #> Classes       n     % Model G #>   setosa     50 33.33   EEE 2 #>   versicolor 50 33.33   XXX 1 #>   virginica  50 33.33   XXX 1 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         50          0         0 #>   versicolor      0         48         2 #>   virginica       0          1        49 #> Classification error = 0.02  #> Brier score          = 0.0116  summary(mod, parameters = TRUE) #> ------------------------------------------------  #> Gaussian finite mixture model for classification  #> ------------------------------------------------  #>  #> MclustDA model summary:  #>  #>  log-likelihood   n df       BIC #>       -172.8135 150 47 -581.1269 #>              #> Classes       n     % Model G #>   setosa     50 33.33   EEE 2 #>   versicolor 50 33.33   XXX 1 #>   virginica  50 33.33   XXX 1 #>  #> Class prior probabilities: #>     setosa versicolor  virginica  #>  0.3333333  0.3333333  0.3333333  #>  #> Class = setosa #>  #> Mixing probabilities: 0.8081091 0.1918909  #>  #> Means: #>                   [,1]      [,2] #> Sepal.Length 4.9484622 5.2483085 #> Sepal.Width  3.3627745 3.7026840 #> Petal.Length 1.4322810 1.5871556 #> Petal.Width  0.2036194 0.4244774 #>  #> Variances: #> [,,1] #>               Sepal.Length  Sepal.Width Petal.Length   Petal.Width #> Sepal.Length  0.1078221133  0.081427298 0.0088268249 -0.0001451869 #> Sepal.Width   0.0814272976  0.122899586 0.0033006551 -0.0025292826 #> Petal.Length  0.0088268249  0.003300655 0.0258364946  0.0006438246 #> Petal.Width  -0.0001451869 -0.002529283 0.0006438246  0.0033200166 #> [,,2] #>               Sepal.Length  Sepal.Width Petal.Length   Petal.Width #> Sepal.Length  0.1078221133  0.081427298 0.0088268249 -0.0001451869 #> Sepal.Width   0.0814272976  0.122899586 0.0033006551 -0.0025292826 #> Petal.Length  0.0088268249  0.003300655 0.0258364946  0.0006438246 #> Petal.Width  -0.0001451869 -0.002529283 0.0006438246  0.0033200166 #>  #> Class = versicolor #>  #> Mixing probabilities: 1  #>  #> Means: #>               [,1] #> Sepal.Length 5.936 #> Sepal.Width  2.770 #> Petal.Length 4.260 #> Petal.Width  1.326 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.261104     0.08348      0.17924    0.054664 #> Sepal.Width      0.083480     0.09650      0.08100    0.040380 #> Petal.Length     0.179240     0.08100      0.21640    0.071640 #> Petal.Width      0.054664     0.04038      0.07164    0.038324 #>  #> Class = virginica #>  #> Mixing probabilities: 1  #>  #> Means: #>               [,1] #> Sepal.Length 6.588 #> Sepal.Width  2.974 #> Petal.Length 5.552 #> Petal.Width  2.026 #>  #> Variances: #> [,,1] #>              Sepal.Length Sepal.Width Petal.Length Petal.Width #> Sepal.Length     0.396256    0.091888     0.297224    0.048112 #> Sepal.Width      0.091888    0.101924     0.069952    0.046676 #> Petal.Length     0.297224    0.069952     0.298496    0.047848 #> Petal.Width      0.048112    0.046676     0.047848    0.073924 #>  #> Training confusion matrix: #>             Predicted #> Class        setosa versicolor virginica #>   setosa         50          0         0 #>   versicolor      0         48         2 #>   virginica       0          1        49 #> Classification error = 0.02  #> Brier score          = 0.0116"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing dimension reduction method for model-based clustering and classification — summary.MclustDR","title":"Summarizing dimension reduction method for model-based clustering and classification — summary.MclustDR","text":"Summary method class \"MclustDR\".","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing dimension reduction method for model-based clustering and classification — summary.MclustDR","text":"","code":"# S3 method for MclustDR summary(object, numdir, std = FALSE, ...) # S3 method for summary.MclustDR print(x, digits = max(5, getOption(\"digits\") - 3), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing dimension reduction method for model-based clustering and classification — summary.MclustDR","text":"object object class 'MclustDR' resulting call MclustDR. x object class 'summary.MclustDR', usually, result call summary.MclustDR. numdir integer providing number basis directions printed. std TRUE coefficients basis scaled              predictors unit standard deviation. digits number significant digits use printing. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing dimension reduction method for model-based clustering and classification — summary.MclustDR","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustSSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","title":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","text":"Summary method class \"MclustSSC\".","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustSSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","text":"","code":"# S3 method for MclustSSC summary(object, parameters = FALSE, ...) # S3 method for summary.MclustSSC print(x, digits = getOption(\"digits\"), ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustSSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","text":"object object class 'MclustSSC' resulting call MclustSSC. x object class 'summary.MclustSSC', usually, result call summary.MclustSSC. parameters Logical; TRUE, parameters mixture components printed. digits number significant digits use printing. ... arguments passed methods.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustSSC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","text":"function summary.MclustSSC computes returns list summary statistics estimated MclustSSC model semi-supervised classification.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.MclustSSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing semi-supervised classification model based on Gaussian finite mixtures — summary.MclustSSC","text":"Luca Scrucca","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.mclustBIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for model-based clustering via BIC — summary.mclustBIC","title":"Summary function for model-based clustering via BIC — summary.mclustBIC","text":"Optimal model characteristics classification model-based   clustering via mclustBIC.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.mclustBIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for model-based clustering via BIC — summary.mclustBIC","text":"","code":"# S3 method for mclustBIC summary(object, data, G, modelNames, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/summary.mclustBIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for model-based clustering via BIC — summary.mclustBIC","text":"object 'mclustBIC' object,      result applying mclustBIC      data. data matrix vector observations used generate `object'. G vector integers giving numbers mixture components (clusters)     best model according BIC selected    (.character(G) must subset row names      object).     default select best model numbers     mixture components used obtain object. modelNames vector integers giving model parameterizations     best model according BIC selected    (.character(model) must subset column names      object).     default select best model parameterizations     used obtain object. ... used. generic/method consistency.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/summary.mclustBIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary function for model-based clustering via BIC — summary.mclustBIC","text":"list giving optimal (according BIC) parameters,   conditional probabilities z, log-likelihood,   together associated classification uncertainty. details output components follows: modelName character string denoting model corresponding optimal BIC. n number observations data. d dimension data. G number mixture components model corresponding optimal     BIC. bic optimal BIC value. loglik log-likelihood corresponding optimal BIC. parameters list following components: pro vector whose kth component mixing proportion               kth component mixture model.               missing, equal proportions assumed. mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  z matrix whose [,k]th entry probability observation     data belongs kth class. classification map(z): classification corresponding z. uncertainty uncertainty associated classification. Attributes: \"bestBICvalues\" best bic values analysis.\"prior\" prior specified input.\"control\" control parameters EM specified        input.\"initialization\" parameters used initial EM        computing maximum likelihood values used obtain BIC.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/summary.mclustBIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for model-based clustering via BIC — summary.mclustBIC","text":"","code":"irisBIC <- mclustBIC(iris[,-5]) summary(irisBIC, iris[,-5]) #> Best BIC values: #>              VEV,2        VEV,3      VVV,2 #> BIC      -561.7285 -562.5522369 -574.01783 #> BIC diff    0.0000   -0.8237748  -12.28937 #>  #> Classification table for model (VEV,2):  #>  #>   1   2  #>  50 100  summary(irisBIC, iris[,-5], G = 1:6, modelNames = c(\"VII\", \"VVI\", \"VVV\")) #> Best BIC values: #>              VVV,2       VVV,3      VVV,4 #> BIC      -574.0178 -580.839630 -630.59996 #> BIC diff    0.0000   -6.821798  -56.58213 #>  #> Classification table for model (VVV,2):  #>  #>   1   2  #>  50 100"},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Density or uncertainty surface for bivariate mixtures — surfacePlot","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"Plots density uncertainty surface given bivariate data parameters  MVN mixture model data.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"","code":"surfacePlot(data, parameters,              what = c(\"density\", \"uncertainty\"),              type = c(\"contour\", \"hdr\", \"image\", \"persp\"),              transformation = c(\"none\", \"log\", \"sqrt\"),                       grid = 200, nlevels = 11, levels = NULL,              prob = c(0.25, 0.5, 0.75),             col = gray(0.5),             col.palette = function(...) hcl.colors(..., \"blues\", rev = TRUE),             hdr.palette = blue2grey.colors,             xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,              main = FALSE, scale = FALSE, swapAxes = FALSE,              verbose = FALSE, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"data matrix, data frame bivariate observations.     Categorical variables allowed.     matrix data frame, rows correspond observations     columns correspond variables. parameters named list giving parameters MCLUST model,       used produce superimposing ellipses plot.       relevant components follows: mean mean component. one component,               matrix whose kth column mean kth               component mixture model. variance list variance parameters model.               components list depend model               specification. See help file mclustVariance               details.  Choose one following options: \"density\"     (default), \"uncertainty\" indicating plot. type Choose one following three options: \"contour\"      (default), \"hdr\", \"image\", \"persp\" indicating      plot type. transformation Choose one following three options: \"none\"     (default), \"log\", \"sqrt\" indicating transformation     applied plotting. grid number grid points (evenly spaced axis).      mixture density uncertainty computed      grid x grid points produce surface plot.     Default: 100. nlevels number levels use contour plot.     Default: 11. levels vector levels draw lines contour plot. prob vector probability levels computing HDR.      used type = \"hdr\" supersede previous      nlevels levels arguments. col string specifying colour used type = \"contour\"      type = \"persp\" plots. col.palette function defines palette colours used      type = \"image\" plots. hdr.palette function defines palette colours used      type = \"hdr\" plots. xlim, ylim Optional argument specifying bounds ordinate, abscissa plot.     may useful comparing plots. xlab, ylab Optional argument specifying labels x-axis y-axis. main logical variable NULL indicating whether add title      plot identifying dimensions used. scale logical variable indicating whether two     dimensions plotted scale,     thus preserve shape distribution.     default scale. swapAxes logical variable indicating whether axes swapped     plot. verbose logical variable telling whether print indication     function process computing values grid points,     typically takes time complete. ... graphics parameters.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"plots showing (transformation ) density uncertainty given mixture model data. function also returns invisible list components x,  y, z x y values used  define grid z transformed density uncertainty  grid points.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"image plot, color scheme may need selected display   device order view plot.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/surfacePlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density or uncertainty surface for bivariate mixtures — surfacePlot","text":"","code":"# \\donttest{ faithfulModel <- Mclust(faithful) surfacePlot(faithful, parameters = faithfulModel$parameters,             type = \"contour\", what = \"density\", transformation = \"none\",             drawlabels = FALSE)  surfacePlot(faithful, parameters = faithfulModel$parameters,             type = \"persp\", what = \"density\", transformation = \"log\")  surfacePlot(faithful, parameters = faithfulModel$parameters,             type = \"contour\", what = \"uncertainty\", transformation = \"log\")  # }"},{"path":"https://mclust-org.github.io/mclust/reference/thyroid.html","id":null,"dir":"Reference","previous_headings":"","what":"UCI Thyroid Gland Data — thyroid","title":"UCI Thyroid Gland Data — thyroid","text":"Data five laboratory tests administered sample 215 patients. tests used predict whether patient's thyroid can classified euthyroidism (normal thyroid gland function), hypothyroidism (underactive thyroid producing enough thyroid hormone) hyperthyroidism (overactive thyroid producing secreting excessive amounts free thyroid hormones T3 /thyroxine T4). Diagnosis thyroid operation based complete medical record, including anamnesis, scan, etc.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/thyroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UCI Thyroid Gland Data — thyroid","text":"","code":"data(thyroid)"},{"path":"https://mclust-org.github.io/mclust/reference/thyroid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"UCI Thyroid Gland Data — thyroid","text":"data frame following variables: Diagnosis Diagnosis thyroid operation: Hypo, Normal, Hyper. RT3U T3-resin uptake test (percentage). T4 Total Serum thyroxin measured isotopic displacement method. T3 Total serum triiodothyronine measured radioimmuno assay. TSH Basal thyroid-stimulating hormone (TSH) measured radioimmuno assay. DTSH Maximal absolute difference TSH value injection 200 micro grams thyrotropin-releasing hormone compared basal value.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/thyroid.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"UCI Thyroid Gland Data — thyroid","text":"One several databases Thyroid Disease Data Set (new-thyroid.data, new-thyroid.names) UCI Machine Learning Repository https://archive.ics.uci.edu/ml/datasets/thyroid+disease. Please note UCI conditions use.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/thyroid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"UCI Thyroid Gland Data — thyroid","text":"Coomans, D., Broeckaert, M. Jonckheer M. Massart D.L. (1983) Comparison Multivariate Discriminant Techniques Clinical Data - Application Thyroid Functional State, Meth. Inform. Med. 22, pp. 93-101. Coomans, D. . Broeckaert (1986) Potential Pattern Recognition Cemical Medical Decision Making, Research Studies Press, Letchworth, England.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Uncertainty Plot for Model-Based Clustering — uncerPlot","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"Displays uncertainty converting conditional probablility EM   classification model-based clustering.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"","code":"uncerPlot(z, truth, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"z matrix whose [,k]th entry     conditional probability ith observation belonging     kth component mixture. truth numeric character vector giving true classification data. ... Provided allow lists elements arguments can     passed indirect list calls .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"plot uncertainty profile data,   uncertainties increasing order magnitude.   truth supplied number   classes number columns  z, uncertainty   misclassified data marked vertical lines plot.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"truth provided number classes compatible   z, function compareClass used find best   correspondence classes truth z.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/uncerPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uncertainty Plot for Model-Based Clustering — uncerPlot","text":"","code":"irisModel3 <-  Mclust(iris[,-5], G = 3)  uncerPlot(z = irisModel3$z)    uncerPlot(z = irisModel3$z, truth = iris[,5])"},{"path":"https://mclust-org.github.io/mclust/reference/unmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Indicator Variables given Classification — unmap","title":"Indicator Variables given Classification — unmap","text":"Converts classification matrix indicator variables.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/unmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Indicator Variables given Classification — unmap","text":"","code":"unmap(classification, groups=NULL, noise=NULL, ...)"},{"path":"https://mclust-org.github.io/mclust/reference/unmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Indicator Variables given Classification — unmap","text":"classification numeric character vector. Typically distinct entries     vector represent classification observations data set. groups numeric character vector indicating groups     classification drawn. supplied, default     assumed unique entries classification. noise single numeric character value used indicate value     groups corresponding noise. ... Catches unused arguments indirect list calls via .call.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/unmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Indicator Variables given Classification — unmap","text":"n m matrix (0,1) indicator variables,   n length classification m   number unique values symbols  classification.    Columns labeled unique values classification,    [,j]th entry 1 classification[] jth unique value symbol sorted order  classification.    noise value symbol designated, corresponding indicator    variables relocated last column matrix.","code":""},{"path":[]},{"path":"https://mclust-org.github.io/mclust/reference/unmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Indicator Variables given Classification — unmap","text":"","code":"z <- unmap(iris[,5]) z[1:5, ] #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    1    0    0 #> [3,]    1    0    0 #> [4,]    1    0    0 #> [5,]    1    0    0    emEst <- me(modelName = \"VVV\", data = iris[,-5], z = z) emEst$z[1:5,] #>      [,1]         [,2]         [,3] #> [1,]    1 1.340380e-44 1.861339e-34 #> [2,]    1 2.201405e-31 6.676298e-28 #> [3,]    1 1.896748e-36 1.102178e-29 #> [4,]    1 3.488647e-32 6.409600e-26 #> [5,]    1 4.393475e-47 7.745885e-35    map(emEst$z) #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 2 #>  [75] 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 #> [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [149] 3 3"},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":null,"dir":"Reference","previous_headings":"","what":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"data set provides data 569 patients 30 features cell nuclei obtained digitized image fine needle aspirate (FNA) breast mass. patient cancer diagnosed malignant benign.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"","code":"data(wdbc)"},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"data frame 569 observations following variables: ID ID number Diagnosis cancer diagnosis: M = malignant, B = benign Radius_mean numeric vector Texture_mean numeric vector Perimeter_mean numeric vector Area_mean numeric vector Smoothness_mean numeric vector Compactness_mean numeric vector Concavity_mean numeric vector Nconcave_mean numeric vector Symmetry_mean numeric vector Fractaldim_mean numeric vector Radius_se numeric vector Texture_se numeric vector Perimeter_se numeric vector Area_se numeric vector Smoothness_se numeric vector Compactness_se numeric vector Concavity_se numeric vector Nconcave_se numeric vector Symmetry_se numeric vector Fractaldim_se numeric vector Radius_extreme numeric vector Texture_extreme numeric vector Perimeter_extreme numeric vector Area_extreme numeric vector Smoothness_extreme numeric vector Compactness_extreme numeric vector Concavity_extreme numeric vector Nconcave_extreme numeric vector Symmetry_extreme numeric vector Fractaldim_extreme numeric vector","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"recorded features : Radius mean distances center points perimeter Texture standard deviation gray-scale values Perimeter cell nucleus perimeter Area cell nucleus area Smoothness local variation radius lengths Compactness cell nucleus compactness, perimeter^2 / area - 1 Concavity severity concave portions contour Nconcave number concave portions contour Symmetry cell nucleus shape Fractaldim fractal dimension, \"coastline approximation\" - 1 feature recorded values computed image <feature_name>_mean, <feature_name>_se, <feature_name>_extreme, mean, standard error, mean three largest values.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"Breast Cancer Wisconsin (Diagnostic) Data Set (wdbc.data, wdbc.names) UCI Machine Learning Repository https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic). Please note UCI conditions use.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wdbc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"UCI Wisconsin Diagnostic Breast Cancer Data — wdbc","text":"Mangasarian, O. L., Street, W. N., Wolberg, W. H. (1995) Breast cancer diagnosis prognosis via linear programming. Operations Research, 43(4), pp. 570-577.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wreath.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Simulated from a 14-Component Mixture — wreath","title":"Data Simulated from a 14-Component Mixture — wreath","text":"dataset consisting 1000 observations drawn 14-component  normal mixture covariances components size shape differ orientation.","code":""},{"path":"https://mclust-org.github.io/mclust/reference/wreath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data Simulated from a 14-Component Mixture — wreath","text":"","code":"data(wreath)"},{"path":"https://mclust-org.github.io/mclust/reference/wreath.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data Simulated from a 14-Component Mixture — wreath","text":"C. Fraley,  . E. Raftery R. Wehrens (2005).   Incremental model-based clustering large datasets small clusters.   Journal Computational Graphical Statistics 14:1:18.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-61","dir":"Changelog","previous_headings":"","what":"mclust 6.1","title":"mclust 6.1","text":"CRAN release: 2024-02-23 Added logsumexp() softmax() functions wrapper efficiently implementations written Fortran code. Substituted R code several parts package Fortran-based functions compute densities posterior probabilities Gaussian mixtures. Changes .weighted() use convergence criterion mclust functions improved efficiency using mentioned Fortran-based functions. also brings computational improvements weighted likelihood bootstrap implemented MclustBootstrap(..., type = \"wlbs\"). Bug fix MclustDA() number obs less number vars. Bug fix MclustBootstrap(object, ..., type = \"pb\") object class densityMclust.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-601","dir":"Changelog","previous_headings":"","what":"mclust 6.0.1","title":"mclust 6.0.1","text":"CRAN release: 2023-11-15 Changed initialization MclustSSC() components unlabeled data via k-means. Corrected output summary.MclustSCC() components unlabeled data. Updated citation info reference book published Chapman & Hall/CRC","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-600","dir":"Changelog","previous_headings":"","what":"mclust 6.0.0","title":"mclust 6.0.0","text":"CRAN release: 2022-10-31 Major release mclust accompanying upcoming book Chapman & Hall/CRC.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-5411-not-on-cran","dir":"Changelog","previous_headings":"","what":"mclust 5.4.11 (NOT ON CRAN)","title":"mclust 5.4.11 (NOT ON CRAN)","text":"Added summary.crimcoords() method removed argument plot crimcoords() function call.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-5410","dir":"Changelog","previous_headings":"","what":"mclust 5.4.10","title":"mclust 5.4.10","text":"CRAN release: 2022-05-20 Updated banner startup. Updated info man page datasets diabetes, wdbc, thyroid. Std. error cross-validation cvMclustDA() uses formula weighted standard deviation weights given folds size. Fix .Rd files.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-549","dir":"Changelog","previous_headings":"","what":"mclust 5.4.9","title":"mclust 5.4.9","text":"CRAN release: 2021-12-17 Added crimcoords() compute discriminant coordinates crimcoords. Fixed man page cvMclustDA().","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-548","dir":"Changelog","previous_headings":"","what":"mclust 5.4.8","title":"mclust 5.4.8","text":"CRAN release: 2021-11-05 densityMclust() default draw graph density estimate. Fixed bug computing mixture density noise component present. Changed default behaviour hc() called perform agglomerative hierarchical clustering instead using EM initialization. default mclust.options(\"hcModelName\") now returns model used. Changed default partition argument hc() function adding dupPartion() remove data duplicates. Added checks mclustBootstrapLRT() stop invalid modelName provided one-component mixture model provided. Extended functionality cvMclustDA() including cross-validated metrics classification error Brier score. Updated info dataset man pages.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-547","dir":"Changelog","previous_headings":"","what":"mclust 5.4.7","title":"mclust 5.4.7","text":"CRAN release: 2020-11-20 Updated plot method (dendrogram) hierarchical clustering — now based classification likelihood. Added MclustSSC() function (related print, summary, plot, predict, methods) semi-supervised classification. Exchanged order models VEE EVE account increasing complexity EVE. Added cex argument clPairs() control character expansion used plotting symbols. em() () now data first argument.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-546","dir":"Changelog","previous_headings":"","what":"mclust 5.4.6","title":"mclust 5.4.6","text":"CRAN release: 2020-04-11 Fixed issues source Fortran code gfortran 10 reported CRAN. Clean code hcCriterion(). Replaced CEX argument functions standard base graph cex argument. Removed ylim argument function; can passed via .... MclustDA models use default SVD transformation data initialization EM algorithm. Added icl criterion object returned Mclust(). Fixed number pages RJ reference. quantileMclust() uses bisection line search method numerically computing quantiles.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-545","dir":"Changelog","previous_headings":"","what":"mclust 5.4.5","title":"mclust 5.4.5","text":"CRAN release: 2019-07-08 Fixed warnings Fortran calls raised CRAN.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-544","dir":"Changelog","previous_headings":"","what":"mclust 5.4.4","title":"mclust 5.4.4","text":"CRAN release: 2019-06-27 Added classPriorProbs() estimate prior class probabilities. Added BrierScore() compute Brier score assessing accuracy probabilistic predictions. Added randomOrthogonalMatrix() generate random orthogonal basis matrices. Partial rewriting summary.MclustDA() internals provide classification error Brier score training /test data. Partial rewriting plot.MclustDA() internals. Added dmvnorm() computing density general multivariate Gaussian distribution via efficient Fortran code. Added Wisconsin diagnostic breast cancer (WDBC) data. Added EuroUnemployment data. Fixed mismatches Fortran calls. Bugs fix.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-543","dir":"Changelog","previous_headings":"","what":"mclust 5.4.3","title":"mclust 5.4.3","text":"CRAN release: 2019-03-14 Added website site update DESCRIPTION URL. Fixed bug checking univariate data single observation several instances. Using NCOL() works n-values vector nx1 matrix. Fixed bug hcPairs provided initialization argument mclustBIC() (relatives) number observations exceed threshold subsetting. Fixed bugs axes manual pairs plots. Renamed type = \"level\" type = \"hdr\", level.prob prob, surfacePlot() getting HDRs graphs Fixed bug type = \"hdr\" plot surfacePlot(). Fixed bug .Mclust(). Small changes summary.MclustDA() modelType = \"EDDA\" general compact output.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-542","dir":"Changelog","previous_headings":"","what":"mclust 5.4.2","title":"mclust 5.4.2","text":"CRAN release: 2018-11-17 Added mclustBICupdate() merge best values two BIC results returned mclustBIC(). Added mclustLoglik() compute maximal log-likelihood values BIC results returned mclustBIC(). Added option type = \"level\" plot.densityMclust() surfacePlot() draw highest density regions. Added meXXI() meXXX() exported functions. Updated vignette.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-541","dir":"Changelog","previous_headings":"","what":"mclust 5.4.1","title":"mclust 5.4.1","text":"CRAN release: 2018-06-27 Added parametric bootstrap option (type = \"pb\") MclustBootstrap(). Added options get averages resampling distributions summary.MclustBootstrap() plot resampling-based confidence intervals plot.MclustBootstrap(). Added function catwrap() wrapping printed lines getOption(\"width\") using cat(). mclust.options() now modify variable .mclust namespace package, work even inside mclust-function call. Fixed bug covw() normalize = TRUE. Fixed bug estepVEV() estepVEE() parameters contains Vinv. Fixed bug plotDensityMclustd() drawing marginal axes. Fixed bug summary.MclustDA() computing classification error extreme case minor class assignment. Fixed bug initialisation mclustBIC() noise component present 1-dimensional data. Fixed bugs examples documenting clustCombi() related functions.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-54","dir":"Changelog","previous_headings":"","what":"mclust 5.4","title":"mclust 5.4","text":"CRAN release: 2017-11-22 Model-based hierarchical clustering used start EM-algorithm now based scaled SVD transformation proposed Scrucca Raftery (2016). change backward compatible. However, previous results can easily obtained issuing command: mclust.options(hcUse = \"VARS\") details see help(\"mclust.options\"). Added subset parameter mclust.options() control maximal sample size used initial model-based hierarchical phase. predict.densityMclust() can optionally returns density logarithm scale. Removed normalization mixing proportions new models single mstep. Internal rewrite code used packageStartupMessage(). Fixed small bug MclustBootstrap() univariate data case. Fixed bugs noise subset provided initialization. Vignette updated include references, startup message, css style, etc. Various bug fixes plotting methods noise present. Updated references citation() man pages.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-53-2017-05","dir":"Changelog","previous_headings":"","what":"mclust 5.3 (2017-05)","title":"mclust 5.3 (2017-05)","text":"CRAN release: 2017-05-21 Added gmmhd() function relative methods. Added MclustDRsubsel() function relative methods. Added option use subset hierarchical initialization step noise component present. plot.clustCombi() presents menu interactive sessions, need data classification plots extract data clustCombi object. Added combiTree() plot clustCombi objects. clPairs() now produces single scatterplot bivariate case. Fixed bug imputeData() seed provided. Now seed provided data matrix reproducible. imputeData() imputePairs() name arguments modified coherent rest package. Added functions matchCluster() majorityVote(). Rewrite print summary methods clustCombi class objects. Added clustCombiOptim(). Fixed bug randomPairs() nrow input data odd. Fixed bug plotDensityMclust2(), plotDensityMclustd() surfacePlot() noise component present.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-523-2017-03","dir":"Changelog","previous_headings":"","what":"mclust 5.2.3 (2017-03)","title":"mclust 5.2.3 (2017-03)","text":"CRAN release: 2017-03-13 Added native routine registration Fortran code. Fixed lowercase argument PACKAGE .Fortran() calls.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-522-2017-01","dir":"Changelog","previous_headings":"","what":"mclust 5.2.2 (2017-01)","title":"mclust 5.2.2 (2017-01)","text":"CRAN release: 2017-01-22 Fixed bug rare case performing extra M step end EM algorithm.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-521-2017-01","dir":"Changelog","previous_headings":"","what":"mclust 5.2.1 (2017-01)","title":"mclust 5.2.1 (2017-01)","text":"CRAN release: 2017-01-03 Replaced structure(NULL, *) structure(list(), *)","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-52-2016-03","dir":"Changelog","previous_headings":"","what":"mclust 5.2 (2016-03)","title":"mclust 5.2 (2016-03)","text":"CRAN release: 2016-03-31 Added argument x Mclust() use BIC values previous computations avoid recomputing models. argument functionality already available mclustBIC(). Added argument x mclustICL() use ICL values previous computations avoid recomputing models. Fixed bug plot.MclustBootstrap() \"mean\" \"var\" univariate case. Fixed uncertainty plots. Added functions .Mclust() .densityMclust() convert object specific mclust classes. Solved numerical accuracy problem qclass() scale x () large making tolerance eps scale dependent. Use transpose subroutine instead non-Fortran 77 TRANSPOSE function mclustaddson.f. Fixed predict.Mclust() predict.MclustDR() implementing efficient accurate algorithm computing densities.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-51-2015-10","dir":"Changelog","previous_headings":"","what":"mclust 5.1 (2015-10)","title":"mclust 5.1 (2015-10)","text":"CRAN release: 2015-10-27 Fixed slow convergence VVE EVE models. Fixed bug orientation model VEE. Added extra M-step parameters update Mclust() call via summaryMclustBIC().","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-502-2015-07","dir":"Changelog","previous_headings":"","what":"mclust 5.0.2 (2015-07)","title":"mclust 5.0.2 (2015-07)","text":"CRAN release: 2015-07-08 Added option MclustBootstrap() using weighted likelihood bootstrap. Added plot method MclustBootstrap objects. Added errorBars() function. Added clPairsLegend() function. Added covw() function. Fixed rescaling mixing probabilities new models. Bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-501-2015-04","dir":"Changelog","previous_headings":"","what":"mclust 5.0.1 (2015-04)","title":"mclust 5.0.1 (2015-04)","text":"CRAN release: 2015-04-22 Fixed bugs. Added print method hc objects.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-500-2015-03","dir":"Changelog","previous_headings":"","what":"mclust 5.0.0 (2015-03)","title":"mclust 5.0.0 (2015-03)","text":"CRAN release: 2015-04-09 Added four missing models (EVV, VEE, EVE, VVE) mclust family. noise component allowed, prior available. Added mclustBootstrapLRT() function (corresponding print plot methods) selecting number mixture components based sequential bootstrap likelihood ratio test. Added MclustBootstrap() function (corresponding print summary methods) performing bootstrap inference. provides standard errors parameters confidence intervals. Added \"quick tour mclust\" vignette html generated using rmarkdown knitr. Older vignettes included documentation package. Modified arguments mvn2plot() control colour, lty, lwd, pch ellipses mean point. Added functions emX(), emXII(), emXXI(), emXXX(), cdensX(), cdensXII(), cdensXXI(), cdensXXX(), deal single-component cases, calling em function works even G = 1. Small changes icl(), now generic method, specialized methods Mclust MclustDA objects. Fixed bug transformations initialization step variables constant (.e. variance zero) one-dimensional data provided. Changed order arguments hc() (functions calling ). Small modification CITATION file upon request CRAN maintainers. Various bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-44-2014-09","dir":"Changelog","previous_headings":"","what":"mclust 4.4 (2014-09)","title":"mclust 4.4 (2014-09)","text":"CRAN release: 2014-09-16 Added option using transformation variables hierarchical initialization step. Added quantileMclust() computing quantiles univariate Gaussian mixture distribution. Fixed bugs summaryMclustBIC(), summaryMclustBICn(), Mclust() return matrix 1s single column z even case G = 1. avoid error plots. Moved pdf files (previously included vignettes) inst/doc corresponding index.html.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-43-2014-03","dir":"Changelog","previous_headings":"","what":"mclust 4.3 (2014-03)","title":"mclust 4.3 (2014-03)","text":"CRAN release: 2014-03-31 Fixed bug logLik.MclustDA() univariate case. Added argument \"\" predict.densityMclust() function choosing retrieve, mixture density component density. hc() function additional parameter control original variables transformation used hierarchical clustering. Added \"hcUse\" argument mclust.options() passed default hc(). Added storing original data (class classification models) object returned main functions. Added component hypvol Mclust object provide hypervolume noise component required, otherwise set NA. Added warning prior used BIC returns NAs. Fixed bugs summary.Mclust(), print.summary.Mclust(), plot.Mclust() icl() case presence noise component. Fixed bug plots plot.MclustDR() requires plot.new() calling plot.window(). Fixed bug MclustDR() one-dimensional case. Corrections Mclust man page. Various small bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-42-2013-07","dir":"Changelog","previous_headings":"","what":"mclust 4.2 (2013-07)","title":"mclust 4.2 (2013-07)","text":"CRAN release: 2013-07-19 Fixed bug sim*() functions obs assigned component. MclustDA() allows fit single class model. Fixex bug summary.Mclust() subset used initialization. Fixed bug function qclass() ties present quantiles, always return required number classes. Various small bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-41-2013-04","dir":"Changelog","previous_headings":"","what":"mclust 4.1 (2013-04)","title":"mclust 4.1 (2013-04)","text":"CRAN release: 2013-05-01 Added icl() function computing integrated complete-data likelihood. Added mclustICL() function associated print plot methods. print.mclustBIC() shows also top models based BIC. Modified summary.Mclust() return also icl. Rewrite adjustedRandIndex() function. version efficient large vectors. Updated help adjustedRandIndex(). Modifications MclustDR() summary method. Changed behavior plot.MclustDR(..., = \"contour\"). Improved plot uncertainty plot.MclustDR(..., = \"boundaries\"). Corrected bug malformed GvHD data. Corrected version qclass() selecting initial values case 1D data successive quantiles coincide. Corrected version plot BIC values single G-component models fitted. Various bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-40-2012-08","dir":"Changelog","previous_headings":"","what":"mclust 4.0 (2012-08)","title":"mclust 4.0 (2012-08)","text":"CRAN release: 2012-08-09 Added new summary print methods Mclust(). Added new summary print methods densityMclust(). Included MclustDA() function methods. Included MclustDR() function methods. Included .weighted() function. Restored hierarchical clustering capability EEE model (hcEEE). Included vignettes mclust version 4 Technical Report .  597 using weights mclust. Adoption GPL (>= 2) license.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-35-2012-07","dir":"Changelog","previous_headings":"","what":"mclust 3.5 (2012-07)","title":"mclust 3.5 (2012-07)","text":"CRAN release: 2012-07-22 Added summary.Mclust(). New functions plotting summarizing density estimation. Various bug fixes. Added clustCombi() related functions (code doc provided Jean-Patrick Baudry). Bug fix: variable names lost G = 1.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-3411-2012-01","dir":"Changelog","previous_headings":"","what":"mclust 3.4.11 (2012-01)","title":"mclust 3.4.11 (2012-01)","text":"CRAN release: 2012-01-07 Added NAMESPACE.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-3410-2011-05","dir":"Changelog","previous_headings":"","what":"mclust 3.4.10 (2011-05)","title":"mclust 3.4.10 (2011-05)","text":"CRAN release: 2011-05-30 Removed intrinsic gamma-","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-349-2011-05","dir":"Changelog","previous_headings":"","what":"mclust 3.4.9 (2011-05)","title":"mclust 3.4.9 (2011-05)","text":"CRAN release: 2011-05-28 Fixed hypvol() function avoid overflow. Fixed hypvol() help file value description. Removed unused variables tabs source code. Switched intrinsic gamma source code. Fixed default warning estepVEV mstepVEV.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-348-2010-12","dir":"Changelog","previous_headings":"","what":"mclust 3.4.8 (2010-12)","title":"mclust 3.4.8 (2010-12)","text":"CRAN release: 2010-12-12 Fixed output G = 1 (NA missing z component).","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-347-2010-10","dir":"Changelog","previous_headings":"","what":"mclust 3.4.7 (2010-10)","title":"mclust 3.4.7 (2010-10)","text":"CRAN release: 2010-10-23 Removed hierarchical clustering capability EEE model (hcEEE). R 2.12.0 build failed due 32-bit Windows compiler error, forcing removal underlying Fortran code hcEEE package, contain errors compiles platforms.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-346-2010-08","dir":"Changelog","previous_headings":"","what":"mclust 3.4.6 (2010-08)","title":"mclust 3.4.6 (2010-08)","text":"CRAN release: 2010-08-10 Added description parameters output component Mclust summary.mclustBIC help files.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-345-2010-07","dir":"Changelog","previous_headings":"","what":"mclust 3.4.5 (2010-07)","title":"mclust 3.4.5 (2010-07)","text":"CRAN release: 2010-07-24 Added densityMclust() function.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-344-2010-04","dir":"Changelog","previous_headings":"","what":"mclust 3.4.4 (2010-04)","title":"mclust 3.4.4 (2010-04)","text":"CRAN release: 2010-04-08 Fixed bug covariance matrix output EEV VEV models.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-343-2010-02","dir":"Changelog","previous_headings":"","what":"mclust 3.4.3 (2010-02)","title":"mclust 3.4.3 (2010-02)","text":"CRAN release: 2010-02-20 Bug fixes.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-342-2010-02","dir":"Changelog","previous_headings":"","what":"mclust 3.4.2 (2010-02)","title":"mclust 3.4.2 (2010-02)","text":"CRAN release: 2010-02-13 Moved CITATION inst used standard format BibTex entries inst/cite. Fixed bug handling missing classes mclustBIC(). Clarified license wording.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-341-2010-01","dir":"Changelog","previous_headings":"","what":"mclust 3.4.1 (2010-01)","title":"mclust 3.4.1 (2010-01)","text":"CRAN release: 2010-01-22 Corrected output description mclustModel help file. Updated mclust manual reference show revision.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-34-2009-12","dir":"Changelog","previous_headings":"","what":"mclust 3.4 (2009-12)","title":"mclust 3.4 (2009-12)","text":"CRAN release: 2009-12-16 Updated defaultPrior help file. Added utility functions imputing missing data mix package. Changed default max number mixture components class 9 3.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-332-2009-10","dir":"Changelog","previous_headings":"","what":"mclust 3.3.2 (2009-10)","title":"mclust 3.3.2 (2009-10)","text":"CRAN release: 2009-10-13 Fixed problems mclustOptions help file","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-331-2009-06","dir":"Changelog","previous_headings":"","what":"mclust 3.3.1 (2009-06)","title":"mclust 3.3.1 (2009-06)","text":"CRAN release: 2009-07-01 Fixed plot.mclustBIC() plot.Mclust() handle modelNames. Changed “orientation” VEV, VVV models consistent R eigen() literature Fixed problems including doc noise option. Updated unmap() function optionally include missing groups.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-33-2009-06","dir":"Changelog","previous_headings":"","what":"mclust 3.3 (2009-06)","title":"mclust 3.3 (2009-06)","text":"Fixed bug \"errors\" option randProj(). Fixed boundary cases \"noise\" option.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-32-2009-04","dir":"Changelog","previous_headings":"","what":"mclust 3.2 (2009-04)","title":"mclust 3.2 (2009-04)","text":"CRAN release: 2009-04-29 Added permission CRAN distribution LICENSE. Fixed problems help files found new parser. Changed PKG_LIBS order src/Makevars. Fixed Mclust() handle sampling data expression call.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-3110-2008-11","dir":"Changelog","previous_headings":"","what":"mclust 3.1.10 (2008-11)","title":"mclust 3.1.10 (2008-11)","text":"Added EXPR = switch functions didn’t already .","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-319-2008-10","dir":"Changelog","previous_headings":"","what":"mclust 3.1.9 (2008-10)","title":"mclust 3.1.9 (2008-10)","text":"Added pro component parameters dens() help file. Fixed problems noise option.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-311-2007-03","dir":"Changelog","previous_headings":"","what":"mclust 3.1.1 (2007-03)","title":"mclust 3.1.1 (2007-03)","text":"Default seed changed sim*() functions. Added model name check various functions. Otherwise backward compatible version 3.0","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-31-2007-01","dir":"Changelog","previous_headings":"","what":"mclust 3.1 (2007-01)","title":"mclust 3.1 (2007-01)","text":"plotting functions changed use color. Mclust() mclustBIC() fixed work G=1 Otherwise backward compatible version 3.0.","code":""},{"path":"https://mclust-org.github.io/mclust/news/index.html","id":"mclust-30-2006-10","dir":"Changelog","previous_headings":"","what":"mclust 3.0 (2006-10)","title":"mclust 3.0 (2006-10)","text":"New functionality added, including conjugate priors Bayesian regularization. Backward compatibility guaranteed since implementation functions changed make easier use maintain.","code":""}]
